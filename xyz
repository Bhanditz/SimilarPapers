http://research.google.com/pubs/papers.html
found
http://research.google.com/pubs/AlgorithmsandTheory.html
found
http://research.google.com/pubs/pub44315.html
found
=========================
Distributed Balanced Partitioning via Linear Embedding
WSDM 2016: Ninth ACM International Conference on Web Search and Data Mining, ACM (to appear)
[u'Kevin Aydin', u'Mohammadhossein Bateni', u'Vahab Mirrokni']
AlgorithmsandTheory
Abstract: Balanced partitioning is often a crucial first step in solving large-scale graph optimization problems: in some cases, a big graph is chopped into pieces that fit on one machine to be processed independently before stitching the results together, leading to certain suboptimality from the interaction among different pieces. In other cases, links between different parts may show up in the running time and/or network communications cost, hence the desire to have small cut size. We study a distributed balanced partitioning problem where the goal is to partition the vertices of a given graph into k pieces, minimizing the total cut size. Our algorithm is composed of a few steps that are easily implementable in distributed computation frameworks, e.g., MapReduce. The algorithm first embeds nodes of the graph onto a line, and then processes nodes in a distributed manner guided by the linear embedding order. We examine various ways to find the first embedding, e.g., via a hierarchical clustering or Hilbert curves. Then we apply four different techniques such as local swaps, minimum cuts on partition boundaries, as well as contraction and dynamic programming. Our empirical study compares the above techniques with each other, and to previous work in distributed algorithms, e.g., a label propagation method [34], FENNEL [32] and Spinner [23]. We report our results both on a private map graph and several public social networks, and show that our results beat previous distributed algorithms: we notice, e.g., 15-25% reduction in cut size over [34]. We also observe that our algorithms allow for scalable distributed implementation for any number of partitions. Finally, we apply our techniques for the Google Maps Driving Directions to minimize the number of multi-shard queries with the goal of saving in CPU usage. During live experiments, we observe an 40% drop in the number of multi-shard queries when comparing our method with a standard geography-based method.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Ego-net Community Mining Applied to Friend Suggestion
Proceedings of VLDB (2016) (to appear)
[u'Alessandro Epasto', u'Silvio Lattanzi', u'Vahab S. Mirrokni', u'Ismail Sebe', u'Ahmed Taei', u'Sunita Verma']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Expander via Local Edge Flips
SODA (2016) (to appear)
[u'Zeyuan Allen-Zhu', u'Aditya Bhaskara', u'Silvio Lattanzi', u'Vahab Mirrokni', u'Lorenzo Orecchia']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43980.html
found
=========================
1ML - core and modules united (F-ing first-class modules)
International Conference on Functional Programming, ACM-SIGPLAN, Vancouver, Canada (2015)
[u'Andreas Rossberg']
AlgorithmsandTheory
Abstract: ML is two languages in one: there is the core, with types and expressions, and there are modules, with signatures, structures and functors. Modules form a separate, higher-order functional language on top of the core. There are both practical and technical reasons for this stratification; yet, it creates substantial duplication in syntax and semantics, and it reduces expressiveness. For example, selecting a module cannot be made a dynamic decision. Language extensions allowing modules to be packaged up as first-class values have been proposed and implemented in different variations. However, they remedy expressiveness only to some extent, are syntactically cumbersome, and do not alleviate redundancy. We propose a redesign of ML in which modules are truly first-class values, and core and module layer are unified into one language. In this "1ML", functions, functors, and even type constructors are one and the same construct; likewise, no distinction is made between structures, records, or tuples. Or viewed the other way round, everything is just ("a mode of use of") modules. Yet, 1ML does not require dependent types, and its type structure is expressible in terms of plain System F, in a minor variation of our F-ing modules approach. We introduce both an explicitly typed version of 1ML, and an extension with Damas/Milner-style implicit quantification. Type inference for this language is not complete, but, we argue, not substantially worse than for Standard ML. An alternative view is that 1ML is a user-friendly surface syntax for System F that allows combining term and type abstraction in a more compositional manner than the bare calculus.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43961.html
found
=========================
A representation theorem for second-order functionals
Journal of Functional Programming, vol. 25 (2015)
[u'Mauro Jaskelioff', u"Russell O'Connor"]
AlgorithmsandTheory
Abstract: Representation theorems relate seemingly complex objects to concrete, more tractable ones. In this paper, we take advantage of the abstraction power of category theory and provide a datatype-generic representation theorem. More precisely, we prove a representation theorem for a wide class of second-order functionals which are polymorphic over a class of functors. Types polymorphic over a class of functors are easily representable in languages such as Haskell, but are difficult to analyse and reason about. The concrete representation provided by the theorem is easier to analyse, but it might not be as convenient to implement. Therefore, depending on the task at hand, the change of representation may prove valuable in one direction or the other. We showcase the usefulness of the representation theorem with a range of examples. Concretely, we show how the representation theorem can be used to prove that traversable functors are finitary containers, how coalgebras of a parameterised store comonad relate to very well-behaved lenses, and how algebraic effects might be implemented in a functional language.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43855.html
found
=========================
Abstract Interpretation as Automated Deduction
Automated Deduction - CADE 25, Springer International Publishing (2015), pp. 450-464
[u"Vijay D'Silva", u'Caterina Urban']
AlgorithmsandTheory
Abstract: Algorithmic deduction and abstract interpretation are two widely used and successful approaches to implementing program verifiers. A major impediment to combining these approaches is that their mathematical foundations and implementation approaches are fundamentally different. This paper presents a new, logical perspective on abstract interpreters that perform reachability analysis using non-relational domains. We encode reachability of a location in a control-flow graph as satisfiability in a monadic, second-order logic parameterized by a first-order theory. We show that three components of an abstract interpreter, the lattice, transformers and iteration algorithm, represent a first-order, substructural theory, parametric deduction and abduction in that theory, and second-order constraint propagation.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44291.html
found
=========================
Advertising on YouTube and TV: A Meta-analysis of Optimal Media-mix Planning
Google, Inc. (2015), pp. 1-28 (to appear)
[u'Georg M. Goerg', u'Christoph Best', u'Sheethal Shobowale', u'Jim Koehler', u'Nicolas Remy']
AlgorithmsandTheory
Abstract: In this work we investigate under what circumstances a TV campaign should be complemented with online advertising to increase combined reach. First, we use probabilistic models to derive necessary and sufficient conditions. We then test these optimality conditions on empirical findings of a large collection of TV campaigns to answer two important questions: i) which characteristics of a TV campaign make it favorable to shift part of its budget to online advertising?; and ii) if it should shift, how much cost savings and additional reach can advertisers expect? First, we use classification methods such as linear discriminant analysis, logistic regression, and decision trees to decide whether a TV campaign should add online advertising; secondly, we train linear and support vector regression models to predict optimal budget allocation, cost savings, or additional reach. To train these models we use optimization results on roughly 26,000 campaigns. We do not only achieve excellent out-of-sample predictive power, but also obtain simple, interpretable, and actionable rules that improve the understanding of media mix advertising.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
An optimal online algorithm for retrieving heavily perturbed statistical databases in the low-dimensional querying model
Proceedings of the Twenty-Fourth ACM International Conference on Information and Knowledge Management (CIKM 2015) (to appear)
[u'Krzysztof Choromanski', u'Afshin Rostamizadeh', u'Umar Syed']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43787.html
found
=========================
Cardinal Contests
Proceedings of the 24th International Conference on the World Wide Web (WWW) (2015), pp. 377-387
[u'Arpita Ghosh', u'Patrick Hummel']
AlgorithmsandTheory
Abstract: Contests are widely used as a means for effort elicitation in settings ranging from government R&D contests to online crowdsourcing contests on platforms such as Kaggle, Innocentive, or TopCoder. Such rank-order mechanisms where agents' rewards depend only on the relative ranking of their submissions' qualitiesare natural mechanisms for incentivizing effort when it is easier to obtain ordinal, rather than cardinal, information about agents' outputs, or where absolute measures of quality are unverifiable. An increasing number of online contests, however, rank entries according to some numerical evaluation of their absolute qualityfor instance, the performance of an algorithm on a test dataset, or the performance of an intervention in a randomized trial. Can the contest designer incentivize higher effort by making the rewards in an ordinal rank-order mechanism contingent on such cardinal information? We model and analyze cardinal contests, where a principal running a rank-order tournament has access to an absolute measure of the qualities of agents' submissions in addition to their relative rankings, and ask how modifying the rank-order tournament to incorporate cardinal information can improve incentives for effort. Our main result is that a simple threshold mechanisma mechanism that awards the prize for a rank if and only if the absolute quality of the agent at that rank exceeds a certain thresholdis optimal amongst all mixed cardinal-ordinal mechanisms where the fraction of the j-th prize awarded to the j-th-ranked agent is any arbitrary non-decreasing function of her submission's quality. Further, the optimal threshold mechanism uses exactly the same threshold for each rank. We study what contest parameters determine the extent of the benefit from incorporating such cardinal information into an ordinal rank-order contest, and investigate the extent of improvement in equilibrium effort via numerical simulations.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43876.html
found
=========================
Computing weak consistency in polynomial time
Proceedings of the 2015 ACM Symposium on Principles of Distributed Computing, ACM, New York, NY, USA, pp. 395-404
[u'Wojciech Golab', u'Xiaozhou (Steve) Li', u'Alejandro Lpez-Ortiz', u'Naomi Nishimura']
AlgorithmsandTheory
Abstract: The k-atomicity property can be used to describe the consistency of data operations in large distributed storage systems. The weak consistency guarantees offered by such systems are seen as a necessary compromise in view of Brewer's CAP principle. The k-atomicity property requires that every read operation obtains a value that is at most k updates (writes) old, and becomes a useful way to quantify weak consistency if k is treated as a variable that can be computed from a history of operations. Specifically, the value of k quantifies how far the history deviates from Lamport's atomicity property for read/write registers. We address the problem of computing k indirectly by solving the k-atomicity verification problem (k-AV): given a history of read/write operations and a positive integer k, decide whether the history is k-atomic. Gibbons and Korach showed that in general this problem is NP-complete when k = 1, and hence not solvable in polynomial time unless P = NP. In this paper we present two algorithms that solve the k-AV problem for any k >= 2 in special cases. Similarly to known solutions for k = 1 and k = 2, both algorithms assume that all the values written to a given object are distinct. The first algorithm places an additional restriction on the structure of the input history and solves k-AV in O(n^2 + n (k log k) time. The second algorithm does not place any additional restrictions on the input but is efficient only when k is small and when concurrency among write operations is limited. Its time complexity is O(n^2) if both k and our particular measure of write concurrency are bounded by constants.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43854.html
found
=========================
Conflict-Driven Conditional Termination
Computer Aided Verification, Springer International Publishing (2015), pp. 271-286
[u"Vijay D'Silva", u'Caterina Urban']
AlgorithmsandTheory
Abstract: Conflict-driven learning, which is essential to the performance of sat and smt solvers, consists of a procedure that searches for a model of a formula, and refutation procedure for proving that no model exists. This paper shows that conflict-driven learning can improve the precision of a termination analysis based on abstract interpretation. We encode non-termination as satisfiability in a monadic second-order logic and use abstract interpreters to reason about the satisfiability of this formula. Our search procedure combines decisions with reachability analysis to find potentially non-terminating executions and our refutation procedure uses a conditional termination analysis. Our implementation extends the set of conditional termination arguments discovered by an existing termination analyzer.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41010.html
found
=========================
Data Enriched Linear Regression
Electronic Journal of Statistics, vol. 9 (2015), pp. 1078-1112 (to appear)
[u'Aiyou Chen', u'Art Owen', u'Minghui Shi']
AlgorithmsandTheory
Abstract: We present a linear regression method for predictions on a small data set making use of a second possibly biased data set that may be much larger. Our method fits linear regressions to the two data sets while penalizing the difference between predictions made by those two models. The resulting algorithm is a shrinkage method similar to those used in small area estimation. We find a Stein-type result for Gaussian responses: when the model has 5 or more coefficients and 10 or more error degrees of freedom, it becomes inadmissible to use only the small data set, no matter how large the bias is. We also present both plug-in and AICc-based methods to tune our penalty parameter. Most of our results use an L2 penalty, but we obtain formulas for L1 penalized estimates when the model is specialized to the location setting. Ordinary Stein shrinkage provides an inadmissibility result for only 3 or more coefficients, but we find that our shrinkage method typically produces much lower squared errors in as few as 5 or 10 dimensions when the bias is small and essentially equivalent squared errors when the bias is large.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43979.html
found
=========================
Distributed Authorization With Distributed Grammars
Programming Languages with Applications to Biology and Security, Springer International Publishing Switzerland, Gewerbestrasse 11 CH-6330 Cham (ZG) Switzerland (2015) (to appear)
[u'Martin Abadi', u'Mike Burrows', u'Himabindu Pucha', u'Adam Sadovsky', u'Asim Shankar', u'Ankur Taly']
AlgorithmsandTheory
Abstract: While groups are generally helpful for the definition of authorization policies, their use in distributed systems is not straightforward. This paper describes a design for authorization in distributed systems that treats groups as formal languages. The design supports forms of delegation and negative clauses in authorization policies. It also considers the wish for privacy and efficiency in group-membership checks, and the possibility that group definitions may not all be available and may contain cycles.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44013.html
found
=========================
Dynamic adjustment of video quality
Patent (2015)
[u'Thomas Steiner']
AlgorithmsandTheory
Abstract: A video quality module receives data indicating a visibility status of a tab of a web browser running on a user device. The video quality module determines, based on the data indicating the visibility status of the tab whether the tab of the web browser is currently visible to a user of the user device, the tab of the web browser comprising a streaming media player. If the tab of the web browser is not currently visible to the user, the video quality module decreases a quality of a video component of a streaming media file playing in the streaming media player.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44273.html
found
=========================
Efficient Traffic Splitting on Commodity Switches
Proceedings of the 11th ACM International on Conference on emerging Networking Experiments and Technologies (CoNEXT), ACM (2015) (to appear)
[u'Nanxi Kang', u'Monia Ghobadi', u'John Reumann', u'Alexander Shraer', u'Jennifer Rexford']
AlgorithmsandTheory
Abstract: Traffic often needs to be split over multiple equivalent backend servers, links, paths, or middleboxes. For example, in a load-balancing system, switches distribute requests of online services to backend servers. Hash-based approaches like Equal-Cost Multi-Path (ECMP) have low accuracy due to hash collision and incur significant churn during update. In a Software-Defined Network (SDN) the accuracy of traffic splits can be improved by crafting a set of wildcard rules for switches that better match the actual traffic distribution. The drawback of existing SDN-based traffic-splitting solutions is poor scalability as they generate too many rules for small rule-tables on switches. In this paper, we propose Niagara, an SDN-based traffic-splitting scheme that achieves accurate traffic splits while being extremely efficient in the use of rule-table space available on commodity switches. Niagara uses an incremental update strategy to minimize the traffic churn given an update. Experiments demonstrate that Niagara (1) achieves nearly optimal accuracy using only 1.2%37% of the rule space of the current state-of-art, (2) scales to tens of thousands of services with the constrained rule-table capacity and (3) offers nearly minimum churn.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43451.html
found
=========================
How Many Millenials Visit YouTube? Estimating Unobserved Events From Incomplete Panel Data Conditioned on Demographic Covariates
TBD, Google, Inc. (2015), pp. 1-27 (to appear)
[u'Georg M. Goerg', u'Yuxue Jin', u'Nicolas Remy', u'Jim Koehler']
AlgorithmsandTheory
Abstract: Many socio-economic studies rely on panel data as they also provide detailed demographic information about consumers. For example, advertisers use TV and web metering panels to estimate ads effectiveness in selected target demographics. However, panels often record only a fraction of all events due to non-registered devices, technical problems, or work usage. Goerg et al. (2015) present a beta-binomial negative-binomial hurdle (BBNBH) model to impute missing events in count data with excess zeros. In this work, we study empirical properties of the MLE for the BBNBH model, extend it to categorical covariates, introduce a penalized maximum likelihood estimator (MLE) to get accurate estimates by demographic group, and apply the methodology to a German media panel to learn about demographic patterns in the YouTube viewership.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43286.html
found
=========================
How Many People Visit YouTube? Imputing Missing Events in Panels With Excess Zeros
Google Inc. (2015), pp. 1-6
[u'Georg M. Goerg', u'Yuxue Jin', u'Nicolas Remy', u'Jim Koehler']
AlgorithmsandTheory
Abstract: Media-metering panels track TV and online usage of people to analyze viewing behavior. However, panel data is often incomplete due to non-registered devices, non-compliant panelists, or work usage. We thus propose a probabilistic model to impute missing events in data with excess zeros using a negative-binomial hurdle model for the unobserved events and beta-binomial sub-sampling to account for missingness. We then use the presented models to estimate the number of people in Germany who visit YouTube.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41854.html
found
=========================
Inferring causal impact using Bayesian structural time-series models
Annals of Applied Statistics, vol. 9 (2015), pp. 247-274
[u'Kay H. Brodersen', u'Fabian Gallusser', u'Jim Koehler', u'Nicolas Remy', u'Steven L. Scott']
AlgorithmsandTheory
Abstract: An important problem in econometrics and marketing is to infer the causal impact that a designed market intervention has exerted on an outcome metric over time. In order to allocate a given budget optimally, for example, an advertiser must assess to what extent different campaigns have contributed to an incremental lift in web searches, product installs, or sales. This paper proposes to infer causal impact on the basis of a diffusion-regression state-space model that predicts the counterfactual market response that would have occurred had no intervention taken place. In contrast to classical difference-in-differences schemes, state-space models make it possible to (i) infer the temporal evolution of attributable impact, (ii) incorporate empirical priors on the parameters in a fully Bayesian treatment, and (iii) flexibly accommodate multiple sources of variation, including the time-varying influence of contemporaneous covariates, i.e., synthetic controls. Using a Markov chain Monte Carlo algorithm for model inversion, we illustrate the statistical properties of our approach on synthetic data. We then demonstrate its practical utility by evaluating the effect of an online advertising campaign on search-related site visits. We discuss the strengths and limitations of state-space models in enabling causal attribution in those settings where a randomised experiment is unavailable. The CausalImpact R package provides an implementation of our approach.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42550.html
found
=========================
Multi-armed bandit experiments in the online service economy
Applied Stochastic Models in Business and Industry, vol. 31 (2015), pp. 37-49
[u'Steven L. Scott']
AlgorithmsandTheory
Abstract: The modern service economy is substantively different from the agricultural and manufacturing economies that preceded it. In particular, the cost of experimenting is dominated by opportunity cost rather than the cost of obtaining experimental units. The different economics require a new class of experiments, in which stochastic models play an important role. This article briefly summarizes mulit-armed bandit experiments, where the experimental design is modified as the experiment progresses to make the experiment as inexpensive as possible.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Non-textual user input
Patent (2015)
[u'Thomas Steiner']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
On Learning Mixture Models for Permutations
ITCS (2015)
[u'Flavio Chierichetti', u'Anirban Dasgupta', u'Ravi Kumar', u'Silvio Lattanzi']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Online Stochastic Matching with Unequal Probabilities
SODA, SIAM (2015), pp. 1388-1404
[u'Aranyak Mehta', u'Bo Waggoner', u'Morteza Zadimoghaddam']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44279.html
found
=========================
Precentile-Based Approach to Forecasting Workload Growth
IT Performance and Capacity by CMG 41st International Conference (CMG2015), Computer Measurement Group, 3501 Route 42 Suite 130 #121 Turnersville, NJ 08012-1734 USA
[u'Alex Gilgur', u'Stephen Gunn', u'Douglas Browning', u'Xiaojun Di', u'Wei Chen', u'Rajesh Krishnaswamy']
AlgorithmsandTheory
Abstract: When forecasting resource workloads (traffic, CPU load, memory usage, etc.), we often extrapolate from the upper percentiles of data distributions. This works very well when the resource is far enough from its saturation point. However, when the resource utilization gets closer to the workload-carrying capacity of the resource, upper percentiles level off (the phenomenon is colloquially known as flat-topping or clipping), leading to underpredictions of future workload and potentially to undersized resources. This paper explains the phenomenon and proposes a new approach that can be used for making useful forecasts of workload when historical data for the forecast are collected from a resource approaching saturation.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43834.html
found
=========================
Probabilistic Analysis of Localized DNA Hybridization Circuits
ACS Synthetic Biology (2015)
[u'Neil Dalchau', u'Harish Chandran', u'Nikhil Gopalkrishnan', u'Andrew Phillips', u'John Reif']
AlgorithmsandTheory
Abstract: Molecular devices made of nucleic acids can perform complex information processing tasks at the nanoscale, with potential applications in biofabrication and smart therapeutics. However, limitations in the speed and scalability of such devices in a well-mixed setting can significantly affect their performance. In this paper, we propose designs for localized circuits involving DNA molecules that are arranged on addressable substrates and interact via hybridization reactions. We propose designs for localized elementary logic circuits, which we compose to produce more complex devices, including a circuit for computing the square root of a four bit number. We develop an efficient method for probabilistic model-checking of localized circuits, which we implement within the Visual DSD design tool. We use this method to prove the correctness of our circuits with respect to their functional specifications, and to analyze their performance over a broad range of local rate parameters. Specifically, we analyze the extent to which our localized designs can overcome the limitations of well-mixed circuits, with respect to speed and scalability. To provide an estimate of local rate parameters, we propose a biophysical model of localized hybridization. Finally, we use our analysis to identify constraints in the rate parameters that enable localized circuits to retain their advantages in the presence of unintended interferences between strands.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43941.html
found
=========================
Quantum Simulation of Helium Hydride Cation in a Solid-State Spin Register
ACS Nano, vol. 9 (2015), 77697774
[u'Ya Wang', u'Florian Dolde', u'Jacob Biamonte', u'Ryan Babbush', u'Ville Bergholm', u'Sen Yang', u'Ingmar Jakobi', u'Philipp Neumann', u'Aln Aspuru-Guzik', u'James Whitfield', u'Jrg Wrachtrup']
AlgorithmsandTheory
Abstract: Ab initio computation of molecular properties is one of the most promising applications of quantum computing. While this problem is widely believed to be intractable for classical computers, efficient quantum algorithms exist which have the potential to vastly accelerate research throughput in fields ranging from material science to drug discovery. Using a solid-state quantum register realized in a nitrogen-vacancy (NV) defect in diamond, we compute the bond dissociation curve of the minimal basis helium hydride cation, HeH+. Moreover, we report an energy uncertainty (given our model basis) of the order of 1e14 hartree, which is 10 orders of magnitude below the desired chemical precision. As NV centers in diamond provide a robust and straightforward platform for quantum information processing, our work provides an important step toward a fully scalable solid-state implementation of a quantum chemistry simulator.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43342.html
found
=========================
R for Marketing Research and Analytics
Springer, New York (2015)
[u'Chris Chapman', u'Elea McDonnell Feit']
AlgorithmsandTheory
Abstract: This book is a complete introduction to the power of R for marketing research practitioners. The text describes statistical models from a conceptual point of view with a minimal amount of mathematics, presuming only an introductory knowledge of statistics. Hands-on chapters accelerate the learning curve by asking readers to interact with R from the beginning. Core topics include the R language, basic statistics, linear modeling, and data visualization, which is presented throughout as an integral part of analysis. Later chapters cover more advanced topics yet are intended to be approachable for all analysts. These sections examine logistic regression, customer segmentation, hierarchical linear modeling, market basket analysis, structural equation modeling, and conjoint analysis in R. The text uniquely presents Bayesian models with a minimally complex approach, demonstrating and explaining Bayesian methods alongside traditional analyses for analysis of variance, linear models, and metric and choice-based conjoint analysis. With its emphasis on data visualization, model assessment, and development of statistical intuition, this book provides guidance for any analyst looking to develop or improve skills in R for marketing applications.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
R for marketing research and analytics: discussion
Joint Statistical Meetings (JSM) 2015, Seattle, WA
[u'Chris Chapman', u'Elea McDonnell Feit']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43815.html
found
=========================
Revenue Maximization for Selling Multiple Correlated Items
23rd Annual European Symposium on Algorithms (ESA), Springer-Verlag (2015)
[u'Mohammadhossein Bateni', u'Sina Dehghani', u'MohammadTaghi Hajiaghayi', u'Saeed Seddighin']
AlgorithmsandTheory
Abstract: We study the problem of selling $n$ items to a single buyer with an additive valuation function. We consider the valuation of the items to be correlated, i.e., desirabilities of the buyer for the items are not drawn independently. Ideally, the goal is to design a mechanism to maximize the revenue. However, it has been shown that a revenue optimal mechanism might be very complicated and as a result inapplicable to real-world auctions. Therefore, our focus is on designing a simple mechanism that achieves a constant fraction of the optimal revenue. Babaioff et al. (FOCS'14) propose a simple mechanism that achieves a constant fraction of the optimal revenue for independent setting with a single additive buyer. However, they leave the following problem as an open question: "Is there a simple, approximately optimal mechanism for a single additive buyer whose value for $n$ items is sampled from a common base-value distribution?" Babaioff et al. show a constant approximation factor of the optimal revenue can be achieved by either selling the items separately or as a whole bundle in the independent setting. We show a similar result for the correlated setting when the desirabilities of the buyer are drawn from a common base-value distribution. It is worth mentioning that the core decomposition lemma which is mainly the heart of the proofs for efficiency of the mechanisms does not hold for correlated settings. Therefore we propose a modified version of this lemma which is applicable to the correlated settings as well. Although we apply this technique to show the proposed mechanism can guarantee a constant fraction of the optimal revenue in a very weak correlation, this method alone can not directly show the efficiency of the mechanism in stronger correlations. Therefore, via a combinatorial approach we reduce the problem to an auction with a weak correlation to which the core decomposition technique is applicable. In addition, we introduce a generalized model of correlation for items and show the proposed mechanism achieves an $O(\log k)$ approximation factor of the optimal revenue in that setting.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Revenue Maximization with Nonexcludable Goods
Transactions on Economics and Computation (2015)
[u'Mohammadhossein Bateni', u'Nima Haghpanah', u'Balasubramanian Sivan', u'Morteza Zadimoghaddam']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Robust Hierarchical k-center clustering
ITCS (2015)
[u'Silvio Lattanzi', u'Stefano Leonardi', u'Vahab Mirrokni', u'Ilya Razenshteyn']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43797.html
found
=========================
The Maximal Two-Sided Ideals of Nest Algebras
Journal of Operator Theory, vol. 73:2 (2015), pp. 407-416
[u'John Lindsay Orr']
AlgorithmsandTheory
Abstract: We give a necessary and sufficient criterion for an operator in a nest algebra to belong to a proper two-sided ideal of that algebra. Using this result, we describe the strong radical of a nest algebra, and give a general description of the maximal two-sided ideals. This also enables us to provide the final piece in the complete description of epimorphisms of one nest algebra onto another.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Timely Dataflow: A Model
FORTE (2015), pp. 131-145
[u'Martn Abadi', u'Michael Isard']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Triangulation Refinement and Approximate Shortest Paths in Weighted Regions
Proceedings of the 26th Annual ACM-SIAM Symposium on Discrete Algorithms (2015), pp. 1626-1640
[u'Siu-Wing Cheng', u'Jiongxin Jin', u'Antoine Vigneron']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Weakly Supervised Clustering: Learning Fine-Grained Signals from Coarse Labels
Annals of Applied Statistics (2015) (to appear)
[u'Stefan Wager', u'Alexander W Blocker', u'Niall Cardin']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43156.html
found
=========================
A Game-Theoretic Analysis of Rank-Order Mechanisms for User-Generated Content
Journal of Economic Theory, vol. 154 (2014), pp. 349-374
[u'Arpita Ghosh', u'Patrick Hummel']
AlgorithmsandTheory
Abstract: We investigate the widely-used rank-order mechanism for displaying user-generated content, where contributions are displayed on a webpage in decreasing order of their ratings, in a game-theoretic model where strategic contributors benefit from attention and have a cost to quality. We show that the lowest quality elicited by this rank-order mechanism in any mixed-strategy equilibrium becomes optimal as the available attention diverges. Additionally, these equilibrium qualities are higher, with probability tending to 1 in the limit of diverging attention, than those elicited by a more equitable proportional mechanism which distributes attention in proportion to the positive ratings a contribution receives, but the proportional mechanism elicits a greater number of contributions than the rank-order mechanism.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42494.html
found
=========================
A critical review of studies investigating the quality of data obtained with online panels based on probability and nonprobability samples
Online Panel Research: A Data Quality Perspective, Wiley (2014), pp. 23-53
[u'Mario Callegaro', u'Ana Villar', u'David S. Yeager', u'Jon A. Krosnick']
AlgorithmsandTheory
Abstract: his chapter provides an overview of studies comparing the quality of data collected by online survey panels by looking at three criteria: (1) comparisons of point estimates from online panels to high-quality, established population benchmarks; (2) comparisons of the relationship among variables; and (3) the reproducibility of results for online survey panels conducted on probability samples to panels conducted on nonprobability samples. When looking at point estimates, all online survey panels differed to some extent from the population benchmarks. However, the largest comparison studies suggest that point estimates from online panels of nonprobability samples have higher differences as compared to benchmarks than online panels of probability samples. This finding is consistent across time and across studies conducted in different countries. Moreover, post-stratification weighting strategies helped little and in an inconsistent way to reduce such differences for data coming from online panels of nonprobability samples, whereas these strategies did bring estimates from online panels of probability samples consistently closer to the benchmarks. When comparing relationships among variables, it was found that researchers would reach different conclusions when using online panels of nonprobability samples versus panels of probability samples. When looking at reproducibility of results, the limited evidence found suggests that there are no substantial differences in replication and effect size across probability and nonprobability samples for question wording experiments and when comparing students samples to other samples. It is worth noting that in pre-election polls, an area where abundant prior knowledge exists, online panels of nonprobability samples have consistently performed as well and in some cases better than polls based on probability samples in predicting election winners.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
An efficient reconciliation algorithm for social networks.
PVLDB (2014), pp. 377-388
[u'Nitish Korula', u'Silvio Lattanzi']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43249.html
found
=========================
An optimized template matching approach to intra coding in video/image compression
IS&T/SPIE Electronic Imaging, 2014, SPIE, pp. 1-6
[u'Hui Su', u'Jingning Han', u'Yaowu Xu']
AlgorithmsandTheory
Abstract: The template matching prediction is an established approach to intra-frame coding that makes use of previously coded pixels in the same frame for reference. It compares the previously reconstructed upper and left boundaries in searching from the reference area the best matched block for prediction, and hence eliminates the need of sending additional information to reproduce the same prediction at decoder. In viewing the image signal as an auto-regressive model, this work is premised on the fact that pixels closer to the known block boundary are better predicted than those far apart. It significantly extends the scope of the template matching approach, which is typically followed by a conventional discrete cosine transform (DCT) for the prediction residuals, by employing an asymmetric discrete sine transform (ADST), whose basis functions vanish at the prediction boundary and reach maximum magnitude at far end, to fully exploit statistics of the residual signals. It was experimentally shown that the proposed scheme provides substantial coding performance gains on top of the conventional template matching method over the baseline.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Approximate Shortest Descending Paths
SIAM Journal on Computing, vol. 43 (2014), pp. 410-428
[u'Siu-Wing Cheng', u'Jiongxin Jin']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Biobjective Online Bipartite Matching
Workshop in Internet and Network Economics, Springer (2014), pp. 218-231
[u'Gagan Aggarwal', u'Yang Cai', u'Aranyak Mehta', u'George Pierrakos']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42958.html
found
=========================
C/C++ Thread Safety Analysis
2014 IEEE 14th International Working Conference on Source Code Analysis and Manipulation, IEEE
[u'DeLesley Hutchins', u'Aaron Ballman', u'Dean Sutherland']
AlgorithmsandTheory
Abstract: Writing multithreaded programs is hard. Static analysis tools can help developers by allowing threading policies to be formally specified and mechanically checked. They essentially provide a static type system for threads, and can detect potential race conditions and deadlocks. This paper describes Clang Thread Safety Analysis, a tool which uses annotations to declare and enforce thread safety policies in C and C++ programs. Clang is a production-quality C++ compiler which is available on most platforms, and the analysis can be enabled for any build with a simple warning flag: Wthreadsafety. The analysis is deployed on a large scale at Google, where it has provided sufficient value in practice to drive widespread voluntary adoption. Contrary to popular belief, the need for annotations has not been a liability, and even confers some benefits with respect to software evolution and maintenance.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43144.html
found
=========================
Circulant Binary Embedding
International Conference on Machine Learning (ICML) (2014)
[u'Felix X. Yu', u'Sanjiv Kumar', u'Yunchao Gong', u'Shih-Fu Chang']
AlgorithmsandTheory
Abstract: Binary embedding of high-dimensional data requires long codes to preserve the discriminative power of the input space. Traditional binary coding methods often suffer from very high computation and storage costs in such a scenario. To address this problem, we propose Circulant Binary Embedding (CBE) which generates binary codes by projecting the data with a circulant matrix. The circulant structure enables the use of Fast Fourier Transformation to speed up the computation. Compared to methods that use unstructured matrices, the proposed method improves the time complexity from O(d^2) to O(dlogd), and the space complexity from O(d^2) to O(d) where d is the input dimensionality. We also propose a novel time-frequency alternating optimization to learn data-dependent circulant projections, which alternatively minimizes the objective in original and Fourier domains. We show by extensive experiments that the proposed approach gives much better performance than the state-of-the-art approaches for fixed time, and provides much faster computation with no performance degradation for fixed number of bits.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Circumlocution in Diagnostic Medical Queries
The 37th Annual ACM SIGIR Conference (2014)
[u'Isabelle Stanton', u'Samuel Ieong', u'Nina Mishra']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Clinching auctions beyond hard budget constraints
EC, ACM (2014)
[u'Gagan Goel', u'Vahab Mirrokni', u'Renato Paes Leme']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41926.html
found
=========================
Collaboration in the Cloud at Google
research.google.com (2014), pp. 1-13
[u'Yunting Sun', u'Diane Lambert', u'Makoto Uchida', u'Nicolas Remy']
AlgorithmsandTheory
Abstract: Through a detailed analysis of logs of activity for all Google employees, this paper shows how the Google Docs suite (documents, spreadsheets and slides) enables and increases collaboration within Google. In particular, visualization and analysis of the evolution of Googles collaboration network show that new employees, have started collaborating more quickly and with more people as usage of Docs has grown. Over the last two years, the percentage of new employees who collaborate on Docs per month has risen from 70% to 90% and the percentage who collaborate with more than two people has doubled from 35% to 70%. Moreover, the culture of collaboration has become more open, with public sharing within Google overtaking private sharing.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Concise Bid Optimization Strategies with Multiple Budget Constraints
WINE, The 10th Conference on Web and Internet Economics (2014)
[u'Arash Asadpour', u'Mohammadhossein Bateni', u'Kshipra Bhawalkar', u'Vahab Mirrokni']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Coupled and k-Sided Placements: Generalizing Generalized Assignment
Integer Programming and Combinatorial Optimization (IPCO) (2014)
[u'Madhukar Korupolu', u'Adam Meyerson', u'Rajmohan Rajaraman', u'Brian Tagiku']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42246.html
found
=========================
Data enrichment for incremental reach estimation
Google Inc. (2014), pp. 1-21 (to appear)
[u'Aiyou Chen', u'Jim Koehler', u'Art Owen', u'Nicolas Remy', u'Minghui Shi']
AlgorithmsandTheory
Abstract: There is increasing interest in measuring the overlap and/or incremental reach of cross-media campaigns. The direct method is to use a cross-media panel but these are expensive to scale across all media. Typically, the cross-media panel is too small to produce reliable estimates when the interest comes down to subsets of the population. An alternative is to combine information from a small cross-media panel with a larger, cheaper but potentially biased single media panel. In this article, we develop a data enrichment approach specifically for incremental reach estimation. The approach not only integrates information from both panels that takes into account potential panel bias, but borrows strength from modeling conditional dependence of cross-media reaches. We demonstrate the approach with data from six campaigns for estimating YouTube video ad incremental reach over TV. In a simulation directly modeled on the actual data, we find that data enrichment yields much greater accuracy than one would get by either ignoring the larger panel, or by using it in a data fusion.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Definable functions continuous on curves in o-minimal structures
Annals of Pure and Applied Logic, vol. 165 (2014), pp. 1339-1351
[u'Janak Ramakrishnan']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42951.html
found
=========================
Definably extending partial orders in totally ordered structures
Mathematical Logic Quarterly, vol. 60 (2014), pp. 205-210
[u'Janak Ramakrishnan', u'Charles Steinhorn']
AlgorithmsandTheory
Abstract: We show, for various classes of totally ordered structures \mathcal M=(M,<,...), including o-minimal and weakly o-minimal structures, that every definable partial order on a subset of M^n extends definably in \mathcal M to a total order. This extends the result proved in [5] for n=1 and \mathcal M o-minimal.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43218.html
found
=========================
Estimating reach curves from one data point
Google Inc. (2014), pp. 1-7
[u'Georg M. Goerg']
AlgorithmsandTheory
Abstract: Reach curves arise in advertising and media analysis as they relate the number of content impressions to the number of people who have seen it. This is especially important for measuring the effectiveness of an ad on TV or websites. For a mathematical and data-driven analysis, it would be very useful to know the entire reach curve; advertisers, however, often only know its last data point, i.e., the total number of impressions and the total reach. In this work I present a new method to estimate the entire curve using only this last data point. Furthermore, analytic derivations reveal a surprisingly simple, yet insightful relationship between marginal cost per reach, average cost per impression, and frequency. Thus, advertisers can estimate the cost of an additional reach point by just knowing their total number of impressions, reach, and cost. A comparison of the proposed one-data point method to two competing regression models on TV reach curve data, shows that the proposed methodology performs only slightly poorer than regression fits to a collection of several points along the curve.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43981.html
found
=========================
F-ing modules
Journal of Functional Programming, vol. 24 (5) (2014)
[u'Andreas Rossberg', u'Claudio Russo', u'Derek Dreyer']
AlgorithmsandTheory
Abstract: ML modules are a powerful language mechanism for decomposing programs into reusable components. Unfortunately, they also have a reputation for being "complex" and requiring fancy type theory that is mostly opaque to non-experts. While this reputation is certainly understandable, given the many non-standard methodologies that have been developed in the process of studying modules, we aim here to demonstrate that it is undeserved. To do so, we give a very simple elaboration semantics for a full-featured, higher-order ML-like module language. Our elaboration defines the meaning of module expressions by a straightforward, compositional translation into vanilla System F (the higher-order polymorphic -calculus), under plain F typing environments. We thereby show that ML modules are merely a particular mode of use of System F. We start out with a module language that supports the usual second-class modules with Standard ML-style generative functors, and includes local module definitions. To demonstrate the versatility of our approach, we further extend the language with the ability to package modules as first-class values a very simple extension, as it turns out and a novel treatment of OCaml-style applicative functors. Unlike previous work combining both generative and applicative functors, we do not require two distinct forms of functor or sealing expressions. Instead, whether a functor is applicative or not depends only on the computational purity of its body in fact, we argue that applicative/generative is rather incidental terminology for what is best understood as pure vs. impure functors. This approach results in a semantics that we feel is simpler and more natural, and moreover prohibits breaches of data abstraction that are possible under earlier semantics for applicative functors. We also revive (in refined form) the long-lost notion of structure sharing from SML'90. Although previous work on module type systems has disparaged structure sharing as type-theoretically questionable, we observe that (1) some variant of it is in fact necessary in order to provide a proper treatment of abstraction in the presence of applicative functors, and (2) it is straightforward to account for using ``phantom types''. Based on this, we can even justify the (previously poorly understood) "where module" operator for signatures and the related notion of manifest module specifications. Altogether, we describe a comprehensive, unified, and yet simple semantics of a full-blown module language that with the main exception of cross-module recursion covers almost all interesting features that can be found in either the literature or in practical implementations of ML modules. We prove the language sound and its type checking decidable.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42531.html
found
=========================
Insulin Resistance: Regression and Clustering
PLoS ONE, vol. 9(6) (2014)
[u'Sangho Yoon']
AlgorithmsandTheory
Abstract: In this paper we try to define insulin resistance (IR) precisely for a group of Chinese women. Our definition deliberately does not depend upon body mass index (BMI) or age, although in other studies, with particular random effects models quite different from models used here, BMI accounts for a large part of the variability in IR. We accomplish our goal through application of Gauss mixture vector quantization (GMVQ), a technique for clustering that was developed for application to lossy data compression. Defining data come from measurements that play major roles in medical practice. A precise statement of what the data are is in Section 1. Their family structures are described in detail. They concern levels of lipids and the results of an oral glucose tolerance test (OGTT). We apply GMVQ to residuals obtained from regressions of outcomes of an OGTT and lipids on functions of age and BMI that are inferred from the data. A bootstrap procedure developed for our family data supplemented by insights from other approaches leads us to believe that two clusters are appropriate for defining IR precisely. One cluster consists of women who are IR, and the other of women who seem not to be. Genes and other features are used to predict cluster membership. We argue that prediction with main effects is not satisfactory, but prediction that includes interactions may be.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42495.html
found
=========================
Internet and mobile ratings panels
Online Panel Research: A Data Quality Perspective, Wiley (2014), pp. 387-407
[u'Philip M. Napoli', u'Paul J. Lavrakas', u'Mario Callegaro']
AlgorithmsandTheory
Abstract: This chapter examines how Internet (PC and mobile) ratings panels are constructed, managed, and utilized. We provide an overview of the history and evolution of Internet/mobile ratings panels and examines the methodological challenges associated with creating and maintaining accurate and reliable Internet/mobile ratings panels. The research that has assessed the accuracy and validity of online panel data is critically discussed; as well as research that illustrates the type of scholarly and applied research questions that can be investigated using online ratings panel data. The chapter concludes with a discussion of the future of online ratings panels within the rapidly evolving field of Internet audience measurement.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42950.html
found
=========================
Interpretable groups are definable
Journal of Mathematical Logic, vol. 14 (2014)
[u'Pantelis Eleftheriou', u"Ya'acov Peterzil", u'Janak Ramakrishnan']
AlgorithmsandTheory
Abstract: We prove that in an arbitrary o-minimal structure, every interpretable group is definably isomorphic to a definable one. We also prove that every definable group lives in a cartesian product of one-dimensional definable group-intervals (or one-dimensional definable groups). We discuss the general open question of elimination of imaginaries in an o-minimal structure.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Learning Entangled Single-Sample Gaussians
Proceedings of the Twenty-Fifth Annual ACM-SIAM Symposium on Discrete Algorithms, SODA 2014
[u'Flavio Chierichetti', u'Anirban Dasgupta', u'Ravi Kumar', u'Silvio Lattanzi']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42434.html
found
=========================
Machine Learning in an Auction Environment
Proceedings of the 23rd International Conference on the World Wide Web (WWW) (2014), pp. 7-18
[u'Patrick Hummel', u'Preston McAfee']
AlgorithmsandTheory
Abstract: We consider a model of repeated online auctions in which an ad with an uncertain click-through rate faces a random distribution of competing bids in each auction and there is discounting of payoffs. We formulate the optimal solution to this explore/exploit problem as a dynamic programming problem and show that efficiency is maximized by making a bid for each advertiser equal to the advertiser's expected value for the advertising opportunity plus a term proportional to the variance in this value divided by the number of impressions the advertiser has received thus far. We then use this result to illustrate that the value of incorporating active exploration into a machine learning system in an auction environment is exceedingly small.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Multiplicative Bidding in Online Advertising
ACM Conference on Economics and Computation (EC) (2014)
[u'Mohammadhossein Bateni', u'Jon Feldman', u'Vahab Mirrokni', u'Sam Chiu-wai Wong']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Network Cournot Competition
WINE, The 10th Conference on Web and Internet Economics (2014)
[u'Melika Abolhasani', u'Mohammadhossein Bateni', u'MohammadTaghi Hajiaghayi', u'Hamid Mahini', u'Anshul Sawant']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42030.html
found
=========================
On Estimating the Average Degree
23rd International World Wide Web Conference, WWW '14, ACM (2014) (to appear)
[u'Anirban Dasgupta', u'Ravi Kumar', u'Tamas Sarlos']
AlgorithmsandTheory
Abstract: Networks are characterized by nodes and edges. While there has been a spate of recent work on estimating the number of nodes in a network, the edge-estimation question appears to be largely unaddressed. In this work we consider the problem of estimating the average degree of a large network using efficient random sampling, where the number of nodes is not known to the algorithm. We propose a new estimator for this problem that relies on access to edge samples under a prescribed distribution. Next, we show how to efficiently realize this ideal estimator in a random walk setting. Our estimator has a natural and simple implementation using random walks; we bound its performance in terms of the mixing time of the underlying graph. We then show that our estimators are both provably and practically better than many natural estimators for the problem. Our work contrasts with existing theoretical work on estimating average degree, which assume a uniform random sample of nodes is available and the number of nodes is known.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
On Reconstructing a Hidden Permutation
RANDOM (2014)
[u'Flavio Chierichetti', u'Anirban Dasgupta', u'Ravi Kumar', u'Silvio Lattanzi']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42492.html
found
=========================
Online Panel Research: A Data Quality Perspective
Wiley (2014), pp. 512
[u'Mario Callegaro', u'Reg Baker', u'Jelke Bethlehem', u'Anja S. Goritz', u'Jon A. Krosnick', u'Paul J. Lavrakas']
AlgorithmsandTheory
Abstract: This edited volume provides new insights into the accuracy and value of online panels for completing surveys Over the last decade, there has been a major global shift in survey and market research towards data collection, using samples selected from online panels. Yet despite their widespread use, remarkably little is known about the quality of the resulting data. This edited volume is one of the first attempts to carefully examine the quality of the survey data being generated by online samples. It describes some of the best empirically-based research on what has become a very important yet controversial method of collecting data. Online Panel Research presents 19 chapters of previously unpublished work addressing a wide range of topics, including coverage bias, nonresponse, measurement error, adjustment techniques, the relationship between nonresponse and measurement error, impact of smartphone adoption on data collection, Internet rating panels, and operational issues. The datasets used to prepare the analyses reported in the chapters are available on the accompanying website: www.wiley.com/go/online_panel
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42493.html
found
=========================
Online panel research: History, concepts, applications and a look at the future
Online Panel Research: A Data Quality Perspective, Wiley (2014), pp. 1-22
[u'Mario Callegaro', u'Reg Baker', u'Jelke Bethlehem', u'Anja S. Goritz', u'Jon A. Krosnick', u'Paul J. Lavrakas']
AlgorithmsandTheory
Abstract: In this introductory chapter, written by the six editors of this volume, we introduce and attempt to systematize the key concepts used when discussing online panels. The connection between Internet penetration and the evolution of panels is discussed as are the different types of online panels, their composition, and how they are built. Most online panels do not use probability-based methods, but some do and the differences are discussed. The chapter also describes in some detail the process of joining a panel, answering initial profiling questions, and becoming an active panel member. We discuss the most common sampling techniques, highlighting their strengths and limitations, and touch on techniques to increase representativeness when using a non-probability panel. The variety of incentive methods in current use also is described. Panel maintenance is another key issue, since attrition often is substantial and a panel must be constantly refreshed. Online panels can be used to support a wide range of study designs, some cross-sectional or and others longitudinal, where the same sample members are surveyed multiple times on the same topic. We also discuss industry standards and professional association guidelines for conducting research using online panels. The chapter concludes with a look to the future of online panels and more generally online sampling via means other than classic panels.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Parallel Algorithms for Unsupervised Tagging
Transactions of the ACL (2014)
[u'Sujith Ravi', u'Sergei Vassilivitskii', u'Vibhor Rastogi']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43246.html
found
=========================
Perfect Reconstructability of Control Flow from Demand Dependence Graphs
Transactions on Architecture and Code Optimization (2014) (to appear)
[u'Helge Bahmann', u'Nico Reissmann', u'Magnus Jahre', u'Jan Christian Meyer']
AlgorithmsandTheory
Abstract: Functional demand-based dependence graphs, such as the Regionalized Value State Dependence Graph, are intermediate representations that only model the flow of data and state with implicit and severely restricted control flow. While suitable for formulation of program transformations, they require algorithms for conversion from and to representations with explicit control flow such as CFG. Existing solutions exhibit structural constraints limiting quality of generated control flow, but we show that this is not intrinsic to RVSDGs. We provide algorithms capable of perfect round-trip conversions, prove their correctness and empirically evaluate their run-time performance and representation overhead.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43219.html
found
=========================
Position Auctions with Externalities
Proceedings of the 10th Conference on Web and Internet Economics (WINE) (2014), pp. 417-422
[u'Patrick Hummel', u'Preston McAfee']
AlgorithmsandTheory
Abstract: This paper presents models for predicted click-through rates in position auctions that take into account the externalities ads shown in other positions may impose on the probability that an ad in a particular position receives a click. We present a general axiomatic methodology for how click probabilities are affected by the qualities of the ads in the other positions, and illustrate that using these axioms will increase revenue as long as higher quality ads tend to be ranked ahead of lower quality ads. We also present appropriate algorithms for selecting the optimal allocation of ads when predicted click-through rates are governed by a natural special case of this axiomatic model of externalities.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Predicting the Present with Bayesian Structural Time Series
International Journal of Mathematical Modelling and Numerical Optimisation, vol. 5 (2014), pp. 4-23
[u'Steven L. Scott', u'Hal Varian']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42258.html
found
=========================
Price Competition in Online Combinatorial Markets
Proceedings of the 23st World Wide Web Conference 2014
[u'Moshe Babaioff', u'Renato Paes Leme', u'Noam Nisan']
AlgorithmsandTheory
Abstract: We consider a single buyer with a combinatorial preference that would like to purchase related products and services from different vendors, where each vendor supplies exactly one product. We study the general case where subsets of products can be substitutes as well as complementary and analyze the game that is induced on the vendors, where a vendor's strategy is the price that he asks for his product. This model generalizes both Bertrand competition (where vendors are perfect substitutes) and Nash bargaining (where they are perfect complements), and captures a wide variety of scenarios that can appear in complex crowd sourcing or in automatic pricing of related products. We study the equilibria of such games and show that a pure efficient equilibrium always exists. In the case of submodular buyer preferences we fully characterize the set of pure Nash equilibria, essentially showing uniqueness. For the even more restricted "substitutes" buyer preferences we also prove uniqueness over {\em mixed} equilibria. Finally we begin the exploration of natural generalizations of our setting such as when services have costs, when there are multiple buyers or uncertainty about the the buyer's valuation, and when a single vendor supplies multiple products.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Quantum Algorithms for Simulated Annealing
Encyclopedia of Algorithms, Springer (2014) (to appear)
[u'Sergio Boixo', u'Rolando Somma']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Randomized Revenue Monotone Mechanisms for Online Advertising.
WINE (2014)
[u'Gagan Goel', u'MohammadTaghi Hajiaghayi', u'Reza Khani']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Reduce and aggregate: similarity ranking in multi-categorical bipartite graphs
WWW (2014), pp. 349-360
[u'Alessandro Epasto', u'Jon Feldman', u'Silvio Lattanzi', u'Stefano Leonardi', u'Vahab Mirrokni']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42457.html
found
=========================
Reporting Neighbors in High-Dimensional Euclidean Space
SIAM journal of computing, vol. 43 (2014), pp. 1239-1511
[u'Dror Aiger', u'Haim Kaplan', u'Micha Sharir']
AlgorithmsandTheory
Abstract: We consider the following problem, which arises in many database and web-based applications: Given a set P of n points in a high-dimensional space Rd and a distance r, we want to report all pairs of points of P at Euclidean distance at most r. We present two randomized algorithms, one based on randomly shifted grids, and the other on randomly shifted and rotated grids. The running time of both algorithms is of the form C(d)(n + k)log n, where k is the output size and C(d) is a constant that depends on the dimension d. The log n factor is needed to guarantee, with high probability, that all neighbor pairs are reported, and can be dropped if it suffices to report, in expectation, an arbitrarily large fraction of the pairs. When only translations are used, C(d) is of the form (ad)d, for some (small) absolute constant a0.484; this bound is worst-case tight, up to an exponential factor of about 2d. When both rotations and translations are used, C(d) can be improved to roughly 6.74d, getting rid of the super-exponential factor dd. When the input set (lies in a subset of d-space that) has low doubling dimension ,the performance of the first algorithm improves to C(d,)(n + k)log n (or to C(d,)(n + k)), where C(d,)=O((ed/),), for d. Otherwise, (d,)=O(edd. We also present experimental results on several large datasets, demonstrating that our algorithms run significantly faster than all the leading existing algorithms for reporting neighbors.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Revenue monotone mechanisms for online advertising
WWW (2014)
[u'Gagan Goel', u'Reza Khani']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42935.html
found
=========================
Revisiting Stein's Paradox: Multi-Task Averaging
Journal Machine Learning Research, vol. 15 (2014)
[u'Sergey Feldman', u'Maya R. Gupta', u'Bela A. Frigyik']
AlgorithmsandTheory
Abstract: We present a multi-task learning approach to jointly estimate the means of multiple independent distributions from samples. The proposed multi-task averaging (MTA) algorithm results in a convex combination of the individual task's sample averages We derive the optimal amount of regularization for the two task case for the minimum risk estimator and a minimax estimator, and show that the optimal amount of regularization can be practically estimated without cross-validation. We extend the practical estimators to an arbitrary number of tasks. Simulations and real data experiments demonstrate the advantage of the proposed MTA estimators over standard averaging and James-Stein estimation.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Secretary Problems and Online Auctions
Encyclopedia of Algorithms, Springer (2014), pp. 1-4
[u'Mohammadhossein Bateni']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Shortest paths on polyhedral surfaces and terrains
Proceedings of the 46th Annual ACM Symposium on Theory of Computing (2014), pp. 373-382
[u'Siu-Wing Cheng', u'Jiongxin Jin']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Streaming Balanced Graph Partitioning for Random Graphs
Symposium on Discrete Algorithms (SODA) (2014)
[u'Isabelle Stanton']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42193.html
found
=========================
Temporal Synchronization of Multiple Audio Signals
Proceedings of the International Conference on Signal Processing (ICASSP), Florence, Italy (2014)
[u'Julius Kammerl', u'Neil Birkbeck', u'Sasi Inguva', u'Damien Kelly', u'Andy Crawford', u'Hugh Denman', u'Anil Kokaram', u'Caroline Pantofaru']
AlgorithmsandTheory
Abstract: Given the proliferation of consumer media recording devices, events often give rise to a large number of recordings. These recordings are taken from different spatial positions and do not have reliable timestamp information. In this paper, we present two robust graph-based approaches for synchronizing multiple audio signals. The graphs are constructed atop the over-determined system resulting from pairwise signal comparison using cross-correlation of audio features. The first approach uses a Minimum Spanning Tree (MST) technique, while the second uses Belief Propagation (BP) to solve the system. Both approaches can provide excellent solutions and robustness to pairwise outliers, however the MST approach is much less complex than BP. In addition, an experimental comparison of audio features-based synchronization shows that spectral flatness outperforms the zero-crossing rate and signal energy.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43968.html
found
=========================
Theoretical Foundations for Learning Kernels in Supervised Kernel PCA
Modern Nonparametrics 3: Automating the Learning Pipeline, Neural Information Processing Systems, Workshop (2014)
[u'Mehryar Mohri', u'Afshin Rostamizadeh', u'Dmitry Storcheus']
AlgorithmsandTheory
Abstract: This paper presents a novel learning scenario which combines dimensionality reduction, supervised learning as well as kernel selection. We carefully define the hypothesis class that addresses this setting and provide an analysis of its Rademacher complexity and thereby provide generalization guarantees. The proposed algorithm uses KPCA to reduce the dimensionality of the feature space, i.e. by projecting data onto top eigenvectors of covariance operator in a kernel reproducing space. Moreover, it simultaneously learns a linear combination of base kernel functions, which defines a reproducing space, as well as the parameters of a supervised learning algorithm in order to minimize a regularized empirical loss. The bound on Rademacher complexity of our hypothesis is shown to be logarithmic in the number of base kernels, which encourages practitioners to combine as many base kernels as possible.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42966.html
found
=========================
Topology-Driven Trajectory Synthesis with an Example on Retinal Cell Motions
14th Workshop on Algorithms in Bioinformatics, Springer, Wroclaw, Poland (2014), pp. 326-339
[u'Chen Gu', u'Leonidas Guibas', u'Michael Kerber']
AlgorithmsandTheory
Abstract: We design a probabilistic trajectory synthesis algorithm for generating time-varying sequences of geometric configuration data. The algorithm takes a set of observed samples (each may come from a different trajectory) and simulates the dynamic evolution of the patterns in O(n^2 log n) time. To synthesize geometric configurations with indistinct identities, we use the pair correlation function to summarize point distribution, and alpha-shapes to maintain topological shape features based on a fast persistence matching approach. We apply our method to build a computational model for the geometric transformation of the cone mosaic in retinitis pigmentosa --- an inherited and currently untreatable retinal degeneration.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42901.html
found
=========================
Visualizing Statistical Mix Effects and Simpson's Paradox
Proceedings of IEEE InfoVis 2014, IEEE (to appear)
[u'Zan Armstrong', u'Martin Wattenberg']
AlgorithmsandTheory
Abstract: We discuss how mix effects can surprise users of visualizations and potentially lead them to incorrect conclusions. This statistical issue (also known as omitted variable bias or, in extreme cases, as Simpsons paradox) is widespread and can affect any visualization in which the quantity of interest is an aggregated value such as a weighted sum or average. Our first contribution is to document how mix effects can be a serious issue for visualizations, and we analyze how mix effects can cause problems in a variety of popular visualization techniques, from bar charts to treemaps. Our second contribution is a new technique, the comet chart, that is meant to ameliorate some of these issues.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42522.html
found
=========================
Web Surveys for the General Population: How, why and when?
Natcen (2014), pp. 22
[u'Gerri Nicolaas', u'Lisa Calderwood', u'Peter Lynn', u'Caroline Roberts', u'Mario Callegaro']
AlgorithmsandTheory
Abstract: Cultural and technological change has made the web a possible and even desirable mode for complex social surveys, but the financial challenges faced by the Research Councils and the UK Government has accelerated this shift, creating an urgent need to explore both its potential and hazards for a range of studies. While some progress in carrying out large-scale complex social surveys on the web has been made, there is still no consensus about how this can best be achieved while maintaining population representativeness and preserving data quality. To address this problem, the NCRM funded a network of methodological innovation Web Surveys for the General Population: How, Why and When? (also known by its acronym GenPopWeb). A key objective of the networks activities was to review and synthesise existing knowledge about the use of web-based data collection for general population samples and to identify areas where new research is needed. The network Web Surveys for the General Population: Why, How and When? was supported with funding from the ESRC National Centre for Research Methods under the initiative Networks for Methodological Innovation 2012. We are also grateful to the Institute of Education and the University of Essex for hosting the two main events of the network. We would like to thank all of the presenters at the events as well as the participants for their contribution. Particular thanks are due to the UK Core Group for their time, advice and support: Bill Blyth, TNS Global Mario Callegaro, Google UK Ed Dunn & Laura Wilson, ONS Rory Fitzgerald, City University London Joanna Lake, ESRC Carli Lessof & Joel Williams, TNS BMRB Nick Moon, GfK NOP Patten Smith, Ipsos MORI Professor Patrick Sturgis, NCRM Joe Twyman & Michael Wagstaff, YouGov UK
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
2013 Recent Books and Journals in Public Opinion, Survey Methods, and Survey Statistics
Survey Practice, vol. 1 (2013)
[u'Mario Callegaro']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41418.html
found
=========================
A Butterfly Structured Design of The Hybrid Transform Coding Scheme
Picture Coding Symposium, IEEE (2013), pp. 1-4
[u'Jingning Han', u'Yaowu Xu', u'Debargha Mukherjee']
AlgorithmsandTheory
Abstract: The hybrid transform coding scheme that alternates amongst the asymmetric discrete sine transform (ADST) and the discrete cosine transform (DCT) depending on the boundary prediction conditions, is an efficient tool for video and image compression. It optimally exploits the statistical characteristics of prediction residual, thereby achieving significant coding performance gains over the conventional DCT-based approach. A practical concern lies in the intrinsic conflict between transform kernels of ADST and DCT, which prevents a butterfly structured implementation for parallel computing. Hence the hybrid transform coding scheme has to rely on matrix multiplication, which presents a speed-up barrier due to under-utilization of the hardware, especially for larger block sizes. In this work, we devise a novel ADST-like transform whose kernel is consistent with that of DCT, thereby enabling butterfly structured computation flow, while largely retaining the performance advantages of hybrid transform coding scheme in terms of compression efficiency. A prototype implementation of the proposed butterfly structured hybrid transform coding scheme is available in the VP9 codec repository.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Local Algorithm for Finding Well-Connected Clusters
The 30th International Conference on Machine Learning, ICML 2013
[u'Zeyuan Allen Zhu', u'Silvio Lattanzi', u'Vahab Mirrokni']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41471.html
found
=========================
Adversary Lower Bound for the k-sum Problem
Proceeding of 4th Annual ACM Conference on Innovations in Theoretical Computer Science (ITCS'13) (2013), pp. 323-328
[u'Aleksandrs Belovs', u'Robert Spalek']
AlgorithmsandTheory
Abstract: We prove a tight quantum query lower bound (n^(k/(k+1))) for the problem of deciding whether there exist k numbers among n that sum up to a prescribed number, provided that the alphabet size is sufficiently large.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37040.html
found
=========================
Applications and Extensions of Alloy: Past, Present, and Future
Mathematical Structures in Computer Science, vol. 23 (2013), pp. 915-933
[u'Emina Torlak', u'Mana Taghdiri', u'Greg Dennis', u'Joseph Near']
AlgorithmsandTheory
Abstract: Alloy is a declarative language for lightweight modelling and analysis of software. The core of the language is based on first-order relational logic, which offers an attractive balance between analysability and expressiveness. The logic is expressive enough to capture the intricacies of real systems, but is also simple enough to support fully automated analysis with the Alloy Analyzer. The Analyzer is built on a SAT-based constraint solver and provides automated simulation, checking and debugging of Alloy specifications. Because of its automated analysis and expressive logic, Alloy has been applied in a wide variety of domains. These applications have motivated a number of extensions both to the Alloy language and to its SAT-based analysis. This paper provides an overview of Alloy in the context of its three largest application domains, lightweight modelling, bounded code verification and test-case generation, and three recent application-driven extensions, an imperative extension to the language, a compiler to executable code and a proof-capable analyser based on SMT.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40757.html
found
=========================
Approximation Algorithms for the Directed k-Tour and k-Stroll Problems
Algorithmica, vol. 65 (2013), pp. 545-561
[u'Mohammadhossein Bateni', u'Julia Chuzhoy']
AlgorithmsandTheory
Abstract: We consider two natural generalizations of the Asymmetric Traveling Salesman problem: the k-Stroll and the k-Tour problems. The input to the k-Stroll problem is a directed n-vertex graph with nonnegative edge lengths, an integer k, as well as two special vertices s and t. The goal is to find a minimum-length s-t walk, containing at least k distinct vertices (including the endpoints s,t). The k-Tour problem can be viewed as a special case of k-Stroll, where s=t. That is, the walk is required to be a tour, containing some pre-specified vertex s. When k=n, the k-Stroll problem becomes equivalent to Asymmetric Traveling Salesman Path, and k-Tour to Asymmetric Traveling Salesman. Our main result is a polylogarithmic approximation algorithm for the k-Stroll problem. Prior to our work, only bicriteria (O(log2 k),3)-approximation algorithms have been known, producing walks whose length is bounded by 3OPT, while the number of vertices visited is ?(k/log2 k). We also show a simple O(log2 n/loglogn)-approximation algorithm for the k-Tour problem. The best previously known approximation algorithms achieved min(O(log3 k),O(log2 n?logk/loglogn)) approximation in polynomial time, and O(log2 k) approximation in quasipolynomial time.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41849.html
found
=========================
Bayes and Big Data: The Consensus Monte Carlo Algorithm
Bayes 250 (2013) (to appear)
[u'Steven L. Scott', u'Alexander W. Blocker', u'Fernando V. Bonassi']
AlgorithmsandTheory
Abstract: A useful definition of ``big data'' is data that is too big to comfortably process on a single machine, either because of processor, memory, or disk bottlenecks. Graphics processing units can alleviate the processor bottleneck, but memory or disk bottlenecks can only be eliminated by splitting data across multiple machines. Communication between large numbers of machines is expensive (regardless of the amount of data being communicated), so there is a need for algorithms that perform distributed approximate Bayesian analyses with minimal communication. Consensus Monte Carlo operates by running a separate Monte Carlo algorithm on each machine, and then averaging individual Monte Carlo draws across machines. Depending on the model, the resulting draws can be nearly indistinguishable from the draws that would have been obtained by running a single machine algorithm for a very long time. Examples of consensus Monte Carlo are shown for simple models where single-machine solutions are available, for large single-layer hierarchical models, and for Bayesian additive regression trees (BART).
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Behavioural reconfigurable and adaptive data reduction in body sensor networks
International Journal of Autonomous and Adaptive Communications Systems, vol. 6 (2013), pp. 207-224
[u'Foad Dabiri', u'Hyduke Noshadi', u'Majid Sarrafzadeh']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42473.html
found
=========================
Best-response dynamics out of sync: complexity and characterization
EC, ACM (2013), pp. 379-396
[u'Roee Engelberg', u'Alex Fabrikant', u'Michael Schapira', u'David Wajc']
AlgorithmsandTheory
Abstract: In many computational and economic models of multi-agent interaction, each participant repeatedly "best-responds" to the others' actions. Game theory research on the prominent "best-response dynamics" model typically relies on the premise that the interaction between agents is somehow synchronized. However, in many real-life settings, e.g., internet protocols and large-scale markets, the interaction between participants is asynchronous. We tackle the following important questions: (1) When are best-response dynamics guaranteed to converge to an equilibrium even under asynchrony? (2) What is the (computational and communication) complexity of verifying guaranteed convergence? We show that, in general, verifying guaranteed convergence is intractable. In fact, our main negative result establishes that this task is undecidable. We exhibit, in contrast, positive results for several environments of interest, including complete, computationally-tractable, characterizations of convergent systems. We discuss the algorithmic implications of our results, which extend beyond best-response dynamics to applications such as asynchronous Boolean circuits.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41699.html
found
=========================
Classifying with Confidence From Incomplete Test Data
Journal Machine Learning Research (JMLR), vol. 14 (2013)
[u'Nathan Parris', u'Hyrum S. Anderson', u'Maya R. Gupta', u'Dun Yu Hsaio']
AlgorithmsandTheory
Abstract: We consider the classification problem given incomplete information about a test sample. This problem arises naturally when data about the test sample is collected over time, or when costs must be incurred to collect the data. For example, in a distributed sensor network only a fraction of the sensors may have reported measurements at a certain time, and either additional time, power, bandwidth or some other cost must be incurred to collect the complete data to classify. A practical goal is to assign a class label as soon as enough data is available to make a good decision. We formalize this goal through the notion of reliability --- the probability that a label assigned to the incomplete data matches the label that would be assigned to the complete data, and we propose a method to classify incomplete data only if some reliability threshold is met. Our approach models the complete data as a random variable whose distribution is dependent on the current incomplete data and the (complete) training data. The method differs from standard imputation strategies in that our focus is on determining the reliability of the classification decision, rather than just the class label. We show that the method provides useful reliability estimates of the correctness of the imputed class labels on a set of experiments on time-series datasets, where the goal is to classify the time-series as early as possible while still guaranteeing that the reliability threshold is met.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40464.html
found
=========================
Clinching Auctions with Online Supply
SODA (2013), pp. 605-619
[u'Gagan Goel', u'Vahab Mirrokni', u'Renato Paes Leme']
AlgorithmsandTheory
Abstract: Auctions for perishable goods such as internet ad inventory need to make real-time allocation and pricing decisions as the supply of the good arrives in an online manner, without knowing the entire supply in advance. These allocation and pricing decisions get complicated when buyers have some global constraints. In this work, we consider a multi-unit model where buyers have global {\em budget} constraints, and the supply arrives in an online manner. Our main contribution is to show that for this setting there is an individually-rational, incentive-compatible and Pareto-optimal auction that allocates these units and calculates prices on the fly, without knowledge of the total supply. We do so by showing that the Adaptive Clinching Auction satisfies a {\em supply-monotonicity} property. We also analyze and discuss, using examples, how the insights gained by the allocation and payment rule can be applied to design better ad allocation heuristics in practice. Finally, while our main technical result concerns multi-unit supply, we propose a formal model of online supply that captures scenarios beyond multi-unit supply and has applications to sponsored search. We conjecture that our results for multi-unit auctions can be extended to these more general models.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41339.html
found
=========================
Cluster forest
Computational Statistics and Data Analysis, vol. 66 (2013), pp. 178-192
[u'Donghui Yan', u'Aiyou Chen', u'Michael I Jordan']
AlgorithmsandTheory
Abstract: With inspiration from Random Forests (RF) in the context of classification, a new clustering ensemble method---Cluster Forests (CF) is proposed. Geometrically, CF randomly probes a high-dimensional data cloud to obtain "good local clusterings" and then aggregates via spectral clustering to obtain cluster assignments for the whole dataset. The search for good local clusterings is guided by a cluster quality measure kappa. CF progressively improves each local clustering in a fashion that resembles the tree growth in RF. Empirical studies on several real-world datasets under two different performance metrics show that CF compares favorably to its competitors. Theoretical analysis reveals that the kappa measure makes it possible to grow the local clustering in a desirable way---it is "noise-resistant". A closed-form expression is obtained for the mis-clustering rate of spectral clustering under a perturbation model, which yields new insights into some aspects of spectral clustering.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40806.html
found
=========================
Design, Implementation and Verification of an eXtensible and Modular Hypervisor Framework
IEEE Symposium on Security and Privacy (2013) (to appear)
[u'Amit Vasudevan', u'Sagar Chaki', u'Limin Jia', u'Jonathan McCune', u'James Newsome', u'Anupam Datta']
AlgorithmsandTheory
Abstract: We present the design, implementation, and verification of XMHF - an eXtensible and Modular Hypervisor Framework. XMHF is designed to achieve three goals - modular extensibility, automated verification, and high performance. XMHF includes a core that provides functionality common to many hypervisor-based security architectures and supports extensions that augment the core with additional security or functional properties while preserving the fundamental hypervisor security property of memory integrity (i.e., ensuring that the hypervisor's memory is not modified by software running at a lower privilege level). We verify the memory integrity of the XMHF core - 6018 lines of code - using a combination of automated and manual techniques. The model checker CBMC automatically verifies 5208 lines of C code in about 80 seconds using less than 2GB of RAM. We manually audit the remaining 422 lines of C code and 388 lines of assembly language code that are stable and unlikely to change as development proceeds. Our experiments indicate that XMHF's performance is comparable to popular high-performance general-purpose hypervisors for the single guest that it supports.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Differences in search engine evaluations between query owners and non-owners
WSDM 2013, ACM, pp. 103-112
[u'Alexandra Chouldechova', u'David Mease']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41408.html
found
=========================
Diversity maximization under matroid constraints
KDD, ACM SIGKDD (2013), pp. 32-40
[u'Zeinab Abbassi', u'Vahab Mirrokni', u'Mayur Thakur']
AlgorithmsandTheory
Abstract: Aggregator websites typically present documents in the form of representative clusters. In order for users to get a broader perspective, it is important to deliver a diversied set of representative documents in those clusters. One approach to diversication is to maximize the average dissimilarity among documents. Another way to capture diversity is to avoid showing several documents from the same category (e.g. from the same news channel). We combine the above two diversication concepts by modeling the latter approach as a (partition) matroid constraint, and study diversity maximization problems under matroid constraints. We present the rst constant-factor approximation algorithm for this problem, using a new technique. Our local search 0:5-approximation algorithm is also the rst constant-factor approximation for the max-dispersion problem under matroid constraints. Our combinatorial proof technique for maximizing diversity under matroid constraints uses the existence of a family of Latin squares which may also be of independent interest. In order to apply these diversity maximization algorithms in the context of aggregator websites and as a preprocessing step for our diversity maximization tool, we develop greedy clustering algorithms that maximize weighted coverage of a predened set of topics. Our algorithms are based on computing a set of cluster centers, where clusters are formed around them. We show the better performance of our algorithms for diversity and coverage maximization by running experiments on real (Twitter) and synthetic data in the context of real-time search over micro-posts. Finally we perform a user study validating our algorithms and diversity metrics.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41896.html
found
=========================
Efficient and Accurate Label Propagation on Dynamic Graphs and Label Sets
International Journal on Advances in Networks and Services, vol. 6 (2013), pp. 246-259
[u'Michele Covell', u'Shumeet Baluja']
AlgorithmsandTheory
Abstract: Many web-based application areas must infer label distributions starting from a small set of sparse, noisy labels. Previous work has shown that graph-based propagation can be very effective at finding the best label distribution across nodes, starting from partial information and a weighted-connection graph. In their work on video recommendations, Baluja et al. showed high-quality results using Adsorption, a normalized propagation process. An important step in the original formulation of Adsorption was re-normalization of the label vectors associated with each node, between every propagation step. That interleaved normalization forced computation of all label distributions, in synchrony, in order to allow the normalization to be correctly determined. Interleaved normalization also prevented use of standard linear-algebra methods, like stabilized bi-conjugate gradient descent (BiCGStab) and Gaussian elimination. We show how to replace the interleaved normalization with a single pre-normalization, done once before the main propagation process starts, allowing use of selective label computation (label slicing) as well as large-matrix-solution methods. As a result, much larger graphs and label sets can be handled than in the original formulation and more accurate solutions can be found in fewer propagation steps. We further extend that work to handle graphs that change and expand over time. We report results from using pre-normalized Adsorption in topic labeling for web domains, using label slicing and BiCGStab. We also report results from using incremental updates on changing co-author network data. Finally, we discuss two options for handling mixed-sign (positive and negative) graphs and labels.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41144.html
found
=========================
Efficient and Accurate Label Propagation on Large Graphs and Label Sets
Proceedings International Conference on Advances in Multimedia, IARIA (2013)
[u'Michele Covell', u'Shumeet Baluja']
AlgorithmsandTheory
Abstract: Many web-based application areas must infer label distributions starting from a small set of sparse, noisy labels. Examples include searching for, recommending, and advertising against image, audio, and video content. These labeling problems must handle millions of interconnected entities (users, domains, content segments) and thousands of competing labels (interests, tags, recommendations, topics). Previous work has shown that graph-based propagation can be very effective at finding the best label distribution across nodes, starting from partial information and a weighted-connection graph. In their work on video recommendations, Baluja et al. [1] showed high-quality results using Adsorption, a normalized propagation process. An important step in the original formulation of Adsorption was re-normalization of the label vectors associated with each node, between every propagation step. That interleaved normalization forced computation of all label distributions, in synchrony, in order to allow the normalization to be correctly determined. Interleaved normalization also prevented use of standard linear-algebra methods, like stabilized bi-conjugate gradient descent (BiCGStab) and Gaussian elimination. This paper presents a method that replaces the interleaved normalization with a single pre-normalization, done once before the main propagation process starts, allowing use of selective label computation (label slicing) as well as large-matrix-solution methods. As a result, much larger graphs and label sets can be handled than in the original formulation and more accurate solutions can be found in fewer propagation steps. We also report results from using pre-normalized Adsorption in topic labeling for web domains, using label slicing and BiCGStab.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Efficient controller synthesis for a fragment of MTL
Acta Informatica, vol. 50 (2013), pp. 1-28
[u'Peter Bulychev', u'Alexandre David', u'Kim G. Larsen', u'Guangyuan Li']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41466.html
found
=========================
Fastfood - Approximating Kernel Expansions in Loglinear Time
30th International Conference on Machine Learning (ICML), Omnipress (2013)
[u'Quoc Le', u'Tamas Sarlos', u'Alex Smola']
AlgorithmsandTheory
Abstract: Fast nonlinear function classes are crucial for nonparametric estimation, such as in kernel methods. This paper proposes an improvement to random kitchen sinks that offers significantly faster computation in log-linear time without sacrificing accuracy. Furthermore, we show how one may adjust the regularization properties of the kernel simply by changing the spectral distribution of the projection matrix. We provide experimental results which show that even for for moderately small problems we already achieve two orders of magnitude faster computation and three orders of magnitude lower memory footprint.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41763.html
found
=========================
GOOGLE DISEASE TRENDS: AN UPDATE
International Society of Neglected Tropical Diseases 2013, International Society of Neglected Tropical Diseases, pp. 3
[u'Patrick Copeland', u'Raquel Romano', u'Tom Zhang', u'Greg Hecht', u'Dan Zigmond', u'Christian Stefansen']
AlgorithmsandTheory
Abstract: The purpose of Google Flu Trends (GFT) is to use search keyword trends from Google.com to produce a daily estimate, or nowcast, of the occurrence of flu two weeks in advance of publication of official surveillance data. While not covered in detail in this paper, Google Dengue Trends, launched in June 2011, is a service that uses similar techniques to track Dengue fever. During the 2012 flu season we observed our algorithm overestimating influenza-like illness (ILI). We have concluded that our algorithm for Flu and Dengue were susceptible to heightened media coverage and have since developed several improvements.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42474.html
found
=========================
How to grow more pairs: suggesting review targets for comparison-friendly review ecosystems
WWW (2013), pp. 237-248
[u'James Cook', u'Alex Fabrikant', u'Avinatan Hassidim']
AlgorithmsandTheory
Abstract: We consider the algorithmic challenges behind a novel interface that simplifies consumer research of online reviews by surfacing relevant comparable review bundles: reviews for two or more of the items being researched, all generated in similar enough circumstances to provide for easy comparison. This can be reviews by the same reviewer, or by the same demographic category of reviewer, or reviews focusing on the same aspect of the items. But such an interface will work only if the review ecosystem often has comparable review bundles for common research tasks. Here, we develop and evaluate practical algorithms for suggesting additional review targets to reviewers to maximize comparable pair coverage, the fraction of co-researched pairs of items that have both been reviewed by the same reviewer (or more generally are comparable in one of several ways). We show the exact problem and many subcases to be intractable, and give a greedy online, linear-time 2-approximation for a very general setting, and an offline 1.583-approximation for a narrower setting. We evaluate the algorithms on the Google+ Local reviews dataset, yielding more than 10x gain in pair coverage from six months of simulated replacement of existing reviews by suggested reviews. Even allowing for 90% of reviewers ignoring the suggestions, the pair coverage grows more than 2x in the simulation. To explore other parts of the parameter space, we also evaluate the algorithms on synthetic models.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40671.html
found
=========================
HyperLogLog in Practice: Algorithmic Engineering of a State of The Art Cardinality Estimation Algorithm
Proceedings of the EDBT 2013 Conference, ACM, Genoa, Italy (to appear)
[u'Stefan Heule', u'Marc Nunkesser', u'Alex Hall']
AlgorithmsandTheory
Abstract: Cardinality estimation has a wide range of applications and is of particular importance in database systems. Various algorithms have been proposed in the past, and the HyperLogLog algorithm is one of them. In this paper, we present a series of improvements to this algorithm that reduce its memory requirements and signi?cantly increase its accuracy for an important range of cardinalities. We have implemented our proposed algorithm for a system at Google and evaluated it empirically, comparing it to the original HyperLogLog algorithm. Like HyperLogLog, our improved algorithm parallelizes perfectly and computes the cardinality estimate in a single pass.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Identifying Surrogate Geographic Research Regions with Advanced Exact Test Statistics
American Marketing Association Advanced Research Techniques Forum (2013), Poster
[u'Steven Ellis']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Image Compression via Colorization Using Semi-Regular Color Samples
Data Compression Conference (2013)
[u'Chenguang Zhang', u'Hui Fang']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41135.html
found
=========================
Improved Approximation Algorithms for (Budgeted) Node-weighted Steiner Problems
ICALP, Springer (2013)
[u'Mohammadhossein Bateni', u'MohammadTaghi Hajiaghayi', u'Vahid Liaghat']
AlgorithmsandTheory
Abstract: Moss and Rabani [12] study constrained node-weighted Steiner tree problems with two independent weight values associated with each node, namely, cost and prize (or penalty). They give an O(logn)-approximation algorithm for the prize-collecting node-weighted Steiner tree problem (PCST)
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Large Scale SVD and Manifold Learning
Journal of Machine Learning Research (JMLR) (2013)
[u'Ameet Talwalkar', u'Sanjiv Kumar', u'Mehryar Morhri', u'Henry A. Rowley']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42185.html
found
=========================
Mechanism Design for Fair Division: Allocating Divisible Items without Payments
EC 2013, ACM
[u'Richard Cole', u'Vasilis Gkatzelis', u'Gagan Goel']
AlgorithmsandTheory
Abstract: We revisit the classic problem of fair division from a mechanism design perspective, using Proportional Fairness as a benchmark. In particular, we aim to allocate a collection of divisible items to a set of agents while incentivizing the agents to be truthful in reporting their valuations. For the very large class of homogeneous valuations, we design a truthful mechanism that provides every agent with at least 0.368 fraction of her Proportionally Fair valuation. To complement this result, we show that no truthful mechanism can guarantee more than a 0.5 fraction, even for the restricted class of additive linear valuations. We also propose another mechanism for additive linear valuations that works really well when every item is highly demanded. To guarantee truthfulness, our mechanisms discard a carefully chosen fraction of the allocated resources; we conclude by uncovering interesting connections between our mechanisms and known mechanisms that use money instead.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41859.html
found
=========================
Minimax Optimal Algorithms for Unconstrained Linear Optimization
Advances in Neural Information Processing Systems (NIPS) (2013)
[u'H. Brendan McMahan', u'Jacob Abernethy']
AlgorithmsandTheory
Abstract: We design and analyze minimax-optimal algorithms for online linear optimization games where the player's choice is unconstrained. The player strives to minimize regret, the difference between his loss and the loss of a post-hoc benchmark strategy. While the standard benchmark is the loss of the best strategy chosen from a bounded comparator set, we consider a very broad range of benchmark functions. The problem is cast as a sequential multi-stage zero-sum game, and we give a thorough analysis of the minimax behavior of the game, providing characterizations for the value of the game, as well as both the player's and the adversary's optimal strategy. We show how these objects can be computed efficiently under certain circumstances, and by selecting an appropriate benchmark, we construct a novel hedging strategy for an unconstrained betting game.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40493.html
found
=========================
Minimizing weighted flowtime on capacitated machines
ACM-SIAM Symposium on Discrete Algorithms (SODA) (2013)
[u'Kyle Fox', u'Madhukar Korupolu']
AlgorithmsandTheory
Abstract: It is well-known that SRPT is optimal for minimizing flow time on machines that run one job at a time. However, running one job at a time is a big under- utilization for modern systems where sharing, simultane- ous execution, and virtualization-enabled consolidation are a common trend to boost utilization. Such machines, used in modern large data centers and clouds, are powerful enough to run multiple jobs/VMs at a time subject to overall CPU, memory, network, and disk capacity constraints. Motivated by this prominent trend and need, in this work, we give the first scheduling algorithms to minimize weighted flow time on such capacitated machines. To capture the difficulty of the problem, we show that without resource augmentation, no online algorithm can achieve a bounded competitive ratio. We then investigate algorithms with a small resource augmentation in speed and/or capacity. Our first result is a simple (2 + )- capacity O(1/)-competitive greedy algorithm. Using only speed augmentation, we then obtain a 1.75-speed O(1)-competitive algorithm. Our main technical result is a near-optimal (1 + )-speed, (1 + )-capacity O(1/3 )- competitive algorithm using a novel combination of knapsacks, densities, job classification into categories, and potential function methods. We show that our results also extend to the multiple unrelated capacitated machines setting.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43982.html
found
=========================
Mixin' up the ML module system
Transactions on Programming Languages and Systems, vol. 35 (1) (2013)
[u'Andreas Rossberg', u'Derek Dreyer']
AlgorithmsandTheory
Abstract: ML modules provide hierarchical namespace management, as well as fine-grained control over the propagation of type information, but they do not allow modules to be broken up into mutually recursive, separately compilable components. Mixin modules facilitate recursive linking of separately compiled components, but they are not hierarchically composable and typically do not support type abstraction. We synthesize the complementary advantages of these two mechanisms in a novel module system design we call MixML. A MixML module is like an ML structure in which some of the components are specified but not defined. In other words, it unifies the ML structure and signature languages into one. MixML seamlessly integrates hierarchical composition, translucent ML-style data abstraction, and mixin-style recursive linking. Moreover, the design of MixML is clean and minimalist; it emphasizes how all the salient, semantically interesting features of the ML module system (and several proposed extensions to it) can be understood simply as stylized uses of a small set of orthogonal underlying constructs, with mixin composition playing a central role. We provide a declarative type system for MixML, including two important extensions: higher-order modules, and modules as first-class values. We also present a sound and complete, three-pass type checking algorithm for this system. The operational semantics of MixML is defined by an elaboration translation into an internal core language called LTG namely, a polymorphic lambda calculus with single-assignment references and recursive type generativity which employs a linear type and kind system to track definedness of term and type imports.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41333.html
found
=========================
Neighborhood Preserving Codes for Assigning Point Labels: Applications to Stochastic Search
Procedia Computer Science: 2013 International Conference on Computational Science, Elsevier, pp. 956-965
[u'Shumeet Baluja', u'Michele Covell']
AlgorithmsandTheory
Abstract: Selecting a good representation of a solution-space is vital to solving any search and optimization problem. In particular, once regions of high performance are found, having the property that small changes in the candidate solution correspond to searching nearby neighborhoods provides the ability to perform effective local optimization. To achieve this, it is common for stochastic search algorithms, such as stochastic hillclimbing, evolutionary algorithms (including genetic algorithms), and simulated annealing, to employ Gray Codes for encoding ordinal points or discretized real numbers. In this paper, we present a novel method to label similar and/or close points within arbitrary graphs with small Hamming distances. The resultant point labels can be seen as an approximate high-dimensional variant of Gray Codes with standard Gray Codes as a subset of the labels found here. The labeling procedure is applicable to any task in which the solution requires the search algorithm to select a small subset of items out of many. Such tasks include vertex selection in graphs, knapsack-constrained item selection, bin packing, prototype selection for machine learning, and numerous scheduling problems, to name a few.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41097.html
found
=========================
On the k-atomicity-verification problem
The 33rd International Conference on Distributed Computing Systems, IEEE (2013)
[u'Wojciech Golab', u'Jeremy Hurwitz', u'Xiaozhou Li']
AlgorithmsandTheory
Abstract: Modern Internet-scale storage systems often provide weak consistency in exchange for better perfor- mance and resilience. An important weak consistency prop- erty is k-atomicity, which bounds the staleness of values returned by read operations. The k-atomicity-verification problem (or k-AV for short) is the problem of deciding whether a given history of operations is k-atomic. The 1-AV problem is equivalent to verifying atomicity/linearizability, a well-known and solved problem. However, for k ? 2, no polynomial-time k-AV algorithm is known. This paper makes the following contributions towards solving the k-AV problem. First, we present a simple 2- AV algorithm called LBT, which is likely to be efficient (quasilinear) for histories that arise in practice, although it is less efficient (quadratic) in the worst case. Second, we present a more involved 2-AV algorithm called FZF, which runs efficiently (quasilinear) even in the worst case. To our knowledge, these are the first algorithms that solve the 2-AV problem fully. Third, we show that the weighted k-AV problem, a natural extension of the k-AV problem, is NP-complete.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42472.html
found
=========================
On the structure of weakly acyclic games
Theory of Computing Systems, vol. 53 (2013), pp. 107-122
[u'Alex Fabrikant', u'Aaron D Jaggard', u'Michael Schapira']
AlgorithmsandTheory
Abstract: The class of weakly acyclic games, which includes potential games and dominance-solvable games, captures many practical application domains. In a weakly acyclic game, from any starting state, there is a sequence of better-response moves that leads to a pure Nash equilibrium; informally, these are games in which natural distributed dynamics, such as better-response dynamics, cannot enter inescapable oscillations. We establish a novel link between such games and the existence of pure Nash equilibria in subgames. Specifically, we show that the existence of a unique pure Nash equilibrium in every subgame implies the weak acyclicity of a game. In contrast, the possible existence of multiple pure Nash equilibria in every subgame is insufficient for weak acyclicity in general; here, we also systematically identify the special cases (in terms of the number of players and strategies) for which this is sufficient to guarantee weak acyclicity.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Online Matching and Ad Allocation
Foundations and Trends in Theoretical Computer Science, vol. 8 (4) (2013), pp. 265-368
[u'Aranyak Mehta']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41465.html
found
=========================
Optimal Hashing Schemes for Entity Matching
22nd International World Wide Web Conference, WWW '13, ACM, Rio de Janeiro, Brazil (2013), pp. 295-306
[u'Nilesh Dalvi', u'Vibhor Rastogi', u'Anirban Dasgupta', u'Anish Das Sarma', u'Tamas Sarlos']
AlgorithmsandTheory
Abstract: In this paper, we consider the problem of devising blocking schemes for entity matching. There is a lot of work on blocking techniques for supporting various kinds of predicates, e.g. exact matches, fuzzy string-similarity matches, and spatial matches. However, given a complex entity matching function in the form of a Boolean expression over several such predicates, we show that it is an important and non-trivial problem to combine the individual blocking techniques into an efficient blocking scheme for the entity matching function, a problem that has not been studied previously. In this paper, we make fundamental contributions to this problem. We consider an abstraction for modeling complex entity matching functions as well as blocking schemes. We present several results of theoretical and practical interest for the problem. We show that in general, the problem of computing the optimal blocking strategy is NP-hard in the size of the DNF formula describing the matching function. We also present several algorithms for computing the exact optimal strategies (with exponential complexity, but often feasible in practice) as well as fast approximation algorithms. We experimentally demonstrate over commercially used rule-based matching systems over real datasets at Yahoo!, as well as synthetic datasets, that our blocking strategies can be an order of magnitude faster than the baseline methods, and our algorithms can efficiently find good blocking strategies.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40804.html
found
=========================
Optimizing Budget Constrained Spend in Search Advertising
Sixth ACM International Conference on Web Search and Data Mining, WSDM 2013, ACM, pp. 697-706
[u'Chinmay Karande', u'Aranyak Mehta', u'Ramakrishnan Srikant']
AlgorithmsandTheory
Abstract: Search engine ad auctions typically have a significant fraction of advertisers who are budget constrained, i.e., if allowed to participate in every auction that they bid on, they would spend more than their budget. This yields an important problem: selecting the ad auctions in which these advertisers participate, in order to optimize different system objectives such as the return on investment for advertisers, and the quality of ads shown to users. We present a system and algorithms for optimizing such budget constrained spend. The system is designed be deployed in a large search engine, with hundreds of thousands of advertisers, millions of searches per hour, and with the query stream being only partially predictable. We have validated the system design by implementing it in the Google ads serving system and running experiments on live traffic. We have also compared our algorithm to previous work that casts this problem as a large linear programming problem limited to popular queries, and show that our algorithms yield substantially better results.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
PASS Approximation: A Framework for Analyzing and Designing Heuristics.
Algorithmica, vol. 450-478 (2013)
[u'Uri Feige', u'Nicole Immorlica', u'Vahab Mirrokni', u'Hamid Nazerzadeh']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40700.html
found
=========================
Pay by the Bit: An Information-Theoretic Metric for Collective Human Judgment
Proc CSCW, ACM, ACM New York, NY, USA (2013), pp. 623-638
[u'Tamsyn P. Waterhouse']
AlgorithmsandTheory
Abstract: We consider the problem of evaluating the performance of human contributors for tasks involving answering a series of questions, each of which has a single correct answer. The answers may not be known a priori. We assert that the measure of a contributor's judgments is the amount by which having these judgments decreases the entropy of our discovering the answer. This quantity is the pointwise mutual information between the judgments and the answer. The expected value of this metric is the mutual information between the contributor and the answer prior, which can be computed using only the prior and the conditional probabilities of the contributor's judgments given a correct answer, without knowing the answers themselves. We also propose using multivariable information measures, such as conditional mutual information, to measure the interactions between contributors' judgments. These metrics have a variety of applications. They can be used as a basis for contributor performance evaluation and incentives. They can be used to measure the efficiency of the judgment collection process. If the collection process allows assignment of contributors to questions, they can also be used to optimize this scheduling.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41884.html
found
=========================
Performance tournaments with crowdsourced judges
Proceedings of the American Statistical Association, section on marketing statistics, American Statistical Association, 732 North Washtington Street, Alexandria, VA 22314-1943 (2013)
[u'Daryl Pregibon', u'Williiam D Heavlin']
AlgorithmsandTheory
Abstract: A performance slam is a competition among a fixed set of performances whereby pairs of performances are judged by audience participants. When performances are recorded on electronic media, performance slams become amenable to audiences that watch online and judge asynchronously (crowdsourced). In order to better entertain the audience, we want to show the better performances (exploitation). In order to identify the good videos, we want to glean a least some information about all videos (exploration). Our approach has three elements: (1) We take our preference model from Bradley and Terry (1952). (2) Its parameters we calculate by rewriting the likelihood gradient into a fixed point estimate, one which mimics the estimate of Mantel and Haenszel (1959). (3) Each pair of performances is chosen sequentially, always chosen to minimize the weighted variance of (the logarithms of) the Bradley-Terry parameter estimates. Our preferred weights consist of the logrank weights proposed by Savage (1956).
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41468.html
found
=========================
Permutation Indexing: Fast Approximate Retrieval from Large Corpora
22nd International Conference on Information and Knowledge Management (CIKM), ACM (2013)
[u'Maxim Gurevich', u'Tamas Sarlos']
AlgorithmsandTheory
Abstract: Inverted indexing is a ubiquitous technique used in retrieval systems including web search. Despite its popularity, it has a drawback - query retrieval time is highly variable and grows with the corpus size. In this work we propose an alternative technique, permutation indexing, where retrieval cost is strictly bounded and has only logarithmic dependence on the corpus size. Our approach is based on two novel techniques: partitioning of the term space into overlapping clusters of terms that frequently co-occur in queries, and a data structure for compactly encoding results of all queries composed of terms in a cluster as continuous sequences of document ids. Then, query results are retrieved by fetching few small chunks of these sequences. There is a price though: our encoding is lossy and thus returns approximate result sets. The fraction of the true results returned, recall, is controlled by the level of redundancy. The more space is allocated for the permutation index the higher is the recall. We analyze permutation indexing both theoretically under simplified document and query models, and empirically on a realistic document and query collections. We show that although permutation indexing can not replace traditional retrieval methods, since high recall cannot be guaranteed on all queries, it covers up to 77% of tail queries and can be used to speed up retrieval for these queries.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41332.html
found
=========================
Point Representation for Local Optimization: Towards Multi-Dimensional Gray Codes
Proceedings IEEE Congress on Evolutionary Computation, IEEE (2013)
[u'Shumeet Baluja', u'Michele Covell']
AlgorithmsandTheory
Abstract: In the context of stochastic search, once regions of high performance are found, having the property that small changes in the candidate solution correspond to searching nearby neighborhoods provides the ability to perform effective local optimization. To achieve this, Gray Codes are often employed for encoding ordinal points or discretized real numbers. In this paper, we present a method to label similar and/or close points within arbitrary graphs with small Hamming distances. The resultant point labels can be viewed as an approximate high-dimensional variant of Gray Codes. The labeling procedure is useful for any task in which the solution requires the search algorithm to select a small subset of items out of many. A large number of empirical results using these encodings with a combination of genetic algorithms and hill-climbing are presented.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Positive Results for Mechanism Design without Money
AAMAS (2013)
[u'Richard Cole', u'Vasilis Gkatzelis', u'Gagan Goel']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40697.html
found
=========================
Pseudo-likelihood methods for community detection in large sparse networks
Annals of Statistics (2013), pp. 1-27
[u'Arash A Amini', u'Aiyou Chen', u'Peter Bickel', u'Liza Levina']
AlgorithmsandTheory
Abstract: Many algorithms have been proposed for fitting network models with communities but most of them do not scale well to large networks, and often fail on sparse networks. Here we propose a new fast pseudo-likelihood method for fitting the stochastic block model for networks, as well as a variant that allows for an arbitrary degree distribution by conditioning on degrees. We show that the algorithms perform well under a range of settings, including on very sparse networks, and illustrate on the example of a network of political blogs. We also propose spectral clustering with perturbations, a method of independent interest, which works well on sparse networks where regular spectral clustering fails, and use it to provide an initial value for pseudo-likelihood.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Reporting Neighbors in High-Dimensional Euclidean Space
SODA (2013)
[u'Dror Aiger', u'Haim Kaplan', u'Micha Sharir']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Revenue Maximization with Nonexcludable Goods
Internet and Network Economics - 9th International Workshop, WINE 2013, Springer
[u'Mohammadhossein Bateni', u'Nima Haghpanah', u'Balasubramanian Sivan', u'Morteza Zadimoghaddam']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41467.html
found
=========================
Scalable all-pairs similarity search in metric spaces
Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining, ACM, 2 Pennsylvania Plaza, New York, NY (2013), pp. 829-837
[u'Ye Wang', u'Ahmed Metwally', u'Srinivasan Parthasarathy']
AlgorithmsandTheory
Abstract: Given a set of entities, the all-pairs similarity search aims at identifying all pairs of entities that have similarity greater than (or distance smaller than) some user-defined threshold. In this article, we propose a parallel framework for solving this problem in metric spaces. Novel elements of our solution include: i) flexible support for multiple metrics of interest; ii) an autonomic approach to partition the input dataset with minimal redundancy to achieve good load-balance in the presence of limited computing resources; iii) an on-the- fly lossless compression strategy to reduce both the running time and the final output size. We validate the utility, scalability and the effectiveness of the approach on hundreds of machines using real and synthetic datasets.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Shortest paths avoiding forbidden subpaths
Networks, vol. 61 (2013), pp. 322-334
[u'Mustaq Ahmed', u'Anna Lubiw']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41697.html
found
=========================
Similarity-based Clustering by Left-Stochastic Matrix Factorization
Journal Machine Learning Research (JMLR), vol. 14 (2013), pp. 1715-1746
[u'Raman Arora', u'Maya R. Gupta', u'Amol Kapila', u'Maryam Fazel']
AlgorithmsandTheory
Abstract: For similarity-based clustering, we propose modeling the entries of a given similarity matrix as the inner products of the unknown cluster probabilities. To estimate the cluster probabilities from the given similarity matrix, we introduce a left-stochastic non-negative matrix factorization problem. A rotation-based algorithm is proposed for the matrix factorization. Conditions for unique matrix factorizations and clusterings are given, and an error bound is provided. The algorithm is particularly efficient for the case of two clusters, which motivates a hierarchical variant for cases where the number of desired clusters is large. Experiments show that the proposed left-stochastic decomposition clustering model produces relatively high within-cluster similarity on most data sets and can match given class labels, and that the efficient hierarchical variant performs surprisingly well.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Submodular secretary problems with extensions
ACM Transactions on Algorithms, vol. 9 (4) (2013)
[u'Mohammadhossein Bateni', u'MohammadTaghi Hajiaghayi', u'Morteza Zadimoghaddam']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Summarization Through Submodularity and Dispersion
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL) (2013)
[u'Anirban Dasgupta', u'Ravi Kumar', u'Sujith Ravi']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42182.html
found
=========================
System and method for determining active topics
Patent (2013)
[u'Michael Jeffrey Procopio']
AlgorithmsandTheory
Abstract: A method for determining active topics may include receiving topic information for a document, the information including at least one topic and a weight for each topic, where the topic relates to content of the document, and the weight represents how strongly the topic is associated with the document. User activity information for the document, including a user activity value including at least one of a number of viewers and a number of editors of the document may be received. A topic intensity for each topic may be generated and stored by multiplying the user activity value for the document by the weight of the topic in the document. The topic intensity may be monitored over time. An alert may be generated based on the topic intensity.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41669.html
found
=========================
The Optimal Mix of TV and Online Ads to Maximize Reach
research.google.com, 76 Ninth Avenue (2013), pp. 1-16
[u'Yuxue Jin', u'Jim Koehler', u'Georg M. Goerg', u'Nicolas Remy']
AlgorithmsandTheory
Abstract: Brand marketers often wonder how they should allocate budget between TV and online ads in order to maximize reach or maintain the same reach at a lower cost. We use probability models based on historical cross media panel data to suggest the optimal budget allocation between TV and online ads to maximize reach to the target demographics. We take a historical TV campaign and estimate the reach and GRPs of a hypothetical cross-media campaign if some budget was shifted from TV to online. The models are validated against simulations and historical cross-media campaigns. They are illustrated on one case study to show how an optimized cross-media campaign can obtain a higher reach at the same cost or maintain the same reach at a lower cost than the TV-only campaign.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
The Structure, Efficacy, and Manipulation of Double-Elimination Tournaments
Journal of Quantitative Analysis of Sports (2013)
[u'Isabelle Stanton', u'Virginia Vassilevska Williams']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41544.html
found
=========================
The non-adaptive query complexity of testing k-parities
Chicago Journal of Theoretical Computer Science, vol. 2013 (2013), pp. 1-11
[u'Harry Buhrman', u'David Garcia', u'Arie Matsliah', u'Ronald de Wolf']
AlgorithmsandTheory
Abstract: We prove tight bounds of (klogk) queries for non-adaptively testing whether a function f:{0,1}^n{0,1} is a k-parity or far from any k-parity. The lower bound combines a recent method of Blais, Brody and Matulef to get lower bounds for testing from communication complexity with an (klogk) lower bound for the one-way communication complexity of k-disjointness.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40815.html
found
=========================
Top-k Publish-Subscribe for Social Annotation of News
Proceedings of the 39th International Conference on Very Large Data Bases, VLDB Endowment (2013)
[u'Alexander Shraer', u'Maxim Gurevich', u'Marcus Fontoura', u'Vanja Josifovski']
AlgorithmsandTheory
Abstract: Social content, such as Twitter updates, often have the quickest first-hand reports of news events, as well as numerous commentaries that are indicative of public view of such events. As such, social updates provide a good complement to professionally written news articles. In this paper we consider the problem of automatically annotating news stories with social updates (tweets), at a news website serving high volume of pageviews. The high rate of both the pageviews (millions to billions a day) and of the incoming tweets (more than 100 millions a day) make real-time indexing of tweets ineffective, as this requires an index that is both queried and updated extremely frequently. The rate of tweet updates makes caching techniques almost unusable since the cache would become stale very quickly. We propose a novel architecture where each story is treated as a subscription for tweets relevant to the story's content, and new algorithms that efficiently match tweets to stories, proactively maintaining the top-k tweets for each story. Such {\em top-k pub-sub} consumes only a small fraction of the resource cost of alternative solutions, and can be applicable to other large scale content-based publish-subscribe problems. We demonstrate the effectiveness of our approach on real-world data: a corpus of news stories from Yahoo! News and a log of Twitter updates.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Two-stage Robust Network Design with Exponential Scenarios
Algorithmica, vol. 65 (2013), pp. 391-408
[u'Rohit Khandekar', u'Guy Kortsarz', u'Vahab S. Mirrokni', u'Mohammad R. Salavatipour']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42038.html
found
=========================
Verified Boot on Chrome OS and How to do it yourself
Embedded Linux Conference Europe, Linux Foundation, 660 York Street, Suite 102, San Francisco, CA 94110, USA (2013)
[u'Simon Glass']
AlgorithmsandTheory
Abstract: Chrome OS uses a first stage read-only firmware and second-stage updatable firmware. The updatable firmware is signed and contains kernel keys and a dm-verify hash, so that the firmware, Linux kernel and root filesystem are all protected against corruption and attack. This system is described and discussed. As part of Google's upstream efforts in U-Boot, a generalized secure boot system has been developed and released with U-Boot 2013.07. This implementation uses the FIT format, which collects together images, such as kernels, device tree, RAM disks. Support is provided for TPMs (Trust Platform Module), RSA-based signing and verificaiton, and hashing with hardware acceleration. This system is also described and discussed, along with the specific steps needed to implement it in your designs.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Whole-page optimization and submodular welfare maximization with online bidders
ACM Conference on Electronic Commerce (EC) 2013, pp. 305-322
[u'Nikhil Devanur', u'Zhiyi Huang', u'Nitish Korula', u'Vahab Mirrokni', u'Qiqi Yan']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
2012: Recent Books and Journals in Public Opinion, Survey Methods, and Survey Statistics
Survey Practice, vol. April (2012)
[u'Mario Callegaro']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40603.html
found
=========================
A QCQP Approach to Triangulation
European Conference on Computer Vision, Springer Verlag (2012)
[u'Chris Aholt', u'Rekha Thomas', u'Sameer Agarwal']
AlgorithmsandTheory
Abstract: Triangulation of a three-dimensional point from n >=2 two-dimensional images can be formulated as a quadratically constrained quadratic program. We propose an algorithm to extract candidate solutions to this problem from its semidefinite programming relaxations. We then describe a sucient condition and a polynomial time test for certifying when such a solution is optimal. This test has no false positives. Experiments indicate that false negatives are rare, and the algorithm has excellent performance in practice. We explain this phenomenon in terms of the geometry of the triangulation problem.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Theoretical Examination of Practical Game Playing: Lookahead Search
SAGT (2012), pp. 251-262
[u'Vahab S. Mirrokni', u'Nithum Thain', u'Adrian Vetta']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A polynomial-time approximation scheme for planar multiway cut
Proceedings of the 23rd Annual ACM-SIAM Symposium on Discrete Algorithms (SODA) (2012)
[u'Mohammadhossein Bateni', u'MohammadTaghi Hajiaghayi', u'Philip Klein', u'Claire Mathieu']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40392.html
found
=========================
A practical comparison of the bivariate probit and linear IV estimators
Economics Letters, vol. 117 (2012), pp. 762-766
[u'Richard C. Chiburis', u'Jishnu Das', u'Michael Lokshin']
AlgorithmsandTheory
Abstract: This paper compares asymptotic and finite sample properties of linear IV and bivariate probit in models with an endogenous binary treatment and binary outcome. The results provide guidance on the choice of model specification and help to explain large differences in the estimates depending on the specification chosen.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40498.html
found
=========================
Accuracy at the Top
NIPS: Neural Information Processing Systems Foundation (2012)
[u'Stephen Boyd', u'Corinna Cortes', u'Mehryar Mohri', u'Ana Radovanovic']
AlgorithmsandTheory
Abstract: We introduce a new notion of classication accuracy based on the top -quantile values of a scoring function, a relevant criterion in a number of problems arising for search engines. We dene an algorithm optimizing a convex surrogate of the corresponding loss, and show how its solution can be obtained by solving a set of convex optimization problems. We also present margin-based guarantees for this algorithm based on the top -quantile of the scores of the functions in the hypothesis set. Finally, we report the results of several experiments in the bipartite setting evaluating the performance of our algorithm and comparing the results to several other algorithms seeking high precision at the top. In most examples, our algorithm achieves a better performance in precision at the top.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Ad auctions with data
INFOCOM Workshops (2012), pp. 184-189
[u'Hu Fu', u'Patrick R. Jordan', u'Mohammad Mahdian', u'Uri Nadav', u'Inbal Talgam-Cohen', u'Sergei Vassilvitskii']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub39973.html
found
=========================
Algorithmic Thermodynamics
Mathematical Structures in Computer Science, vol. 22 (2012), pp. 771-787
[u'John Baez', u'Michael Stay']
AlgorithmsandTheory
Abstract: Algorithmic entropy can be seen as a special case of entropy as studied in statistical mechanics. This viewpoint allows us to apply many techniques developed for use in thermodynamics to the subject of algorithmic information theory. In particular, suppose we fix a universal prefix-free Turing machine and let X be the set of programs that halt for this machine. Then we can regard X as a set of 'microstates', and treat any function on X as an 'observable'. For any collection of observables, we can study the Gibbs ensemble that maximizes entropy subject to constraints on expected values of these observables. We illustrate this by taking the log runtime, length, and output of a program as observables analogous to the energy E, volume V and number of molecules N in a container of gas. The conjugate variables of these observables allow us to define quantities which we call the 'algorithmic temperature' T, 'algorithmic pressure' P and algorithmic potential' mu, since they are analogous to the temperature, pressure and chemical potential. We derive an analogue of the fundamental thermodynamic relation dE = T dS - P d V + mu dN, and use it to study thermodynamic cycles analogous to those for heat engines. We also investigate the values of T, P and mu for which the partition function converges. At some points on the boundary of this domain of convergence, the partition function becomes uncomputable. Indeed, at these points the partition function itself has nontrivial algorithmic entropy.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Beyond myopic best response (in Cournot competition)
Proceedings of the Twenty-Third Annual ACM-SIAM Symposium on Discrete Algorithms, SIAM (2012), pp. 993-1005
[u'Amos Fiat', u'Elias Koutsoupias', u'Katrina Ligett', u'Yishay Mansour', u'Svetlana Olonetsky']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38395.html
found
=========================
Budget-Constrained Auctions with Heterogeneous Items
Theory of Computing, vol. 8 (2012), pp. 429-460
[u'Sayan Bhattacharya', u'Gagan Goel', u'Sreenivas Gollapudi', u'Kamesh Munagala']
AlgorithmsandTheory
Abstract: We present the rst approximation algorithms for designing revenue-optimal incentive-compatible mechanisms in the following setting: There are multiple (heterogeneous) items, and bidders have arbitrary demand and budget constraints (and additive valuations). Furthermore, the type of a bidder (which species her valuations for each item) is private knowledge, and the types of different bidders are drawn from publicly known mutually independent distributions. Our mechanisms are surprisingly simple. First, we assume that the type of each bidder is drawn from a discrete distribution with polynomially bounded support size. This restriction on the type-distribution, however, allows the random variables corresponding to a bidders valuations for different items to be arbitrarily correlated. In this model, we describe a sequential all-pay mechanism that is truthful in expectation and Bayesian incentive compatible. The outcome of our all-pay mechanism can be computed in polynomial time, and its revenue is a 4-approximation to the revenue of the optimal truthful-in-expectation Bayesian incentive-compatible mechanism. Next, we assume that the valuations of each bidder for different items are drawn from mutually independent discrete distributions satisfying the monotone hazard-rate condition. In this model, we present a sequential posted-price mechanism that is universally truthful and incentive compatible in dominant strategies. The outcome of the mechanism is computable in polynomial time, and its revenue is a O(1)-approximation to the revenue of the optimal truthful-in-expectation Bayesian incentive-compatible mechanism. If the monotone hazard-rate condition is removed, then we show a logarithmic approximation, and we complete the picture by proving that no sequential posted-price scheme can achieve a sub-logarithmic approximation. Finally, if the distributions are regular, and if the space of mechanisms is restricted to sequential posted-price schemes, then we show that there is a O(1)-approximation within this space. Our results are based on formulating novel LP relaxations for these problems, and developing generic rounding schemes from rst principles.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Cache me if you can: capacitated selfish replication games
Proceedings of the 10th Latin American international conference on Theoretical Informatics, Springer-Verlag, Berlin, Heidelberg (2012), pp. 420-432
[u'Ragavendran Gopalakrishnan', u'Dimitrios Kanoulas', u'Naga Naresh Karuturi', u'C. Pandu Rangan', u'Rajmohan Rajaraman', u'Ravi Sundaram']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
CloudRAMSort: fast and efficient large-scale distributed RAM sort on shared-nothing cluster
Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data, ACM, New York, NY, USA, pp. 841-850
[u'Changkyu Kim', u'Jongsoo Park', u'Nadathur Satish', u'Hongrae Lee', u'Pradeep Dubey', u'Jatin Chhugani']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Computing Socially-Efficient Cake Divisions
COMSOC (2012)
[u'Yonatan Aumann', u'Yair Dombb', u'Avinatan Hassidim']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Convergence and approximation in potential games
Theor. Comput. Sci., vol. 438 (2012), pp. 13-27
[u'George Christodoulou', u'Vahab S. Mirrokni', u'Anastasios Sidiropoulos']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42296.html
found
=========================
De Bruijn Sequences Revisited
International Journal of Foundations of Computer Science, vol. 23 (2012), pp. 1307-1322
[u'Lila Kari', u'Zhi Xu']
AlgorithmsandTheory
Abstract: A (non-circular) de Bruijn sequence w of order n is a word such that every word of length n appears exactly once in w as a factor. In this paper, we generalize the concept to different settings: the multi-shift de Bruijn sequence and the pseudo de Bruijn sequence. An m-shift de Bruijn sequence of order n is a word such that every word of length n appears exactly once in w as a factor that starts at a position im + 1 for some integer i 0. A pseudo de Bruijn sequence of order n with respect to an antimorphic involution is a word such that for every word u of length n the total number of appearances of u and (u) as a factor is one. We show that the number of m-shift de Bruijn sequences of order n is an!a(m-n)(an-1) for 1 n m and is (am!)an-m for 1 m n, where a is the size of the alphabet. We provide two algorithms for generating a multi-shift de Bruijn sequence. The multi-shift de Bruijn sequence is important for solving the Frobenius problem in a free monoid. We show that the existence of pseudo de Bruijn sequences depends on the given alphabet and antimorphic involution, and obtain formulas for the number of such sequences in some particular settings.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40414.html
found
=========================
Dynamic Covering for Recommendation Systems
CIKM (2012)
[u'Ioannis Antonellis', u'Anish Das Sarma', u'Shaddin Dughmi']
AlgorithmsandTheory
Abstract: In this paper, we identify a fundamental algorithmic problem that we term succinct dynamic covering (SDC), arising in many modern-day web applications, including ad-serving and online recommendation systems in eBay and Netflix. Roughly speaking, SDC applies two restrictions to the well-studied Max-Coverage problem: Given an integer k, X={1,2,...,n} and I={S_1, ..., S_m}, S_i a subset of X, find a subset J of I, such that |J| <= k and the union of S in J is as large as possible. The two restrictions applied by SDC are: (1) Dynamic: At query-time, we are given a query Q, a subset of X, and our goal is to find J such that the intersection of Q with the union of S in J is as large as possible; (2) Space-constrained: We don't have enough space to store (and process) the entire input; specifically, we have o(mn), and maybe as little as O((m+n)polylog(mn)) space. The goal of SDC is to maintain a small data structure so as to answer most dynamic queries with high accuracy. We call such a scheme a Coverage Oracle. We present algorithms and complexity results for coverage oracles. We present deterministic and probabilistic near-tight upper and lower bounds on the approximation ratio of SDC as a function of the amount of space available to the oracle. Our lower bound results show that to obtain constant-factor approximations we need Omega(mn) space. Fortunately, our upper bounds present an explicit tradeoff between space and approximation ratio, allowing us to determine the amount of space needed to guarantee certain accuracy.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40590.html
found
=========================
Empowering Online Advertisements by Empowering Viewers with the Right to Choose
Journal of Advertising Research, vol. 52 (2012), pp. 65-71
[u'Max Pashkevich', u'Sundar Dorai-Raj', u'Melanie Kellar', u'Dan Zigmond']
AlgorithmsandTheory
Abstract: In 2010, YouTube introduced TrueView in-stream advertisingonline video advertisements that allowed the user to skip directly to the desired video content after five seconds of viewing. Google sought to compare these skippable in-stream advertisements to the conventional (non-skippable) in-stream video advertising formats, using a new advertising effectiveness metric based on the propensity to search for terms related to advertising content. Googles findings indicated that skippable video advertisements may be as effective on a per-impression basis as traditional video advertisements. In addition, data from randomized experiments showed a strong implied viewer preference for the skippable advertisements. Taken together, these results suggest that formats like TrueView in-stream advertisements can improve the viewing experience for users without sacrificing advertising value for advertisers or content owners.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37516.html
found
=========================
End-to-end Verification of QoS Policies
The 13th IEEE/IFIP Network Operations and Management Symposium (NOMS 2012)
[u'Adel El-Atawy', u'Taghrid Samak']
AlgorithmsandTheory
Abstract: Conguring a large number of routers and network devices to achieve quality of service (QoS) goals is a challenging task. In a differentiated services (DiffServ) environment, trafc ows are assigned specic classes of service, and service level agreements (SLA) are enforced at routers within each domain. We present a model for QoS congurations that facilitates efcient property-based verication. Network conguration is given as a set of policies governing each device. The model efciently checks the required properties against the current conguration using computation tree logic (CTL) model checking. By symbolically modeling possible decision paths for different ows from source to destination, properties can be checked at each hop, and assessments can be made on how closely congurations adhere to the specied agreement. The model also covers conguration debugging given a specic QoS violation. Efciency and scalability of the model are analyzed for policy per-hop behavior (PHB) parameters over large network congurations.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Energy and Cost Reduction in Localized Multisensory Systems through Application-Driven Compression
Data Compression Conference (DCC), IEEE (2012), pp. 411
[u'James Wendt', u'Saro Meguerdichian', u'Hyduke Noshadi', u'Miodrag Potkonjak']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43157.html
found
=========================
Estimating Uncertainty for Massive Data Streams
Google (2012)
[u'Nicholas Chamandy', u'Omkar Muralidharan', u'Amir Najmi', u'Siddartha Naidu']
AlgorithmsandTheory
Abstract: We address the problem of estimating the variability of an estimator computed from a massive data stream. While nearly-linear statistics can be computed exactly or approximately from Google- scale data, second-order analysis is a challenge. Unfortunately, massive sample sizes do not obviate the need for uncertainty calculations: modern data often have heavy tails, large coefficients of variation, tiny effect sizes, and generally exhibit bad behaviour. We describe in detail this New Frontier in statistics, outline the computing infrastructure required, and motivate the need for modification of existing methods. We introduce two procedures for basic uncertainty estimation, one derived from the bootstrap and the other from a form of subsampling. Their costs and theoretical properties are briefly discussed, and their use is demonstrated using Google data.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Finding Connected Components in Map-reduce in Logarithmic Rounds
ICDE, IEE (2012) (to appear)
[u'Vibhor Rastogi', u'Ashwin Machanavajjhala', u'Laukik Chitnis', u'Anish Das Sarma']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38310.html
found
=========================
General and nested Wiberg minimization: L2 and maximum likelihood
European Conference on Computer Vision, Springer (2012)
[u'Dennis Strelow']
AlgorithmsandTheory
Abstract: Wiberg matrix factorization breaks a matrix Y into low-rank factors U and V by solving for V in closed form given U, linearizing V (U) about U, and iteratively minimizing jjY UV (U)jj2 with respect to U only. This approach factors the matrix while eectively removing V from the minimization. We generalize the Wiberg approach beyond factorization to minimize an arbitrary function that is nonlinear in each of two sets of variables. In this paper we focus on the case of L2 minimization and maximum likelihood estimation (MLE), presenting an L2 Wiberg bundle adjustment algorithm and a Wiberg MLE algorithm for Poisson matrix factorization. We also show that one Wiberg minimization can be nested inside another, eectively removing two of three sets of variables from a minimization. We demonstrate this idea with a nested Wiberg algorithm for L2 projective bundle adjustment, solving for camera matrices, points, and projective depths.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Gipfeli - High Speed Compression Algorithm
DCC (2012), pp. 109-118
[u'Rastislav Lenhardt', u'Jyrki Alakuijala']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Global alignment of molecular sequences via ancestral state reconstruction
Stochastic Processes and Applications (2012)
[u'Alex Andoni', u'Costis Daskalakis', u'Avinatan Hassidim', u'Sebastien Roch']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
How to approximate optimal auctions
SIGecom Exchanges, vol. 11 (2012), pp. 30-33
[u'Nima Haghpanah', u'Nicole Immorlica', u'Vahab S. Mirrokni', u'Kamesh Munagala']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40741.html
found
=========================
Human Computation Must Be Reproducible
WWW 2012, Lyon.
[u'Praveen Paritosh']
AlgorithmsandTheory
Abstract: Human computation is the technique of performing a computational process by outsourcing some of the difficult-to-automate steps to humans. In the social and behavioral sciences, when using humans as measuring instruments, reproducibility guides the design and evaluation of experiments. We argue that human computation has similar properties, and that the results of human computation must be reproducible, in the least, in order to be informative. We might additionally require the results of human computation to have high validity or high utility, but the results must be reproducible in order to measure the validity or utility to a degree better than chance. Additionally, a focus on reproducibility has implications for design of task and instructions, as well as for the communication of the results. It is humbling how often the initial understanding of the task and guidelines turns out to lack reproducibility. We suggest ensuring, measuring and communicating reproducibility of human computation tasks.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37731.html
found
=========================
Impact Of Ranking Of Organic Search Results On The Incrementality Of Search Ads
Google Inc. (2012)
[u'David Chan', u'Deepak Kumar', u'Sheng Ma', u'Jim Koehler']
AlgorithmsandTheory
Abstract: In an earlier study, we reported that on average 89% of the visits to the advertisers site from search ad clicks were incremental. In this research, we examine how the ranking of an advertisers organic listings on the search results page affects the incrementality of ad clicks expressed through Incremental Ad Clicks (IAC) and as estimated by Search Ads Pause models. A meta-analysis of 390 Search Ads Pause studies highlights the limited opportunity for clicks from organic search results to substitute for ad clicks when the ads are turned off. On average, 81% of ad impressions and 66% of ad clicks occur in the absence of an associated organic search result. We find that having an associated organic search result in rank one does not necessarily mean a low IAC. On average, 50% of the ad clicks that occur with a top rank organic result are incremental, compared to 100% of the ad clicks being incremental in the absence of an associated organic result.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40655.html
found
=========================
Italy
Telephone surveys in Europe: Research and practice, Springer, Berlin (2012), pp. 59-72
[u'Teresio Poggio', u'Mario Callegaro']
AlgorithmsandTheory
Abstract: This chapter highlights the current Italian situation about telephone surveys. Table of contents: Introduction The reality of phone surveys in Italy Main recent changes in the technological and social context Coverage error as the big issue in phone surveys Conclusions: no way to skip the low cost-low quality vicious cycle?
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40390.html
found
=========================
LIL: CLOS reaches higher-order, sheds identity, and has a transformative experience
Proceedings of the International Lisp Conference 2012 (to appear)
[u'Franois-Ren Rideau']
AlgorithmsandTheory
Abstract: LIL, the Lisp Interface Library, is a data structure library based on Interface-Passing Style. This programming style was designed to allow for parametric polymorphism (abstracting over types, classes, functions, data) as well as ad-hoc polymorphism (incremental development with inheritance and mixins). It consists in isolating algorithmic information into first-class interfaces, explicitly passed around as arguments dispatched upon by generic functions. As compared to traditional objects, these interfaces typically lack identity and state, while they manipulate data structures without intrinsic behavior. This style makes it just as easy to use pure functional persistent data structures without identity or state as to use stateful imperative ephemeral data structures. Judicious Lisp macros allow developers to avoid boilerplate and to abstract away interface objects to expose classic-looking Lisp APIs. Using on a very simple linear type system to model the side-effects of methods, it is even possible to transform pure interfaces into stateful interfaces or the other way around, or to transform a stateful interface into a traditional object-oriented API.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40567.html
found
=========================
MEASURING NOISE CORRELATION FOR IMPROVED VIDEO DENOISING
IEEE International Conference on Image Processing, IEEE, 1600 Amphitheatre Parkway (2012)
[u'Anil Kokaram', u'Damien Kelly', u'Hugh Denman', u'Andrew Crawford']
AlgorithmsandTheory
Abstract: The vast majority of previous work in noise reduction for visual media has assumed uncorrelated, white, noise sources. In practice this is almost always violated by real media. Film grain noise is never white, and this paper highlights that the same applies to almost all consumer video content. We therefore present an algorithm for measuring the spatial and temporal spectral density of noise in archived video content, be it consumer digital camera or film orginated. As an example of how this information can be used for video denoising, the spectral density is then used for spatio-temporal noise reduction in the Fourier frequency domain. Results show improved performance for noise reduction in an easily pipelined system.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38136.html
found
=========================
Machine learning: a probabilistic perspective
MIT Press, Cambridge, MA (2012)
[u'Kevin P Murphy']
AlgorithmsandTheory
Abstract: Todays Web-enabled deluge of electronic data calls for automated methods of data analysis. Machine learning provides these, developing methods that can automatically detect patterns in data and then use the uncovered patterns to predict future data. This textbook offers a comprehensive and self-contained introduction to the field of machine learning, using a unified, probabilistic approach. The coverage combines breadth and depth, offering necessary background material on such topics as probability, optimization, and linear algebra as well as discussion of recent developments in the field, including conditional random fields, L1 regularization, and deep learning. The book is written in an informal, accessible style, complete with pseudo-code for the most important algorithms. All topics are copiously illustrated with color images and worked examples drawn from such application domains as biology, text processing, computer vision, and robotics. Rather than providing a cookbook of different heuristic methods, the book stresses a principled model-based approach, often using the language of graphical models to specify models in a concise and intuitive way. Almost all the models described have been implemented in a MATLAB software package--PMTK (probabilistic modeling toolkit)--that is freely available online. The book is suitable for upper-level undergraduates with an introductory-level college math background and beginning graduate students.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Matching with our Eyes Closed
FOCS (2012)
[u'Gagan Goel', u'Pushkar Tripathi']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38331.html
found
=========================
Mathematics at Google
Google, Inc. (2012), pp. 52
[u'Javier Tordable']
AlgorithmsandTheory
Abstract: There is a wide variety of Mathematics used at Google. For example Linear Algebra in the PageRank algorithm, used to rank web pages in search results. Or Game Theory, used in ad auctions, or Graph Theory in Google Maps. At Google there are literally dozens of products which use interesting Mathematics. These are not just research prototypes, but real Google products; in which Mathematics play a crucial role. In this presentation, I introduce several applications of Mathematics at Google. I begin with a detailed explanation of search on the web and PageRank. Then I show a dozen examples of Google products and the corresponding Mathematics that are used. The presentation has an extensive list of links and references. And it's available in English and Spanish.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Negotiation in Exploration-Based Environment
AAAI (2012)
[u'Avinatan Hassidim', u'David Sarne', u'Israel Sofer']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41691.html
found
=========================
On Big Data Algorithmics
Algorithms ESA, Springer (2012), pp. 1
[u'Yossi Matias']
AlgorithmsandTheory
Abstract: The extensive use of Big Data has now become common in plethora of technologies and industries. From massive data bases to business intelligence and datamining applications; from search engines to recommendation systems; advancing the state of the art of voice recognition, translation and more. The design, analysis and engineering of Big Data algorithms has multiple flavors, including massive parallelism, streaming algorithms, sketches and synopses, cloud technologies, and more. We will discuss some of these aspects, and reflect on their evolution and on the interplay between the theory and practice of Big Data algorithmics.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
On Fixed-Price Marketing for Goods with Positive Network Externalities
WINE (2012), pp. 532-538
[u'Vahab S. Mirrokni', u'Sebastien Roch', u'Mukund Sundararajan']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
On multiway cut parameterized above lower bounds
Proceedings of the 6th international conference on Parameterized and Exact Computation, Springer-Verlag, Berlin, Heidelberg (2012), pp. 1-12
[u'Marek Cygan', u'Marcin Pilipczuk', u'Michal Pilipczuk', u'Jakub Onufry Wojtaszczyk']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
On the advantage of overlapping clusters for minimizing conductance
Proceedings of the 10th Latin American international conference on Theoretical Informatics, Springer-Verlag, Berlin, Heidelberg (2012), pp. 494-505
[u'Rohit Khandekar', u'Guy Kortsarz', u'Vahab Mirrokni']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40805.html
found
=========================
Online Graph Edge-Coloring in the Random-Order Arrival Model
Theory of Computing, vol. 8(1) (2012), pp. 567-595
[u'Bahman Bahmani', u'Aranyak Mehta', u'Rajeev Motwani']
AlgorithmsandTheory
Abstract: A classic theorem by Vizing asserts that if the maximum degree of a graph is ?, then it is possible to color its edges, in polynomial time, using at most ?+1 colors. However, this algorithm is offline, i.e., it assumes the whole graph is known in advance. A natural question then is how well we can do in the online setting, where the edges of the graph are revealed one by one, and we need to color each edge as soon as it is added to the graph. Online edge coloring has an important application in fast switch scheduling. A natural model is that edges arrive online, but in a random permutation. Even in the random permutation model, the best proven approximation factor for any algorithm is the factor 2 of the simple greedy algorithm (which holds even in the worst-case online model). The algorithm of Aggarwal et al. (FOCS'03) provides a 1+o(1) factor algorithm for the case of very dense multi-graphs, when ?=?(n2), where n is the number of vertices. In this paper, we show that for graphs with ?=?(logn), it is possible to color the graph with (1+ee2?1+o(1))??1.43? colors, with high probability, in the online random-order model. Our algorithm is inspired by a 1.6-approximate distributed offline algorithm of Panconesi and Srinivasan (PODC'92), which we extend by reusing failed colors online. Further, we show how we can extend the algorithm to reuse colors multiple times, which reduces the approximation factor below 1.43. We conjecture that the algorithm becomes nearly optimal (i.e., uses ?+o(?) colors) with O(log(?/logn)) reuses. We reduce the question to proving the non-negativity of a certain recursively defined sequence, which looks true in computer simulations. This non-negativity can be proved explicitly for a small number of reuses, giving improved algorithms: e.g., the algorithm which reuses colors 5 times uses 1.26? colors.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40363.html
found
=========================
Online Matching with Stochastic Rewards
Symposium on Foundations of Computer Science (FOCS), IEEE (2012)
[u'Aranyak Mehta', u'Debmalya Panigrahi']
AlgorithmsandTheory
Abstract: The online matching problem has received significant attention in recent years because of its connections to allocation problems in Internet advertising, crowd-sourcing, etc. In these real-world applications, the typical goal is not to maximize the number of allocations, rather it is to maximize the number of successful allocations, where success of an allocation is governed by a stochastic process which follows the allocation. To address such applications, we propose and study the online matching problem with stochastic rewards (called the Online Stochastic Matching problem) in this paper. Our problem also has close connections to the existing literature on stochastic packing problems, in fact, our work initiates the study of online stochastic packing problems. We give a deterministic algorithm for the Online Stochastic Matching problem whose competitive ratio converges to (approximately) 0.567 for uniform and vanishing probabilities. We also give a randomized algorithm which outperforms the deterministic algorithm for higher probabilities. Finally, we complement our algorithms by giving an upper bound on the competitive ratio of any algorithm for this problem. This result shows that the best achievable competitive ratio for the Online Stochastic Matching problem is provably worse than that for the (non-stochastic) online matching problem.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Online allocation of display ads with smooth delivery
KDD (2012), pp. 1213-1221
[u'Anand Bhalgat', u'Jon Feldman', u'Vahab S. Mirrokni']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38137.html
found
=========================
Open Problem: Better Bounds for Online Logistic Regression
COLT/ICML Joint Open Problem Session, JMLR: Workshop and Conference Proceedings (2012)
[u'H. Brendan McMahan', u'Matthew Streeter']
AlgorithmsandTheory
Abstract: Known algorithms applied to online logistic regression on a feasible set of L2 diameter D achieve regret bounds like O(eD log T) in one dimension, but we show a bound of O(sqrt(D) + log T) is possible in a binary 1-dimensional problem. Thus, we pose the following question: Is it possible to achieve a regret bound for online logistic regression that is O(poly(D)log(T))? Even if this is not possible in general, it would be interesting to have a bound that reduces to our bound in the one-dimensional case.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40340.html
found
=========================
Optimistic Scheduling with Geographically Replicated Services in the Cloud Environment (COLOR)
Cluster, Cloud and Grid Computing (CCGrid), 2012 12th IEEE/ACM International Symposium on, IEEE CONFERENCE PUBLICATIONS, pp. 735-740
[u'Wenbo Zhu', u'C. Murray Woodside']
AlgorithmsandTheory
Abstract: This paper proposes a system model that unifies different optimistic algorithms designed for deploying geographically replicated services in a cloud environment. The proposed model thereby enables a generalized solution (COLOR) by which well-specified safety and timeliness guarantees are achievable in conjunction with tunable performance requirements. The proposed solution explicitly takes advantage of the unique client-cloud interface in specifying how the level of consistency violation may be bounded, for instance using probabilistic rollbacks or restarts as parameters. The solution differs from traditional Eventual Consistency models in that inconsistency is solved concurrently with online client-cloud interactions over strongly connected networks. We believe that such an approach will bring clarity to the role and limitations of the ever-popular Eventual Consistency model in cloud services.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
PageRank on an evolving graph
KDD (2012), pp. 24-32
[u'Bahman Bahmani', u'Ravi Kumar', u'Mohammad Mahdian', u'Eli Upfal']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40405.html
found
=========================
Performance bounds and design criteria for estimating finite rate of innovation signals
IEEE Transactions on Information Theory, vol. 58 (2012), pp. 4993-5015
[u'Zvika Ben-Haim', u'Tomer Michaeli', u'Yonina C. Eldar']
AlgorithmsandTheory
Abstract: In this paper, we consider the problem of estimating nite rate of innovation (FRI) signals from noisy measurements, and specically analyze the interaction between FRI techniques and the underlying sampling methods. We rst obtain a fundamental limit on the estimation accuracy attainable regardless of the sampling method. Next, we provide a bound on the performance achievable using any specic sampling approach. Essential differences between the noisy and noise-free cases arise from this analysis. In particular, we identify settings in which noise-free recovery techniques deteriorate substantially under slight noise levels, thus quantifying the numerical instability inherent in such methods. This instability, which is only present in some families of FRI signals, is shown to be related to a specic type of structure, which can be characterized by viewing the signal model as a union of subspaces. Finally, we develop a methodology for choosing the optimal sampling kernels for linear reconstruction, based on a generalization of the KarhunenLoeve transform. The results are illustrated for several types of time-delay estimation problems.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Polyhedral clinching auctions and the adwords polytope
STOC, ACM (2012), pp. 107-122
[u'Gagan Goel', u'Vahab Mirrokni', u'Renato Paes Leme']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Quantum Money
Communications of the ACM, vol. 55 No. 8 (2012), pp. 84-92
[u'Scott Aaronson', u'Edward Farhi', u'David Gosset', u'Avinatan Hassidim', u'Jon Kelner']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Quantum money from knots
Proceedings of the 3rd Innovations in Theoretical Computer Science Conference, ACM, New York, NY, USA (2012), pp. 276-289
[u'Edward Farhi', u'David Gosset', u'Avinatan Hassidim', u'Andrew Lutomirski', u'Peter Shor']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40337.html
found
=========================
Repeatedly Appending Any Digit to Generate Composite Numbers
The American Mathematical Monthly (2012) (to appear)
[u'John Grantham', u'Witold Jarnicki', u'Jon Rickert', u'Stan Wagon']
AlgorithmsandTheory
Abstract: We investigate the problem of nding integers k such that ap- pending any number of copies of the base-ten digit d to k yields a composite number. In particular, we prove that there exist innitely many integers co- prime to all digits such that repeatedly appending any digit yields a composite number.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40361.html
found
=========================
Routing multi-class traffic flows in the plane
Computational Geometry, vol. 45 (2012), pp. 99-114
[u'Joondong Kim', u'Joseph S. B. Mitchell', u'Valentin Polishchuk', u'Shang Yang', u'Jingyu Zou']
AlgorithmsandTheory
Abstract: We study a class of multi-commodity flow problems in geometric domains: For a given planar domain P populated with obstacles (holes) of K2types, compute a set of thick paths from a source edge of P to a sink edge of P for vehicles of K distinct classes. Each class k of vehicle has a given set, Ok, of obstacles it must avoid and a certain width, wk, of path it requires. The problem is to determine if it is possible to route Nk width-wk paths for class k vehicles from source to sink, with each path avoiding the requisite set Ok of obstacles, and no two paths overlapping. This form of multi-commodity flow in two-dimensional domains arises in computing throughput capacity for multiple classes of aircraft in an airspace impacted by different types of constraints, such as those arising from weather hazards. We give both algorithmic theory results and experimental results. We show hardness of many versions of the problem by proving that two simple variants are NP-hard even in the case K=2. If w1=w2=1, then the problem is NP-hard even when O1=. If w1=2, w2=3, then the problem is NP-hard even when O1=O2. In contrast, the problem for a single width and a single type of obstacles is polynomially solvable. We present approximation algorithms for the multi-criteria optimization problems that arise when trying to maximize the number of routable paths. We also give a polynomial-time algorithm for the case in which the number of holes in the input domain is bounded. Finally, we give experimental results based on an implementation of our methods and experiment with enhanced heuristics for efficient solutions in practice. Our algorithms are being utilized in simulations with NASAs Future Air traffic management Concepts Evaluation Tool (FACET). We report on experimental results based on applying our algorithms to weather-impacted airspaces, comparing heuristic strategies for searching for feasible path orderings and for computing short multi-class routes. Our results show that multi-class routes can feasibly be computed on real weather data instances on the scale required in air traffic management applications.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Simultaneous Approximations for Adversarial and Stochastic Online Budgeted Allocation
Symposium on Discrete Algorithms (SODA), ACM/SIAM (2012)
[u'Vahab Mirrokni', u'Shayan Oveis Gharan', u'Morteza Zadimoghaddam']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38097.html
found
=========================
Smart Pricing Grows the Pie
Google, Inc (2012)
[u'Guy Calvert']
AlgorithmsandTheory
Abstract: Some publisher advertising networks provide features intended to help advertisers bid more efficiently with a single bid in many publishers click auctions at once Smart Pricing on the Google Display Network is one example. Typically such features involve discounting advertiser bids or prices for clicks on publisher websites according to how click values vary across sites (for some appropriate measure of advertiser value). Contrary to concerns that such features necessarily result in reduced publisher (and network) revenue we find that, in many simple cases, the modified auction dynamics produce rational incentives for advertisers to bid more and spend more than they would without the benefit of these features. So if advertisers act in their own interest then publishers and networks stand to make more revenue as well.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Solving the 2-disjoint connected subgraphs problem faster than 2n
Proceedings of the 10th Latin American international conference on Theoretical Informatics, Springer-Verlag, Berlin, Heidelberg (2012), pp. 195-206
[u'Marek Cygan', u'Marcin Pilipczuk', u'Michal Pilipczuk', u'Jakub Onufry Wojtaszczyk']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub33344.html
found
=========================
Span-program-based quantum algorithm for evaluating formulas
Theory of Computing, vol. 8(13) (2012), pp. 291-319
[u'Ben Reichardt', u'Robert Spalek']
AlgorithmsandTheory
Abstract: We give a quantum algorithm for evaluating formulas over an extended gate set, including all two- and three-bit binary gates (e. g., NAND, 3-majority). The algorithm is optimal on read-once formulas for which each gates inputs are balanced in a certain sense. The main new tool is a correspondence between a classical linear-algebraic model of computation, span programs, and weighted bipartite graphs. A span programs evaluation corresponds to an eigenvalue-zero eigenvector of the associated graph. A quantum computer can therefore evaluate the span program by applying spectral estimation to the graph. For example, the classical complexity of evaluating the balanced ternary majority formula is unknown, and the natural generalization of randomized alpha-beta pruning is known to be suboptimal. In contrast, our algorithm generalizes the optimal quantum AND-OR formula evaluation algorithm and is optimal for evaluating the balanced ternary majority formula.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Super-polynomial quantum speed-ups for boolean evaluation trees with hidden structure
Proceedings of the 3rd Innovations in Theoretical Computer Science Conference, ACM, New York, NY, USA (2012), pp. 249-265
[u'Bohua Zhan', u'Shelby Kimmel', u'Avinatan Hassidim']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40660.html
found
=========================
Systematic Software Testing: The Korat Approach
Foundations of Software Engineering (FSE), ACM (2012), pp. 1
[u'Chandrasekhar Boyapati', u'Sarfraz Khurshid', u'Darko Marinov']
AlgorithmsandTheory
Abstract: At ISSTA 2002, the three authors (then Ph.D. students) published the paper Korat: Automated Testing Based on Java Predicates", which won one of the first ACM SIGSOFT Distinguished paper awards. In 2012, the paper won the ACM SIGSOFT Impact Paper Award. The authors briefly recount the motivation behind the Korat research, the ideas presented in the original paper, and some work it inspired.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40426.html
found
=========================
The Incremental Reach and Cost Efficiency of Online Video Ads over TV Ads
Google Inc (2012), pp. 1-17
[u'Yuxue Jin', u'Sheethal Shobowale', u'Jim Koehler', u'Harry Case']
AlgorithmsandTheory
Abstract: As people spend more time online, an increasing number of brand marketers are including video ads in their advertising campaigns. These advertisers would like to know the incremental reach and cost efficiency of their video and display ads compared to their TV ads. In this paper, we measure the incremental reach to a target demographic and estimate the cost per incremental reach point of YouTube (YT) and the Google Display Network (GDN) compared to TV ad campaigns. We consider two media planning scenarios: what it would have cost for the TV ad campaign to have delivered the equivalent of the online incremental reach, and what saving could have been achieved by having spent less on TV ads and complementing them with online ads for a given reach goal.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
The maximum degree of random planar graphs
Proceedings of the Twenty-Third Annual ACM-SIAM Symposium on Discrete Algorithms, SIAM (2012), pp. 281-287
[u'Michael Drmota', u'Omer Gimenez', u'Marc Noy', u'Konstantinos Panagiotou', u'Angelika Steger']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40606.html
found
=========================
Towards A Unified Modeling and Verification of Network and System Security Configuration
5th Symposium on Configuration Analytics and Automation (SafeConfig 2012)
[u'Mohammed Noraden Alsaleh', u'Ehab Al-Shaer', u'Adel El-Atawy']
AlgorithmsandTheory
Abstract: Systems and networks access control configuration are usually analyzed independently although they are logically combined to define the the end-to-end security property. While systems and applications security policies define access control based on user identity or group, request type and the requested resource, network security policies uses flow information such as host and service addresses for source and destination to define access control. Therefore, both network and systems access control have to be configured consistently in order enforce end-to-end security policies. Many previous research attempt to verify either side separately, but it does not provide a unified approach to automatically validate the logical consistency between both of them. Thus, using existing techniques requires error-prone manual and ad-hoc analysis to validate this link. In this paper, we introduce a cross-layer modeling and verification system that can analyzes the configurations and policies across both application and network components as a single unit. It combines policies from different devices as firewalls, NAT, routers and IPSec gateways as well as basic RBAC-based policies of higher service layers. This will allow analyzing, for example, firewall polices in the context of application access control and vice versa. Thus, by incorporating policies across the network and over multiple layers, we provide a true end-to-end configuration verification tool. Our model represents the system as a state machine where packet header, service request and location determine the state and transitions that conform with the configurations, device operations, and packet values are established. We encode the model as Boolean functions using binary decision diagrams (BDDs). We used an extended version of computational tree logic (CTL) to provide more useful operators and then use it with symbolic model checking to prove or find counter examples to needed properties. The tool is implemented and we gave special consideration to efficiency and scalability. Our extensive evaluation study shows acceptable computation and space requirements with large number of nodes and configuration sizes.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40378.html
found
=========================
Uncertainty in Aggregate Estimates from Sampled Distributed Traces
2012 Workshop on Managing Systems Automatically and Dynamically, USENIX
[u'Nate Coehlo', u'Arif Merchant', u'Murray Stokely']
AlgorithmsandTheory
Abstract: Tracing mechanisms in distributed systems give important insight into system properties and are usually sampled to control overhead. At Google, Dapper [8] is the always-on system for distributed tracing and performance analysis, and it samples fractions of all RPC trafc. Due to difcult implementation, excessive data volume, or a lack of perfect foresight, there are times when system quantities of interest have not been measured directly, and Dapper samples can be aggregated to estimate those quantities in the short or long term. Here we nd unbiased variance estimates of linear statistics over RPCs, taking into account all layers of sampling that occur in Dapper, and allowing us to quantify the sampling uncertainty in the aggregate estimates. We apply this methodology to the problem of assigning jobs and data to Google datacenters, using estimates of the resulting cross-datacenter trafc as an optimization criterion, and also to the detection of change points in access patterns to certain data partitions.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40413.html
found
=========================
Upper and Lower Bounds on the Cost of a Map-Reduce Computation
Arxiv (2012)
[u'Foto Afrati', u'Anish Das Sarma', u'Semih Salihoglu', u'Jeffrey Ullman']
AlgorithmsandTheory
Abstract: In this paper we study the tradeoff between parallelism and communication cost in a map-reduce computation. For any problem that is not "embarrassingly parallel," the finer we partition the work of the reducers so that more parallelism can be extracted, the greater will be the total communication between mappers and reducers. We introduce a model of problems that can be solved in a single round of map-reduce computation. This model enables a generic recipe for discovering lower bounds on communication cost as a function of the maximum number of inputs that can be assigned to one reducer. We use the model to analyze the tradeoff for three problems: finding pairs of strings at Hamming distance $d$, finding triangles and other patterns in a larger graph, and matrix multiplication. For finding strings of Hamming distance 1, we have upper and lower bounds that match exactly. For triangles and many other graphs, we have upper and lower bounds that are the same to within a constant factor. For the problem of matrix multiplication, we have matching upper and lower bounds for one-round map-reduce algorithms. We are also able to explore two-round map-reduce algorithms for matrix multiplication and show that these never have more communication, for a given reducer size, than the best one-round algorithm, and often have significantly less.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40346.html
found
=========================
Video Description Length Guided Constant Quality Video Coding with Bitrate Constraint
Multimedia and Expo Workshops (ICMEW), 2012 IEEE International Conference on, IEEE, 2001 L Street, NW. Suite 700 Washington, DC 20036-4910 USA, pp. 366-371
[u'Lei Yang', u'Debargha Mukherjee', u'Dapeng Wu']
AlgorithmsandTheory
Abstract: In this paper, we propose a new video encoding strategy - Video description length guided Constant Quality video coding with Bitrate Constraint (V-CQBC), for large scale video transcoding systems of video charing websites with varying unknown video contents. It provides smooth quality and saves bitrate and computation for transcoding millions of videos in both real time and batch mode. The new encoding strategy is based on the average bitrate-quality regression model and adapt to the encoded videos. Furthermore, three types of video description length (VDL), describing the video overall, spatial and temporal content complexity, are proposed to guide video coding. Experimental results show that the proposed coding strategy with saved computation could achieve better or similar RD performance than other coding strategies.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Filter-based Algorithm for Efficient Composition of Finite-State Transducers
International Journal of Foundations of Computer Science, vol. 22 (2011), pp. 1781-1795
[u'Cyril Allauzen', u'Michael Riley', u'Johan Schalkwyk']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Perfect Price Discrimination Market Model with Production, and a Rational Convex Program for it.
Math of Operations Research, vol. 36 (2011), pp. 762-782
[u'Gagan Goel', u'Vijay Vazirani']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37038.html
found
=========================
Adapting Online Advertising Techniques to Television
Online Multimedia Advertising: Techniques and Technologies, Information Science Reference, Hershey PA (2011), pp. 148-165
[u'Sundar Dorai-Raj', u'Yannet Interian', u'Igor Naverniouk', u'Dan Zigmond']
AlgorithmsandTheory
Abstract: The availability of precise data on TV ad consumption fundamentally changes this advertising medium, and allows many techniques developed for analyzing online ads to be adapted for TV. This chapter looks in particular at how results from the emerging field of online ad quality analysis can now be applied to TV.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37146.html
found
=========================
Advertising and Traffic: Learning from online video data
Audience Measurement 6.0, New York, NY (2011)
[u'Dan Zigmond']
AlgorithmsandTheory
Abstract: Online media portals like Googles YouTube are generating unprecedented volumes of data on usage patterns and viewing behavior. Learn about improving online advertising by understanding how ads impact online traffic.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
An Efficient Partitioning Oracle for Bounded-Treewidth Graphs
APPROX-RANDOM (2011), pp. 530-541
[u'Alan Edelman', u'Avinatan Hassidim', u'Krzysztof Onak', u'Huy Nguyen']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37374.html
found
=========================
Approximation Schemes for Capacitated Geometric Network Design
ICALP 2011, Rynek Gwny 12 (to appear)
[u'Anna Adamaszek', u'Artur Czumaj', u'Andrzej Lingas', u'Jakub Onufry Wojtaszczyk']
AlgorithmsandTheory
Abstract: We study a capacitated network design problem in geometric setting. We assume that the input consists of an integral link capacity k and two sets of points on a plane, sources and sinks, each source/sink having an associated integral demand (amount of ow to be shipped from/to). The capacitated geometric network design problem is to construct a minimum-length network N that allows to route the requested ow from sources to sinks, such that each link in N has capacity k; the ow is splittable and parallel links are allowed in N. The capacitated geometric network design problem generalizes, among others, the geometric Steiner tree problem, and as such it is NP-hard. We show that if the demands are polynomially bounded and the link capacity k is not too large, the single-sink capacitated geometric network design problem admits a polynomial-time approximation scheme. If the capacity is arbitrarily large, then we design a quasi-polynomial time approximation scheme for the capacitated geometric network design problem allowing for arbitrary number of sinks. Our results rely on a derivation of an upper bound on the number of vertices different from sources and sinks (the so called Steiner vertices) in an optimal network. The bound is polynomial in the total demand of the sources.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Data Augmentation, Frequentist Estimation, and the Bayesian Analysis of Multinomial Logit Models
Statistical Papers, vol. 52 (2011), pp. 87-109
[u'Steven L. Scott']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Data augmentation for support vector machines
Bayesian Analysis, vol. 6 (2011), pp. 1-24
[u'Nicholas G. Polson', u'Steven L. Scott']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37169.html
found
=========================
Distinct counting with a self-learning bitmap
Journal of American Statistical Association, vol. 106 (2011), 879890
[u'Aiyou Chen', u'Jin Cao', u'Larry Shepp', u'Tuan Nguyen']
AlgorithmsandTheory
Abstract: Counting the number of distinct elements (cardinality) in a dataset is a fundamental problem in database management. In recent years, due to many of its modern applications, there has been signicant interest to address the distinct counting problem in a data stream setting, where each incoming data can be seen only once and cannot be stored for long periods of time. Many probabilistic approaches based on either sampling or sketching have been proposed in the computer science literature, that only require limited computing and memory resources. However, the performances of these methods are not scale invariant, in the sense that their relative root mean square estimation errors (RRMSE) depend on the unknown cardinalities. This is not desirable in many applications where cardinalities can be very dynamic or inhomogeneous and many cardinalities need to be estimated. In this article, we develop a novel approach, called self-learning bitmap (S-bitmap) that is scale invariant for cardinalities in a specied range. S-bitmap uses a binary vector whose entries are updated from 0 to 1 by an adaptive sampling process for inferring the unknown cardinality, where the sampling rates are reduced sequentially as more and more entries change from 0 to 1. We prove rigorously that the S-bitmap estimate is not only unbiased but scale invariant. We demonstrate that to achieve a small RRMSE value of or less, our approach requires significantly less memory and consumes similar or less operations than state-of-the-art methods for many common practice cardinality scales. Both simulation and experimental studies are reported.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Distributed Verification and Hardness of Distributed Approximation
ACM Symposium on Theory of Computing (STOC) (2011)
[u'Atish Das Sarma', u'Stephan Holzer', u'Liah Kor', u'Amos Korman', u'Danupon Nanongkai', u'Gopal Pandurangan', u'David Peleg', u'Roger Wattenhofer']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37166.html
found
=========================
Entire Relaxation Path for Maximum Entropy Problems
EMNLP 2011 (to appear)
[u'Moshe Dubiner', u'Yoram Singer']
AlgorithmsandTheory
Abstract: We discuss and analyze the problem of finding a distribution that minimizes the relative entropy to a prior distribution while satisfying max-norm constraints with respect to an observed distribution. This setting generalizes the classical maximum entropy problems as it relaxes the standard constraints on the observed values. We tackle the problem by introducing a re-parametrization in which the unknown distribution is distilled to a single scalar. We then describe a homotopy between the relaxation parameter and the distribution characterizing parameter. The homotopy also reveals an aesthetic symmetry between the prior distribution and the observed distribution. We then use the reformulated problem to describe a space and time efficient algorithm for tracking the entire relaxation path. Our derivations are based on a compact geometric view of the relaxation path as a piecewise linear function in a two dimensional space of the relaxation-characterization parameters. We demonstrate the usability of our approach by applying the problem to Zipfian distributions over a large alphabet.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Estimating PageRank on Graph Streams
Journal of the ACM (JACM) (2011)
[u'Atish Das Sarma', u'Sreenivas Gollapudi', u'Rina Panigrahy']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37522.html
found
=========================
Extracting Patterns from Location History
ACM SIGSPATIAL GIS 2011, ACM, http://www.sigspatial.org/, pp. 397-400
[u'Andrew Kirmse', u'Tushar Udeshi', u'Pablo Bellver', u'Jim Shuma']
AlgorithmsandTheory
Abstract: In this paper, we describe how a user's location history (recorded by tracking the user's mobile device location with his permission) is used to extract the user's location patterns. We describe how we compute the user's commonly visited places (including home and work), and commute patterns. The analysis is displayed on the Google Latitude history dashboard [7] which is only accessible to the user.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37240.html
found
=========================
Filtering: a method for solving graph problems in MapReduce.
SPAA 2011: Proceedings of the 23rd Annual ACM Symposium on Parallelism in Algorithms and Architectures, pp. 85-94
[u'Silvio Lattanzi', u'Benjamin Moseley', u'Siddharth Suri', u'Sergei Vassilvitskii']
AlgorithmsandTheory
Abstract: The MapReduce framework is currently the de facto standard used throughout both industry and academia for petabyte scale data analysis. As the input to a typical MapReduce computation is large, one of the key requirements of the framework is that the input cannot be stored on a single machine and must be processed in parallel. In this paper we describe a general algorithmic design technique in the MapReduce framework called filtering. The main idea behind filtering is to reduce the size of the input in a distributed fashion so that the resulting, much smaller, problem instance can be solved on a single machine. Using this approach we give new algorithms in the MapReduce framework for a variety of fundamental graph problems. Specifically, we present algorithms for minimum spanning trees, maximal matchings, approximate weighted matchings, approximate vertex and edge covers and minimum cuts. In all of these cases, we will parameterize our algorithms by the amount of memory available on the machines allowing us to show tradeoffs between the memory available and the number of MapReduce rounds. For each setting we will show that even if the machines are only given substantially sublinear memory, our algorithms run in a constant number of MapReduce rounds. To demonstrate the practical viability of our algorithms we implement the maximal matching algorithm that lies at the core of our analysis and show that it achieves a significant speedup over the sequential version.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37118.html
found
=========================
Fuzzy Computing Applications for Anti-Money Laundering and Distributed Storage System Load Monitoring
World conference on soft computing (2011) (2011)
[u'Yu-To Chen', u'Johan Mathe']
AlgorithmsandTheory
Abstract: Fuzzy computing (FC) has made a great impact in capturing human domain knowledge and modeling non-linear mapping of input-output space. In this paper, we describe the design and implementation of FC systems for detection of money laundering behaviors in financial transactions and monitoring of distributed storage system load. Our objective is to demonstrate the power of FC for real-world applications which are char- acterized by imprecise, uncertain data, and incomplete domain knowledge. For both applications, we designed fuzzy rules based on experts domain knowledge, depending on money laundering scenarios in transactions or the health of a distributed storage system. In addition, we developped a generic fuzzy inference engine and contributed to the open source community.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
General Algorithms for Testing the Ambiguity of Finite Automata and the Double-Tape Ambiguity of Finite-State Transducers
International Journal of Foundations of Computer Science, vol. 22 (2011), pp. 883-904
[u'Cyril Allauzen', u'Mehryar Mohri', u'Ashish Rastogi']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37250.html
found
=========================
Hiring a secretary from a poset.
Proceedings 12th ACM Conference on Electronic Commerce (EC-2011), pp. 39-48
[u'Ravi Kumar', u'Silvio Lattanzi', u'Sergei Vassilvitskii', u'Andrea Vattani']
AlgorithmsandTheory
Abstract: The secretary problem lies at the core of mechanism design for online auctions. In this work we study the generalization of the classical secretary problem in a setting where there is only a partial order be- tween the elements and the goal of the algorithm is to return one of the maximal elements of the poset. This is equivalent to the setting where the seller has a multidimensional objective function with only a partial order among the outcomes. We obtain an algorithm that succeeds with probability at least?1 + l k^{k/(k1)} ((1+log^{-1/(k-1)} k)^k -1) where k is the number of maximal elements in the poset and is the only information about the poset that is known to the algorithm. On the other hand, we prove an almost matching upper bound of k^{1/(k1)} on the success probability of any algorithm for this problem; this upper bound holds even if the algorithm knows the complete structure of the poset.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
How is it done? A multinational survey of YouTube user satisfaction
University of Washington, Seattle, WA (2011)
[u'Joshua Tabak']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37161.html
found
=========================
Incremental Clicks Impact Of Search Advertising
Google, Inc. (2011)
[u'David Chan', u'Yuan Yuan', u'Jim Koehler', u'Deepak Kumar']
AlgorithmsandTheory
Abstract: Advertisers often wonder whether search ads cannibalize their organic traffic. In other words, if search ads were paused, would clicks on organic results increase, and make up for the loss in paid traffic? Google statisticians recently ran over 400 studies on paused accounts to answer this question. In what we call Search Ads Pause Studies, our group of researchers observed organic click volume in the absence of search ads. Then they built a statistical model to predict the click volume for given levels of ad spend using spend and organic impression volume as predictors. These models generated estimates for the incremental clicks attributable to search ads (IAC), or in other words, the percentage of paid clicks that are not made up for by organic clicks when search ads are paused. The results were surprising. On average, the incremental ad clicks percentage across verticals is 89%. This means that a full 89% of the traffic generated by search ads is not replaced by organic clicks when ads are paused. This number was consistently high across verticals.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Inner Product Spaces for MinSum Coordination Mechanisms
STOC (2011)
[u'Richard Cole', u'Jose R. Correa', u'Vasilis Gkatzelis', u'Vahab Mirrokni', u'Neil Olver']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37483.html
found
=========================
Large-Scale Parallel Statistical Forecasting Computations in R
JSM Proceedings, Section on Physical and Engineering Sciences, American Statistical Association, Alexandria, VA (2011)
[u'Murray Stokely', u'Farzan Rohani', u'Eric Tassone']
AlgorithmsandTheory
Abstract: We demonstrate the utility of massively parallel computational infrastructure for statistical computing using the MapReduce paradigm for R. This framework allows users to write computations in a high-level language that are then broken up and distributed to worker tasks in Google datacenters. Results are collected in a scalable, distributed data store and returned to the interactive user session. We apply our approach to a forecasting application that fits a variety of models, prohibiting an analytical description of the statistical uncertainty associated with the overall forecast. To overcome this, we generate simulation-based uncertainty bands, which necessitates a large number of computationally intensive realizations. Our technique cut total run time by a factor of 300. Distributing the computation across many machines permits analysts to focus on statistical issues while answering questions that would be intractable without significant parallel computational infrastructure. We present real-world performance characteristics from our application to allow practitioners to better understand the nature of massively parallel statistical simulations in R.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Leaky Pseudo-Entropy Functions
ICS (2011), pp. 353-366
[u'Mark Braverman', u'Avinatan Hassidim', u'Yael Tauman Kalai']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Matching with couples revisited
Electronic Commerce (EC) (2011), pp. 335-336
[u'Itai Ashlagi', u'Mark Braverman', u'Avinatan Hassidim']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37562.html
found
=========================
Measuring the Impact of Advertising on YouTube Traffic
The Market Research Event, The Market Research Event, Orlando FL (2011)
[u'Sundar Dorai-Raj']
AlgorithmsandTheory
Abstract: At YouTube, balancing ad load and user happiness is a major concern. One way we measure this tradeoff is through live experiments, which we run on a small percentage of traffic. For example, by holding back certain ad formats we can build metrics around the impact of YouTube advertising on the user experience. In this talk we will discuss the benefits and challenges of running large-scale advertising experiments.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37235.html
found
=========================
Milgram-routing in social networks.
Proceedings of the 20th International Conference on World Wide Web, WWW 2011, pp. 725-734
[u'Silvio Lattanzi', u'Alessandro Panconesi', u'D. Sivakumar']
AlgorithmsandTheory
Abstract: We demonstrate how a recent model of social networks (Affiliation Networks) offers powerful cues in local routing within social networks, a theme made famous by sociologist Milgrams six degrees of separation experiments. This model posits the existence of an interest space that underlies a social network; we prove that in networks produced by this model, not only do short paths exist among all pairs of nodes but natural local routing algorithms can discover them effectively. Specifically, we show that local routing can discover paths of length O(log^2 n) to targets chosen uniformly at random, and paths of length O(1) to targets chosen with probability proportional to their degrees. Experiments on the co-authorship graph derived from DBLP data confirm our theoretical results, and shed light into the power of one step of lookahead in routing algorithms for social networks.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37068.html
found
=========================
Multicut in trees viewed through the eyes of vertex cover
WADS 2011
[u'Jianer Chen', u'Jiahao Fan', u'Iyad A. Kanj', u'Yang Liu', u'Fenghui Zhang']
AlgorithmsandTheory
Abstract: We take a new look at the multicut problem in trees through the eyes of the vertex cover problem. This connection, together with other techniques that we develop, allows us to signicantly improve the O(k^6) upper bound on the kernel size for multicut, given by Bousquet et al., to O(k^3). We exploit this connection further to present a parameterized algorithm for multicut that runs in time O(p^k), where p = ( sqrt(5) + 1)/2 ~= 1.618. This improves the previous (time) upper bound of O(2^k), given by Guo and Niedermeier, for the problem.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Near-oracle performance of greedy block-sparse estimation techniques from noisy measurements
Selected Topics in Signal Processing, vol. 5 (2011), pp. 1032-1047
[u'Zvika Ben-Haim', u'Yonina C. Eldar']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
New Exact and Approximation Algorithms for the Star Packing Problem in Undirected Graphs
28th International Symposium on Theoretical Aspects of Computer Science, Schloss Dagstuhl, Leibniz-Center for Informatics GmbH, Dagstuhl Publishing, Saarbrcken/Wadern, Germany (2011), pp. 519-530
[u'Maxim Babenko', u'Alexey Gusakov']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43983.html
found
=========================
Non-Parametric Parametricity
Journal of Funcitonal Programming, vol. 21 (4 & 5) (2011)
[u'Georg Neis', u'Derek Dreyer', u'Andreas Rossberg']
AlgorithmsandTheory
Abstract: Type abstraction and intensional type analysis are features seemingly at oddstype abstraction is intended to guarantee parametricity and representation independence, while type analysis is inherently non-parametric. Recently, however, several researchers have proposed and implemented dynamic type generation as a way to reconcile these features. The idea is that, when one defines an abstract type, one should also be able to generate at run time a fresh type name, which may be used as a dynamic representative of the abstract type for purposes of type analysis. The question remains: in a language with non-parametric polymorphism, does dynamic type generation provide us with the same kinds of abstraction guarantees that we get from parametric polymorphism? Our goal is to provide a rigorous answer to this question. We define a step-indexed Kripke logical relation for a language with both non-parametric polymorphism (in the form of type-safe cast) and dynamic type generation. Our logical relation enables us to establish parametricity and representation independence results, even in a non-parametric setting, by attaching arbitrary relational interpretations to dynamically-generated type names. In addition, we explore how programs that are provably equivalent in a more traditional parametric logical relation may be wrapped systematically to produce terms that are related by our non-parametric relation, and vice versa. This leads us to develop a polarized variant of our logical relation, which enables us to distinguish formally between positive and negative notions of parametricity.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37467.html
found
=========================
On Multiway Cut paramterized above lower bounds
IPEC 2011 (to appear)
[u'Marek Cygan', u'Marcin Pilipczuk', u'Micha Pilipczuk', u'Jakub Onufry Wojtaszczyk']
AlgorithmsandTheory
Abstract: In this paper we consider two above lower bound parameterizations of Node Multiway Cut above maximum separating cut and above a natural LP-relaxation and prove them to be fixed-parameter tractable. Our results imply O(4^k) algorithms for Vertex Cover above Maximum Matching and Almost 2-SAT as well as a O*(2^k) algorithm for Node Multiway Cut with a standard parameterization by the solution size, improving previous bounds for these problems.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
On the number of shortest descending paths on the surface of a convex terrain
Journal of Discrete Algorithms, vol. 9(2) (2011), pp. 182-189
[u'Mustaq Ahmed', u'Anil Maheshwari', u'Subhas C. Nandy', u'Sasanka Roy']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Online Stochastic Weighted Matching: Improved Approximation Algorithms
Workshop of Network and Internet Economics (WINE) 2011
[u'Bernard Haeupler', u'Vahab Mirrokni', u'Morteza Zadimoghaddam']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36742.html
found
=========================
Online Vertex-Weighted Bipartite Matching and Single-bid Budgeted Allocations
Proceedings of ACM-SIAM Symposium on Discrete Algorithms (2011)
[u'Gagan Aggarwal', u'Gagan Goel', u'Chinmay Karande', u'Aranyak Mehta']
AlgorithmsandTheory
Abstract: We study the following vertex-weighted online bipartite matching problem: G(U, V, E) is a bipartite graph. The vertices in U have weights and are known ahead of time, while the vertices in V arrive online in an arbitrary order and have to be matched upon arrival. The goal is to maximize the sum of weights of the matched vertices in U. When all the weights are equal, this reduces to the classic online bipartite matching problem for which Karp, Vazirani and Vazirani gave an optimal (1 1/e)-competitive algorithm in their seminal work [KVV90]. Our main result is an optimal (1 1/e)-competitive randomized algorithm for general vertex weights. We use random perturbations of weights by appropriately chosen multiplicative factors. Our solution constitutes the rst known generalization of the algorithm in [KVV90] in this model and provides new insights into the role of randomization in online allocation problems. It also effectively solves the problem of online budgeted allocations [MSVV05] in the case when an agent makes the same bid for any desired item, even if the bid is comparable to his budget - complementing the results of [MSVV05, BJN07] which apply when the bids are much smaller than the budgets.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Online bipartite matching with unknown distributions
STOC '11 (2011)
[u'Chinmay Karande', u'Aranyak Mehta', u'Pushkar Tripathi']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34405.html
found
=========================
Physics, Topology, Logic and Computation: A Rosetta Stone
Lecture Notes in Physics, vol. 813 (2011), pp. 95-172
[u'John Baez', u'Michael Stay']
AlgorithmsandTheory
Abstract: In physics, Feynman diagrams are used to reason about quantum processes. In the 1980s, it became clear that underlying these diagrams is a powerful analogy between quantum physics and topology: namely, a linear operator behaves very much like a "cobordism". Similar diagrams can be used to reason about logic, where they represent proofs, and computation, where they represent programs. With the rise of interest in quantum cryptography and quantum computation, it became clear that there is extensive network of analogies between physics, topology, logic and computation. In this expository paper, we make some of these analogies precise using the concept of "closed symmetric monoidal category". We assume no prior knowledge of category theory, proof theory or computer science.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Quantum algorithms for testing properties of distributions
IEEE Transactions on Information Theory (2011)
[u'Sergey Bravyi', u'Aram Harrow', u'Avinatan Hassidim']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41472.html
found
=========================
Quantum query complexity of state conversion
Proceeding of 52nd Annual IEEE Symposium on Foundations of Computer Science (FOCS'11) (2011), pp. 344-353
[u'Troy Lee', u'Rajat Mittal', u'Ben Reichardt', u'Robert Spalek', u'Mario Szegedy']
AlgorithmsandTheory
Abstract: State conversion generalizes query complexity to the problem of converting between two input-dependent quantum states by making queries to the input. We characterize the complexity of this problem by introducing a natural information-theoretic norm that extends the Schur product operator norm. The complexity of converting between two systems of states is given by the distance between them, as measured by this norm. In the special case of function evaluation, the norm is closely related to the general adversary bound, a semi-definite program that lower-bounds the number of input queries needed by a quantum algorithm to evaluate a function. We thus obtain that the general adversary bound characterizes the quantum query complexity of any function whatsoever. This generalizes and simplifies the proof of the same result in the case of boolean input and output. Also in the case of function evaluation, we show that our norm satisfies a remarkable composition property, implying that the quantum query complexity of the composition of two functions is at most the product of the query complexities of the functions, up to a constant. Finally, our result implies that discrete and continuous-time query models are equivalent in the bounded-error setting, even for the general state-conversion problem.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37039.html
found
=========================
Reducing the size of resolution proofs in linear time
International Journal on Software Tools for Technology Transfer, vol. 13 (2011)
[u'Omer Bar Ilan', u'Oded Fuhrmann', u'Ofer Strichman', u'Ohad Shacham', u'Shlomo Hoory']
AlgorithmsandTheory
Abstract: DPLL-based SAT solvers progress by implicitly applying bi- nary resolution. The resolution proofs that they generate are used, afterthe SAT solvers run has terminated, for various purposes. Most notable uses in formal verification are: extracting an unsatisfiable core, extracting an interpolant, and detecting clauses that can be reused in an incremental satisfiability setting (the latter uses the proof only implicitly, during the run of the SAT solver). Making the resolution proof smaller can benefit all of these goals: it can lead to smaller cores, smaller interpolants, and smaller clauses that are propagated to the next SAT instance in an incremental setting. We suggest two methods that are linear in the size of the proof for doing so. Our first technique, called Recycle-Units , uses each learned constant (unit clause) (x) for simplifying resolution steps in which x was the pivot, prior to when it was learned. Our second technique, called Recycle-Pivots, simplifies proofs in which there are several nodes in the resolution graph, one of which dominates the others, that correspond to the same pivot. Our experiments with industrial in- stances show that these simplifications reduce the core by 5% and the proof by 13%. It reduces the core less than competing methods such as run-till-fix, but whereas our algorithms are linear in the size of the proof, the latter and other competing techniques are all exponential as they are based on SAT runs. If we consider the size of the proof (the resolution graph) as being polynomial in the number of variables (it is not necessarily the case in general), this gives our method an exponen- tial time reduction comparing to existing tools for small core extraction. Our experiments show that this result is evident in practice more so for the second method: rarely it takes more than a few seconds, even when competing tools time out, and hence it can be used as a cheap proof post-processing procedure.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37466.html
found
=========================
Scheduling partially ordered jobs faster than 2^n
ESA (2011) (to appear)
[u'Marek Cygan', u'Marcin Pilipczuk', u'Micha Pilipczuk', u'Jakub Onufry Wojtaszczyk']
AlgorithmsandTheory
Abstract: In the SCHED problem we are given a set of n jobs, together with their processing times and precedence constraints. The task is to order the jobs so that their total completion time is minimized. SCHED is a special case of the Traveling Repairman Problem with precedences. A natural dynamic programming algorithm solves both these problems in 2^n n^O(1) time, and whether there exists an algorithms solving SCHED in O(c^n) time for some constant c < 2 was an open problem posted in 2004 by Woeginger. In this paper we answer this question positively.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37147.html
found
=========================
Sharing-aware algorithms for virtual machine colocation
Proceedings of the 23rd ACM symposium on Parallelism in algorithms and architectures, ACM, New York, NY, USA (2011), pp. 367-378
[u'Michael Sindelar', u'Ramesh Sitaraman', u'Prashant Shenoy']
AlgorithmsandTheory
Abstract: Virtualization technology enables multiple virtual machines (VMs) to run on a single physical server. VMs that run on the same physical server can share memory pages that have identical content, thereby reducing the overall memory requirements on the server. We develop sharing-aware algorithms that can colocate VMs with similar page content on the same physical server to optimize the benefits of inter-VM sharing. We show that inter-VM sharing occurs in a largely hierarchical fashion, where the sharing can be attributed to VM's running the same OS platform, OS version, software libraries, or applications. We propose two hierarchical sharing models: a tree model and a more general cluster-tree model. Using a set of VM traces, we show that up to 67% percent of the inter-VM sharing is captured by the tree model and up to 82% is captured by the cluster-tree model. Next, we study two problem variants of critical interest to a virtualization service provider: the VM Maximization problem that determines the most profitable subset of the VMs that can be packed into the given set of servers, and the VM packing problem that determines the smallest set of servers that can accommodate a set of VMs. While both variants are NP-hard, we show that both admit provably good approximation schemes in the hierarchical sharing models. We show that VM maximization for the tree and cluster-tree models can be approximated in polytime to within a (1 - 1/e) factor of optimal. Further, we show that VM packing can be approximated in polytime to within a factor of O(log n) of optimal for cluster-trees and to within a factor of 3 of optimal for trees, where n is the number of VMs. Finally, we evaluate our VM packing algorithm for the tree sharing model on real-world VM traces and show that our algorithm can exploit most of the available inter-VM sharing to achieve a 32% to 50% reduction in servers and a 25% to 57% reduction in memory footprint compared to sharing-oblivious algorithms.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Shortest descending paths: Towards an exact algorithm
International J. Computational Geometry and Applications, vol. 21(4) (2011), pp. 431-466
[u'Mustaq Ahmed', u'Anna Lubiw']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Simple Adaptive Cognition for PSO
In Proceedings of the Congress on Evolutionary Computation (CEC 2011), IEEE Press
[u'Christopher K. Monson']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42859.html
found
=========================
Simultaneous Technology Mapping and Placement for Delay Minimization
IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS, vol. 30 (2011), pp. 416-426
[u'Yifang Liu', u'Rupesh S. Shelar', u'Jiang Hu']
AlgorithmsandTheory
Abstract: AbstractTechnology mapping and placement have a significant impact on delays in standard cell-based very large scale integrated circuits. Traditionally, these steps are applied separately to optimize the delays, possibly since efficient algorithms that allow the simultaneous exploration of the mapping and placement solution spaces are unknown. In this paper, we present an exact polynomial time algorithm for delay-optimal placement of a tree and extend the same to simultaneous technology mapping and placement for the optimal delay in the tree. We extend the algorithm by employing Lagrangian relaxation technique, which assesses the timing criticality of paths beyond a tree, to optimize the delays in directed acyclic graphs. Experimental results on benchmark circuits in a 70 nm technology show that our algorithms improve timing significantly with remarkably less runtimes compared to a competitive approach of iterative conventional timing-driven mapping and multilevel placement. Index Termsalgorithms, directed acyclic graph, physical synthesis, placement, technology mapping, tree.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37373.html
found
=========================
Solving connectivity problems parameterized by treewidth in single exponential time
Foundations of Computer Science 2011, Rynek Gwny 12 (to appear)
[u'Marek Cygan', u'Jesper Nederlof', u'Marcin Pilipczuk', u'Micha Pilipczuk', u'Johann M. M. van Rooij', u'Jakub Onufry Wojtaszczyk']
AlgorithmsandTheory
Abstract: For the vast majority of local problems on graphs of small treewidth (where by local we mean that a solution can be verified by checking separately the neighbourhood of each vertex), standard dynamic programming techniques give c^tw |V|^O(1) time algorithms, where tw is the treewidth of the input graph, G = (V; E) and c is a constant. On the other hand, for problems with a global requirement (usually connectivity) the bestknown algorithms were naive dynamic programming schemes running in at least tw^tw time. We breach this gap by introducing a technique we named Cut&Count that allows to produce c^tw |V|^O(1) time Monte Carlo algorithms for most connectivity-type problems, including HAMILTONIAN PATH, STEINER TREE, FEEDBACK VERTEX SET and CONNECTED DOMINATING SET. These results have numerous consequences in various elds, like parameterized complexity, exact and approximate algorithms on planar and H-minor-free graphs and exact algorithms on graphs of bounded degree. The constant c in our algorithms is in all cases small, and in several cases we are able to show that improving those constants would cause the Strong Exponential Time Hypothesis to fail. In contrast to the problems aiming to minimize the number of connected components that we solve using Cut&Count as mentioned above, we show that, assuming the Exponential Time Hypothesis, the aforementioned gap cannot be breached for some problems that aim to maximize the number of connected components like CYCLE PACKING.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37063.html
found
=========================
Space-Filling Trees: A New Perspective on Incremental Search for Motion Planning
Proc. IEEE/RSJ International Conference on Intelligent Robots and Systems, IEEE (2011)
[u'James J. Kuffner', u'Steven M. LaValle']
AlgorithmsandTheory
Abstract: This paper introduces space-filling trees and analyzes them in the context of sampling-based motion planning. Space-filling trees are analogous to space-filling curves, but have a branching, tree-like structure, and are defined by an incremental process that results in a tree for which every point in the space has a finite-length path that converges to it. In contrast to space-filling curves, individual paths in the tree are short, allowing any part of the space to be quickly reached from the root. We compare some basic constructions of space-filling trees to Rapidly-exploring Random Trees (RRTs), which underlie a number of popular algorithms used for sampling-based motion planning. We characterize several key tree properties related to path quality and the overall efficiency of exploration and conclude with a number of open mathematical questions.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37375.html
found
=========================
Subset Feedback Vertex Set is fixed parameter tractable
ICALP 2011 (to appear)
[u'Marek Cygan', u'Marcin Pilipczuk', u'Micha Pilipczuk', u'Jakub Onufry Wojtaszczyk']
AlgorithmsandTheory
Abstract: The classical Feedback Vertex Set problem asks, for a given undirected graph G and an integer k, to find a set of at most k vertices that hits all the cycles in the graph G. Feedback Vertex Set has attracted a large amount of research in the parameterized setting, and subsequent kernelization and fixed-parameter algorithms have been a rich source of ideas in the field. In this paper we consider a more general and difficult version of the problem, named Subset Feedback Vertex Set (SFVS in short) where an instance comes additionally with a set S of vertices, and we ask for a set of at most k vertices that hits all simple cycles passing through S. Because of its applications in circuit testing and genetic linkage analysis SFVS was studied from the approximation algorithms perspective by Even et al. [SICOMP'00, SIDMA'00]. The question whether the SFVS problem is fixed parameter tractable was posed independently by Kawarabayashi and Saurabh in 2009. We answer this question affirmatively. We begin by showing that this problem is fixed-parameter tractable when parametrized by |S|. Next we present an algorithm which reduces the size of S to O(k^3) in 2^{O(k\log k)}n^{O(1)} time using kernelization techniques such as the 2-Expansion Lemma, Menger's theorem and Gallai's theorem. These two facts allow us to give a 2^{O(k\log k)} n^{O(1)} time algorithm solving the SFVS problem, proving that it is indeed fixed parameter tractable.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Telling Two Distributions Apart: a Tight Characterization
Arxiv.org (2011)
[u'Eyal Even-Dar', u'Mark Sandler']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37127.html
found
=========================
The Method of Moments and Degree Distributions for Network Models
Annals of Statistics (2011)
[u'Peter Bickel', u'Aiyou Chen', u'Liza Levina']
AlgorithmsandTheory
Abstract: Probability models on graphs are becoming increasingly important in many applications, but statistical tools for fitting such models are not yet well developed. Here we propose a general method of moments approach that can be used to fit a large class of probability models through empirical counts of certain patterns in a graph. We establish some general asymptotic properties of empirical graph moments and prove consistency of the estimates as the graph size grows for all ranges of the average degree including (1). Additional results are obtained for the important special case of degree distributions.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
The provably total search problems of bounded arithmetic
Proceedings of the London Mathematical Society (2011), pp. 1-33
[u'Alan Skelley', u'Neil Thapen']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37259.html
found
=========================
Traffic Light Mapping and Detection
Proceedings of ICRA 2011
[u'Nathaniel Fairfield', u'Chris Urmson']
AlgorithmsandTheory
Abstract: The outdoor perception problem is a major challenge for driver-assistance and autonomous vehicle systems. While these systems can often employ active sensors such as sonar, radar, and lidar to perceive their surroundings, the state of standard traffic lights can only be perceived visually. By using a prior map, a perception system can anticipate and predict the locations of traffic lights and improve detection of the light state. The prior map also encodes the control semantics of the individual lights. This paper presents methods for automatically mapping the three dimensional positions of traffic lights and robustly detecting traffic light state onboard cars with cameras. We have used these methods to map more than four thousand traffic lights, and to perform onboard traffic light detection for thousands of drives through intersections.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36975.html
found
=========================
Yield Optimization of Display Advertising with Ad Exchange
ACM Conference on Electronic Commerce (2011)
[u'Santiago Balseiro', u'Jon Feldman', u'Vahab Mirrokni', u'S. Muthukrishnan']
AlgorithmsandTheory
Abstract: In light of the growing market of Ad Exchanges for the real-time sale of advertising slots, publishers face new challenges in choosing between the allocation of contract-based reservation ads and spot market ads. In this setting, the publisher should take into account the tradeoff between short-term revenue from an Ad Exchange and quality of allocating reservation ads. In this paper, we formalize this combined optimization problem as a stochastic control problem and derive an efficient policy for online ad allocation in settings with general joint distribution over placement quality and exchange bids. We prove asymptotic optimality of this policy in terms of any trade-off between quality of delivered reservation ads and revenue from the exchange, and provide a rigorous bound for its convergence rate to the optimal policy. We also give experimental results on data derived from real publisher inventory, showing that our policy can achieve any pareto-optimal point on the quality vs. revenue curve. Finally, we study a parametric training-based algorithm in which instead of learning the dual variables from a sample data (as is done in non-parametric training-based algorithms), we learn the parameters of the distribution and construct those dual variables from the learned parameter values. We compare parametric and non-parametric ways to estimate from data both analytically and experimentally in the special case without the ad exchange, and show that though both methods converge to the optimal policy as the sample size grows, our parametric method converges faster, and thus performs better on smaller samples.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A 1.43-Competitive Online Graph Edge Coloring Algorithm in the Random Order Arrival Model.
Proceedings of the Twenty-First Annual ACM-SIAM Symposium on Discrete Algorithms, SODA 2010,, SIAM, pp. 31-39
[u'Bahman Bahmani', u'Aranyak Mehta', u'Rajeev Motwani']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A modern Bayesian look at the multi-armed bandit
Applied Stochastic Models in Business and Industry, vol. 26 (2010), pp. 639-658
[u'Steven L. Scott']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Achieving anonymity via clustering
ACM Transactions on Algorithms, vol. 6 (2010), 49:1-49:19
[u'Gagan Aggarwal', u'Toms Feder', u'Krishnaram Kenthapadi', u'Samir Khuller', u'Rina Panigrahy', u'Dilys Thomas', u'An Zhu']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Auctions with intermediaries: extended abstract
ACM Conference on Electronic Commerce (2010), pp. 23-32
[u'Jon Feldman', u'Vahab S. Mirrokni', u'S. Muthukrishnan', u'Mallesh M. Pai']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Beyond Position Bias: Examining Result Attractiveness as a Source of Presentation Bias in Clickthrough Data
WWW, WWW, Raleigh, NC, USA (2010)
[u'Yisong Yue', u'Rajan Patel', u'Hein Roehrig']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Bucketing coding and information theory for the statistical high-dimensional nearest-neighbor problem
IEEE Transactions on Information Theory, vol. 56(8) (2010), pp. 4166-4179
[u'Moshe Dubiner']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Equilibrium Pricing with Positive Externalities (Extended Abstract)
WINE (2010), pp. 424-431
[u'Nima Anari', u'Shayan Ehsani', u'Mohammad Ghodsi', u'Nima Haghpanah', u'Nicole Immorlica', u'Hamid Mahini', u'Vahab Mirrokni']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36552.html
found
=========================
Evaluating Online Ad Campaigns in a Pipeline: Causal Models at Scale
Proceedings of ACM SIGKDD 2010, pp. 7-15
[u'David Chan', u'Rong Ge', u'Ori Gershony', u'Tim Hesterberg', u'Diane Lambert']
AlgorithmsandTheory
Abstract: Display ads proliferate on the web, but are they effective? Or are they irrelevant in light of all the other advertising that people see? We describe a way to answer these questions, quickly and accurately, without randomized experiments, surveys, focus groups or expert data analysts. Doubly robust estimation protects against the selection bias that is inherent in observational data, and a nonparametric test that is based on irrelevant outcomes provides further defense. Simulations based on realistic scenarios show that the resulting estimates are more robust to selection bias than traditional alternatives, such as regression modeling or propensity scoring. Moreover, computations are fast enough that all processing, from data retrieval through estimation, testing, validation and report generation, proceeds in an automated pipeline, without anyone needing to see the raw data.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36495.html
found
=========================
Evaluating TV Ad Campaigns Using Set-Top Box Data
Re:Think 2010
[u'Sundar Dorai-Raj', u'Yannet Interian', u'Dan Zigmond']
AlgorithmsandTheory
Abstract: Google has developed new metrics based on set-top box data for predicting the future audience retention of TV ads. This paper examines how to use these metrics to judge the effectiveness of TV ad campaigns. More specifically, we analyze how these metrics can inform future campaign targeting and placement goals.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36672.html
found
=========================
Fast Routing in Very Large Public Transportation Networks Using Transfer Patterns
Algorithms - ESA 2010, 18th Annual European Symposium. Proceedings, Part I, Springer, pp. 290-301
[u'Hannah Bast', u'Erik Carlsson', u'Arno Eigenwillig', u'Robert Geisberger', u'Chris Harrelson', u'Veselin Raychev', u'Fabien Viger']
AlgorithmsandTheory
Abstract: We show how to route on very large public transportation networks (up to half a billion arcs) with average query times of a few milliseconds. We take into account many realistic features like: traffic days, walking between stations, queries between geographic locations instead of a source and a target station, and multi-criteria cost functions. Our algorithm is based on two key observations: (1) many shortest paths share the same transfer pattern, i.e., the sequence of stations where a change of vehicle occurs; (2) direct connections without change of vehicle can be looked up quickly. We precompute the respective data; in practice, this can be done in time linear in the network size, at the expense of a small fraction of non-optimal results. We have accelerated public transportation routing on Google Maps with a system based on our ideas. We report experimental results for three data sets of various kinds and sizes.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Filters for Efficient Composition of Weighted Finite-State Transducers
CIAA (2010), pp. 28-38
[u'Cyril Allauzen', u'Michael Riley', u'Johan Schalkwyk']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36496.html
found
=========================
How Surfers Watch: Measuring audience response to video advertising online
Proceedings of ADKDD (2010)
[u'Sundar Dorai-Raj', u'Dan Zigmond']
AlgorithmsandTheory
Abstract: For several years, Google has been analyzing television set-top box data to measure audience response to specific TV ads. This paper presents how similar techniques can be applied to online video advertising on YouTube. As more and more video programming is made available online, it will become increasingly important to understand how to engage with online viewers through video advertising. Furthermore, we find that viewing behavior is even more effected by specific video ad creatives online than it is on TV. This suggests that online viewing can become a valuable source data on viewer response to video ad creatives more generally.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Inferring strings from runs
In Proc. The Prague Stringology Conference '10 (PSC'10) (2010)
[u'Wataru Matsubara', u'Akira Ishino', u'Ayumi Shinohara']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Market Equilibrium with Transaction Costs
WINE 2010
[u'Sourav Chakraborty', u'Nikhil Devanur', u'Chinmay Karande']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36582.html
found
=========================
Max-Cover in Map-Reduce
Proceedings of the 19th international conference on World Wide Web, ACM, Raleigh, North Carolina (2010), pp. 231-240
[u'Flavio Chierichetti', u'Ravi Kumar', u'Andrew Tomkins']
AlgorithmsandTheory
Abstract: The NP-hard Max-k-cover problem requires selecting k sets from a collection so as to maximize the size of the union. This classic problem occurs commonly in many settings in web search and advertising. For moderately-sized instances, a greedy algorithm gives an approximation of (1-1/e). However, the greedy algorithm requires updating scores of arbitrary elements after each step, and hence becomes intractable for large datasets. We give the first max cover algorithm designed for today's large-scale commodity clusters. Our algorithm has provably almost the same approximation as greedy, but runs much faster. Furthermore, it can be easily expressed in the MapReduce programming paradigm, and requires only polylogarithmically many passes over the data. Our experiments on five large problem instances show that our algorithm is practical and can achieve good speedups compared to the sequential greedy algorithm.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Maximizing Nonmonotone Submodular Functions under Matroid or Knapsack Constraints
SIAM J. Discrete Math., vol. 23 (2010), pp. 2053-2078
[u'Jon Lee', u'Vahab S. Mirrokni', u'Viswanath Nagarajan', u'Maxim Sviridenko']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Monitoring Algorithms for Negative Feedback Systems
WWW, ACM (2010), pp. 871-880
[u'Mark Sandler', u'S. Muthukrishnan']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Online Stochastic Packing Applied to Display Ad Allocation
ESA (1) (2010), pp. 182-194
[u'Jon Feldman', u'Monika Henzinger', u'Nitish Korula', u'Vahab S. Mirrokni', u'Clifford Stein']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Quasi-Proportional Mechanisms: Prior-free Revenue Maximization
Latin (2010), to appear
[u'Vahab S. Mirrokni', u'S. Muthukrishnan', u'Uri Nadav']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Revenue Management of Reusable Resources - Provably Near-Optimal LP-Based Policies
Operations Research, vol. 58(2) (2010)
[u'Retsef Levi', u'Ana Radovanovic']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Revenue Maximization in Reservation-based Online Advertising Through Dynamic Inventory Management
48th Annual Allerton Conference on Communication, Control and Computing (2010), pp. 1502-1509
[u'Ana Radovanovic', u'Assaf Zeevi']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Robust self-assembly of graphs
Natural Computing, vol. 9 (2010), pp. 111-133
[u'Stanislav Angelov', u'Sanjeev Khanna', u'Mirk Visontai']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36825.html
found
=========================
SemWebVid - Making Video a First Class Semantic Web Citizen and a First Class Web Bourgeois
International Semantic Web Conference 2010 (ISWC2010)
[u'Thomas Steiner']
AlgorithmsandTheory
Abstract: SemWebVid is an online Ajax application that allows for the automatic generation of Resource Description Framework (RDF) video descriptions. These descriptions are based on two pillars: first, on a combination of user-generated metadata such as title, summary, and tags; and second, on closed captions which can be user-generated, or be auto-generated via speech recognition. The plaintext contents of both pillars are being analyzed using multiple Natural Language Processing (NLP) Web services in parallel whose results are then merged and where possible matched back to concepts in the sense of Linking Open Data (LOD). The final result is a deep-linkable RDF description of the video, and a scroll-along view of the video as an example of video visualization formats.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41367.html
found
=========================
Semantic Multimodal Compression for Wearable sensing Systems
In Proceedings of the 9th Annual IEEE Conference on Sensors, IEEE (2010), pp. 1149-1453
[u'Saro Meguerdichian', u'Hyduke Noshadi', u'Foad Dabiri', u'Miodrag Potkonjak']
AlgorithmsandTheory
Abstract: Wearable sensing systems (WSS's) are emerging as an important class of distributed embedded systems in application domains ranging from medical to military. Such systems can be expensive and power hungry due to their multi sensor implementations that require constant use, yet by nature they demand low-cost and low-power implementations. Semantic multimodal compression (SMC) mitigates these metrics in terms of data size by leveraging the natural tendency of signals in many types of embedded sensing systems to be composed of phases. In our driving example of a medical shoe with an insole lined with pressure sensors, we find that the natural airborne, landing, and take-off segments have sharply different and repetitive properties. SMC models and compresses each segment independently, selecting the best compression scheme for each segment and thus reducing total transmission energy.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36556.html
found
=========================
Statistical verification of probabilistic properties with unbounded until
Proceedings of the 13th Brazilian Symposium on Formal Methods, Springer, Berlin / Heidelberg (2010), pp. 144-160
[u'Hkan L. S. Younes', u'Edmund M. Clarke', u'Paolo Zuliani']
AlgorithmsandTheory
Abstract: We consider statistical (sampling-based) solution methods for verifying probabilistic properties with unbounded until. Statistical solution methods for probabilistic verification use sample execution trajectories for a system to verify properties with some level of confidence. The main challenge with properties that are expressed using unbounded until is to ensure termination in the face of potentially infinite sample execution trajectories. We describe two alternative solution methods, each one with its own merits. The first method relies on reachability analysis, and is suitable primarily for large Markov chains where reachability analysis can be performed efficiently using symbolic data structures, but for which numerical probability computations are expensive. The second method employs a termination probability and weighted sampling. This method does not rely on any specific structure of the model, but error control is more challenging. We show how the choice of termination probability---when applied to Markov chains---is tied to the subdominant eigenvalue of the transition probability matrix, which relates it to iterative numerical solution techniques for the same problem.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Trawling Traffic under Attack, Overcoming DDoS Attacks by Target-Controlled Traffic Filtering
econd International Workshop on Reliability, Availability, and Security (WRAS) (2010), pp. 336-341
[u'Shlomi Dolev', u'Yuval Elovici', u'Alex Kesselman', u'Polina Zilberman']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36581.html
found
=========================
A Complete, Co-Inductive Syntactic Theory of Sequential Control and State
Semantics and Algebraic Specification: Essays Dedicated to Peter D. Mosses on the Occasion of His 60th Birthday, Springer (2009), pp. 329-375
[u'Kristian Stvring', u'Soren B. Lassen']
AlgorithmsandTheory
Abstract: We present a co-inductive syntactic theory, eager normal form bisimilarity, for the untyped call-by-value lambda calculus extended with continuations and mutable references. We demonstrate that the associated bisimulation proof principle is easy to use and that it is a powerful tool for proving equivalences between recursive imperative higher-order programs. The theory is modular in the sense that eager normal form bisimilarity for each of the calculi extended with continuations and/or mutable references is a fully abstract extension of eager normal form bisimilarity for its sub-calculi. For each calculus, we prove that eager normal form bisimilarity is a congruence and is sound with respect to contextual equivalence. Furthermore, for the calculus with both continuations and mutable references, we show that eager normal form bisimilarity is complete: it coincides with contextual equivalence. Eager normal form bisimilarity is inspired by Bhm-tree equivalence in the pure lambda calculus. We clarify the associated proof principle by reviewing properties of Bhm trees and surveying previous work on normal form bisimulation. Extended version of an earlier conference paper, incorporating parts of Chapter 2 of the first authors PhD dissertation.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A new family of Markov branching trees: the alpha-gamma model
Electronic Journal of Probability (2009), pp. 400-430
[u'Bo Chen', u'Daniel Ford', u'Matthias Winkel']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35581.html
found
=========================
Adaptive Dynamic of Realistic Small World Networks
2009 European Conference on Complex Systems (to appear)
[u'Olof Mogren', u'Oskar Sandberg', u'Vilhelm Verendel', u'Devdatt Dubhashi']
AlgorithmsandTheory
Abstract: Continuing in the steps of Jon Kleinbergs and others celebrated work on decentralized search, we conduct an experimental analysis of destination sampling, a dynamic algorithm that produces small-world networks. We find that the algorithm adapts robustly to a wide variety of situations in realistic geographic networks with synthetic test data and with real world data, even when vertices are unevenly and non-homogeneously distributed. We investigate the same algorithm in the case where some vertices are more popular destinations for searches than others, for example obeying power-laws. We find that the algorithm adapts and adjusts the networks according to the distributions, leading to improved performance. The ability of the dynamic process to adapt and create small worlds in such diverse settings suggests a possible mechanism by which such networks appear in nature.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35369.html
found
=========================
Affiliation Networks
Proceedings of the 41st Annual ACM Symposium on Theory of Computing, ACM (2009), pp. 427-434
[u'Silvio Lattanzi', u'D. Sivakumar']
AlgorithmsandTheory
Abstract: In the last decade, structural properties of several naturally arising networks (the Internet, social networks, the web graph, etc.) have been studied intensively with a view to understanding their evolution. In recent empirical work, Leskovec, Kleinberg, and Faloutsos identify two new and surprising properties of the evolution of many real-world networks: densification (the ratio of edges to vertices grows over time), and shrinking diameter (the diameter reduces over time to a constant). These properties run counter to conventional wisdom, and are certainly inconsistent with graph models prior to their work. In this paper, we present the first model that provides a simple, realistic, and mathematically tractable generative model that intrinsically explains all the well-known properties of the social networks, as well as densification and shrinking diameter. Our model is based on ideas studied empirically in the social sciences, primarily on the groundbreaking work of Breiger (1973) on bipartite models of social networks that capture the affiliation of agents to societies. We also present algorithms that harness the structural consequences of our model. Specifically, we show how to overcome the bottleneck of densification in computing shortest paths between vertices by producing sparse subgraphs that preserve or approximate shortest distances to all or a distinguished subset of vertices. This is a rare example of an algorithmic benefit derived from a realistic graph model. Finally, our work also presents a modular approach to connecting random graph paradigms (preferential attachment, edge-copying, etc.) to structural consequences (heavy-tailed degree distributions, shrinking diameter, etc.)
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35260.html
found
=========================
Algorithms for Secretary Problems on Graphs and Hypergraphs
ICALP 2009
[u'Nitish Korula', u'Martin Pl']
AlgorithmsandTheory
Abstract: We examine several online matching problems, with applications to Internet advertising reservation systems. Consider an edge-weighted bipartite graph G, with partite sets L, R. We develop an 8-competitive algorithm for the following secretary problem: Initially given R, and the size of L, the algorithm receives the vertices of L sequentially, in a random order. When a vertex l \in L is seen, all edges incident to l are revealed, together with their weights. The algorithm must immediately either match l to an available vertex of R, or decide that l will remain unmatched. Dimitrov and Plaxton show a 16-competitive algorithm for the transversal matroid secretary problem, which is the special case with weights on vertices, not edges. (Equivalently, one may assume that for each l \in L, the weights on all edges incident to l are identical.) We use a similar algorithm, but simplify and improve the analysis to obtain a better competitive ratio for the more general problem. Perhaps of more interest is the fact that our analysis is easily extended to obtain competitive algorithms for similar problems, such as to find disjoint sets of edges in hypergraphs where edges arrive online. We also introduce secretary problems with adversarially chosen groups. Finally, we give a 2e-competitive algorithm for the secretary problem on graphic matroids, where, with edges appearing online, the goal is to find a maximum-weight acyclic subgraph of a given graph.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Approximating Submodular Functions Everywhere
Symposium on Discrete Algorithms (SODA) (2009)
[u'Michel Goemans', u'Nick Harvey', u'S. Iwata', u'Vahab Mirrokni']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Approximation Hardness of Deadline-TSP Reoptimization
Theory of Computing Systems, vol. 410 (2009), pp. 2241-2249
[u'Hans-Joachim Bckenhauer', u'Joachim Kneis', u'Joachim Kupke']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Asymptotic Optimality of the Static Frequency Caching in the Presence of Correlated Requests
Operations Research Letters, vol. 37 (2009), pp. 307-311
[u'Predrag Jelenkovic', u'Ana Radovanovic']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Average Value of Sum of Exponents of Runs in a String
International Journal of Foundations of Computer Science, vol. 20(6) (2009), pp. 1135-1146
[u'Kazuhiko Kusano', u'Wataru Matsubara', u'Akira Ishino', u'Ayumi Shinohara']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Bid optimization for broad match ad auctions
WWW (2009), pp. 231-240
[u'Eyal Even-Dar', u'Vahab S. Mirrokni', u'S. Muthukrishnan', u'Yishay Mansour', u'Uri Nadav']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Competitive Routing over Time
Workshop of Internet Economics (WINE) (2009), pp. 18-29
[u'Martin Hoefer', u'Vahab S. Mirrokni', u'Heiko Rglin', u'Shang-Hua Teng']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Competitive buffer management with packet dependencies
2009 IEEE International Symposium on Parallel&Distributed Processing, IEEE Computer Society, pp. 1-12
[u'Alex Kesselman', u'Boaz Patt-Shamir', u'Gabriel Scalosub']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Coordination mechanisms for selfish scheduling
Theor. Comput. Sci., vol. 410 (2009), pp. 1589-1598
[u'Nicole Immorlica', u'Li (Erran) Li', u'Vahab S. Mirrokni', u'Andreas S. Schulz']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Detecting The Origin Of Text Segments Efficiently
Proceedings of WWW'2009 (to appear)
[u'Ossama Abdel-Hamid', u'Behshad Behzadi', u'Stefan Christoph', u'Monika Henzinger']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35605.html
found
=========================
Differential Synchronization
DocEng'09, Proceedings of the 2009 ACM Symposium on Document Engineering, The Association for Computing Machinery, 2 Penn Plaza, Suite 701, New York, New York 10121-0701, pp. 13-20
[u'Neil Fraser']
AlgorithmsandTheory
Abstract: This paper describes the Differential Synchronization (DS) method for keeping documents synchronized. The key feature of DS is that it is simple and well suited for use in both novel and existing state-based applications without requiring application redesign. DS uses deltas to make efficient use of bandwidth, and is fault-tolerant, allowing copies to converge in spite of occasional errors. We consider practical implementation of DS and describe some techniques to improve its performance in a browser environment.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Efficient Algorithms to Compute Compressed Longest Common Substrings and Compressed Palindromes
Theoretical Computer Science, vol. 410 (8--10) (2009), pp. 900-913
[u'Wataru Matsubara', u'Shunsuke Inenaga', u'Akira Ishino', u'Ayumi Shinohara', u'Tomoyuki Nakamura', u'Kazuo Hashimoto']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
General Auction Mechanism for Search Advertising
WWW 2009
[u'Gagan Aggarwal', u'S. Muthukrishnan', u'David Pal', u'Martin Pl']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
General Suffix Automaton Construction Algorithm and Space Bounds
Theoretical Computer Science, vol. 410 (2009)
[u'Mehryar Mohri', u'Pedro Moreno', u'Eugene Weinstein']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35667.html
found
=========================
Measuring Advertising Quality on Television: Deriving Meaningful Metrics from Audience Retention Data
Journal of Advertising Research, vol. 49 (2009), pp. 419-428
[u'Dan Zigmond', u'Sundar Dorai-Raj', u'Yannet Interian', u'Igor Naverniouk']
AlgorithmsandTheory
Abstract: This paper introduces a measure of television ad quality based on audience retention, using logistic regression techniques to normalize such scores against expected audience behavior. By adjusting for features such as time of day, network, recent user behavior, and household demographics, we are able to isolate ad quality from these extraneous factors. We introduce the current model used in our production system, as well as two new competing models that show some improvement. We also devise metrics for calculating a models predictive power and variance, allowing us to determine which of our models performs best. We conclude with discussions of retention score applications for advertisers to evaluate their ad strategies, and potential as an aid in future ad pricing.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36235.html
found
=========================
Metric Embeddings with Relaxed Guarantees
SIAM Journal on Computing, vol. 38 (2009), pp. 2303-2329
[u'T H Hubert Chan', u'Kedar Dhamdhere', u'Anupam Gupta', u'Jon m Kleinberg', u'Aleksandrs Slivkins']
AlgorithmsandTheory
Abstract: We consider the problem of embedding finite metrics with slack: We seek to produce embeddings with small dimension and distortion while allowing a (small) constant fraction of all distances to be arbitrarily distorted. This definition is motivated by recent research in the networking community, which achieved striking empirical success at embedding Internet latencies with low distortion into low-dimensional Euclidean space, provided that some small slack is allowed. Answering an open question of Kleinberg, Slivkins, and Wexler [in Proceedings of the 45th IEEE Symposium on Foundations of Computer Science, 2004], we show that provable guarantees of this type can in fact be achieved in general: Any finite metric space can be embedded, with constant slack and constant distortion, into constant-dimensional Euclidean space. We then show that there exist stronger embeddings into $\ell_1$ which exhibit gracefully degrading distortion: There is a single embedding into $\ell_1$ that achieves distortion at most $O(\log\frac{1}{\epsilon})$ on all but at most-1.5pt an $\epsilon$ fraction of distances simultaneously for all $\epsilon>0$. We extend this with distortion1pt $O(\log\frac{1}{\epsilon})^{1/p}$ to maps into general $\ell_p$, $p\geq1$, for several classes of metrics, including those with bounded doubling dimension and those arising from the shortest-path metric of a graph with an excluded minor. Finally, we show that many of our constructions are tight and give a general technique to obtain lower bounds for $\epsilon$-slack embeddings from lower bounds for low-distortion embeddings.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
N-Way Composition of Weighted Finite-State Transducers
International Journal of Foundations of Computer Science, vol. 20 (2009), pp. 613-627
[u'Cyril Allauzen', u'Mehryar Mohri']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Non-monotone submodular maximization under matroid and knapsack
STOC (2009), pp. 323-332
[u'Jon Lee', u'Vahab S. Mirrokni', u'Viswanath Nagarajan', u'Maxim Sviridenko']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35384.html
found
=========================
On the Convergence of Regret Minimization Dynamics in Concave Games
41st Annual ACM Symposium on Theory of Computing, STOC, ACM (2009), pp. 523-532
[u'Eyal Even-Dar', u'Yishay Mansour', u'Uri Nadav']
AlgorithmsandTheory
Abstract: We consider standard regret minimization setting where at each time step the decision maker has to choose a distribution over k alternatives, and then observes the loss of each alternative. The setting is very similar to the classical online job scheduling setting with three major differences: Information model: in the regret minimization setting losses are only observed after the actions (assigning the job to a machine) is performed and not observed before the action selection, as assumed in the classical online job scheduling setting, The comparison class: in regret minimization the comparison class is the best static algorithm (i.e., distribution over alternatives) and not the optimal offline solution. Performance measure: In regret minimization we measure the additive difference to the optimal solution in the comparison class, in contrast to the ratio used in online job scheduling setting. Motivated by load balancing and job scheduling, we consider a global cost function (over the losses incur by each alternative/machine), rather than simply a summation of the instantaneous losses as done traditionally in regret minimization. Such global cost functions include the makespan (the maximum over the alternatives/machines) and the Ld norm (over the alternatives/machines). The major contribution of this work is to design a novel regret minimization algorithm based on calibration that guarantees a vanishing average regret, where the regret is measured with respect to the best static decision maker, who selects the same distribution over alternatives at every time step. Our results hold for a wide class of global cost functions. which include the makespan and the Ld norms, for d>1. In contrast, we show that for concave global cost functions, such as Ld norms for d<1, the worst-case average regret does not vanish. In addition to the general calibration based algorithm, we provide simple and efficient algorithms for special interesting cases.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
On the Fourier spectrum of symmetric Boolean functions
Combinatorica, vol. 29 (2009), pp. 363-387
[u'Mihail N. Kolountzakis', u'Richard J. Lipton', u'Evangelos Markakis', u'Aranyak Mehta', u'Nisheeth K. Vishnoi']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
On the complexity of nash dynamics and sink equilibria
ACM Conference on Electronic Commerce (2009), pp. 1-10
[u'Vahab S. Mirrokni', u'Alexander Skopalik']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Online Ad Assignment with Free Disposal
Workshop of Internet Economics (WINE) (2009), pp. 374-385
[u'Jon Feldman', u'Nitish Korula', u'Vahab S. Mirrokni', u'S. Muthukrishnan', u'Martin Pl']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35385.html
found
=========================
Online Learning with Global Cost Functions
22nd Annual Conference on Learning Theory, COLT, Omnipress (2009)
[u'Eyal Even-Dar', u'Robert Kleinberg', u'Shie Mannor', u'Yishay Mansour']
AlgorithmsandTheory
Abstract: We consider an online learning setting where at each time step the decision maker has to choose how to distribute the future loss between k alternatives, and then observes the loss of each alternative. Motivated by load balancing and job scheduling, we consider a global cost function (over the losses incurred by each alternative), rather than a summation of the instantaneous losses as done traditionally in online learning. Such global cost functions include the makespan (the maximum over the alternatives) and the Ld norm (over the alternatives). Based on approachability theory, we design an algorithm that guarantees vanishing regret for this setting, where the regret is measured with respect to the best static decision that selects the same distribution over alternatives at every time step. For the special case of makespan cost we devise a simple and efficient algorithm. In contrast, we show that for concave global cost functions, such as Ld norms for d<1, the worst-case average regret does not vanish.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Online Markov Decision Processes
Math. Oper. Res., vol. 34 (2009), pp. 726-736
[u'Eyal Even-Dar', u'Sham. M. Kakade', u'Yishay Mansour']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Online Stochastic Matching: Beating 1-1/e
Symposium on the Foundations of Computer Science (FOCS) (2009)
[u'Jon Feldman', u'Aranyak Mehta', u'Vahab Mirrokni', u'S. Muthukrishnan']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
PASS Approximation
APPROX-RANDOM (2009), pp. 111-124
[u'Uriel Feige', u'Nicole Immorlica', u'Vahab S. Mirrokni', u'Hamid Nazerzadeh']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Solving Maximum Flow Problems on Real World Bipartite Graphs
ALENEX (2009), pp. 14-28
[u'Cosmin Silvestru Negruseri', u'Mircea Bogdan Pasoi', u'Barbara Stanley', u'Clifford Stein', u'Cristian George Strat']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Stochastic Data Streams
MFCS '09: Proceedings of the 34th International Symposium on Mathematical Foundations of Computer Science 2009, Springer-Verlag, Berlin, Heidelberg, pp. 55-55
[u'S. Muthukrishnan']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
The Price of Uncertainty
ACM Conference on Electronic Commerce, ACM (2009), pp. 285-294
[u'Maria-Florina Balcan', u'Avrim Blum', u'Yishay Mansour']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Tutorial summary: Convergence of natural dynamics to equilibria
ICML (2009), pp. 173
[u'Eyal Even-Dar', u'Vahab S. Mirrokni']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36734.html
found
=========================
Typicality Effects and the Logic of Reciprocity
Cornell University, Ithaca, NY (2009), pp. 257-274
[u'Nir Kerem', u'Naama Friedmann', u'Yoad Winter']
AlgorithmsandTheory
Abstract: The variability in the interpretation of reciprocal expressions has been extensively addressed in the literature and received detailed semantic accounts. After pointing out a central empirical limitation of previous logical accounts of reciprocity, we argue that these approaches suffer from inadequacies due to ignoring typicality preferences with binary predicate concepts. We claim that typicality preferences are crucial for interpreting reciprocals and introduce a new principle, the Maximal Typicality Hypothesis (MTH), which analyzes reciprocals using an extension of the Strongest Meaning Hypothesis (SMH) proposed in Dalrymple et al. (1998) Unlike the SMH, which is a principle that implicitly presupposes a classical two-valued (definitional) treatment of predicate concepts, the MTH respects the fuzziness of such concepts as manifested by their typicality preferences, and expects strong correlations between these preferences and the range of logical interpretations available for reciprocal expressions. The expected correlations are supported by new empirical results elicited in a series of experiments with speakers of Hebrew.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Weighted Automata Algorithms
Handbook of weighted automata, Springer (to appear) (2009)
[u'Mehryar Mohri']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42243.html
found
=========================
Why Locally-Fair Maximal Flows in Client-Server Networks Perform Well
Computing and Combinatorics, Springer Berlin Heidelberg, 12715 NE 81st PL (2009), pp. 368-377
[u'Chad Yoshikawa', u'Ken Berman']
AlgorithmsandTheory
Abstract: Maximal flows reach at least a 1/2 approximation of the maximum flow in client-server networks. By adding only 1 additional time round to any distributed maximal flow algorithm we show how this 1/2-approximation can be improved on bounded-degree networks. We call these modified maximal flows locally fair since there is a measure of fairness prescribed to each client and server in the network. Let N=(U,V,E,b) represent a client-server network with clients U, servers V, network links E, and node capacities b, where we assume that each capacity is at least one unit. Let d(u) denote the b-weighted degree of any node uUV, = max {d(u) | uU } and = min { d(v) | vV }. We show that a locally-fair maximal flow f achieves an approximation to the maximum flow of min{1,222 }, and this result is sharp for any given integers and . This results are of practical importance since local-fairness loosely models the steady-state behavior of TCP/IP and these types of degree-bounds often occur naturally (or are easy to enforce) in real client-server systems.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
3-Way Composition of Weighted Finite-State Transducers
Proceedings of the 13th International Conference on Implementation and Application of Automata (CIAA 2008), Springer-Verlag, Heidelberg, Germany, San Francisco, California, pp. 262-273
[u'Cyril Allauzen', u'Mehryar Mohri']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Algorithmen fr dynamische geometrische Datenstrme
Ausgezeichnete Informatikdissertationen 2006 (Outstanding Informatics dissertations 2006), Gesellschaft fr Informatik (2008) (to appear)
[u'Gereon Frahling']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Algorithms for Distributed Functional Monitoring
Proc. 19th ACM-SIAM Symposium on Discrete Algorithms, SIAM, San Francisco (2008), pp. 1076-1085
[u'Graham Cormode', u'S. Muthukrishnan', u'Ke Yi']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
An approximate string matching approach for handling incorrectly typed urls
CIKM (2008), pp. 1339-1340
[u'Mihai Stroe', u'Radu Berinde', u'Cosmin Negruseri', u'Dan Popovici']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34721.html
found
=========================
Asymptotic Performance of the Non-Forced Idle Time Scheduling Policies in the Presence of Variable Demand for Resources
Proceedings of the 46th Annual Conference on Communication, Control, and Computing (2008), pp. 499-503
[u'Ana Radovanovic', u'Cliff Stein']
AlgorithmsandTheory
Abstract: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4797599&tag=1
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Attack Resistant Collaborative Filtering
The 31st Annual International ACM SIGIR Conference (SIGIR) (2008)
[u'Bhaskar Mehta', u'Wolfgang Nejdl']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Best Effort and Priority Queuing Policies for Buffered Crossbar Switches
SIROCCO '08: Proceedings of the 15th international colloquium on Structural Information and Communication Complexity, Springer-Verlag, Berlin, Heidelberg (2008), pp. 170-184
[u'Alex Kesselman', u'Kirill Kogan', u'Michael Segal']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Binary operations on automatic functions
RAIRO-Theor. Inf. Appl., vol. 42 (2008), pp. 217-236
[u'Juhani Karhumki', u'Jarkko Kari', u'Joachim Kupke']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34704.html
found
=========================
Combinational Collaborative Filtering for Personalized Community Recommendation
ACM SIGKDD Int'l Conference on Knowledge Discovery and Data Mining (KDD), ACM (2008), pp. 115-123
[u'Wen-Yen Chen', u'Dong Zhang', u'Edward Chang']
AlgorithmsandTheory
Abstract: Rapid growth in the amount of data available on social networking sites has made information retrieval increasingly challenging for users. In this paper, we propose a collaborative ltering method, Combinational Collaborative Filtering (CCF), to perform personalized community recommendations by considering multiple types of co-occurrences in social data at the same time. This ltering method fuses semantic and user information, then applies a hybrid training strategy that combines Gibbs sampling and Expectation-Maximization algorithm. To handle the large-scale dataset, parallel computing is used to speed up the model training. Through an empirical study on the Orkut dataset, we show
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Competitive buffer management for shared-memory switches
ACM Trans. Algorithms, vol. 5 (2008), pp. 1-16
[u'William Aiello', u'Alex Kesselman', u'Yishay Mansour']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Corrigendum to Efficient Similarity Search and Classification via Rank Aggregation
Proc. ACM SIGMOD International Conference on Management of Data, ACM, Vancouver (2008), pp. 1375-1376
[u'Alexandr Andoni', u'Ronald Fagin', u'Ravi Kumar', u'Mihai Patrascu', u'D. Sivakumar']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Delaunay Graphs of Point Sets in the Plane with Respect to Axis-parallel Rectangles
Proc. 19th ACM-SIAM Symposium on Discrete Algorithms, SIAM, San Francisco (2008), pp. 94-101
[u'Xiaomin Chen', u'Jnos Pach', u'Mario Szegedy', u'Gbor Tardos']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Dense fast random projections and Lean Walsh Transforms,
RANDOM (2008) (to appear)
[u'Nir Ailon', u'Edo Liberty']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Dimension Reduction Using Rademacher Series on Dual BCH Codes
Proc. 19th ACM-SIAM Symposium on Discrete Algorithms, SIAM, San Francisco (2008), pp. 1-9
[u'Nir Ailon', u'Edo Liberty']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Edge Splitting and Edmonds' Arborescence Construction for Unweighted Graphs
Proc. ACM-SIAM Symposium on Discrete Algorithms, SIAM, San Francisco (2008), pp. 455-464
[u'Anand Bhalgat', u'Ramesh Hariharan', u'Telikepalli Kavitha', u'Debmalya Panigrahi']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Estimation of Web Page Change Rates
JSM 2008
[u'Carrie Grimes', u'Daniel Ford']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
General Algorithms for Testing the Ambiguity of Finite Automata
DLT 2008, LNCS 5257, Springer, pp. 108-120
[u'Cyril Allauzen', u'Mehryar Mohri', u'Ashish Rastogi']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Improved Algorithms for Orienteering and Related Problems
Proc. 19th Annual Symposium on Discrete Algorithms (SODA), SIAM (2008)
[u'Chandra Chekuri', u'Nitish Korula', u'Martin Pl']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Improved Competitive Performance Bounds for CIOQ Switches
ESA '08: Proceedings of the 16th annual European symposium on Algorithms, Springer-Verlag, Berlin, Heidelberg (2008), pp. 577-588
[u'Alex Kesselman', u'Kirill Kogan', u'Michael Segal']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34906.html
found
=========================
It's Time To Retire the "n >= 30" rule.
Proceedings of the Joint Statistical Meetings, American Statistical Association, Alexandria VA (2008)
[u'Tim Hesterberg']
AlgorithmsandTheory
Abstract: The old rule of using z or t tests or confidence intervals if n >= 30 is a relic of the pre-computer era, and should be discarded in favor of bootstrap-based diagnostics. The diagnostics will surprise many statisticians, who don't realize how lousy the classical inferences are. For example, 95% confidence intervals should miss 2.5% on each side, and we might expect the actual non-coverage to be within 10% of that. Using a t interval, this requires n > 5000 for a moderately-skewed (exponential) population. There are better confidence intervals and tests, bootstrap and others. The bootstrap also offers pedagogical benefits in teaching sampling distributions and other statistical concepts, offering actual distributions that can be viewed using histograms and other familiar techniques.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Keeping a Search Engine Fresh: Risk and Optimality in estimating refresh rates for web pages
Proceedings of INTERFACE 2008
[u'Carrie Grimes', u'Daniel Ford', u'Eric Tassone']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Linear-Space Computation of the Edit-Distance between a String and a Finite Automaton
London Algorithmics 2008: Theory and Practice, College Publications (to appear)
[u'Cyril Allauzen', u'Mehryar Mohri']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Modularity-Maximizing Graph Communities via Mathematical Programming
European Physics Journal B, vol. Volume 66, number 3 (2008), pp. 409-418
[u'Gaurav Agarwal', u'David Kempe']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
On Distributing Symmetric Streaming Computations
Proc. 19th Annual Symposium on Discrete Algorithms (SODA) (2008)
[u'Jon Feldman', u'S. Muthukrishnan', u'Anastasios Sidiropoulos', u'Cliff Stein', u'Zoya Svitkina']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
On the Computation of the Relative Entropy of Probabilistic Automata
International Journal of Foundations of Computer Science, vol. 19 (2008), pp. 219-242
[u'Corinna Cortes', u'Mehryar Mohri', u'Ashish Rastogi', u'Michael Riley']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34436.html
found
=========================
Online Effects of Offline Ads
AdKDD08 (in the ACM digital library), ACM (2008), pp. 10-17
[u'Diane Lambert', u'Daryl Pregibon']
AlgorithmsandTheory
Abstract: We propose a methodology for assessing how ad campaigns in offline media such as print, audio and TV affect online interest in the advertiser's brand. Online interest can be measured by daily counts of the number of search queries that contain brand related keywords, by the number of visitors to the advertiser's web pages, by the number of pageviews at the advertiser's websites, or by the total duration of visits to the advertiser's website. An increase in outcomes like these in designated market areas (DMAs) where the offline ad appeared suggests heightened interest in the advertised product, as long as there would have been no such increase if the ad had not appeared. We propose a regression analysis to estimate the incremental value of the ad campaign beyond the baseline interest that would have been seen if the campaign had not been shown. A small print ad campaign illustrates the method.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Packet mode and QoS algorithms for buffered crossbar switches with FIFO queuing
PODC '08: Proceedings of the twenty-seventh ACM symposium on Principles of distributed computing, ACM, New York, NY, USA (2008), pp. 335-344
[u'Alex Kesselman', u'Kirill Kogan', u'Michael Segal']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Permutation betting markets: singleton betting with extra information
ACM Conference on Electronic Commerce (2008), pp. 180-189
[u'Mohammad Ghodsi', u'Hamid Mahini', u'Vahab S. Mirrokni', u'Morteza Zadimoghaddam']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Potential-Driven Load Distribution for Distributed Data Stream Processing
Proc. 2nd International Workshop on Scalable Stream Processing Systems, ACM, Nantes (2008), pp. 13-22
[u'Weihan Wang', u'Mohamed A. Sharaf', u'Shimin Guo', u'M. Tamer zsu']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Robust Self-assembly of Graphs
DNA Computing (2008), pp. 127-143
[u'Stanislav Angelov', u'Sanjeev Khanna', u'Mirk Visontai']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35370.html
found
=========================
The One-Way Communication Complexity of Hamming Distance
Theory of Computing, vol. 4 (2008), pp. 129-135
[u'T. S. Jayram', u'Ravi Kumar', u'D. Sivakumar']
AlgorithmsandTheory
Abstract: Consider the following version of the Hamming distance problem for {1,-1}-vectors of length n: the promise is that the distance is either at least (n/2)+sqrt{n} or at most (n/2)-sqrt{n}, and the goal is to find out which of these two cases occurs. Woodruff (Proc. ACM-SIAM Symposium on Discrete Algorithms, 2004) gave a linear lower bound for the randomized one-way communication complexity of this problem. In this note we give a simple proof of this result. Our proof uses a simple reduction from the indexing problem and avoids the VC-dimension arguments used in the previous paper. As shown by Woodruff (loc. cit.), this implies an Omega(1/epsilon^2)-space lower bound for approximating frequency moments within a factor 1+epsilon in the data stream model.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
The Persistent-Access-Caching Algorithm
Random Structures & Algorithms, vol. 33 (2008), pp. 219-251
[u'Predrag Jelenkovic', u'Ana Radovanovic']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Theory research at Google
SIGACT News, vol. 39 (2008), pp. 10-28
[u'Gagan Aggarwal', u'Nir Ailon', u'Florin Constantin', u'Eyal Even-Dar', u'Jon Feldman', u'Gereon Frahling', u'Monika R. Henzinger', u'S. Muthukrishnan', u'Noam Nisan', u'Martin Pl', u'Mark Sandler', u'Anastasios Sidiropoulos']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Two-Stage Robust Network Design with Exponential Scenarios
ESA (2008), pp. 589-600
[u'Rohit Khandekar', u'Guy Kortsarz', u'Vahab S. Mirrokni', u'Mohammad R. Salavatipour']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35310.html
found
=========================
Typed Normal Form Bisimulation for Parametric Polymorphism
Proceedings of the 23rd Annual IEEE Symposium on Logic in Computer Science (LICS' 08), IEEE (2008), pp. 341-352
[u'Soren B. Lassen', u'Paul Blain Levy']
AlgorithmsandTheory
Abstract: This paper presents a new bisimulation theory for parametric polymorphism which enables straightforward co-inductive proofs of program equivalences involving existential types. The theory is an instance of typed normal form bisimulation and demonstrates the power of this recent framework for modeling typed lambda calculi as labelled transition systems. We develop our theory for a continuation-passing style calculus, Jump-With-Argument, where normal form bisimulation takes a simple form. We equip the calculus with both existential and recursive types. An "ultimate pattern matching theorem" enables us to define bisimilarity and we show it to be a congruence. We apply our theory to proving program equivalences, type isomorphisms and genericity.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Using Mixture Models for Collaborative Filtering
Journal of Computer and System Science, vol. 74, no. 1 (2008), pp. 49-69
[u'Jon Kleinberg', u'Mark Sandler']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Fast k-Means Implementation using Coresets
International Journal of Computational Geometry and Applications (IJCGA) (2007)
[u'Gereon Frahling', u'Christian Sohler']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Heterogeneous High Dimensional Approximate Nearest Neighbor Algorithm
IEEE Transactions on Information Theory (2007) (to appear)
[u'Moshe Dubiner']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Statistical View of the Transient Signals that Support a Wireless Call
Technometrics, vol. 49, no. 3 (2007), pp. 305-317
[u'A. Buvaneswari', u'John M. Graybeal', u'David A. James', u'Diane Lambert', u'Chuanhai Liu', u'W. Michael MacDonald']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A complete, co-inductive syntactic theory of sequential control and state
Proc. 34th Annual ACM Symposium on Principles of Programming Languages, ACM, Nice, France (2007), pp. 161-172
[u'Kristian Stvring', u'Soren B. Lassen']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
AdWords and Generalized Online Matching
Journal of the ACM, vol. 54, no. 5 (2007)
[u'Aranyak Mehta', u'Amin Saberi', u'Umesh Vazirani', u'Vijay Vazirani']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Algorithms for Efficient Near-Perfect Phylogenetic Tree Reconstruction in Theory and Practice
IEEE/ACM Trans. Comput. Biology Bioinform., vol. 4 (2007), pp. 561-571
[u'Srinath Sridhar', u'Kedar Dhamdhere', u'Guy E. Blelloch', u'Eran Halperin', u'R. Ravi', u'Russell Schwartz']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
An Algorithm for Fast, Model-Free Tracking Indoors
ACM SIGMOBILE Mobile Computing and Communications Review (2007)
[u'Aiyou Chen', u'Christina Harko', u'Diane Lambert', u'P. A. Whiting']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Approximation via Cost Sharing: Simpler and Better Approximation Algorithms for Network Design
Journal of the ACM, vol. 54, no 3 (2007), pp. 11
[u'Anupam Gupta', u'Amit Kumar', u'Martin Pl', u'Tim Roughgarden']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40748.html
found
=========================
Autonomous spectrum balancing for digital subscriber lines
IEEE Transactions on Signal Processing, vol. 8 (2007), pp. 4241-4257
[u'Raphael Cendrillon', u'Jianwei Huang', u'Mung Chiang', u'Marc Moonen']
AlgorithmsandTheory
Abstract: The main performance bottleneck of modern digital subscriber line (DSL) networks is the crosstalk among different lines (i.e., users). By deploying dynamic spectrum management (DSM) techniques and reducing excess crosstalk among users, a network operator can dramatically increase the data rates and service reach of broadband access. However, current DSM algorithms suffer from either substantial suboptimality in typical deployment scenarios or prohibitively high complexity due to centralized computation. This paper develops, analyzes, and simulates a new suite of DSM algorithms for DSL interference-channel models called autonomous spectrum balancing (ASB). The ASB algorithms utilize the concept of a "reference line," which mimics a typical victim line in the interference channel. In ASB, each modem tries to minimize the harm it causes to the reference line under the constraint of achieving its own target data-rate. Since the reference line is based on the statistics of the entire network, rather than any specific knowledge of the binder a modem operates in, ASB can be implemented autonomously without the need for a centralized spectrum management center. ASB has a low complexity and simulations using a realistic simulator show that it achieves large performance gains over existing autonomous algorithms, coming close to the optimal rate region in some typical scenarios. Sufficient conditions for convergence of ASB are also proved.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Combinatorial algorithms for web search engines: three success stories
Proc. ACM SODA Symposium on Discrete Algorithms, ACM, New Orleans (2007), pp. 1022-1026
[u'Monika Henzinger']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Efficient Algorithms for Large-Scale Asteroid Discovery
Astronomical Data Analysis Software and Systems XVI (2007), pp. 395-404
[u'Jeremy Kubica', u'Larry Denneau Jr.', u'Andrew Moore', u'Robert Jedicke', u'Andrew Connolly']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Efficient Pebbling for List Traversal Synopses with Application to Program Rollback
Theoretical Computer Science, vol. 379, issue 3 (2007), pp. 418-436
[u'Yossi Matias', u'Ely Porat']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Efficient kinetic data structures for MaxCut
Proc. of the 19th Canadian Conference on Computational Geometry (2007)
[u'Artur Czumaj', u'Gereon Frahling', u'Christian Sohler']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Efficiently Computing Minimax Expected-Size Confidence Regions
Proc. 24th ICML, ACM, Corvalis (2007), pp. 97-104
[u'Brent Bryan', u'H. Brendan McMahan', u'Chad M. Schafer', u'Jeff Schneider']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Estimating Clustering Indexes in Data Streams
Proc. 15th European Symposium on Algorithms (ESA) (2007) (to appear)
[u'Luciana Buriol', u'Gereon Frahling', u'Stefano Leonardi', u'Christian Sohler']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Factor Automata of Automata and Applications
Proceedings of the 12th International Conference on Implementation and Application of Automata (CIAA2007), July, CIAA 2007Proceedings of the 12th International Conference on Implementation and Application of Automata (CIAA2007), Prague, Czech Republic.
[u'Mehryar Mohri', u'Pedro J. Moreno', u'Eugene Weinstein']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Hierarchical Mixture Models: A probabilistic Analysis
KDD (2007), pp. 580-589
[u'Mark Sandler']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Integrity and its Applications
ACM Southeast Regional Conference, {ACM}, Winston-Salem (2007), pp. 350-354
[u'Qunwei Zheng', u'Sibabrata Ray', u'Xiaoyan Hong', u'Lei Tang', u'Li Gao']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Lp Distance and Equivalence of Probabilistic Automata
International Journal of Foundations of Computer Science, vol. 18 (2007), pp. 761-780
[u'Corinna Cortes', u'Mehryar Mohri', u'Ashish Rastogi']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Maximizing a Submodular Set Function subject to a Matroid Constraint
Proceedings of the Twelfth Conference on Integer Programming and Combinatorial Optimization (IPCO) 2007
[u'Chandra Chekuri', u'Gruia Calinescu', u'Martin Pl', u'Jan Vondrk']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Minimizing Weighted Flow Time
ACM Transactions on Algorithms, vol. 3, no. 4 (2007), pp. 1-14
[u'Nikhil Bansal', u'Kedar Dhamdhere']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub33329.html
found
=========================
More Bang for Their Bucks: Assessing New Features for Online Advertisers
AdKDD07 (in the ACM digital library) (2007)
[u'Diane Lambert', u'Daryl Pregibon']
AlgorithmsandTheory
Abstract: Online search systems that display ads continually offer new features that advertisers can use to fine-tune and enhance their ad campaigns. An important question is whether a new feature actually helps advertisers. In an ideal world for statisticians, we would answer this question by running a statistically designed experiment. But that would require randomly assigning a set of advertisers to the treatment group and forcing them to use the feature, which is not realistic. Accordingly, in the real world, new features for advertisers are seldom evaluated with a traditional experimental protocol. Instead, customer service representatives (CSRs) select advertisers who are invited to be among the first to test a new feature (i.e., white-listed), and then each white-listed advertiser chooses whether or not to use the new feature. Neither the CSR nor the advertiser chooses at random. This paper addresses the problem of drawing valid inferences from white-list trials about the effects of new features on advertiser happiness. We are guided by three principles. First, statistical procedures for white-list trials are likely to be applied in an automated way, so they should be robust to violations of modeling assumptions. Second, standard analysis tools should be preferred over custom-built ones, both for clarity and for robustness. Standard tools have withstood the test of time and have been thoroughly debugged. Finally, it should be easy to compute reliable confidence intervals for the estimator. We review an estimator that has all these attributes, allowing us to make valid inferences about the effects of a new feature on advertiser happiness. In the example in this paper, the new feature was introduced during the holiday shopping season, thereby further complicating the analysis.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
On the (im)possibility of non-interactive correlation distillation
Theoretical Computer Science, vol. 382, no 2. (2007), pp. 157-166
[u'Ke Yang']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
On the Approximability of TSP on Local Modifications of Optimally Solved Instances
Algorithmic Operations Research, vol. 2/2 (2007), pp. 83-93
[u'Hans-Joachim Bckenhauer', u'Luca Forlizzi', u'Juraj Hromkovi', u'Joachim Kneis', u'Joachim Kupke', u'Guido Proietti', u'Peter Widmayer']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
OpenFst: a General and Efficient Weighted Finite-State Transducer Library
Proceedings of the 12th International Conference on Implementation and Application of Automata (CIAA 2007), Springer-Verlag, Heidelberg, Germany, Prague, Czech Republic
[u'Cyril Allauzen', u'Michael Riley', u'Johan Schalkwyk', u'Wojciech Skut', u'Mehryar Mohri']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Optimal Suffix Selection
Proceedings of the Symposium on Theory of Computation, ACM, San Diego (2007), pp. 328-339
[u'Gianni Frenceschini', u'S. Muthukrishnan']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
RadixZip: Linear Time Compression of Token Streams
VLDB 2007 (33rd Intl. Conf. on Very Large Data Bases)
[u'Binh Vo', u'Gurmeet Singh Manku']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Robust Collaborative Filtering
ACM Conference on Recommender Systems, ACM, Minneapolis, MN (2007), pp. 49-56
[u'Bhaskar Mehta', u'Thomas Hofmann', u'Wolfgang Nejdl']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Sharing the cost more efficiently: Improved approximation for multicommodity rent-or-buy
ACM Transactions on Algorithms, vol. 3, no 2 (2007), pp. 23
[u'L. Becchetti', u'J. Knemann', u'S. Leonardi', u'Martin Pl']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Skip Graphs
ACM Transactions on Algorithms, vol. 3, no 4 (2007), pp. 1-25
[u'James Aspnes', u'Gauri Shah']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Subtyping a la Church
Radboud University Nijmegen (2007) (to appear)
[u'Adriana Compagnoni', u'Healfdene Goguen']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
The Parameterized Approximability of TSP with Deadlines
Theory of Computing Systems, vol. 41/3 (2007), pp. 431-444
[u'Hans-Joachim Bckenhauer', u'Juraj Hromkovi', u'Joachim Kneis', u'Joachim Kupke']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
The k-Traveling Repairmen Problem
ACM Transactions on Algorithms, vol. 3, no. 4 (2007), pp. 1-16
[u'Jittat Fakcharoenphol', u'Chris Harrelson']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Typed Normal Form Bisimulation
Proceedings of the 21st International Workshop on Computer Science Logic (CSL'07), Springer Verlag, Berlin/Heidelberg (2007), pp. 283-297
[u'Soren B. Lassen', u'Paul Blain Levy']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
L_p Distance and Equivalence of Probabilistic Automata
International Journal of Foundations of Computer Science, vol. to appear (2007)
[u'Corinna Cortes', u'Mehryar Mohri', u'Ashish Rastogi']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
On the Computation of the Relative Entropy of Probabilistic Automata
International Journal of Foundations of Computer Science, vol. to appear (2007)
[u'Corinna Cortes', u'Mehryar Mohri', u'Ashish Rastogi', u'Michael Riley']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Achieving Anonymity via Clustering
Proceedings of the 25th ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems (PODS) (2006), pp. 153-162
[u'Gagan Aggarwal', u'Toms Feder', u'Krishnaram Kenthapadi', u'Samir Khuller', u'Rina Panigrahy', u'Dilys Thomas', u'An Zhu']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub32704.html
found
=========================
An Assertional Correctness Proof of a Self-Stabilizing l-Exclusion Algorithm
11th IEEE International Conference on Engineering of Complex Computer Systems (ICECCS'06), IEEE CS (2006), pp. 199-208
[u'Milos Besta', u'Frank Stomp']
AlgorithmsandTheory
Abstract: A formal correctness proof of a self-stabilizing l-exclusion algorithm (SLEX) is described. The analyzed algorithm is an improvement of the SLEX due to Abraham, Dolev, Herman, and Koll, since our version satisfies a stronger liveness property. The proof is formulated in Linear-Time Temporal Logic and utilizes a history variable to model access to regular registers. The proof consists of a safety part and a liveness part. Our analysis provides some new insight in the correctness of the algorithm: (1) Our proof is constructive. That is, we explicitly formulate auxiliary quantities required to establish some of the properties. This contrasts with the operational arguments of Abraham et al., where many quantities are not explicitly formulated and the validity of the above mentioned properties is established by disproving their non-existence. (2) We characterize processes (and their minimum number) identified by some process as attempting to enter the critical section. (3) A novel proof rule for reasoning about programs in the presence of disabled processes is presented to structure the liveness proof.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
An O(log n) Approximation Ratio for the Asymmetric Traveling Salesman Path Problem
Proceedings of APPROX 2006, Springer
[u'Chandra Chekuri', u'Martin Pl']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Approximate reasoning for real-time probabilistic processes
Logical Methods in Computer Science, vol. 2 (2006)
[u'Vineet Gupta', u'Radha Jagadeesan', u'Prakash Panangaden']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Eliminating Dependent Pattern Matching
Essays Dedicated to Joseph A. Goguen, Springer, Heidelberg, Germany (2006), pp. 521-540
[u'Healfdene Goguen', u'Conor McBride', u'James McKinna']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Head Normal Form Bisimulation for Pairs and the Lambda Mu-Calculus (Extended Abstract)
Proceedings of the 21st Annual IEEE Symposium on Logic in Computer Science (LICS' 06), IEEE Computer Society (2006), pp. 297-306
[u'Soren B. Lassen']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Knapsack auctions
SODA (2006), pp. 1083-1092
[u'Gagan Aggarwal', u'Jason D. Hartline']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Linear work suffix array construction
Journal of the ACM, vol. 6 (2006), pp. 918-936
[u'Juha Krkkinen', u'Peter Sanders', u'Stefan Burkhardt']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Monitoring Networked Applications with Incremental Quantile Estimation (with discussion)
Statistical Science, vol. 21 (2006), pp. 463-475
[u'John M. Chambers', u'David A. James', u'Diane Lambert', u'Scott Vander Wiel']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Normal Form Simulation for McCarthy's Amb
Proceedings of the 21st Annual Conference on Mathematical Foundations of Programming Semantics (MFPS XXI), Elsevier (2006), pp. 445-465
[u'Soren B. Lassen']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
On boundaries of highly visible spaces and applications
Theor. Comput. Sci., vol. 354 (2006), pp. 379-390
[u'John H. Reif', u'Zheng Sun']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
On discretization methods for approximating optimal paths in regions with direction-dependent costs
Inf. Process. Lett., vol. 97 (2006), pp. 146-152
[u'Zheng Sun', u'Tian-Ming Bu']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Parallel Assignments in Software Model Checking
Electr. Notes Theor. Comput. Sci., vol. 157 (2006), pp. 77-94
[u'Murray Stokely', u'Sagar Chaki', u'Joel Ouaknine']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Programmable clustering
PODS (2006), pp. 348-354
[u'Sreenivas Gollapudi', u'Ravi Kumar', u'D. Sivakumar']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Quantum Algorithms for Some Hidden Shift Problems
SIAM Journal on Computing, vol. 36 (2006), pp. 763-778
[u'Wim van Dam', u'Sean Hallgren', u'Lawrence Ip']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Using Many Machines to Handle an Enormous Error-Correcting Code
Proc. IEEE Information Theory Workshop (ITW) (2006)
[u'Jon Feldman']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Unified Construction of the Glushkov, Follow, and Antimirov Automata
Proceedings of the 31st International Symposium on Mathematical Foundations of Computer Science (MFCS 2006), Springer-Verlag, Heidelberg, Germany, Star\'a Lesn\'a, Slovakia, pp. 110-121
[u'Cyril Allauzen', u'Mehryar Mohri']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Efficient Computation of the Relative Entropy of Probabilistic Automata
Proceedings of the 7th Latin American Symposium (LATIN 2006), Springer-Verlag, Heidelberg, Germany, Valdivia, Chile
[u'Corinna Cortes', u'Mehryar Mohri', u'Ashish Rastogi', u'Michael Riley']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
On the Computation of Some Standard Distances between Probabilistic Automata
Proceedings of the 11th International Conference on Implementation and Application of Automata (CIAA 2006), Springer-Verlag, Heidelberg, Germany, Taipei, Taiwan
[u'Corinna Cortes', u'Mehryar Mohri', u'Ashish Rastogi']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Loopless Gray Code for Minimal Signed-Binary Representations
ESA 2005 (13th Annual European Symposium on Algorithms), pp. 438-447
[u'Gurmeet Singh Manku', u'Joe Sawada']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Eager Normal Form Bisimulation
Proceedings of the 20th Annual IEEE Symposium on Logic in Computer Science (LICS' 05), IEEE Computer Society (2005), pp. 345-354
[u'Soren B. Lassen']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
The design principles and algorithms of a weighted grammar library
Int. J. Found. Comput. Sci., vol. 16 (2005), pp. 403-421
[u'Cyril Allauzen', u'Mehryar Mohri', u'Brian Roark']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Metrics for labelled Markov processes
Theor. Comput. Sci., vol. 318 (2004), pp. 323-354
[u'Josee Desharnais', u'Vineet Gupta', u'Radha Jagadeesan', u'Prakash Panangaden']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
On the Streaming Model Augmented with a Sorting Primitive
FOCS (2004), pp. 540-549
[u'Gagan Aggarwal', u'Mayur Datar', u'Sridhar Rajagopalan', u'Matthias Ruhl']
AlgorithmsandTheory
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/DataManagement.html
found
=========================
Active Learning in Keyword Search-based Data Integration
The VLDB Journal, vol. 24 (2015), pp. 611-631
[u'Zhepeng Yan', u'Nan Zheng', u'Zachary G. Ives', u'Partha Pratim Talukdar', u'Cong Yu']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Disaster Monitoring with Wikipedia and Online Social Networking Sites: Structured Data and Linked Data Fragments to the Rescue?
2015 AAAI Spring Symposium Series
[u'Thomas Steiner', u'Ruben Verborgh']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Discovering Subsumption Relationships for Web-Based Ontologies
Proc. 18th International Workshop on the Web and Databases (WebDB) (2015)
[u'Dana Movshovitz-Attias', u'Steven Euijong Whang', u'Natalya Noy', u'Alon Halevy']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Efficient Evaluation of Object-Centric Exploration Queries for Visualization
PVLDB (2015), pp. 1752-1763
[u'You Wu', u'Boulos Harb', u'Jun Yang', u'Cong Yu']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Inferencing in Information Extraction: Techniques and Applications
ICDE (2015)
[u'Denilson Barbosa', u'Haixun Wang', u'Cong Yu']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
SQLGraph: An Efficient Relational-Based Property Graph Store
SIGMOD, ACM (2015)
[u'Wen Sun', u'Kavitha Srinivas', u'Achille Fokoue', u'Anastasios Kementsietsidis', u'Gang Hu', u'GuoTong Xie']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43462.html
found
=========================
Yedalog: Exploring Knowledge at Scale
1st Summit on Advances in Programming Languages (SNAPL 2015), Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik, Dagstuhl, Germany, pp. 63-78
[u'Brian Chin', u'Daniel von Dincklage', u'Vuk Ercegovac', u'Peter Hawkins', u'Mark S. Miller', u'Franz Och', u'Chris Olston', u'Fernando Pereira']
DataManagement
Abstract: With huge progress on data processing frameworks, human programmers are frequently the bottleneck when analyzing large repositories of data. We introduce Yedalog, a declarative programming language that allows programmers to mix data-parallel pipelines and computation seamlessly in a single language. By contrast, most existing tools for data-parallel computation embed a sublanguage of data-parallel pipelines in a general-purpose language, or vice versa. Yedalog extends Datalog, incorporating not only computational features from logic programming, but also features for working with data structured as nested records. Yedalog programs can run both on a single machine, and distributed across a cluster in batch and interactive modes, allowing programmers to mix different modes of execution easily.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41894.html
found
=========================
Biperpedia: An Ontology for Search Applications
Proc. 40th Int'l Conf. on Very Large Data Bases (PVLDB) (2014)
[u'Rahul Gupta', u'Alon Halevy', u'Xuezhi Wang', u'Steven Whang', u'Fei Wu']
DataManagement
Abstract: Search engines make significant efforts to recognize queries that can be answered by structured data and invest heavily in creating and maintaining high-precision databases. While these databases have a relatively wide coverage of entities, the number of attributes they model (e.g., gdp, capital, anthem) is relatively small. Extending the number of attributes known to the search engine can enable it to more precisely answer queries from the long and heavy tail, extract a broader range of facts from the Web, and recover the semantics of tables on the Web. We describe Biperpedia, an ontology with 1.6M (class, attribute) pairs and 67K distinct attribute names. Biperpedia extracts attributes from the query stream, and then uses the best extractions to seed attribute extraction from text. For every attribute Biperpedia saves a set of synonyms and text patterns in which it appears, thereby enabling it to recognize the attribute in more contexts. In addition to a detailed analysis of the quality of Biperpedia, we show that it can increase the number of Web tables whose semantics we can recover by more than a factor of 4 compared with Freebase.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Diff-Index: Differentiated Index in Distributed Log-Structured Data Stores
EDBT (2014) (to appear)
[u'Wei Tan', u'Sandeep Tata', u'Yuzhe Tang', u'Liana Fong']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Exploiting Group Recommendation Functions for Flexible Preferences
ICDE (2014)
[u'Senjuti Basu-Roy', u'Saravanan Thirumuruganathan', u'Gautam Das', u'Sihem Amer-Yahia', u'Cong Yu']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42191.html
found
=========================
From Research to Practice: Experiences Engineering a Production Metadata Database for a Scale Out File System
Proceedings of the 12th USENIX Conference on File and Storage Technologies (FAST 2014), USENIX
[u'Charles Johnson', u'Kimberly Keeton', u'Charles B. Morrey III', u'Craig A. N. Soules', u'Alistair Veitch', u'Stephen Bacon', u'Oskar Batuner', u'Marcelo Condotta', u'Hamilton Coutinho', u'Patrick J. Doyle', u'Rafael Eichelberger', u'Hugo Kiehl', u'Guilherme Magalhaes', u'James McEvoy', u'Padmanabhan Nagarajan', u'Patrick Osborne', u'Joaquim Souza', u'Andy Sparkes', u'Mike Spitzer', u'Sebastien Tandel', u'Lincoln Thomas', u'Sebastian Zangaro']
DataManagement
Abstract: HPs StoreAll with Express Query is a scalable commercial file archiving product that offers sophisticated file metadata management and search capabilities. A new REST API enables fast, efficient searching to find all files that meet a given set of metadata criteria and the ability to tag files with custom metadata fields. The product brings together two significant systems: a scale out file system and a metadata database based on LazyBase. In designing and building the combined product, we identified several real-world issues in using a pipelined database system in a distributed environment, and overcame several interesting design challenges that were not contemplated by the original research prototype. This paper highlights our experiences.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43985.html
found
=========================
In-Memory Performance for Big Data
Proceedings of the VLDB Endowment, vol. 8 (2014), pp. 37-48
[u'Goetz Graefe', u'Haris Volos', u'Hideaki Kimura', u'Harumi Kuno', u'Joseph Tucek', u'Mark Lillibridge', u'Alistair Veitch']
DataManagement
Abstract: When a working set fits into memory, the overhead imposed by the buffer pool renders traditional databases non-competitive with in-memory designs that sacrifice the benefits of a buffer pool. However, despite the large memory available with modern hardware, data skew, shifting workloads, and complex mixed workloads make it difficult to guarantee that a working set will fit in memory. Hence, some recent work has focused on enabling in-memory databases to protect performance when the working data set almost fits in memory. Contrary to those prior efforts, we enable buffer pool designs to match in-memory performance while supporting the "big data" workloads that continue to require secondary storage, thus providing the best of both worlds. We introduce here a novel buffer pool design that adapts pointer swizzling for references between system objects (as opposed to application objects), and uses it to practically eliminate buffer pool overheads for memoryresident data. Our implementation and experimental evaluation demonstrate that we achieve graceful performance degradation when the working set grows to exceed the buffer pool size, and graceful improvement when the working set shrinks towards and below the memory and buffer pool sizes.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Incremental Discovery of Prominent Situational Facts
ICDE (2014)
[u'Afroza Sultana', u'Naeemul Hassan', u'Chengkai Li', u'Jun Yang', u'Cong Yu']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
On Social Event Organization
KDD (2014), pp. 1206-1215
[u'Keqian Li', u'Wei Lu', u'Smriti Bhagat', u'Laks V. S. Lakshmanan', u'Cong Yu']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
ReNoun: Fact Extraction for Nominal Attributes
Proc. 2014 Conf. on Empirical Methods in Natural Language Processing (EMNLP)
[u'Mohamed Yahya', u'Steven Whang', u'Rahul Gupta', u'Alon Halevy']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43119.html
found
=========================
Storing and Querying Tree-Structured Records in Dremel
Proceedings of the VLDB Endowment, vol. 7 (2014), pp. 1131-1142
[u'Foto N Afrati', u'Dan Delorey', u'Mosha Pasumansky', u'Jeffrey D. Ullman']
DataManagement
Abstract: In Dremel, data is stored as nested relations. The schema for a relation is a tree, all of whose nodes are attributes, and whose leaf attributes hold values. We explore filter and aggregate queries that are given in the Dremel dialect of SQL. Complications arise because of repeated attributes, i.e., attributes that are allowed to have more than one value. We focus on the common class of Dremel queries that are processed on column-stored data in a way that results in query processing time that is linear on the size of the relevant data, i.e., data in the columns that participate in the query. We formally define the data model, the query language and the algorithms for query processing in column-stored data. The concepts of repetition context and semi-flattening are introduced here and play a central role in understanding this class of queries and their algorithms.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Toward Computational Fact-Checking
PVLDB, vol. 7 (2014)
[u'You Wu', u'Pankaj Agarwal', u'Chengkai Li', u'Jun Yang', u'Cong Yu']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42240.html
found
=========================
Wikidata: A Free Collaborative Knowledge Base
Communications of the ACM, vol. 57 (2014), pp. 78-85
[u'Denny Vrandei', u'Markus Krtzsch']
DataManagement
Abstract: Unnoticed by most of its readers, Wikipedia is currently undergoing dramatic changes, as its sister project Wikidata introduces a new multilingual Wikipedia for data to manage the factual information of the popular online encyclopedia. With Wikipedias data becoming cleaned and integrated in a single location, opportunities arise for many new applications. In this article, we provide an extended overview of Wikidata, including its essential design choices and data model. Based on up-to-date statistics, we discuss the project's development so far and outline interesting application areas for this new resource.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Actively Soliciting Feedback for Query Answers in Keyword Search-Based Data Integration
PVLDB, vol. 6 (2013)
[u'Zhepeng Yan', u'Nan Zheng', u'Zachary Ives', u'Partha Talukdar', u'Cong Yu']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41344.html
found
=========================
F1: A Distributed SQL Database That Scales
VLDB (2013)
[u'Jeff Shute', u'Radek Vingralek', u'Bart Samwel', u'Ben Handy', u'Chad Whipkey', u'Eric Rollins', u'Mircea Oancea', u'Kyle Littleeld', u'David Menestrina', u'Stephan Ellner', u'John Cieslewicz', u'Ian Rae', u'Traian Stancescu', u'Himani Apte']
DataManagement
Abstract: F1 is a distributed relational database system built at Google to support the AdWords business. F1 is a hybrid database that combines high availability, the scalability of NoSQL systems like Bigtable, and the consistency and usability of traditional SQL databases. F1 is built on Spanner, which provides synchronous cross-datacenter replication and strong consistency. Synchronous replication implies higher commit latency, but we mitigate that latency by using a hierarchical schema model with structured data types and through smart application design. F1 also includes a fully functional distributed SQL query engine and automatic change tracking and publishing.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40671.html
found
=========================
HyperLogLog in Practice: Algorithmic Engineering of a State of The Art Cardinality Estimation Algorithm
Proceedings of the EDBT 2013 Conference, ACM, Genoa, Italy (to appear)
[u'Stefan Heule', u'Marc Nunkesser', u'Alex Hall']
DataManagement
Abstract: Cardinality estimation has a wide range of applications and is of particular importance in database systems. Various algorithms have been proposed in the past, and the HyperLogLog algorithm is one of them. In this paper, we present a series of improvements to this algorithm that reduce its memory requirements and signi?cantly increase its accuracy for an important range of cardinalities. We have implemented our proposed algorithm for a system at Google and evaluated it empirically, comparing it to the original HyperLogLog algorithm. Like HyperLogLog, our improved algorithm parallelizes perfectly and computes the cardinality estimate in a single pass.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41376.html
found
=========================
Online, Asynchronous Schema Change in F1
VLDB (2013)
[u'Ian Rae', u'Eric Rollins', u'Jeff Shute', u'Sukhdeep Sodhi', u'Radek Vingralek']
DataManagement
Abstract: We introduce a protocol for schema evolution in a globally distributed database management system with shared data, stateless servers, and no global membership. Our protocol is asynchronousit allows different servers in the database system to transition to a new schema at different timesand onlineall servers can access and update all data during a schema change. We provide a formal model for determining the correctness of schema changes under these conditions, and we demonstrate that many common schema changes can cause anomalies and database corruption. We avoid these problems by replacing corruption-causing schema changes with a sequence of schema changes that is guaranteed to avoid corrupting the database so long as all servers are no more than one schema version behind at any time. Finally, we discuss a practical implementation of our protocol in F1, the database management system that stores data for Google AdWords.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41318.html
found
=========================
Photon: Fault-tolerant and Scalable Joining of Continuous Data Streams
SIGMOD '13: Proceedings of the 2013 international conference on Management of data, ACM, New York, NY, USA, pp. 577-588
[u'Rajagopal Ananthanarayanan', u'Venkatesh Basker', u'Sumit Das', u'Ashish Gupta', u'Haifeng Jiang', u'Tianhao Qiu', u'Alexey Reznichenko', u'Deomid Ryabkov', u'Manpreet Singh', u'Shivakumar Venkataraman']
DataManagement
Abstract: Web-based enterprises process events generated by millions of users interacting with their websites. Rich statistical data distilled from combining such interactions in near real-time generates enormous business value. In this paper, we describe the architecture of Photon, a geographically distributed system for joining multiple continuously flowing streams of data in real-time with high scalability and low latency, where the streams may be unordered or delayed. The system fully tolerates infrastructure degradation and datacenter-level outages without any manual intervention. Photon guarantees that there will be no duplicates in the joined output (at-most-once semantics) at any point in time, that most joinable events will be present in the output in real-time (near-exact semantics), and exactly-once semantics eventually. Photon is deployed within Google Advertising System to join data streams such as web search queries and user clicks on advertisements. It produces joined logs that are used to derive key business metrics, including billing for advertisers. Our production deployment processes millions of events per minute at peak with an average end-to-end latency of less than 10 seconds. We also present challenges and solutions in maintaining large persistent state across geographically distant locations, and highlight the design principles that emerged from our experience.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Recent Progress Towards an Ecosystem of Structured Data on the Web
ICDE (2013), pp. 5-8
[u'Nitin Gupta', u'Alon Y. Halevy', u'Boulos Harb', u'Heidi Lam', u'Hongrae Lee', u'Jayant Madhavan', u'Fei Wu', u'Cong Yu']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41652.html
found
=========================
Rolling Up Random Variables in Data Cubes
Joint Statistical Meetings, American Statistical Association, 732 North Washington Street, Alexandria, VA 22314-1943 (2013) (to appear)
[u'Phillip M. Yelland']
DataManagement
Abstract: Data cubes, first developed in the context of on-line analytic processing (OLAP) applications for databases, have become increasingly widespread as a means of structuring data aggregations in other contexts. For example, increasing levels of aggregation in a data cube can be used to impose a hierarchical structure---often referred to as roll-ups---on sets of cross-categorized values, producing a summary description that takes advantage of commonalities within the cube categories. In this paper, we describe a novel technique for realizing such a hierarchical structure in a data cube containing discrete random variables. Using a generalization of an approach due to Chow and Liu, this technique construes roll-ups as parsimonious approximations to the joint distribution of the variables in terms of the aggregation structure of the cube. The technique is illustrated using a real-life application that involves monitoring and reporting anomalies in Web traffic streams over time.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Scalable Column Concept Determination for Web Tables Using Large Knowledge Bases
PVLDB, vol. 6 (2013)
[u'Dong Deng', u'Yu Jiang', u'Guoliang Li', u'Jian Li', u'Cong Yu']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Shallow Information Extraction for the Knowledge Web
ICDE (2013)
[u'Denilson Barbosa', u'Haixun Wang', u'Cong Yu']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Synthesizing Union Tables from the Web
IJCAI (2013)
[u'Xiao Ling', u'Alon Halevy', u'Fei Wu', u'Cong Yu']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40415.html
found
=========================
An Automatic Blocking Mechanism for Large-Scale De-duplication Tasks
CIKM (2012)
[u'Anish Das Sarma', u'Ankur Jain', u'Ashwin Machanavajjhala', u'Philip Bohannon']
DataManagement
Abstract: De-duplication---identification of distinct records referring to the same real-world entity---is a well-known challenge in data integration. Since very large datasets prohibit the comparison of every pair of records, {\em blocking} has been identified as a technique of dividing the dataset for pairwise comparisons, thereby trading off {\em recall} of identified duplicates for {\em efficiency}. Traditional de-duplication tasks, while challenging, typically involved a fixed schema such as Census data or medical records. However, with the presence of large, diverse sets of structured data on the web and the need to organize it effectively on content portals, de-duplication systems need to scale in a new dimension to handle a large number of schemas, tasks and data sets, while handling ever larger problem sizes. In addition, when working in a map-reduce framework it is important that canopy formation be implemented as a {\em hash function}, making the canopy design problem more challenging. We present CBLOCK, a system that addresses these challenges. CBLOCK learns hash functions automatically from attribute domains and a labeled dataset consisting of duplicates. Subsequently, CBLOCK expresses blocking functions using a hierarchical tree structure composed of atomic hash functions. The application may guide the automated blocking process based on architectural constraints, such as by specifying a maximum size of each block (based on memory requirements), impose disjointness of blocks (in a grid environment), or specify a particular objective function trading off recall for efficiency. As a post-processing step to automatically generated blocks, CBLOCK {\em rolls-up} smaller blocks to increase recall. We present experimental results on two large-scale de-duplication datasets at Yahoo!---consisting of over 140K movies and 40K restaurants respectively---and demonstrate the utility of CBLOCK.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Big Data Storytelling Through Interactive Maps
IEEE Data Engineering Bulletin, vol. 35 (2012), pp. 46-54
[u'Jayant Madhavan', u'Sreeram Balakrishnan', u'Kathryn Hurley', u'Hector Gonzalez', u'Nitin Gupta', u'Alon Halevy', u'Karen Jacqmin-Adams', u'Heidi Lam', u'Anno Langen', u'Hongrae Lee', u'Rod McChesney', u'Rebecca Shapley', u'Warren Shen']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Clydesdale: structured data processing on MapReduce
Proceedings of the 15th International Conference on Extending Database Technology, ACM, New York, NY, USA (2012), pp. 15-25
[u'Tim Kaldewey', u'Eugene J. Shekita', u'Sandeep Tata']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38123.html
found
=========================
Efficient Spatial Sampling of Large Geographical Tables
SIGMOD (2012)
[u'Anish Das Sarma', u'Hongrae Lee', u'Hector Gonzalez', u'Jayant Madhavan', u'Alon Y. Halevy']
DataManagement
Abstract: Large-scale map visualization systems play an increasingly important role in presenting geographic datasets to end users. Since these datasets can be extremely large, a map rendering system often needs to select a small fraction of the data to visualize them in a limited space. This paper addresses the fundamental challenge of {\em thinning}: determining appropriate samples of data to be shown on specific geographical regions and zoom levels. Other than the sheer scale of the data, the thinning problem is challenging because of a number of other reasons: (1) data can consist of complex geographical shapes, (2) rendering of data needs to satisfy certain constraints, such as data being preserved across zoom levels and adjacent regions, and (3) after satisfying the constraints, an {\em optimal} solution needs to be chosen based on {\em objectives} such as {\em maximality}, {\em fairness}, and {\em importance} of data. This paper formally defines and presents a complete solution to the thinning problem. First, we express the problem as an integer programming formulation that efficiently solves thinning for desired objectives. Second, we present more efficient solutions for maximality, based on DFS traversal of a spatial tree. Third, we consider the common special case of point datasets, and present an even more efficient randomized algorithm. Finally, we have implemented all techniques from this paper in Google Maps visualizations of Fusion Tables, and we describe a set of experiments that demonstrate the tradeoffs among the algorithms.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Efficient spatial sampling of large geographical tables
Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data, ACM, New York, NY, USA, pp. 193-204
[u'Anish Das Sarma', u'Hongrae Lee', u'Hector Gonzalez', u'Jayant Madhavan', u'Alon Halevy']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38125.html
found
=========================
F1 - The Fault-Tolerant Distributed RDBMS Supporting Google's Ad Business
SIGMOD (2012)
[u'Jeff Shute', u'Mircea Oancea', u'Stephan Ellner', u'Ben Handy', u'Eric Rollins', u'Bart Samwel', u'Radek Vingralek', u'Chad Whipkey', u'Xin Chen', u'Beat Jegerlehner', u'Kyle Littleeld', u'Phoenix Tong']
DataManagement
Abstract: Many of the services that are critical to Googles ad business have historically been backed by MySQL. We have recently migrated several of these services to F1, a new RDBMS developed at Google. F1 implements rich relational database features, including a strictly enforced schema, a powerful parallel SQL query engine, general transactions, change tracking and notication, and indexing, and is built on top of a highly distributed storage system that scales on standard hardware in Google data centers. The store is dynamically sharded, supports transactionally-consistent replication across data centers, and is able to handle data center outages without data loss. The strong consistency properties of F1 and its storage system come at the cost of higher write latencies compared to MySQL. Having successfully migrated a rich customerfacing application suite at the heart of Googles ad business to F1, with no downtime, we will describe how we restructured schema and applications to largely hide this increased latency from external users. The distributed nature of F1 also allows it to scale easily and to support signicantly higher throughput for batch workloads than a traditional RDBMS. With F1, we have built a novel hybrid system that combines the scalability, fault tolerance, transparent sharding, and cost benets so far available only in NoSQL systems with the usability, familiarity, and transactional guarantees expected from an RDBMS.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38124.html
found
=========================
Finding Related Tables
SIGMOD (2012)
[u'Anish Das Sarma', u'Lujun Fang', u'Nitin Gupta', u'Alon Y. Halevy', u'Hongrae Lee', u'Fei Wu', u'Reynold Xin', u'Cong Yu']
DataManagement
Abstract: We consider the problem of finding related tables in a large corpus of heterogenous tables. Detecting related tables provides users a powerful tool for enhancing their tables with additional data and enables effective reuse of available public data. Our first contribution is a framework that captures several types of relatedness, including tables that are candidates for joins and tables that are candidates for union. Our second contribution is a set of algorithms for detecting related tables that can be either unioned or joined. We describe a set of experiments that demonstrate that our algorithms produce highly related tables. We also show that we can often improve the results of table search by pulling up tables that are ranked much lower based on their relatedness to top-ranked tables. Finally, we describe how to scale up our algorithms and show the results of running it on a corpus of over a million tables extracted from Wikipedia.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Fuzzy Joins Using MapReduce
ICDE (2012) (to appear)
[u'Foto N. Afrati', u'Anish Das Sarma', u'David Menestrina', u'Aditya Parameswaran', u'Jeffrey Ullman']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Hathi: durable transactions for memory using flash
Proceedings of the Eighth International Workshop on Data Management on New Hardware, ACM, New York, NY, USA (2012), pp. 33-38
[u'Mohit Saxena', u'Mehul A. Shah', u'Stavros Harizopoulos', u'Michael M. Swift', u'Arif Merchant']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Interactive Regret Minimization
SIGMOD (2012) (to appear)
[u'Danupon Nanongkai', u'Ashwin Lall', u'Atish Das Sarma', u'Kazuhisa Makino']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Interactive regret minimization
Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data, ACM, New York, NY, USA, pp. 109-120
[u'Danupon Nanongkai', u'Ashwin Lall', u'Atish Das Sarma', u'Kazuhisa Makino']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
On One of the Few Objects
SIGKDD (2012)
[u'You Wu', u'Pankaj Agarwal', u'Chengkai Li', u'Jun Yang', u'Cong Yu']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40465.html
found
=========================
Processing a Trillion Cells per Mouse Click
PVLDB, vol. 5 (2012), pp. 1436-1446
[u'Alex Hall', u'Olaf Bachmann', u'Robert Buessow', u'Silviu-Ionut Ganceanu', u'Marc Nunkesser']
DataManagement
Abstract: Column-oriented database systems have been a real game changer for the industry in recent years. Highly tuned and performant systems have evolved that provide users with the possibility of answering ad hoc queries over large datasets in an interactive manner. In this paper we present the column-oriented datastore developed as one of the central components of PowerDrill. It combines the advantages of columnar data layout with other known techniques (such as using composite range partitions) and extensive algorithmic engineering on key data structures. The main goal of the latter being to reduce the main memory footprint and to increase the efficiency in processing typical user queries. In this combination we achieve large speed-ups. These enable a highly interactive Web UI where it is common that a single mouse click leads to processing a trillion values in the underlying dataset.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Spanner: Google's Globally-Distributed Database
OSDI (2012) (to appear)
[u'James C. Corbett', u'Jeffrey Dean', u'Michael Epstein', u'Andrew Fikes', u'Christopher Frost', u'JJ Furman', u'Sanjay Ghemawat', u'Andrey Gubarev', u'Christopher Heiser', u'Peter Hochschild', u'Wilson Hsieh', u'Sebastian Kanthak', u'Eugene Kogan', u'Hongyi Li', u'Alexander Lloyd', u'Sergey Melnik', u'David Mwaura', u'David Nagle', u'Sean Quinlan', u'Rajesh Rao', u'Lindsay Rolig', u'Dale Woodford', u'Yasushi Saito', u'Christopher Taylor', u'Michal Szymaniak', u'Ruth Wang']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Symbiosis in scale out networking and data management
Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data, ACM, New York, NY, USA, pp. 579-580
[u'Amin Vahdat']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Towards an ecosystem of structured data on the web
Proceedings of the 15th International Conference on Extending Database Technology, ACM, New York, NY, USA (2012), pp. 1-2
[u'Alon Y. Halevy']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Who Tags What? An Analysis Framework
PVLDB, vol. 5 (2012)
[u'Mahashweta Das', u'Saravanan Thirumuruganathan', u'Sihem Amer-Yahia', u'Gautam Das', u'Cong Yu']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Computational Journalism: A Call to Arms to Database Researchers
CIDR (2011)
[u'Sarah Cohen', u'Chengkai Li', u'Jun Yang', u'Cong Yu']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Data Integration with Dependent Sources
EDBT (2011)
[u'Anish Das Sarma', u'Luna Dong', u'Alon Halevy']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37217.html
found
=========================
Dremel: Interactive Analysis of Web-Scale Datasets
Communications of the ACM, vol. 54 (2011), pp. 114-123
[u'Sergey Melnik', u'Andrey Gubarev', u'Jing Jing Long', u'Geoffrey Romer', u'Shiva Shivakumar', u'Matt Tolton', u'Theodore Vassilakis']
DataManagement
Abstract: Dremel is a scalable, interactive ad hoc query system for analysis of read-only nested data. By combining multilevel execution trees and columnar data layout, it is capable of running aggregation queries over trillion-row tables in seconds. The system scales to thousands of CPUs and petabytes of data, and has thousands of users at Google. In this paper, we describe the architecture and implementation of Dremel, and explain how it complements MapReduce-based computing. We present a novel columnar storage representation for nested records and discuss experiments on few-thousand node instances of the system.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Efficiently Encoding Term Co-occurrences in Inverted Indexes
20th ACM Conference on Information and Knowledge Management (CIKM 2011) (to appear)
[u'Marcus Fontoura', u'Maxim Gurevich', u'Vanja Josifovski', u'Sergei Vassilvitskii']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Efficiently Evaluating Graph Constraints in Content-Based Publish/Subscribe
The 20th International World Wide Web Confererence (WWW 2011)
[u'Andrei Broder', u'Shirshanka Das', u'Marcus Fontoura', u'Bhaskar Ghosh', u'Vanja Josifovski', u'Jayavel Shanmugasundaram', u'Sergei Vassilvitskii']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Entity-Relationship Queries over Wikipedia
ACM Transactions on Intelligent Systems and Technology, vol. 3 (2011)
[u'Xiaonan Li', u'Chengkai Li', u'Cong Yu']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Evaluation Strategies for Top-k Queries over Memory-Resident Inverted Indexes
The 37th International Conference on Very Large Databases (VLDB 2011) (to appear)
[u'Marcus Fontoura', u'Vanja Josifovski', u'Jinhui Liu', u'Srihari Venkatesan', u'Xiangfei Zhu', u'Jason Zien']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Factorization-based Lossless Compression of Inverted Indices
20th ACM Conference on Information and Knowledge Management (CIKM 2011) (to appear)
[u'George Beskales', u'Marcus Fontoura', u'Maxim Gurevich', u'Vanja Josifovski', u'Sergei Vassilvitskii']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37657.html
found
=========================
Graph cube: on warehousing and OLAP multidimensional networks
SIGMOD - Proceedings of the 2011 International Conference on Management of Data, ACM, New York, NY
[u'Peixiang Zhao', u'Xialolei Li', u'Dong Xin', u'Jiawei Han']
DataManagement
Abstract: We consider extending decision support facilities toward large sophisticated networks, upon which multidimensional attributes are associated with network entities, thereby forming the so-called multidimensional networks. Data warehouses and OLAP (Online Analytical Processing) technology have proven to be effective tools for decision support on relational data. However, they are not well equipped to handle the new yet important multidimensional networks. In this paper, we introduce Graph Cube, a new data warehousing model that supports OLAP queries effectively on large multidimensional networks. By taking account of both attribute aggregation and structure summarization of the networks, Graph Cube goes beyond the traditional data cube model involved solely with numeric value based group-bys, thus resulting in a more insightful and structure-enriched aggregate network within every possible multidimensional space. Besides traditional cuboid queries, a new class of OLAP queries, crossboid, is introduced that is uniquely useful in multidimensional networks and has not been studied before. We implement Graph Cube by combining special characteristics of multidimensional networks with the existing well-studied data cube techniques. We perform extensive experimental studies on a series of real world data sets and Graph Cube is shown to be a powerful and efficient tool for decision support on large multidimensional networks.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Hyper-local, directions-based ranking of places
Proceedings of VLDB (2011), pp. 290-30
[u'Petros Venetis', u'Hector Gonzalez', u'Alon Y. Halevy', u'Christian S. Jensen']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37233.html
found
=========================
Maestro: Quality-of-Service in Large Disk Arrays
Proceedings of the 8th ACM international conference on Autonomic computing (ICAC), ACM, New York, NY, USA (2011), pp. 245-254
[u'Arif Merchant', u'Mustafa Uysal', u'Pradeep Padala', u'Xiaoyun Zhu', u'Sharad Singhal', u'Kang Shin']
DataManagement
Abstract: Provisioning storage in disk arrays is a difficult problem because many applications with different workload characteristics and priorities share resources provided by the array. Currently, storage in disk arrays is statically partitioned, leading to difficult choices between over-provisioning to meet peak demands and resource sharing to meet efficiency targets. In this paper, we present Maestro, a feedback controller that can manage resources on large disk arrays to provide performance differentiation among multiple applications. Maestro monitors the performance of each application and dynamically allocates the array resources so that diverse performance requirements can be met without static partitioning. It supports multiple performance metrics (e.g., latency and throughput) and application priorities so that important applications receive better performance in case of resource contention. By ensuring that high-priority applications sharing storage with other applications obtain the performance levels they require, Maestro makes it possible to use storage resources efficiently. We evaluate Maestro using both synthetic and real-world workloads on a large, commercial disk array. Our experiments indicate that Maestro can reliably adjust the allocation of disk array resources to achieve application performance targets.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36988.html
found
=========================
Representative Skylines using Threshold-based Preference Distributions
International Conference on Data Engineering (ICDE) (2011)
[u'Atish Das Sarma', u'Ashwin Lall', u'Danupon Nanongkai', u'Richard J. Lipton', u'Jim Xu']
DataManagement
Abstract: The study of skylines and their variants has received considerable attention in recent years. Skylines are essentially sets of most interesting (undominated) tuples in a database. However, since the skyline is often very large, much research effort has been devoted to identifying a smaller subset of (say k) representative skyline points. Several different definitions of representative skylines have been considered. Most of these formulations are intuitive in that they try to achieve some kind of clustering spread over the entire skyline, with k points. In this work, we take a more principled approach in defining the representative skyline objective. One of our main contributions is to formulate the problem of displaying k representative skyline points such that the probability that a random user would click on one of them is maximized. Two major research questions arise naturally from this formulation. First, how does one mathematically model the likelihood with which a user is interested in and will click on a certain tuple? Second, how does one negotiate the absence of the knowledge of an explicit set of target users; in particular what do we mean by a random user? To answer the first question, we model users based on a novel formulation of threshold preferences which we will motivate further in the paper. To answer the second question, we assume a probability distribution of users instead of a fixed set of users. While this makes the problem harder, it lends more mathematical structures that can be exploited as well, as one can now work with probabilities of thresholds and handle cumulative density functions. On the theoretical front, our objective is NP-hard. For the case of a finite set of users with known thresholds, we present a simple greedy algorithm that attains an approximation ratio of (1 1/e) of the optimal. For the case of user distributions, we show that a careful yet similar greedy algorithm achieves the same approximation ratio. Unfortunately, it turns out that this algorithm is rather involved and computationally expensive. So we present a threshold sampling based algorithm that is more computationally affordable and, for any fixed epsilon > 0, has an approximation ratio of (1 1/e epsilon). We perform experiments on both real and synthetic data to show that our algorithm significantly outperforms previously proposed approaches.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub39983.html
found
=========================
Still All On One Server: Perforce at Scale
2011 Perforce User Conference
[u'Dan Bloch']
DataManagement
Abstract: Google runs the busiest single Perforce server on the planet, and one of the largest repositories in any source control system. From that high-water mark this paper looks at server performance and other issues of scale, with digressions into where we are, how we got here, and how we continue to stay one step ahead of our users.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Adaptive query processing in data stream management systems under limited memory resources.
Proceedings of the 3rd workshop on Ph.D. students in information and knowledge management. PIKM 2010, Toronto, Ontario, Canada, October 30, 2010., ACM 2010, Toronto, Ontario, Canada, pp. 9-16
[u'Fatima Farag', u'Moustafa A. Hammad', u'Reda Alhajj']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Automatically incorporating new sources in keyword search-based data integration
SIGMOD Conference, ACM Press (2010), pp. 387-398
[u'Partha Pratim Talukdar', u'Zachary G. Ives', u'Fernando Pereira']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37355.html
found
=========================
Collaborative Environmental In Situ Data Collection: Experiences and Opportunities for Ambient Data Integration
On the Move to Meaningful Internet Systems: OTM 2010 Workshops, Lecture Notes in Computer Science, pp. 119
[u'David Thau']
DataManagement
Abstract: Collaborative environmental in situ data collection occurs when a team of investigators goes into the field together to collect environmental data. These data might be necessary, e.g., for a biodiversity inventory, compilation of a soil density map, or to estimate above-ground forest carbon stocks. Investigators will often arrive at a location and disperse, collecting data, and then compiling it either in the field, or at a later time. Typically, an area will be divided into a set of plots, and within those, subplots. Teams of investigators will visit each of these plots with standardized forms and specialized equipment for collecting the data of interest. For example, in a forest inventory, investigators might collect data about the diameter and species of the trees in the forest, the trees health, fire damage and soil quality at the plot, proximity to roads, and whether any logging has taken place.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Evolution and future directions of large-scale storage and computation systems at Google
SoCC '10: Proceedings of the 1st ACM symposium on Cloud computing, ACM, New York, NY, USA (2010), pp. 1-1
[u'Jeffrey Dean']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36256.html
found
=========================
Google Fusion Tables: Data Management, Integration, and Collaboration in the Cloud
Proceedings of the ACM Symposium on Cloud Computing (SOCC) (2010)
[u'Hector Gonzalez', u'Alon Halevy', u'Christian Jensen', u'Anno Langen', u'Jayant Madhavan', u'Rebecca Shapley', u'Warren Shen']
DataManagement
Abstract: Google Fusion Tables is a cloud-based service for data management and integration. Fusion Tables enables users to upload tabular data les (spreadsheets, CSV, KML), currently of up to 100MB. The system provides several ways of visualizing the data (e.g., charts, maps, and timelines) and the ability to filter and aggregate the data. It supports the integration of data from multiple sources by performing joins across tables that may belong to dierent users. Users can keep the data private, share it with a select set of collaborators, or make it public and thus crawlable by search engines. The discussion feature of Fusion Tables allows collaborators to conduct detailed discussions of the data at the level of tables and individual rows, columns, and cells. This paper describes the inner workings of Fusion Tables, including the storage of data in the system and the tight integration with the Google Maps infrastructure.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36257.html
found
=========================
Google Fusion Tables: Web-Centered Data Management and Collaboration
Proceedings of the ACM SIGMOD conference, ACM (2010)
[u'Hector Gonzalez', u'Alon Halevy', u'Christian Jensen', u'Anno Langen', u'Jayant Madhavan', u'Rebecca Shapley', u'Warren Shen', u'Jonathan Goldberg-Kidon']
DataManagement
Abstract: It has long been observed that database management systems focus on traditional business applications, and that few people use a database management system outside their workplace. Many have wondered what it will take to enable the use of data management technology by a broader class of users and for a much wider range of applications. Google Fusion Tables represents an initial answer to the question of how data management functionality that focused on enabling new users and applications would look in today's computing environment. This paper characterizes such users and applications and highlights the resulting principles, such as seamless Web integration, emphasis on ease of use, and incentives for data sharing, that underlie the design of Fusion Tables. We describe key novel features, such as the support for data acquisition, collaboration, visualization, and web-publishing.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Pregel: a system for large-scale graph processing
Proceedings of the 2010 international conference on Management of data, ACM, New York, NY, USA, pp. 135-146
[u'Grzegorz Malewicz', u'Matthew H. Austern', u'Aart J.C Bik', u'James C. Dehnert', u'Ilan Horn', u'Naty Leiser', u'Grzegorz Czajkowski']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37230.html
found
=========================
The Case Against Data Lock-in
Communications of the ACM, vol. 53 No.11 (2010), pp. 42-46
[u'Brian W. Fitzpatrick', u'JJ Lueck']
DataManagement
Abstract: Want to keep your users? Just make it easy for them to leave.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Threshold query optimization for uncertain data
Special Interest Group on Management of Data (SIGMOD) (2010)
[u'Yinian Qi', u'Rohit Jain', u'Sarvjeet Singh', u'Sunil Prabhakar']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
VoR-Tree: R-trees with Voronoi Diagrams for Efficient Processing of Spatial Nearest Neighbor Queries
Proceedings of VLDB (2010)
[u'Mehdi Sharifzadeh', u'Cyrus Shahabi']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35162.html
found
=========================
DRAM Errors in the Wild: A Large-Scale Field Study
SIGMETRICS (2009)
[u'Bianca Schroeder', u'Eduardo Pinheiro', u'Wolf-Dietrich Weber']
DataManagement
Abstract: Errors in dynamic random access memory (DRAM) are a common form of hardware failure in modern compute clusters. Failures are costly both in terms of hardware replacement costs and service disruption. While a large body of work exists on DRAM in laboratory conditions, little has been reported on real DRAM failures in large production clusters. In this paper, we analyze measurements of memory errors in a large fleet of commodity servers over a period of 2.5 years. The collected data covers multiple vendors, DRAM capacities and technologies, and comprises many millions of DIMM days. The goal of this paper is to answer questions such as the following: How common are memory errors in practice? What are their statistical properties? How are they affected by external factors, such as temperature and utilization, and by chip-specific factors, such as chip density, memory technology and DIMM age? We find that DRAM error behavior in the field differs in many key aspects from commonly held assumptions. For example, we observe DRAM error rates that are orders of magnitude higher than previously reported, with 25,000 to 70,000 errors per billion device hours per Mbit and more than 8\% of DIMMs affected by errors per year. We provide strong evidence that memory errors are dominated by hard errors, rather than soft errors, which previous work suspects to be the dominant error mode. We find that temperature, known to strongly impact DIMM error rates in lab conditions, has a surprisingly small effect on error behavior in the field, when taking all other factors into account. Finally, unlike commonly feared, we don't observe any indication that newer generations of DIMMs have worse error behavior.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Data Integration with Uncertainty
The VLDB Journal, vol. 18 (2009), pp. 469-500
[u'Xin Luna Dong', u'Alon Halevy', u'Cong Yu']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Data Modeling in Dataspace Support Platforms
Conceptual Modeling: Foundations and Applications, Springer-Verlag, Berlin, Heidelberg (2009), pp. 122-138
[u'Anish Das Sarma', u'Xin (Luna) Dong', u'Alon Y. Halevy']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Engineering autonomic systems
ICAC '09: Proceedings of the 6th international conference on Autonomic computing, ACM, New York, NY, USA (2009), pp. 75-76
[u'Joseph L. Hellerstein']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Exploring Schema Repositories with Schemr
Proceedings of the ACM SIGMOD conference (2009), pp. 1095-1098
[u'Kuang Chen', u'Jayant Madhavan', u'Alon Halevy']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Representing uncertain data: models, properties, and algorithms
The VLDB Journal, vol. 18 (2009), pp. 989-1019
[u'Anish Das Sarma', u'Omar Benjelloun', u'Alon Halevy', u'Shubha Nabar', u'Jennifer Widom']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
The Claremont report on database research
Commun. ACM, vol. 52 (2009), pp. 56-65
[u'Rakesh Agrawal', u'Anastasia Ailamaki', u'Philip A. Bernstein', u'Eric A. Brewer', u'Michael J. Carey', u'Surajit Chaudhuri', u'Anhai Doan', u'Daniela Florescu', u'Michael J. Franklin', u'Hector Garcia-Molina', u'Johannes Gehrke', u'Le Gruenwald', u'Laura M. Haas', u'Alon Y. Halevy', u'Joseph M. Hellerstein', u'Yannis E. Ioannidis', u'Hank F. Korth', u'Donald Kossmann', u'Samuel Madden', u'Roger Magoulas', u'Beng Chin Ooi', u"Tim O'Reilly", u'Raghu Ramakrishnan', u'Sunita Sarawagi', u'Michael Stonebraker', u'Alexander S. Szalay', u'Gerhard Weikum']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37674.html
found
=========================
Using Hoarding to Increase Availability in Shared File Systems
Computer and Information Science, 2009. ICIS 2009. Eighth IEEE/ACIS International Conference on, IEEE, pp. 422 - 429
[u'Jochen Hollmann', u'Per Stenstrm']
DataManagement
Abstract: Many mobile devices have reached the point where the users' (active) working set is smaller than the amount of storage available and that trend is likely to continue. Currently these resources are made available for recording new data, but we think that we could make better use of this capacity. Hoarding previously not accessed data could give better data coverage in cases of disconnected operation, when wireless networks are not available or access to them is expensive. We gathered a trace from a university file system used by more than 5000 people over a period of 16 months. This trace is used to drive a simulation model of distributed file systems. This paper studies a novel hoarding scheme that uses the access profile of other users to predict what files a user would need in the future. This hoarding scheme is shown to avoid between 30% and 75% of remote file accesses to files that are accessed for the first time. Furthermore, hoarded but not used data can be expired, because we note experimentally that the population shifts focus each month.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Weighted Proximity Best-Joins for Information Retrieval
ICDE '09: Proceedings of the 2009 IEEE International Conference on Data Engineering, IEEE Computer Society, Washington, DC, USA, pp. 234-245
[u'Risi Thonangi', u'Hao He', u'Anhai Doan', u'Haixun Wang', u'Jun Yang']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Bootstrapping Pay-as-you-go Data Integration Systems
Proc. ACM SIGMOD International Conference on Management of Data, ACM, Vancouver (2008), pp. 861-874
[u'Anish Das Sarma', u'Xin Dong', u'Alon Halevy']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Pay-as-you-go User Feedback for Dataspace Systems
Proc. ACM SIGMOD International Conference on Management of Data, ACM, Vancouver (2008), pp. 847-860
[u'Shawn R. Jeffery', u'Michael J. Franklin', u'Alon Y. Halevy']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
The Space Complexity of Processing XML Twig Queries over Indexed Documents
Proceedings of the 24th International Conference on Data Engineering (ICDE) (2008), pp. 824-832
[u'Mirit Shalem', u'Ziv Bar-Yossef']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Ad Hoc Distributed Simulations
21st International Workshop on Principles of Advanced and Distributed Simulation (PADS'07), IEEE Computer Society (2007), pp. 15-24
[u'Richard Fujimoto', u'Michael Hunter', u'Jason Sirichoke', u'Mahesh Palekar', u'Hoe Kim', u'Wonhu Suh']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
An Information Avalanche
IEEE Computer, vol. 40, no. 1 (2007), pp. 104-105
[u'Vint Cerf']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Building MEMS-Based Storage Systems for Streaming Media
ACM Transactions on Storage, vol. 9 (2007)
[u'Raju Rangaswami', u'Zoran Dimitrijevi', u'Edward Chang', u'Klaus Schauser']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Estimating Statistical Aggregates on Probabilistic Data Streams
Principles of Database Systems (PODS) 2007, ACM, Beijing, China, pp. 243-252
[u'T. S. Jayram', u'Andrew McGregor', u'S. Muthukrishan', u'Erik Vee']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub32774.html
found
=========================
Failure Trends in a Large Disk Drive Population
5th USENIX Conference on File and Storage Technologies (FAST 2007), pp. 17-29
[u'Eduardo Pinheiro', u'Wolf-Dietrich Weber', u'Luiz Andr Barroso']
DataManagement
Abstract: It is estimated that over 90% of all new information produced in the world is being stored on magnetic media, most of it in hard disk drives. Despite their importance, there is relatively little published work on the failure patterns of disk drives, and the key factors that affect their lifetime. Most available data are either based on extrapolation from accelerated aging experiments or from relatively modest sized field studies. Moreover, larger population studies rarely have the infrastructure in place to collect health signals from components in operation, which is critical information for detailed failure analysis. We present data collected from detailed observations of a large disk drive population in a production Internet services deployment. The population observed is many times larger than that of previous studies. In addition to presenting failure statistics, we analyze the correlation between failures and several parameters generally believed to impact longevity. Our analysis identifies several parameters from the drives self monitoring facility (SMART) that correlate highly with failures. Despite this high correlation, we conclude that models based on SMART parameters alone are unlikely to be useful for predicting individual drive failures. Surprisingly, we found that temperature and activity levels were much less correlated with drive failures than previously reported.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Indexing Dataspaces
Proc. ACM SIGMOD, ACM, Beijing (2007)
[u'Xin Dong', u'Alon Halevy']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Life on the Edge: Monitoring and Running a Very Large Perforce Installation.
Perforce User Conference 2007
[u'Dan Bloch']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35206.html
found
=========================
Optimal Traversal Planning in Road Networks with Navigational Constraints
ACM GIS, ACM (2007)
[u'Leyla Kazemi', u'Cyrus Shahabi', u'Mehdi Sharifzadeh', u'Luc Vincent']
DataManagement
Abstract: A frequent query in geospatial planning and decision making domains (e.g., emergency response, data acquisition, street cleaning), is to nd an optimal traversal plan (OTP) that traverses an entire area (e.g., a city) by navigating through all its streets. The optimality is dened in terms of the time it takes to complete the traversal. This time depends on the number of times each street segment is traversed as well as the navigation time such as the time spent on changing direction at each intersection. While the problem roots in the classic problems of graph theory, real-world geospatial constraints of road network introduce new application-specic challenges. In this paper, we propose two algorithms to nd OTP of a directed road network. Our greedy algorithm employs a classic graph traversal algorithm. During the traversal, it utilizes a set of heuristics at each intersection to minimize the total travel time. Our near-optimal algorithm, however, reduces an OTP problem to an Asymmetric Traveling Salesman Problem (ATSP) by extracting the dual graph of the original network in which each edge is represented by a graph node. Using an approximate solution for ATSP, our algorithm finds a near optimal answer. Our experiments using real-world road networks verify that our near-optimal algorithm outperforms the greedy algorithm in terms of the overall cost of its generated traversal by a factor of two, while its complexity is tolerable in real-world cases.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Query Suspend and Resume
Proc. ACM SIGMOD, ACM, Beijing (2007)
[u'Badrish Chandramouli', u'Chris Bond', u'Shivnath Babu', u'Jun Yang']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub32784.html
found
=========================
Web-scale Data Integration: You can only afford to Pay As You Go
CIDR (2007)
[u'Jayant Madhavan', u'Shawn R. Jeffery', u'Shirley Cohen', u'Xin (Luna) Dong', u'David Ko', u'Cong Yu', u'Alon Halevy']
DataManagement
Abstract: The World Wide Web is witnessing an increase in the amount of structured content - vast heterogeneous collections of structured data are on the rise due to the Deep Web, annotation schemes like Flickr, and sites like Google Base. While this phenomenon is creating an opportunity for structured data management, dealing with heterogeneity on the web-scale presents many new challenges. In this paper, we highlight these challenges in two scenarios - the Deep Web and Google Base. We contend that traditional data integration techniques are no longer valid in the face of such heterogeneity and scale. We propose a new data integration architecture, PAYGO, which is inspired by the concept of dataspaces and emphasizes pay-as-you-go data management as means for achieving web-scale data integration.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Achieving completion time guarantees in an opportunistic data migration scheme
ACM SIGMETRICS Performance Evaluation Review, vol. 33 (2006), pp. 11-16
[u'Jianyong Zhang', u'Prasenjit Sarkar', u'Anand Sivasubramaniam']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Data integration: the teenage years
Proc. 32nd International Conference on Very Large Databases, VLDB, Seoul, Korea (2006), pp. 9-16
[u'Alon Halevy', u'Anand Rajaraman', u'Joann Ordille']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Data management projects at Google
SIGMOD Conference (2006), pp. 725-726
[u'Wilson Hsieh', u'Jayant Madhavan', u'Rob Pike']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
On-the-fly Sharing for Streamed Aggregation
SIGMOD Conference (2006), pp. 623-634
[u'Sailesh Krishnamurthy', u'Chung Wu', u'Michael J. Franklin']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Principles of dataspace systems
PODS (2006), pp. 1-9
[u'Alon Y. Halevy', u'Michael J. Franklin', u'David Maier']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Semantically-smart disk systems: past, present, and future
ACM SIGMETRICS Performance Evaluation Review, vol. 33 (2006), pp. 29-35
[u'Andrea C. Arpaci-Dusseau', u'Remzi H. Arpaci-Dusseau', u'Lakshmi N. Bairavasundaram', u'Timothy E. Denehy', u'Florentina I. Popovici', u'Vijayan Prabhakaran', u'Muthuian Sivathanu']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Sender Reputation in a Large Webmail Service
Third Conference on Email and Anti-Spam (CEAS 2006)
[u'Bradley Taylor']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub32593.html
found
=========================
Structured Data Meets the Web: A Few Observations
Data Engineering Bulletin (2006)
[u'Jayant Madhavan', u'Alon Halevy', u'Shirley Cohen', u'Xin (Luna) Dong', u'Shawn R. Jeffery', u'David Ko', u'Cong Yu']
DataManagement
Abstract: The World Wide Web is witnessing an increase in the amount of structured content -- vast heterogeneous collections of structured data are on the rise due to the Deep Web, annotation schemes like Flickr, and sites like Google Base. While this phenomenon is creating an opportunity for structured data management, dealing with heterogeneity on the web-scale presents many new challenges. In this paper we articulate challenges based on our experience with addressing them at Google, and offer some principles for addressing them in a general fashion.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
ULDBs: databases with uncertainty and lineage
Proc. 32nd International Conference on Very Large Databases, VLDB, Seoul, Korea (2006), pp. 953-964
[u'Omar Benjelloun', u'Anish Das Sarma', u'Alon Halevy', u'Jennifer Widom']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
PADX: Querying large-scale ad hoc data with XQuery
Proceedings of PLAN-X 2006: Workshop on Programming Language technologies for XML (2006)
[u'Mary Fernandez', u'Kathleen Fisher', u'Robert Gruber', u'Yitzhak Mandelbaum']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Networking proposal for TR2
ISO (2005)
[u'Gerhard Wesp']
DataManagement
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/DataMiningandModeling.html
found
=========================
Ego-net Community Mining Applied to Friend Suggestion
Proceedings of VLDB (2016) (to appear)
[u'Alessandro Epasto', u'Silvio Lattanzi', u'Vahab S. Mirrokni', u'Ismail Sebe', u'Ahmed Taei', u'Sunita Verma']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Hierarchical Label Propagation and Discovery for Machine Generated Email
Proceedings of the International Conference on Web Search and Data Mining (WSDM) (2016) (to appear)
[u'James B. Wendt', u'Michael Bendersky', u'Lluis Garcia-Pueyo', u'Vanja Josifovski', u'Balint Miklos', u'Ivo Krka', u'Amitabh Saikia', u'Jie Yang', u'Marc-Allen Cartright', u'Sujith Ravi']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Active Learning in Keyword Search-based Data Integration
The VLDB Journal, vol. 24 (2015), pp. 611-631
[u'Zhepeng Yan', u'Nan Zheng', u'Zachary G. Ives', u'Partha Pratim Talukdar', u'Cong Yu']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Applying WebTables in Practice
Conference on Innovative Data Systems Research (2015)
[u'Sreeram Balakrishnan', u'Alon Halevy', u'Boulos Harb', u'Hongrae Lee', u'Jayant Madhavan', u'Afshin Rostamizadeh', u'Warren Shen', u'Kenneth Wilder', u'Fei Wu', u'Cong Yu']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43419.html
found
=========================
Associating Locations with Healthcare Events
Defensive Publications Series, Technical Disclosure Commons (2015)
[u'Daniel V. Klein', u'Dean Jackson']
DataMiningandModeling
Abstract: The disclosed subject matter relates to computer implemented methods for associating locations with healthcare events. In one aspect, a method includes receiving location data from a location-aware client device. The location data includes latitude and longitude information. The method further includes determining, based on the received location data, a routine travel pattern of a user associated with the location-aware client device. The method further includes detecting an anomaly in the routine travel pattern. The method further includes detecting a healthcare event. The healthcare event can be a visit to a healthcare facility and/or a healthcare transaction. The method further includes correlating the anomaly in the routine travel pattern of the user with the healthcare event. The method further includes associating one or more healthcare event locations to the healthcare event based on the correlation.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Automatic Pronunciation Verification for Speech Recognition
ICASSP (2015)
[u'Kanishka Rao', u'Fuchun Peng', u'Franoise Beaufays']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43889.html
found
=========================
Crowdsourcing and the Semantic Web: A Research Manifesto
Human Computation, vol. 2 (2015)
[u'Cristina Sarasua', u'Elena Simperl', u'Natasha Noy', u'Abraham Bernstein', u'Jan Marco Leimeister']
DataMiningandModeling
Abstract: Our goal with this research manifesto is to define a roadmap to guide the evolution of the new research field that is emerging at the intersection between crowdsourcing and the Semantic Web. We analyze the confluence of these two disciplines by exploring their relationship. First, we focus on how the application of crowdsourcing techniques can enhance the machine-driven execution of Semantic Web tasks. Second, we look at the ways in which machine-processable semantics can benefit the design and management of crowdsourcing projects. As a result, we are able to describe a list of successful or promising scenarios for both perspectives, identify scientific and technological challenges, and compile a set of recommendations to realize these scenarios effectively. This research manifesto is an outcome of the Dagstuhl Seminar 14282: Crowdsourcing and the Semantic Web.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Discovering Subsumption Relationships for Web-Based Ontologies
Proc. 18th International Workshop on the Web and Databases (WebDB) (2015)
[u'Dana Movshovitz-Attias', u'Steven Euijong Whang', u'Natalya Noy', u'Alon Halevy']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Efficient Algorithms for Public-Private Social Networks
KDD (2015)
[u'Flavio Chierichetti', u'Alessandro Epasto', u'Ravi Kumar', u'Silvio Lattanzi', u'Vahab Mirrokni']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Efficient Densest Subgraph Computation in Evolving Graphs
WWW (2015)
[u'Alessandro Epasto', u'Silvio Lattanzi', u'Mauro Sozio']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Event Relevant Reminders
Defensive Publications Series, Technical Disclosure Commons (2015)
[u'Daniel V. Klein', u'Dean Jackson']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Fix It Where It Fails: Pronunciation Learning by Mining Error Corrections from Speech Logs
ICASSP (2015)
[u'Zhenzhen Kou', u'Daisy Stanton', u'Fuchun Peng', u'Franoise Beaufays', u'Trevor Strohman']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43887.html
found
=========================
Focus on the Long-Term: It's better for Users and Business
Proceedings 21st Conference on Knowledge Discovery and Data Mining, ACM, Sydney, Australia (2015)
[u'Henning Hohnhold', u"Deirdre O'Brien", u'Diane Tang']
DataMiningandModeling
Abstract: Over the past 10+ years, online companies large and small have adopted widespread A/B testing as a robust data-based method for evaluating potential product improvements. In online experimentation, it is straightforward to measure the short-term effect, i.e., the impact observed during the experiment. However, the short-term effect is not always predictive of the long-term effect, i.e., the final impact once the product has fully launched and users have changed their behavior in response. Thus, the challenge is how to determine the long-term user impact while still being able to make decisions in a timely manner. We tackle that challenge in this paper by first developing experiment methodology for quantifying long-term user learning. We then apply this methodology to ads shown on Google search, more specifically, to determine and quantify the drivers of ads blindness and sightedness, the phenomenon of users changing their inherent propensity to click on or interact with ads. We use these results to create a model that uses metrics measurable in the short-term to predict the long-term. We learn that user satisfaction is paramount: ads blindness and sightedness are driven by the quality of previously viewed or clicked ads, as measured by both ad relevance and landing page quality. Focusing on user satisfaction both ensures happier users but also makes business sense, as our results illustrate. We describe two major applications of our findings: a conceptual change to our search ads auction that further increased the importance of ads quality, and a 50% reduction of the ad load on Googles mobile search interface. The results presented in this paper are generalizable in two major ways. First, the methodology may be used to quantify user learning effects and to evaluate online experiments in contexts other than ads. Second, the ads blindness/sightedness results indicate that a focus on user satisfaction could help to reduce the ad load on the internet at large with long-term neutral, or even positive, business impact.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43807.html
found
=========================
Improving User Topic Interest Profiles by Behavior Factorization
Proceedings of the 24th International Conference on World Wide Web, International World Wide Web Conferences Steering Committee, Republic and Canton of Geneva, Switzerland (2015), pp. 1406-1416
[u'Zhe Zhao', u'Zhiyuan Cheng', u'Lichan Hong', u'Ed H. Chi']
DataMiningandModeling
Abstract: Many recommenders aim to provide relevant recommendations to users by building personal topic interest profiles and then using these profiles to find interesting contents for the user. In social media, recommender systems build user profiles by directly combining users' topic interest signals from a wide variety of consumption and publishing behaviors, such as social media posts they authored, commented on, +1'd or liked. Here we propose to separately model users' topical interests that come from these various behavioral signals in order to construct better user profiles. Intuitively, since publishing a post requires more effort, the topic interests coming from publishing signals should be more accurate of a user's central interest than, say, a simple gesture such as a +1. By separating a single user's interest profile into several behavioral profiles, we obtain better and cleaner topic interest signals, as well as enabling topic prediction for different types of behavior, such as topics that the user might +1 or comment on, but might never write a post on that topic. To do this at large scales in Google+, we employed matrix factorization techniques to model each user's behaviors as a separate example entry in the input user-by-topic matrix. Using this technique, which we call "behavioral factorization", we implemented and built a topic recommender predicting user's topical interests using their actions within Google+. We experimentally showed that we obtained better and cleaner signals than baseline methods, and are able to more accurately predict topic interests as well as achieve better coverage.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Linked Enterprise Data Model and Its Use in Real Time Analytics and Context-Driven Data Discovery
IEEE International Conference on Mobile Services, 1800 (2015), pp. 277-283 (to appear)
[u'KUNAL TANEJA', u'Qian Zhu', u'Desmond Duggan', u'Teresa Tung']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Mining Subjective Properties on the Web
SIGMOD (2015) (to appear)
[u'Immanuel Trummer', u'Alon Halevy', u'Hongrae Lee', u'Sunita Sarawagi', u'Rahul Gupta']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43972.html
found
=========================
Scalable Community Discovery from Multi-Faceted Graphs
2015 IEEE International Conference on Big Data, IEEE, 445 Hoes Lane Piscataway, NJ 08854-4141 USA (to appear)
[u'Ahmed Metwally', u'Jia-Yu Pan', u'Minh Doan', u'Christos Faloutsos']
DataMiningandModeling
Abstract: A multi-faceted graph defines several facets on a set of nodes. Each facet is a set of edges that represent the relationships between the nodes in a specific context. Mining multi-faceted graphs have several applications, including finding fraudster rings that launch advertising traffic fraud attacks, tracking IP addresses of botnets over time, analyzing interactions on social networks and co-authorship of scientific papers. We propose NeSim, a distributed efficient clustering algorithm that does soft clustering on individual facets. We also propose optimizations to further improve the scalability, the efficiency and the clusters quality. We employ general purpose graph-clustering algorithms in a novel way to discover communities across facets. Due to the qualities of NeSim, we employ it as a backbone in the distributed MuFace algorithm, which discovers multi-faceted communities. We evaluate the proposed algorithms on several real and synthetic datasets, where NeSim is shown to be superior to MCL, JP and AP, the well-established clustering algorithms. We also report the success stories of MuFace in finding advertisement click rings.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43783.html
found
=========================
Secrets, Lies, and Account Recovery: Lessons from the Use of Personal Knowledge Questions at Google
WWW'15 - Proceedings of the 22nd international conference on World Wide Web, ACM (2015)
[u'Joseph Bonneau', u'Elie Bursztein', u'Ilan Caron', u'Rob Jackson', u'Mike Williamson']
DataMiningandModeling
Abstract: We examine the first large real-world data set on personal knowledge question's security and memorability from their deployment at Google. Our analysis confirms that secret questions generally offer a security level that is far lower than user-chosen passwords. It turns out to be even lower than proxies such as the real distribution of surnames in the population would indicate. Surprisingly, we found that a significant cause of this insecurity is that users often don't answer truthfully. A user survey we conducted revealed that a significant fraction of users (37%) who admitted to providing fake answers did so in an attempt to make them "harder to guess" although on aggregate this behavior had the opposite effect as people "harden" their answers in a predictable way. On the usability side, we show that secret answers have surprisingly poor memorability despite the assumption that reliability motivates their continued deployment. From millions of account recovery attempts we observed a significant fraction of users (e.g 40\% of our English-speaking US users) were unable to recall their answers when needed. This is lower than the success rate of alternative recovery mechanisms such as SMS reset codes (over 80%). Comparing question strength and memorability reveals that the questions that are potentially the most secure (e.g what is your first phone number) are also the ones with the worst memorability. We conclude that it appears next to impossible to find secret questions that are both secure and memorable. Secret questions continue have some use when combined with other signals, but they should not be used alone and best practice should favor more reliable alternatives.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43422.html
found
=========================
Temporal/Spatial Calendar Events and Triggers
Defensive Publications Series, Technical Disclosure Commons (2015)
[u'Daniel V. Klein', u'Dean Jackson']
DataMiningandModeling
Abstract: Spatial and/or temporal triggers may be established so that when actuated, one or more notifications such as reminders may be provided to one or more users. These triggers may be established manually, e.g., by a user operating a user interface, automatically, e.g., by scraping calendar and/or email data to ascertain and/or predict various aspects of upcoming appointments such as start times, duration, date, location, and so forth, or a combination of the two. Spatial triggers may be actuated based on a determination that a user is, or will be, at a particular location. Temporal triggers may be actuated at particular points in time, e.g., at the scheduled time of an event or at some predetermined time interval before or after the event. Using one or more triggers, it is possible to provide notifications to a user at some predetermined time interval prior to a scheduled event, so that the user has sufficient time to make appropriate arrangements, such as buying tickets, making a reservation, scheduling a rendezvous with a friend, and so forth. A calendar system may also be interfaced with to manually or automatically establish triggers.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44266.html
found
=========================
Unified and contrasting cuts in multiple graphs: application to medical imaging segmentation
KDD (2015), pp. 617-626
[u'Chia-Tung Kuo', u'Xiang Wang', u'Peter Walker', u'Owen Carmichael', u'Jieping Ye', u'Ian Davidson']
DataMiningandModeling
Abstract: The analysis of data represented as graphs is common having wide scale applications from social networks to medical imaging. A popular analysis is to cut the graph so that the disjoint subgraphs can represent communities (for social network) or background and foreground cognitive activity (for medical imaging). An emerging setting is when multiple data sets (graphs) exist which opens up the opportunity for many new questions. In this paper we study two such questions: i) For a collection of graphs find a single cut that is good for all the graphs and ii) For two collections of graphs find a single cut that is good for one collection but poor for the other. We show that existing formulations of multiview, consensus and alternative clustering cannot address these questions and instead we provide novel formulations in the spectral clustering framework. We evaluate our approaches on functional magnetic resonance imaging (fMRI) data to address questions such as: "What common cognitive network does this group of individuals have?" and "What are the differences in the cognitive networks for these two groups?" We obtain useful results without the need for strong domain knowledge.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41894.html
found
=========================
Biperpedia: An Ontology for Search Applications
Proc. 40th Int'l Conf. on Very Large Data Bases (PVLDB) (2014)
[u'Rahul Gupta', u'Alon Halevy', u'Xuezhi Wang', u'Steven Whang', u'Fei Wu']
DataMiningandModeling
Abstract: Search engines make significant efforts to recognize queries that can be answered by structured data and invest heavily in creating and maintaining high-precision databases. While these databases have a relatively wide coverage of entities, the number of attributes they model (e.g., gdp, capital, anthem) is relatively small. Extending the number of attributes known to the search engine can enable it to more precisely answer queries from the long and heavy tail, extract a broader range of facts from the Web, and recover the semantics of tables on the Web. We describe Biperpedia, an ontology with 1.6M (class, attribute) pairs and 67K distinct attribute names. Biperpedia extracts attributes from the query stream, and then uses the best extractions to seed attribute extraction from text. For every attribute Biperpedia saves a set of synonyms and text patterns in which it appears, thereby enabling it to recognize the attribute in more contexts. In addition to a detailed analysis of the quality of Biperpedia, we show that it can increase the number of Web tables whose semantics we can recover by more than a factor of 4 compared with Freebase.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Distributed Balanced Clustering via Mapping Coresets
NIPS, Neural Information Processing Systems Foundation (2014)
[u'Mohammadhossein Bateni', u'Aditya Bhaskara', u'Silvio Lattanzi', u'Vahab Mirrokni']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42929.html
found
=========================
Frame by Frame Language Identification in Short Utterances using Deep Neural Networks
Neural Networks Special Issue: Neural Network Learning in Big Data (2014)
[u'Javier Gonzalez-Dominguez', u'Ignacio Lopez-Moreno', u'Pedro J. Moreno', u'Joaquin Gonzalez-Rodriguez']
DataMiningandModeling
Abstract: This work addresses the use of deep neural networks (DNNs) in automatic language identification (LID) focused on short test utterances. Motivated by their recent success in acoustic modelling for speech recognition, we adapt DNNs to the problem of identifying the language in a given utterance from the short-term acoustic features. We show how DNNs are particularly suitable to perform LID in real-time applications, due to their capacity to emit a language identification posterior at each new frame of the test utterance. We then analyse different aspects of the system, such as the amount of required training data, the number of hidden layers, the relevance of contextual information and the effect of the test utterance duration. Finally, we propose several methods to combine frame-by-frame posteriors. Experiments are conducted on two different datasets: the public NIST Language Recognition Evaluation 2009 (3 seconds task) and a much larger corpus (of 5 million utterances) known as Google 5M LID, obtained from different Google Services. Reported results show relative improvements of DNNs versus the i-vector system of 40% in LRE09 3 second task and 76% in Google 5M LID.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Great Question! Question Quality in Community Q&A
International AAAI Conference on Weblogs and Social Media (ICWSM) (2014)
[u'Sujith Ravi', u'Bo Pang', u'Vibhor Rastogi', u'Ravi Kumar']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43469.html
found
=========================
Handcrafted Fraud and Extortion: Manual Account Hijacking in the Wild
IMC '14 Proceedings of the 2014 Conference on Internet Measurement Conference, ACM, 1600 Amphitheatre Parkway, pp. 347-358
[u'Elie Bursztein', u'Borbala Benko', u'Daniel Margolis', u'Tadek Pietraszek', u'Andy Archer', u'Allan Aquino', u'Andreas Pitsillidis', u'Stefan Savage']
DataMiningandModeling
Abstract: Online accounts are inherently valuable resources---both for the data they contain and the reputation they accrue over time. Unsurprisingly, this value drives criminals to steal, or hijack, such accounts. In this paper we focus on manual account hijacking---account hijacking performed manually by humans instead of botnets. We describe the details of the hijacking workflow: the attack vectors, the exploitation phase, and post-hijacking remediation. Finally we share, as a large online company, which defense strategies we found effective to curb manual hijacking.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42024.html
found
=========================
Knowledge Base Completion via Search-Based Question Answering
WWW (2014)
[u'Robert West', u'Evgeniy Gabrilovich', u'Kevin Murphy', u'Shaohua Sun', u'Rahul Gupta', u'Dekang Lin']
DataMiningandModeling
Abstract: Over the past few years, massive amounts of world knowledge have been accumulated in publicly available knowledge bases, such as Freebase, NELL, and YAGO. Yet despite their seemingly huge size, these knowledge bases are greatly incomplete. For example, over 70% of people included in Freebase have no known place of birth, and 99% have no known ethnicity. In this paper, we propose a way to leverage existing Web-search--based question-answering technology to fill in the gaps in knowledge bases in a targeted way. In particular, for each entity attribute, we learn the best set of queries to ask, such that the answer snippets returned by the search engine are most likely to contain the correct value for that attribute. For example, if we want to find Frank Zappa's mother, we could ask the query "who is the mother of Frank Zappa". However, this is likely to return "The Mothers of Invention", which was the name of his band. Our system learns that it should (in this case) add disambiguating terms, such as Zappa's place of birth, in order to make it more likely that the search results contain snippets mentioning his mother. Our system also learns how many different queries to ask for each attribute, since in some cases, asking too many can hurt accuracy (by introducing false positives). We discuss how to aggregate candidate answers across multiple queries, ultimately returning probabilistic predictions for possible values for each attribute. Finally, we evaluate our system and show that it is able to extract a large number of facts with high confidence.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Near Neighbor Join
ICDE (2014)
[u'Herald Kllapi', u'Boulos Harb', u'Cong Yu']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42030.html
found
=========================
On Estimating the Average Degree
23rd International World Wide Web Conference, WWW '14, ACM (2014) (to appear)
[u'Anirban Dasgupta', u'Ravi Kumar', u'Tamas Sarlos']
DataMiningandModeling
Abstract: Networks are characterized by nodes and edges. While there has been a spate of recent work on estimating the number of nodes in a network, the edge-estimation question appears to be largely unaddressed. In this work we consider the problem of estimating the average degree of a large network using efficient random sampling, where the number of nodes is not known to the algorithm. We propose a new estimator for this problem that relies on access to edge samples under a prescribed distribution. Next, we show how to efficiently realize this ideal estimator in a random walk setting. Our estimator has a natural and simple implementation using random walks; we bound its performance in terms of the mixing time of the underlying graph. We then show that our estimators are both provably and practically better than many natural estimators for the problem. Our work contrasts with existing theoretical work on estimating average degree, which assume a uniform random sample of nodes is available and the number of nodes is known.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42022.html
found
=========================
Quizz: Targeted Crowdsourcing with a Billion (Potential) Users
WWW (2014) (to appear)
[u'Panos Ipeirotis', u'Evgeniy Gabrilovich']
DataMiningandModeling
Abstract: We describe Quizz, a gamified crowdsourcing system that simultaneously assesses the knowledge of users and acquires new knowledge from them. Quizz operates by asking users to complete short quizzes on specific topics; as a user answers the quiz questions, Quizz estimates the user's competence. To acquire new knowledge, Quizz also incorporates questions for which we do not have a known answer; the answers given by competent users provide useful signals for selecting the correct answers for these questions. Quizz actively tries to identify knowledgeable users on the Internet by running advertising campaigns, effectively leveraging the targeting capabilities of existing, publicly available, ad placement services. Quizz quantifies the contributions of the users using information theory and sends feedback to the advertising system about each user. The feedback allows the ad targeting mechanism to further optimize ad placement. Our experiments, which involve over ten thousand users, confirm that we can crowdsource knowledge curation for niche and specialized topics, as the advertising network can automatically identify users with the desired expertise and interest in the given topic. We present controlled experiments that examine the effect of various incentive mechanisms, highlighting the need for having short-term rewards as goals, which incentivize the users to contribute. Finally, our cost-quality analysis indicates that the cost of our approach is below that of hiring workers through paid-crowdsourcing platforms, while offering the additional advantage of giving access to billions of potential users all over the planet, and being able to reach users with specialized expertise that is not typically available through existing labor marketplaces.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42852.html
found
=========================
RAPPOR: Randomized Aggregatable Privacy-Preserving Ordinal Response
Proceedings of the 21st ACM Conference on Computer and Communications Security, ACM, Scottsdale, Arizona (2014) (to appear)
[u'lfar Erlingsson', u'Vasyl Pihur', u'Aleksandra Korolova']
DataMiningandModeling
Abstract: Randomized Aggregatable Privacy-Preserving Ordinal Response, or RAPPOR, is a technology for crowdsourcing statistics from end-user client software, anonymously, with strong privacy guarantees. In short, RAPPORs allow the forest of client data to be studied, without permitting the possibility of looking at individual trees. By applying randomized response in a novel manner, RAPPOR provides the mechanisms for such collection as well as for efficient, high-utility analysis of the collected data. In particular, RAPPOR permits statistics to be collected on the population of client-side strings with strong privacy guarantees for each client, and without linkability of their reports. This paper describes and motivates RAPPOR, details its differential-privacy and utility guarantees, discusses its practical deployment and properties in the face of different attack models, and, finally, gives results of its application to both synthetic and real-world data.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42500.html
found
=========================
Reducing the Sampling Complexity of Topic Models
ACM Conference on Knowledge Discovery and Data Mining (KDD) (2014)
[u'Aaron Li', u'Amr Ahmed', u'Sujith Ravi', u'Alexander J Smola']
DataMiningandModeling
Abstract: Inference in topic models typically involves a sampling step to associate latent variables with observations. Unfortunately, the generative model loses sparsity with the increase in data, requiring O(k) operations per word for k latent states, such as topics. In this paper we propose an algorithm which requires only O(kd) operations per word, where kd is the number of actually instantiated topics in the document. For large document collections and structured hierarchical models kd k, thus yielding an order of magnitude speedup. Our method is general and it applies to a wide variety of statistical models. At its core is the idea that dense, rapidly changing distributions can be approximated efficiently by the combination of a Metropolis-Hastings step, judicious use of sparsity, and amortized preprocessing via the alias method.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42498.html
found
=========================
Scalable Hierarchical Multitask Learning Algorithms for Conversion Optimization in Display Advertising
ACM International Conference on Web Search And Data Mining (WSDM) (2014)
[u'Amr Ahmed', u'Abhimanyu Das', u'Alexander J. Smola']
DataMiningandModeling
Abstract: Many estimation tasks come in groups and hierarchies of related problems. In this paper we propose a hierarchical model and a scalable algorithm to perform inference for multitask learning. It infers task correlation and subtask structure in a joint sparse setting. Implementation is achieved by a distributed subgradient oracle and the successive application of prox-operators pertaining to groups and sub-groups of variables. We apply this algorithm to conversion optimization in display advertising. Experimental results on over 1TB data for up to 1 billion observations and 1 million attributes show that the algorithm provides significantly better prediction accuracy while simultaneously being efficiently scalable by distributed parameter synchronization.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42499.html
found
=========================
Taxonomy Discovery for Personalized Recommendation
ACM International Conference on Web Search And Data Mining (WSDM) (2014)
[u'Yuchen Zhang', u'Amr Ahmed', u'Vanja Josifovski', u'Alexander J Smola']
DataMiningandModeling
Abstract: Personalized recommender systems based on latent factor models are widely used to increase sales in e-commerce. Such systems use the past behavior of users to recommend new items that are likely to be of interest to them. However, latent factor model suffer from sparse user-item interaction in online shopping data: for a large portion of items that do not have sufficient purchase records, their latent factors cannot be estimated accurately. In this paper, we propose a novel approach that automatically discovers the taxonomies from online shopping data and jointly learns a taxonomy-based recommendation system. Out model is non-parametric and can learn the taxonomy structure automatically from the data. Since the taxonomy allows purchase data to be shared between item- s, it effectively improves the accuracy of recommending tail items by sharing strength with the more frequent items. Ex- periments on a large-scale online shopping dataset confirm that our proposed model improves significantly over state-of- the-art latent factor models. Moreover, our model generates high-quality and human readable taxonomies. Finally, us- ing the algorithm-generated taxonomy, our model even out- performs latent factor models based on the human-induced taxonomy, thus alleviating the need for costly manual taxonomy generation.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42023.html
found
=========================
Trust, but Verify: Predicting Contribution Quality for Knowledge Base Construction and Curation
WSDM (2014) (to appear)
[u'Chun How Tan', u'Eugene Agichtein', u'Panos Ipeirotis', u'Evgeniy Gabrilovich']
DataMiningandModeling
Abstract: The largest publicly available knowledge repositories, such as Wikipedia and Freebase, owe their existence and growth to volunteer contributors around the globe. While the majority of contributions are correct, errors can still creep in, due to editors' carelessness, misunderstanding of the schema, malice, or even lack of accepted ground truth. If left undetected, inaccuracies often degrade the experience of users and the performance of applications that rely on these knowledge repositories. We present a new method, CQUAL, for automatically predicting the quality of contributions submitted to a knowledge base. Significantly expanding upon previous work, our method holistically exploits a variety of signals, including the user's domains of expertise as reflected in her prior contribution history, and the historical accuracy rates of different types of facts. In a large-scale human evaluation, our method exhibits precision of 91% at 80% recall. Our model verifies whether a contribution is correct immediately after it is submitted, significantly alleviating the need for post-submission human reviewing.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43158.html
found
=========================
Unsupervised Spatial Event Detection in Targeted Domains with Applications to Civil Unrest Modeling
PLOS ONE, vol. 9 (2014), pp. 1-12
[u'Liang Zhao', u'Feng Cheng', u'Jing Dai', u'Ting Hua', u'Chang-Tien Lu', u'Naren Ramakrishnan']
DataMiningandModeling
Abstract: Twitter has become a popular data source as a surrogate for monitoring and detecting events. Targeted domains such as crime, election, and social unrest require the creation of algorithms capable of detecting events pertinent to these domains. Due to the unstructured language, short-length messages, dynamics, and heterogeneity typical of Twitter data streams, it is technically difficult and labor-intensive to develop and maintain supervised learning systems. We present a novel unsupervised approach for detecting spatial events in targeted domains and illustrate this approach using one specific domain, viz. civil unrest modeling. Given a targeted domain, we propose a dynamic query expansion algorithm to iteratively expand domain-related terms, and generate a tweet homogeneous graph. An anomaly identification method is utilized to detect spatial events over this graph by jointly maximizing local modularity and spatial scan statistics. Extensive experiments conducted in 10 Latin American countries demonstrate the effectiveness of the proposed approach.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40749.html
found
=========================
A Framework for Benchmarking Entity-Annotation Systems
Proceedings of the International World Wide Web Conference (WWW) (Practice & Experience Track), ACM (2013) (to appear)
[u'Marco Cornolti', u'Paolo Ferragina', u'Massimiliano Ciaramita']
DataMiningandModeling
Abstract: In this paper we design and implement a benchmarking framework for fair and exhaustive comparison of entity-annotation systems. The framework is based upon the definition of a set of problems related to the entity-annotation task, a set of measures to evaluate systems performance, and a systematic comparative evaluation involving all publicly available datasets, containing texts of various types such as news, tweets and Web pages. Our framework is easily-extensible with novel entity annotators, datasets and evaluation measures for comparing systems, and it has been released to the public as open source. We use this framework to perform the first extensive comparison among all available entity annotators over all available datasets, and draw many interesting conclusions upon their efficiency and effectiveness. We also draw conclusions between academic versus commercial annotators.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41156.html
found
=========================
Classifying YouTube Channels: a Practical System
Proceedings of the 2nd International Workshop on Web of Linked Entities (WOLE 2013), in Proceedings of the 22nd International conference on World Wide Web companion, ACM, pp. 1295-1304
[u'Vincent Simonet']
DataMiningandModeling
Abstract: This paper presents a framework for categorizing channels of videos in a thematic taxonomy with high precision and coverage. The proposed approach consists of three main steps. First, videos are annotated by semantic entities describing their central topics. Second, semantic entities are mapped to categories using a combination of classifiers. Last, the categorization of channels is obtained by combining the results of both previous steps. This framework has been deployed on the whole corpus of YouTube, in 8 languages, and used to build several user facing products. Beyond the description of the framework, this paper gives insight into practical aspects and experience: rationale from product requirements to the choice of the solution, spam filtering, human-based evaluations of the quality of the results, and measured metrics on the live site.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41436.html
found
=========================
Compacting Large and Loose Communities
Asian Conference on Pattern Recognition (2013) (to appear)
[u'Chandrashekhar V.', u'Shailesh Kumar', u'C. V. Jawahar']
DataMiningandModeling
Abstract: Detecting compact overlapping communities in large networks is an important pattern recognition problem with applications in many domains. Most community detection algorithms trade-off between community sizes, their compactness and the scalability of finding communities. Clique Percolation Method (CPM) and Local Fitness Maximization (LFM) are two prominent and commonly used overlapping community detection methods that scale with large networks. However, significant number of communities found by them are large, noisy, and loose. In this paper, we propose a general algorithm that takes such large and loose communities generated by any method and refines them into compact communities in a systematic fashion. We define a new measure of community-ness based on eigenvector centrality, identify loose communities using this measure and propose an algorithm for partitioning such loose communities into compact communities. We refine the communities found by CPM and LFM using our method and show their effectiveness compared to the original communities in a recommendation engine task.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Crawling deep web entity pages
WSDM (2013), pp. 355-364
[u'Yeye He', u'Dong Xin', u'Venkatesh Ganti', u'Sriram Rajaraman', u'Nirav Shah']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41119.html
found
=========================
Crowd-Sourced Call Identification and Suppression
Federal Trade Commission Robocall Challenge (2013)
[u'Daniel V. Klein', u'Dean K. Jackson']
DataMiningandModeling
Abstract: We recommend the creation of a system that allows users to report, to an online database system, the originating telephone number of unwanted solicitations, advertisements or robotically placed calls (henceforth called 'spammers'). We also recommend that users' telephones or external hardware may automatically query the database about the telephone number of an incoming call (before the call is answered, or even before the telephone rings) to determine if the caller has been flagged as a spammer by other users, and optionally block the call or otherwise handle it differently from a non-spam call. The recommended system thereby would provide a means whereby users can make reports of spam calls as well as ask if others have reported a caller as a spammer. While the first few people called would get spammed, after a sufficient number of reports are made, further calls would be blocked. The recommended system would work on most types of telephonic platforms - smartphones, some feature phones, POTS lines, VoIP, PBX, and telephony providers - through the use of software and optional inline hardware. In addition to crowd-sourced blacklisting, we also recommend a means to whitelist specific numbers so that, for example, emergency calls will always go through.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41657.html
found
=========================
Data Fusion: Resolving Conflicts from Multiple Sources
WAIM (2013), pp. 64-76 (to appear)
[u'Xin Luna Dong', u'Laure Berti-Equille', u'Divesh Srivastava']
DataMiningandModeling
Abstract: Many data management applications, such as setting up Web portals, managing enterprise data, managing community data, and sharing scientific data, require integrating data from multiple sources. Each of these sources provides a set of values and different sources can often provide conflicting values. To present quality data to users, it is critical to resolve conflicts and discover values that reflect the real world; this task is called data fusion. This paper describes a novel approach that finds true values from conflicting information when there are a large number of sources, among which some may copy from others. We present a case study on real-world data showing that the described algorithm can significantly improve accuracy of truth discovery and is scalable when there are a large number of data sources.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41607.html
found
=========================
Dense Subgraph Maintenance under Streaming Edge Weight Updates for Real-time Story Identification
The VLDB Journal (2013), pp. 1-25
[u'Albert Angel', u'Nick Koudas', u'Nikos Sarkas', u'Divesh Srivastava', u'Michael Svendsen', u'Srikanta Tirthapura']
DataMiningandModeling
Abstract: Recent years have witnessed an unprecedented proliferation of social media. People around the globe author, every day, millions of blog posts, micro-blog posts, social network status updates, etc. This rich stream of information can be used to identify, on an ongoing basis, emerging stories, and events that capture popular attention. Stories can be identified via groups of tightly-coupled real-world entities, namely the people, locations, products, etc., that are involved in the story. The sheer scale, and rapid evolution of the data involved necessitate highly efficient techniques for identifying important stories at every point of time. The main challenge in real-time story identification is the maintenance of dense subgraphs (corresponding to groups of tightly-coupled entities) under streaming edge weight updates (resulting from a stream of user-generated content). This is the first work to study the efficient maintenance of dense subgraphs under such streaming edge weight updates. For a wide range of definitions of density, we derive theoretical results regarding the magnitude of change that a single edge weight update can cause. Based on these, we propose a novel algorithm, DynDens, which outperforms adaptations of existing techniques to this setting, and yields meaningful results. Our approach is validated by a thorough experimental evaluation on large-scale real and synthetic datasets.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Distributed Large-scale Natural Graph Factorization
Proceedings of the 22nd International World Wide Web Conference (WWW 2013) (to appear)
[u'Amr Ahmed', u'Nino Shervashidze', u'Shravan Narayanamurthy', u'Vanja Josifovski', u'Alexander J Smola']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41408.html
found
=========================
Diversity maximization under matroid constraints
KDD, ACM SIGKDD (2013), pp. 32-40
[u'Zeinab Abbassi', u'Vahab Mirrokni', u'Mayur Thakur']
DataMiningandModeling
Abstract: Aggregator websites typically present documents in the form of representative clusters. In order for users to get a broader perspective, it is important to deliver a diversied set of representative documents in those clusters. One approach to diversication is to maximize the average dissimilarity among documents. Another way to capture diversity is to avoid showing several documents from the same category (e.g. from the same news channel). We combine the above two diversication concepts by modeling the latter approach as a (partition) matroid constraint, and study diversity maximization problems under matroid constraints. We present the rst constant-factor approximation algorithm for this problem, using a new technique. Our local search 0:5-approximation algorithm is also the rst constant-factor approximation for the max-dispersion problem under matroid constraints. Our combinatorial proof technique for maximizing diversity under matroid constraints uses the existence of a family of Latin squares which may also be of independent interest. In order to apply these diversity maximization algorithms in the context of aggregator websites and as a preprocessing step for our diversity maximization tool, we develop greedy clustering algorithms that maximize weighted coverage of a predened set of topics. Our algorithms are based on computing a set of cluster centers, where clusters are formed around them. We show the better performance of our algorithms for diversity and coverage maximization by running experiments on real (Twitter) and synthetic data in the context of real-time search over micro-posts. Finally we perform a user study validating our algorithms and diversity metrics.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41144.html
found
=========================
Efficient and Accurate Label Propagation on Large Graphs and Label Sets
Proceedings International Conference on Advances in Multimedia, IARIA (2013)
[u'Michele Covell', u'Shumeet Baluja']
DataMiningandModeling
Abstract: Many web-based application areas must infer label distributions starting from a small set of sparse, noisy labels. Examples include searching for, recommending, and advertising against image, audio, and video content. These labeling problems must handle millions of interconnected entities (users, domains, content segments) and thousands of competing labels (interests, tags, recommendations, topics). Previous work has shown that graph-based propagation can be very effective at finding the best label distribution across nodes, starting from partial information and a weighted-connection graph. In their work on video recommendations, Baluja et al. [1] showed high-quality results using Adsorption, a normalized propagation process. An important step in the original formulation of Adsorption was re-normalization of the label vectors associated with each node, between every propagation step. That interleaved normalization forced computation of all label distributions, in synchrony, in order to allow the normalization to be correctly determined. Interleaved normalization also prevented use of standard linear-algebra methods, like stabilized bi-conjugate gradient descent (BiCGStab) and Gaussian elimination. This paper presents a method that replaces the interleaved normalization with a single pre-normalization, done once before the main propagation process starts, allowing use of selective label computation (label slicing) as well as large-matrix-solution methods. As a result, much larger graphs and label sets can be handled than in the original formulation and more accurate solutions can be found in fewer propagation steps. We also report results from using pre-normalized Adsorption in topic labeling for web domains, using label slicing and BiCGStab.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41671.html
found
=========================
Filling Knowledge Base Gaps for Distant Supervision of Relation Extraction
ACL 2013
[u'Wei Xu', u'Raphael Hoffmann', u'Le Zhao', u'Ralph Grishman']
DataMiningandModeling
Abstract: (first author email should be xuwei@cs.nyu.edu) Abstract: Distant supervision has attracted recent in- terest for training information extraction systems because it does not require any human annotation but rather employs ex- isting knowledge bases to heuristically la- bel a training corpus. However, previous work has failed to address the problem of false negative training examples misla- beled due to the incompleteness of knowl- edge bases. To tackle this problem, we propose a simple yet novel framework that combines a passage retrieval model using coarse features into a state-of-the-art rela- tion extractor using multi-instance learn- ing with ne features. We adapt the in- formation retrieval technique of pseudo- relevance feedback to expand knowledge bases, assuming entity pairs in top-ranked passages are more likely to express a rela- tion. Our proposed technique signicantly improves the quality of distantly super- vised relation extraction, boosting recall from 47.7% to 61.2% with a consistently high level of precision of around 93% in the experiments.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Focused Marix Factorization for Audience Selection in Display Advertising
Proceedings of the 29th International Conference on Data Engineering (ICDE) (2013) (to appear)
[u'Bhargav Kanagal', u'Amr Ahmed', u'Sandeep Pandey', u'Vanja Josifovski', u'Lluis Garcia-Pueyo', u'Jeff Yuan']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41442.html
found
=========================
From Assets to Stories via the Google Cultural Institute Platform
IEEE BigData'13 Big Data and the Humanities (2013), pp. 6 (to appear)
[u'W. Brent Seales', u'Steve Crossan', u'Sertan Girgin', u'Mark Yoshitake']
DataMiningandModeling
Abstract: The Google Cultural Institute Platform scale system for ingesting, archiving, organizing, and interacting with digital assets of cultural material. This paper explains the components through which the platform contextualizes individual assets in order to enable storytelling. Contextualization is an inverse problem: given assets that are instances of cultural material, infer their precise context and use that as a way to support the storytelling process. The approach is based on three components: extraction, knowledge, and scale. Extraction is the inference of context from two sources of information: explicitly provided metadata, and automatically extracted features. Knowledge is the use of a large refer- ence fact database for further contextualizing an asset based on its descriptors. And scale, achieved through global self-serve, enables massively expanded coverage of the knowledge database and crowdsource potential for metadata renement. Together these components sustain a storytelling framework and a compelling user experience that has the potential to become the largest repository of cultural information and coherent narrative in history.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41763.html
found
=========================
GOOGLE DISEASE TRENDS: AN UPDATE
International Society of Neglected Tropical Diseases 2013, International Society of Neglected Tropical Diseases, pp. 3
[u'Patrick Copeland', u'Raquel Romano', u'Tom Zhang', u'Greg Hecht', u'Dan Zigmond', u'Christian Stefansen']
DataMiningandModeling
Abstract: The purpose of Google Flu Trends (GFT) is to use search keyword trends from Google.com to produce a daily estimate, or nowcast, of the occurrence of flu two weeks in advance of publication of official surveillance data. While not covered in detail in this paper, Google Dengue Trends, launched in June 2011, is a service that uses similar techniques to track Dengue fever. During the 2012 flu season we observed our algorithm overestimating influenza-like illness (ILI). We have concluded that our algorithm for Flu and Dengue were susceptible to heightened media coverage and have since developed several improvements.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Identifying Surrogate Geographic Research Regions with Advanced Exact Test Statistics
American Marketing Association Advanced Research Techniques Forum (2013), Poster
[u'Steven Ellis']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41382.html
found
=========================
Instant Foodie: Predicting Expert Ratings From Grassroots
CIKM13, Oct. 27Nov. 1, 2013, San Francisco, CA, USA, ACM
[u'Chenhao Tan', u'Ed H. Chi', u'David Huffaker', u'Gueorgi Kossinets', u'Alex J. Smola']
DataMiningandModeling
Abstract: Consumer review sites and recommender systems typically rely on a large volume of user-contributed ratings, which makes rating acquisition an essential component in the design of such systems. User ratings are then summarized to provide an aggregate score representing a popular evaluation of an item. An inherent problem in such summarization is potential bias due to raters self-selection and heterogeneity in terms of experiences, tastes and rating scale interpretations. There are two major approaches to collecting ratings, which have different advantages and disadvantages. One is to allow a large number of volunteers to choose and rate items directly (a method employed by e.g. Yelp and Google Places). Alternatively, a panel of raters may be maintained and invited to rate a predened set of items at regular intervals (such as in Zagat Survey). The latter approach arguably results in more consistent reviews and reduced selection bias, however, at the expense of much smaller coverage (fewer rated items). In this paper, we examine the two different approaches to collecting user ratings of restaurants and explore the question of whether it is possible to reconcile them. Specically, we study the problem of inferring the more calibrated Zagat Survey ratings (which we dub expert ratings) from the user-contributed ratings (grassroots) in Google Places. To achieve this, we employ latent factor models and provide a probabilistic treatment of the ordinal ratings. We can predict Zagat Survey ratings accurately from ad hoc user-generated ratings by employing joint optimization. Furthermore, the resulting model show that users become more discerning as they submit more ratings. We also describe an approach towards cross-city recommendations, answering questions such as What is the equivalent of the Per Se restaurant in Chicago?
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
KDD tutorial: The Dataminer Guide to Scalable Mixed-Membership and Nonparametric Bayesian Models
ACM conference on Knowledge Discovery and Data Mining (KDD) (2013) (to appear)
[u'Amr Ahmed', u'Alexander J Smola']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Latent Factor Models with Additive Hierarchically-smoothed User Preferences
Proceedings of The 6th ACM International Conference on Web Search and Data Mining (WSDM) (2013) (to appear)
[u'Amr Ahmed', u'Bhargav Kanagal', u'Sandeep Pandey', u'Vanja Josifovski', u'Lluis Garcia-Pueyo']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41692.html
found
=========================
Nowcasting with Google Trends
String Processing and Information Retrieval, Springer (2013), pp. 4
[u'Yossi Matias']
DataMiningandModeling
Abstract: Since launching Google Trends we have seen extensive interest in what can be learned from search trends. A plethora of studies have shown how to use search trends data for effective nowcasting in diverse areas such as health, finance, economics, politics and more. We give an overview of Google Trends and Nowcasting, highlighting some exciting Big Data challenges, including large scale engineering, effective data analysis, and domain specific considerations.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41465.html
found
=========================
Optimal Hashing Schemes for Entity Matching
22nd International World Wide Web Conference, WWW '13, ACM, Rio de Janeiro, Brazil (2013), pp. 295-306
[u'Nilesh Dalvi', u'Vibhor Rastogi', u'Anirban Dasgupta', u'Anish Das Sarma', u'Tamas Sarlos']
DataMiningandModeling
Abstract: In this paper, we consider the problem of devising blocking schemes for entity matching. There is a lot of work on blocking techniques for supporting various kinds of predicates, e.g. exact matches, fuzzy string-similarity matches, and spatial matches. However, given a complex entity matching function in the form of a Boolean expression over several such predicates, we show that it is an important and non-trivial problem to combine the individual blocking techniques into an efficient blocking scheme for the entity matching function, a problem that has not been studied previously. In this paper, we make fundamental contributions to this problem. We consider an abstraction for modeling complex entity matching functions as well as blocking schemes. We present several results of theoretical and practical interest for the problem. We show that in general, the problem of computing the optimal blocking strategy is NP-hard in the size of the DNF formula describing the matching function. We also present several algorithms for computing the exact optimal strategies (with exponential complexity, but often feasible in practice) as well as fast approximation algorithms. We experimentally demonstrate over commercially used rule-based matching systems over real datasets at Yahoo!, as well as synthetic datasets, that our blocking strategies can be an order of magnitude faster than the baseline methods, and our algorithms can efficiently find good blocking strategies.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41468.html
found
=========================
Permutation Indexing: Fast Approximate Retrieval from Large Corpora
22nd International Conference on Information and Knowledge Management (CIKM), ACM (2013)
[u'Maxim Gurevich', u'Tamas Sarlos']
DataMiningandModeling
Abstract: Inverted indexing is a ubiquitous technique used in retrieval systems including web search. Despite its popularity, it has a drawback - query retrieval time is highly variable and grows with the corpus size. In this work we propose an alternative technique, permutation indexing, where retrieval cost is strictly bounded and has only logarithmic dependence on the corpus size. Our approach is based on two novel techniques: partitioning of the term space into overlapping clusters of terms that frequently co-occur in queries, and a data structure for compactly encoding results of all queries composed of terms in a cluster as continuous sequences of document ids. Then, query results are retrieved by fetching few small chunks of these sequences. There is a price though: our encoding is lossy and thus returns approximate result sets. The fraction of the true results returned, recall, is controlled by the level of redundancy. The more space is allocated for the permutation index the higher is the recall. We analyze permutation indexing both theoretically under simplified document and query models, and empirically on a realistic document and query collections. We show that although permutation indexing can not replace traditional retrieval methods, since high recall cannot be guaranteed on all queries, it covers up to 77% of tail queries and can be used to speed up retrieval for these queries.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42031.html
found
=========================
Postmarket Drug Surveillance Without Trial Costs: Discovery of Adverse Drug Reactions Through Large-Scale Analysis of Web Search Queries
Journal of Medical Internet Research, vol. 15 (2013)
[u'Elad Yom-Tov', u'Evgeniy Gabrilovich']
DataMiningandModeling
Abstract: Background: Postmarket drug safety surveillance largely depends on spontaneous reports by patients and healthcare providers, hence less common adverse drug reactionsespecially those caused by long-term exposure, multidrug treatments, or specific to special populationsoften elude discovery. Objective: Here we propose an ultra-low-cost fully automated method for continuous monitoring of adverse drug reactions in single drugs and in combinations thereof, and demonstrate the discovery of heretofore unknown ones. Materials and Methods: We use aggregated search data of large populations of Internet users to extract information related to drugs and adverse reactions to them, and correlate these data over time. We further extend our method to identify adverse reactions to combinations of drugs. Results: We validate our method by showing high correlation of our findings with known adverse drug reactions (ADRs). However, while acute, early-onset drug reactions are more likely to be reported to regulatory agencies, we show that less acute, later-onset ones are better captured in Web search queries. Conclusions: Our method is advantageous in identifying previously unknown adverse drug reactions. These ADRs should be considered as candidates for further scrutiny by medical regulatory authorities, e.g., through Phase IV trials.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41652.html
found
=========================
Rolling Up Random Variables in Data Cubes
Joint Statistical Meetings, American Statistical Association, 732 North Washington Street, Alexandria, VA 22314-1943 (2013) (to appear)
[u'Phillip M. Yelland']
DataMiningandModeling
Abstract: Data cubes, first developed in the context of on-line analytic processing (OLAP) applications for databases, have become increasingly widespread as a means of structuring data aggregations in other contexts. For example, increasing levels of aggregation in a data cube can be used to impose a hierarchical structure---often referred to as roll-ups---on sets of cross-categorized values, producing a summary description that takes advantage of commonalities within the cube categories. In this paper, we describe a novel technique for realizing such a hierarchical structure in a data cube containing discrete random variables. Using a generalization of an approach due to Chow and Liu, this technique construes roll-ups as parsimonious approximations to the joint distribution of the variables in terms of the aggregation structure of the cube. The technique is illustrated using a real-life application that involves monitoring and reporting anomalies in Web traffic streams over time.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41467.html
found
=========================
Scalable all-pairs similarity search in metric spaces
Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining, ACM, 2 Pennsylvania Plaza, New York, NY (2013), pp. 829-837
[u'Ye Wang', u'Ahmed Metwally', u'Srinivasan Parthasarathy']
DataMiningandModeling
Abstract: Given a set of entities, the all-pairs similarity search aims at identifying all pairs of entities that have similarity greater than (or distance smaller than) some user-defined threshold. In this article, we propose a parallel framework for solving this problem in metric spaces. Novel elements of our solution include: i) flexible support for multiple metrics of interest; ii) an autonomic approach to partition the input dataset with minimal redundancy to achieve good load-balance in the presence of limited computing resources; iii) an on-the- fly lossless compression strategy to reduce both the running time and the final output size. We validate the utility, scalability and the effectiveness of the approach on hundreds of machines using real and synthetic datasets.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40761.html
found
=========================
Semantic Queries by Example
Proceedings of the 16th International Conference on Extending Database Technology (EDBT 2013) (to appear)
[u'Lipyeow Lim', u'Haixun Wang', u'Min Wang']
DataMiningandModeling
Abstract: With the ever increasing quantities of electronic data, there is a growing need to make sense out of the data. Many advanced database applications are beginning to support this need by integrating domain knowledge encoded as ontologies into queries over relational data. However, it is extremely difficult to express queries against graph structured ontology in the relational SQL query language or its extensions. Moreover, semantic queries are usually not precise, especially when data and its related ontology are complicated. Users often only have a vague notion of their information needs and are not able to specify queries precisely. In this paper, we address these challenges by introducing a novel method to support semantic queries in relational databases with ease. Instead of casting ontology into relational form and creating new language constructs to express such queries, we ask the user to provide a small number of examples that satisfy the query she has in mind. Using those examples as seeds, the system infers the exact query automatically, and the user is therefore shielded from the complexity of interfacing with the ontology. Our approach consists of three steps. In the first step, the user provides several examples that satisfy the query. In the second step, we use machine learning techniques to mine the semantics of the query from the given examples and related ontologies. Finally, we apply the query semantics on the data to generate the full query result. We also implement an optional active learning mechanism to find the query semantics accurately and quickly. Our experiments validate the effectiveness of our approach.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41683.html
found
=========================
TSum: Fast, Principled Table Summarization.
Proceedings of the Seventh International Workshop on Data Mining for Online Advertising, ACM (2013)
[u'Jieying Chen', u'Jia-Yu Pan', u'Christos Faloutsos', u'Spiros Papadimitriou']
DataMiningandModeling
Abstract: Given a table where rows correspond to records and columns correspond to attributes, we want to find a small number of patterns that succinctly summarize the dataset. For example, given a set of patient records with several attributes each, how can we find (a) that the "most representative" pattern is, say, (male, adult, *), followed by (*, child, low-cholesterol), etc.? We propose TSum, a method that provides a sequence of patterns ordered by their "representativeness." It can decide both which these patterns are, as well as how many are necessary to properly summarize the data. Our main contribution is formulating a general framework, TSum, using compression principles. TSum can easily accommodate different optimization strategies for selecting and refining patterns. The discovered patterns can be used to both represent the data efficiently, as well as interpret it quickly. Extensive experiments demonstrate the effectiveness and intuitiveness of our discovered patterns.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
The Nested Chinese Restaurant Franchise Process: User Tracking and Document Modeling
International Conference on Machine Learning (ICML) (2013) (to appear)
[u'Amr Ahmed', u'Liangjie Hong', u'Alexander J Smola']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41769.html
found
=========================
Tracking Large-Scale Video Remix in Real-World Events
IEEE Transactions on Multimedia, vol. 15, no. 6 (2013), pp. 1244-1254
[u'Lexing Xie', u'Apostol Natsev', u'Xuming He', u'John R. Kender', u'Matthew L. Hill', u'John R. Smith']
DataMiningandModeling
Abstract: Content sharing networks, such as YouTube, contain traces of both explicit online interactions (such as likes, comments, or subscriptions), as well as latent interactions (such as quoting, or remixing, parts of a video). We propose visual memes, or frequently re-posted short video segments, for detecting and monitoring such latent video interactions at scale. Visual memes are extracted by scalable detection algorithms that we develop, with high accuracy. We further augment visual memes with text, via a statistical model of latent topics. We model content interactions on YouTube with visual memes, dening several measures of inuence and building predictive models for meme popularity. Experiments are carried out with over 2 million video shots from more than 40,000 videos on two prominent news events in 2009: the election in Iran and the swine u epidemic. In these two events, a high percentage of videos contain remixed content, and it is apparent that traditional news media and citizen journalists have different roles in disseminating remixed content. We perform two quantitative evaluations for annotating visual memes and predicting their popularity. The proposed joint statistical model of visual memes and words outperforms an alternative concurrence model, with an average error of 2% for predicting meme volume and 17% for predicting meme lifespan.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Understanding Latency of Black-Box Service Workloads
WWW 2013 (to appear)
[u'Darja Krushevskaja']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Cross-Lingual Dictionary for English Wikipedia Concepts
Eighth International Conference on Language Resources and Evaluation (LREC 2012)
[u'Valentin I. Spitkovsky', u'Angel X. Chang']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40571.html
found
=========================
An Integrated Framework for Spatio-Temporal-Textual Search and Mining
20th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems (ACM SIGSPATIAL GIS 2012), ACM, 2 Penn Plaza, Suite 701, New York, NY 10121, pp. 570-573
[u'Bingsheng Wang', u'Haili Dong', u'Arnold Boedihardjo', u'Chang-Tien Lu', u'Harland Yu', u'Ing-Ray Chen', u'Jing Dai']
DataMiningandModeling
Abstract: This paper presents an integrated framework for Spatio-Temporal-Textual (STT) information retrieval and knowledge discovery system. The proposed ensemble framework contains an efficient STT search engine with multiple indexing, ranking and scoring schemes, an effective STT pattern miner with Spatio-Temporal (ST) analytics, and novel STT topic modeling. Specifically, we design an effective prediction prototype with a third-order linear regression model, and present an innovative STT topic modeling relevance ranker to score documents based on inherent STT features under topical space. We demonstrate the framework with a crime dataset from the Washington, DC area from 2006 to 2010 and a global terrorism dataset from 2004 to 2010.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41422.html
found
=========================
Automatically Discovering Talented Musicians with Acoustic Analysis of YouTube Videos
Proceedings of the 2012 IEEE 12th International Conference on Data Mining (ICDM), IEEE Computer Society, Washington, DC, USA, pp. 559-565
[u'Eric Nichols', u'Charles DuHadway', u'Hrishikesh Aradhye', u'Richard F. Lyon']
DataMiningandModeling
Abstract: Online video presents a great opportunity for up-and-coming singers and artists to be visible to a worldwide audience. However, the sheer quantity of video makes it difficult to discover promising musicians. We present a novel algorithm to automatically identify talented musicians using machine learning and acoustic analysis on a large set of "home singing" videos. We describe how candidate musician videos are identified and ranked by singing quality. To this end, we present new audio features specifically designed to directly capture singing quality. We evaluate these vis-a-vis a large set of generic audio features and demonstrate that the proposed features have good predictive performance. We also show that this algorithm performs well when videos are normalized for production quality.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Budget Optimization for Online Campaigns with Positive Carryover Effects
WINE (2012), pp. 86-99
[u'Nikolay Archak', u'Vahab S. Mirrokni', u'S. Muthukrishnan']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40414.html
found
=========================
Dynamic Covering for Recommendation Systems
CIKM (2012)
[u'Ioannis Antonellis', u'Anish Das Sarma', u'Shaddin Dughmi']
DataMiningandModeling
Abstract: In this paper, we identify a fundamental algorithmic problem that we term succinct dynamic covering (SDC), arising in many modern-day web applications, including ad-serving and online recommendation systems in eBay and Netflix. Roughly speaking, SDC applies two restrictions to the well-studied Max-Coverage problem: Given an integer k, X={1,2,...,n} and I={S_1, ..., S_m}, S_i a subset of X, find a subset J of I, such that |J| <= k and the union of S in J is as large as possible. The two restrictions applied by SDC are: (1) Dynamic: At query-time, we are given a query Q, a subset of X, and our goal is to find J such that the intersection of Q with the union of S in J is as large as possible; (2) Space-constrained: We don't have enough space to store (and process) the entire input; specifically, we have o(mn), and maybe as little as O((m+n)polylog(mn)) space. The goal of SDC is to maintain a small data structure so as to answer most dynamic queries with high accuracy. We call such a scheme a Coverage Oracle. We present algorithms and complexity results for coverage oracles. We present deterministic and probabilistic near-tight upper and lower bounds on the approximation ratio of SDC as a function of the amount of space available to the oracle. Our lower bound results show that to obtain constant-factor approximations we need Omega(mn) space. Fortunately, our upper bounds present an explicit tradeoff between space and approximation ratio, allowing us to determine the amount of space needed to guarantee certain accuracy.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40408.html
found
=========================
Extracting Unambiguous Keywords from Microposts Using Web and Query Logs Data
Making sense of Microposts (at WWW 2012)
[u'Davi Reis', u'Felipe Goldstein', u'Frederico Quintao']
DataMiningandModeling
Abstract: In the recent years, a new form of content type has become ubiquitous in the web. These are small and noisy text snippets, created by users of social networks such as Twitter and Facebook. The full interpretation of those microposts by machines impose tremendous challenges, since they strongly rely on context. In this paper we propose a task which is much simpler than full interpretation of microposts: we aim to build classication systems to detect keywords that unambiguously refer to a single dominant concept, even when taken out of context. For example, in the context of this task, apple would be classied as ambiguous whereas microsoft would not. The contribution of this work is twofold. First, we formalize this novel classication task that can be directly applied for extracting information from microposts. Second, we show how high precision classiers for this problem can be built out of Web data and search engine logs, combining traditional information retrieval metrics, such as inverted document frequency, and new ones derived from search query logs. Finally, we have proposed and evaluated relevant applications for these classiers, which were able to meet precision 72% and recall 56% on unambiguous keyword extraction from microposts. We also compare those results with closely related systems, none of which could outperform those numbers.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
FastEx: Hash Clustering with Exponential Families
Proceedings of the 26th Conference on Neural Information Processing Systems. (NIPS) (2012)
[u'Amr Ahmed', u'Sujith Ravi', u'Shravan Narayanamurthy', u'Alex Smola']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41322.html
found
=========================
Logical Itemset Mining
IEEE International Conference on Data Mining (Workshop) (2012), pp. 603-610
[u'Shailesh Kumar', u'Chandrashekhar V.', u'C. V. Jawahar']
DataMiningandModeling
Abstract: Frequent Itemset Mining (FISM) attempts to nd large and frequent itemsets in bag-of-items data such as retail market baskets. Such data has two properties that are not naturally addressed by FISM: (i) a market basket might contain items from more than one customer intent (mixture property) and (ii) only a subset of items related to a customer intent are present in most market baskets (projection property). We propose a simple and robust framework called LOGICAL ITEMSET MINING (LISM) that treats each market basket as a mixture-of, projections-of, latent customer intents. LISM attempts to discover logical itemsets from such bagof-items data. Each logical itemset can be interpreted as a latent customer intent in retail or semantic concept in text tagsets. While the mixture and projection properties are easy to appreciate in retail domain, they are present in almost all types of bag-of-items data. Through experiments on two large datasets, we demonstrate the quality, novelty, and actionability of logical itemsets discovered by the simple, scalable, and aggressively noise-robust LISM framework. We conclude that while FISM discovers a large number of noisy, observed, and frequent itemsets, LISM discovers a small number of high quality, latent logical itemsets.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38169.html
found
=========================
Look Who I Found: Understanding the Effects of Sharing Curated Friend Groups
Proceedings of ACM Web Science 2012, ACM, pp. 137-146
[u'Lujun Fang', u'Alex Fabrikant', u'Kristen LeFevre']
DataMiningandModeling
Abstract: Online social networks like Google+, Twitter, and Facebook allow users to build, organize, and manage their social connections for the purposes of information sharing and consumption. Nonetheless, most social network users still report that building and curating contact groups is a time-consuming burden. To help users overcome the burdens of contact discovery and grouping, Google+ recently launched a new feature known as "circle sharing". The feature makes it easy for users to share the benefits of their own contact curation by sharing entire "circles" (contact groups) with others. Recipients of a shared circle can adopt the circle as a whole, merge the circle into one of their own circles, or select specific members of the circle to add. In this paper, we investigate the impact that circle-sharing has had on the growth and structure of the Google+ social network. Using a cluster analysis, we identify two natural categories of shared circles, which represent two qualitatively different use cases: circles comprised primarily of celebrities (celebrity circles), and circles comprised of members of a community (community circles). We observe that exposure to circle-sharing accelerates the rate at which a user adds others to his or her circles. More specifically, we notice that circle-sharing has accelerated the "densification" rate of community circles, and also that it has disproportionately affected users with few connections, allowing them to find new contacts at a faster rate than would be expected based on accepted models of network growth. Finally, we identify features that can be used to predict which of a users circles (s)he is most likely to share, thus demonstrating that it is feasible to suggest to a user which circles to share with friends.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38352.html
found
=========================
MedLDA: Maximum Margin Supervised Topic Models
Journal of Machine Learning Research (2012) (to appear)
[u'Jun Zhu', u'Amr Ahmed', u'Eric P. Xing']
DataMiningandModeling
Abstract: A supervised topic model can utilize side information such as ratings or labels associated with documents or images to discover more predictive low dimensional topical representations of the data. However, existing supervised topic models predominantly employ likelihood-driven objective functions for learning and inference, leaving the popular and potentially powerful max-margin principle unexploited for seeking predictive representations of data and more discriminative topic bases for the corpus. In this paper, we propose the maximum entropy discrimination latent Dirichlet allocation (MedLDA) model, which integrates the mechanism behind the max-margin prediction models (e.g., SVMs) with the mechanism behind the hierarchical Bayesian topic models (e.g., LDA) under a uni- ed constrained optimization framework, and yields latent topical representations that are more discriminative and more suitable for prediction tasks such as document classication or regression. The principle underlying the MedLDA formalism is quite general and can be applied for jointly max-margin and maximum likelihood learning of directed or undirected topic models when supervising side information is available. Ecient variational methods for posterior inference and parameter estimation are derived and extensive empirical studies on several real data sets are also provided. Our experimental results demonstrate qualitatively and quantitatively that MedLDA could: 1) discover sparse and highly discriminative topical representations; 2) achieve state of the art prediction performance;
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Multi-skill Collaborative Teams based on Densest Subgraphs
SDM (2012) (to appear)
[u'Amita Gajewar', u'Atish Das Sarma']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38105.html
found
=========================
Multimedia Semantics: Interactions Between Content and Community
Proceedings of the IEEE, vol. 100, no. 9 (2012)
[u'Hari Sundaram', u'Lexing Xie', u'Munmun De Choudhury', u'Yu-Ru Lin', u'Apostol Natsev']
DataMiningandModeling
Abstract: This paper reviews the state of the art and some emerging issues in research areas related to pattern analysis and monitoring of web-based social communities. This research area is important for several reasons. First, the presence of near-ubiquitous low-cost computing and communication technologies has enabled people to access and share information at an unprecedented scale. The scale of the data necessitates new research for making sense of such content. Furthermore, popular websites with sophisticated media sharing and notification features allow users to stay in touch with friends and loved ones; these sites also help to form explicit and implicit social groups. These social groups are an important source of information to organize and to manage multimedia data. In this article, we study how media-rich social networks provide additional insight into familiar multimedia research problems, including tagging and video ranking. In particular, we advance the idea that the contextual and social aspects of media are as important for successful multimedia applications as is the media content. We examine the interrelationship between content and social context through the prism of three key questions. First, how do we extract the context in which social interactions occur? Second, does social interaction provide value to the media object? Finally, how do social media facilitate the repurposing of shared content and engender cultural memes? We present three case studies to examine these questions in detail. In the first case study, we show how to discover structure latent in the social media data, and use the discovered structure to organize Flickr photo streams. In the second case study, we discuss how to determine the interestingness of conversations---and of participants---around videos uploaded to YouTube. Finally, we show how the analysis of visual content, in particular tracing of content remixes, can help us understand the relationship among YouTube participants. For each case, we present an overview of recent work and review the state of the art. We also discuss two emerging issues related to the analysis of social networks---robust data sampling and scalable data analysis.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Nowcasting the macroeconomy with search engine data
Proceedings of the fifth ACM international conference on Web search and data mining, ACM, New York, NY, USA (2012), pp. 1-2
[u'Hal R. Varian']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Online Selection of Diverse Results
Proceedings of the 5th ACM international Conference on Web Search and Data Mining (2012), pp. 263-272
[u'Debmalya Panigrahi', u'Atish Das Sarma', u'Gagan Aggarwal', u'Andrew Tomkins']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Overlapping clusters for distributed computation
ACM Conference on Web Search and Data Mining (WSDM) (2012)
[u'Reid Andersen', u'David Gleich', u'Vahab Mirrokni']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
PageRank on an evolving graph
KDD (2012), pp. 24-32
[u'Bahman Bahmani', u'Ravi Kumar', u'Mohammad Mahdian', u'Eli Upfal']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Spotting fake reviewer groups in consumer reviews
Proceedings of the 21st international conference on World Wide Web, ACM, New York, NY, USA (2012), pp. 191-200
[u'Arjun Mukherjee', u'Bing Liu', u'Natalie Glance']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41177.html
found
=========================
Student-t based Robust Spatio-Temporal Prediction
IEEE 12th International Conference on Data Mining, IEEE, Brussels, Belgium (2012), pp. 151-160
[u'Yang Chen', u'Feng Chen', u'Jing Dai', u'T. Charles Clancy', u'Yao-Jan Wu']
DataMiningandModeling
Abstract: This paper describes an efficient and effective design of Robust Spatio-Temporal Prediction based on Students t distribution, namely, St-RSTP, to provide estimations based on observations over spatio-temporal neighbors. The proposed St-RSTP is more resilient to outliers or other small departures from model assumptions than its ancestor, the Spatio-Temporal Random Effects (STRE) model. STRE is a state-of-the-art statistical model with linear order complexity for large scale processing. However, it assumes Gaussian observations, which has the well-known limitation of non-robustness. In our St-RSTP design, the measurement error follows Students t distribution, instead of a traditional Gaussian distribution. This design reduces the influence of outliers, improves prediction quality, and keeps the problem analytically intractable. We propose a novel approximate inference approach, which approximates the model into the form that separates the high dimensional latent variables into groups, and then estimates the posterior distributions of different groups of variables separately in the framework of Expectation Propagation. As a good property, our approximate approach degeneralizes to the standard STRE based prediction, when the degree of freedom of the Students t distribution is set to infinite. Extensive experimental evaluations based on both simulation and real-life data sets demonstrated the robustness and the efficiency of our Student-t prediction model. The proposed approach provides critical functionality for stochastic processes on spatio-temporal data.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37738.html
found
=========================
The YouTube Social Network
ICWSM 2012, Sixth International AAAI Conference on Weblogs and Social Media (ICWSM 2012) (to appear)
[u'Mirjam Wattenhofer', u'Roger Wattenhofer', u'Zack Zhu']
DataMiningandModeling
Abstract: Today, YouTube is the largest user-driven video content provider in the world; it has become a major platform for disseminating multimedia information. A major contribution to its success comes from the user-to-user social experience that differentiates it from traditional content broadcasters. This work examines the social network aspect of YouTube by measuring the fullscale YouTube subscription graph, comment graph, and video content corpus. We nd YouTube to deviate signicantly from network characteristics that mark traditional online social networks, such as homophily, reciprocative linking, and assortativity. However, comparing to reported characteristics of another content-driven online social network, Twitter, YouTube is remarkably similar. Examining the social and content facets of user popularity, we nd a stronger correlation between a users social popularity and his/her most popular content as opposed to typical content popularity. Finally, we demonstrate an application of our measurements for classifying YouTube Partners, who are selected users that share YouTubes advertisement revenue. Results are motivating despite the highly imbalanced nature of the classication proble
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37740.html
found
=========================
V-SMART-Join: A Scalable MapReduce Framework for All-Pair Similarity Joins of Multisets and Vectors
PVLDB Proceedings of the VLDB Endowment, vol. 5 (2012), pp. 704-715
[u'Ahmed Metwally', u'Christos Faloutsos']
DataMiningandModeling
Abstract: This work proposes V-SMART-Join, a scalable MapReduce-based framework for discovering all pairs of similar entities. The V-SMART-Join framework is applicable to sets, multisets, and vectors. V-SMART-Join is motivated by the observed skew in the underlying distributions of Internet traffic, and is a family of 2-stage algorithms, where the first stage computes and joins the partial results, and the second stage computes the similarity exactly for all candidate pairs. The V-SMART-Join algorithms are very efficient and scalable in the number of entities, as well as their cardinalities. They were up to 30 times faster than the state of the art algorithm, VCL, when compared on a real dataset of a small size. We also established the scalability of the proposed algorithms by running them on a dataset of a realistic size, on which VCL never succeeded to finish. Experiments were run using real datasets of IPs and cookies, where each IP is represented as a multiset of cookies, and the goal is to discover similar IPs to identify Internet proxies.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40345.html
found
=========================
Vote calibration in community question-answering systems
SIGIR '12 Proceedings of the 35th international ACM SIGIR conference on Research and development in information retrieval (2012), pp. 781-790
[u'Bee-Chung Chen', u'Anirban Dasgupta', u'Xuanhui Wang', u'Jie Yang']
DataMiningandModeling
Abstract: User votes are important signals in community question-answering (CQA) systems. Many features of typical CQA systems, e.g. the best answer to a question, status of a user, are dependent on ratings or votes cast by the community. In a popular CQA site, Yahoo! Answers, users vote for the best answers to their questions and can also thumb up or down each individual answer. Prior work has shown that these votes provide useful predictors for content quality and user expertise, where each vote is usually assumed to carry the same weight as others. In this paper, we analyze a set of possible factors that indicate bias in user voting behavior -- these factors encompass different gaming behavior, as well as other eccentricities, e.g., votes to show appreciation of answerers. These observations suggest that votes need to be calibrated before being used to identify good answers or experts. To address this problem, we propose a general machine learning framework to calibrate such votes. Through extensive experiments based on an editorially judged CQA dataset, we show that our supervised learning method of content-agnostic vote calibration can significantly improve the performance of answer ranking and expert ranking.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38345.html
found
=========================
Web-Scale Multi-Task Feature Selection for Behavioral Targeting
Proceedings of The 21st ACM International Conference on Information and Knowledge Management (CIKM), ACM (2012) (to appear)
[u'Amr Ahmed', u'Mohamed Aly', u'Abhimanyu Das', u'Alex Smola', u'Tasos Anastasakos']
DataMiningandModeling
Abstract: A typical behavioral targeting system optimizing purchase activities, called conversions, faces two main challenges: the web-scale amounts of user histories to process on a daily basis, and the relative sparsity of conversions. In this paper, we try to address these challenges through feature selection. We formulate a multi-task (or group) feature-selection problem among a set of related tasks (sharing a common set of features), namely advertising campaigns. We apply a group-sparse penalty consisting of a combination of an `1 and `2 penalty and an associated fast optimization algorithm for distributed parameter estimation. Our algorithm relies on a variant of the well known Fast Iterative Thresholding Algorithm (FISTA), a closed-form solution for mixed norm programming and a distributed subgradient oracle. To eciently handle web-scale user histories, we present a distributed inference algorithm for the problem that scales to billions of instances and millions of attributes. We show the superiority of our algorithm in terms of both sparsity and ROC performance over baseline feature selection methods (both single-task L1-regularization and multi-task mutual-information gain).
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
YouTube around the world: geographic popularity of videos
Proceedings of the 21st international conference on World Wide Web, ACM, New York, NY, USA (2012), pp. 241-250
[u'Anders Brodersen', u'Salvatore Scellato', u'Mirjam Wattenhofer']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Your Two Weeks of Fame and Your Grandmother's
WWW (2012)
[u'James Cook', u'Atish Das Sarma', u'Alex Fabrikant', u'Andrew Tomkins']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37632.html
found
=========================
A Tale of Two (Similar) Cities: Inferring City Similarity Through Geo-Spatial Query Log Analysis
Proceedings of the International Conference on Knowledge Discovery and Information Retrieval (2011)
[u'Rohan Seth', u'Michele Covell', u'Deepak Ravichandran', u'D. Sivakumar', u'Shumeet Baluja']
DataMiningandModeling
Abstract: Understanding the backgrounds and interest of the people who are consuming a piece of content, such as a news story, video, or music, is vital for the content producer as well the advertisers who rely on the content to provide a channel on which to advertise. We extend traditional search-engine query log analysis, which has primarily concentrated on analyzing either single or small groups of queries or users, to examining the complete query stream of very large groups of users the inhabitants of 13,377 cities across the United States. Query logs can be a good representation of the interests of the citys inhabitants and a useful characterization of the city itself. Further, we demonstrate how query logs can be effectively used to gather city-level statistics sufficient for providing insights into the similarities and differences between cities. Cities that are found to be similar through the use of query analysis correspond well to the similar cities as determined through other large-scale and time-consuming direct measurement studies, such as those undertaken by the Census Bureau.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37650.html
found
=========================
Catching a viral video
Journal of Intelligent Information Systems (2011), pp. 1-19
[u'Tom Broxton', u'Yannet Interian', u'Jon Vaver', u'Mirjam Wattenhofer']
DataMiningandModeling
Abstract: The sharing and re-sharing of videos on social sites, blogs e-mail, and other means has given rise to the phenomenon of viral videosvideos that become popular through internet sharing. In this paper we seek to better understand viral videos on YouTube by analyzing sharing and its relationship to video popularity using millions of YouTube videos. The socialness of a video is quantified by classifying the referrer sources for video views as social (e.g. an emailed link, Facebook referral) or non-social (e.g. a link from related videos). We find that viewership patterns of highly social videos are very different from less social videos. For example, the highly social videos rise to, and fall from, their peak popularity more quickly than less social videos. We also find that not all highly social videos become popular, and not all popular videos are highly social. By using our insights on viral videos we are able develop a method for ranking blogs and websites on their ability to spread viral videos.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37195.html
found
=========================
Detecting Adversarial Advertisements in the Wild
Proceedings of the 17th ACM SIGKDD International Conference on Data Mining and Knowledge Discovery, KDD (2011)
[u'D. Sculley', u'Matthew Eric Otey', u'Michael Pohl', u'Bridget Spitznagel', u'John Hainsworth', u'Yunkai Zhou']
DataMiningandModeling
Abstract: In a large online advertising system, adversaries may attempt to prot from the creation of low quality or harmful advertisements. In this paper, we present a large scale data mining eort that detects and blocks such adversarial advertisements for the benet and safety of our users. Because both false positives and false negatives have high cost, our deployed system uses a tiered strategy combining automated and semi-automated methods to ensure reliable classication. We also employ strategies to address the challenges of learning from highly skewed data at scale, allocating the effort of human experts, leveraging domain expert knowledge, and independently assessing the eectiveness of our system.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Efficient Search Engine Measurements
ACM Transactions on the Web, vol. 5, no. 4 (2011), pp. 18
[u'Ziv Bar-Yossef', u'Maxim Gurevich']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36940.html
found
=========================
Efficient Spectral Neighborhood Blocking for Entity Resolution
International Conference on Data Engineering 2011 (ICDE), IEEE, pp. 1-12
[u'Liangcai Shu', u'Aiyou Chen', u'Ming Xiong', u'Weiyi Meng']
DataMiningandModeling
Abstract: In many telecom and web applications, there is a need to identify whether data objects in the same source or different sources represent the same entity in the real world. This problem arises for subscribers in multiple services, customers in supply chain management, and users in social networks when there lacks a unique identifier across multiple data sources to represent a real-world entity. Entity resolution is to identify and discover objects in the data sets that refer to the same entity in the real world. We investigate the entity resolution problem for large data sets where efficient and scalable solutions are needed. We propose a novel unsupervised blocking algorithm, namely SPectrAl Neighborhood (SPAN), which constructs a fast bipartition tree for the records based on spectral clustering such that real entities can be identified accurately by neighborhood records in the tree. There are two major novel aspects in our approach: 1) We develop a fast algorithm that performs spectral clustering without computing pairwise similarities explicitly, which dramatically improves the scalability of the standard spectral clustering algorithm; 2) We utilize a stopping criterion specified by Newman-Girvan modularity in the bipartition process. Our experimental results with both synthetic and real-world data demonstrate that SPAN is robust and outperforms other blocking algorithms in terms of accuracy while it is efficient and scalable to deal with large data sets.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Estimating the Number of Users behind IPs for Combating Abusive Traffic
SIGKDD International Conference on Knowledge Discovery and Data Mining, ACM, ACM, 2 Penn Plaza New York, NY 10121-0799 (2011), pp. 249-257
[u'Ahmed Metwally', u'Matt Paduano']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36974.html
found
=========================
Fast Algorithms for Finding Extremal Sets
Proc. of the 2011 SIAM Int'l Conf. on Data Mining (to appear)
[u'Roberto J. Bayardo', u'Biswanath Panda']
DataMiningandModeling
Abstract: Identifying the extremal (minimal and maximal) sets from a collection of sets is an important subproblem in the areas of data-mining and satisability checking. For example, extremal set nding algorithms are used in the context of mining maximal frequent itemsets, and for simplifying large propositional satisability instances derived from real world tasks such as circuit routing and verication. In this paper, we describe two new algorithms for the task and detail their performance on real and synthetic data. Each algorithm leverages an entirely dierent principle one primarily exploits set cardinality constraints, the other lexicographic constraints. Despite the inherent diculty of this problem (the best known worst-case bounds are nearly quadratic), we show that both these algorithms provide excellent performance in practice, and can identify all extremal sets from multi-gigabyte itemset data using only a single processor core. Both algorithms are concise and can be implemented in no more than a few hundred lines of code. Our reference C++ implementations are open source and available for download.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Frequent Pattern Discovery and Association Rule Mining of XML Data
XML Data Mining: Models, Methods, and Applications, IGI Publishing (2011) (to appear)
[u'Qin Ding', u'Gnanasekaran Sundarraj']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Influence Maximization in Social Networks When Negative Opinions May Emerge and Propagate
SIAM 2011 International Conference on Data Mining, SIAM, Society for Industrial and Applied Mathematics, 3600 Market Street, 6th Floor, Philadelphia, PA 19104-2688 USA., pp. 379-390
[u'Alex Collins']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Interactive Itinerary Planning
ICDE (2011)
[u'Senjuti Basu-Roy', u'Gautam Das', u'Sihem Amer-Yahia', u'Cong Yu']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37296.html
found
=========================
Large Scale Page-Based Book Similarity Clustering
ICDAR 2011
[u'Nemanja Spasojevic', u'Guillaume Poncin']
DataMiningandModeling
Abstract: The Google Books corpus now counts over 15M books spanning 7 centuries and countless languages. Traditional cataloguing at that scale is imprecise, and often fails to identify more complex book-to-book relationships, such as same text, different pagination or partial overlap. Our contribution is a two-step technique for clustering books based on content similarity (at both book and page level) and classifying their relationships. We run this on our corpora consisting of more than 15M books (5B pages). We rst detect similar books and similar pages within matching books, using hashing techniques and judicious thresholds. We then combine those features to identify the exact relationship between matching books. In this paper, we describe the basic approach to making the problem tractable, as well as the features and classiers that we used. We enumerate a small number of relationships to qualify the link between scanned real-world books. Finally, we provide precision and recall measurements of the classier.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Large-scale community detection on YouTube for Topic Discovery and Exploration
AAAI Conference on Weblogs and Social Media 2011
[u'Ullas Gargi', u'Wenjun Lu', u'Vahab Mirrokni', u'Sangho Yoon']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37667.html
found
=========================
Learning to Target: What Works for Behavioral Targeting
CIKM '11, ACM, Glasgow, Scotland, UK (2011), pp. 1805-1814
[u'Sandeep Pandey', u'Mohamed Aly', u'Abraham Bagherjeiran', u'Andrew Hatch', u'Peter Ciccolo', u'Adwait Ratnaparkhi', u'Martin Zinkevich']
DataMiningandModeling
Abstract: Understanding what interests and delights users is critical to effective behavioral targeting, especially in information-poor contexts. As users interact with content and advertising, their passive behavior can reveal their interests towards advertising. Two issues are critical for building effective targeting methods: what metric to optimize for and how to optimize. More specifically, we rst attempt to understand what the learning objective should be for behavioral targeting so as to maximize advertisers performance. While most popular advertising methods optimize for user clicks, as we will show, maximizing clicks does not necessarily imply maximizing purchase activities or transactions, called conversions, which directly translate to advertisers revenue. In this work we focus on conversions which makes a more relevant metric but also the more challenging one. Second is the issue of how to represent and combine the plethora of user activities such as search queries, page views, ad clicks to perform the targeting. We investigate several sources of user activities as well as methods for inferring conversion likelihood given the activities. We also explore the role played by the temporal aspect of user activities for targeting, e.g., how recent activities compare to the old ones. Based on a rigorous offline empirical evaluation over 200 individual advertising campaigns, we arrive at what we believe are best practices for behavioral targeting. We deploy our approach over live user traffic to demonstrate its superiority over existing state-of-the-art targeting methods.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
MRI: Meaningful Interpretations of Collaborative Ratings
VLDB (2011)
[u'Mahashweta Das', u'Sihem Amer-Yahia', u'Gautam Das', u'Cong Yu']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Personalized Social Recommendations - Accurate or Private?
Very Large Data Bases (VLDB) (2011)
[u'Ashwin Machanavajjhala', u'Aleksandra Korolova', u'Atish Das Sarma']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Stanford's Distantly-Supervised Slot-Filling System
Fourth Text Analysis Conference (TAC 2011)
[u'Mihai Surdeanu', u'Sonal Gupta', u'John Bauer', u'David McClosky', u'Angel X. Chang', u'Valentin I. Spitkovsky', u'Christopher D. Manning']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Stanford-UBC Entity Linking at TAC-KBP, Again
Fourth Text Analysis Conference (TAC 2011)
[u'Angel X. Chang', u'Valentin I. Spitkovsky', u'Eneko Agirre', u'Christopher D. Manning']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Strong Baselines for Cross-Lingual Entity Linking
Fourth Text Analysis Conference (TAC 2011)
[u'Angel X. Chang', u'Valentin I. Spitkovsky']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37120.html
found
=========================
Suggesting (More) Friends Using the Implicit Social Graph
International Conference on Machine Learning (ICML) (2011)
[u'Maayan Roth', u'Tzvika Barenholz', u'Assaf Ben-David', u'David Deutscher', u'Guy Flysher', u'Avinatan Hassidim', u'Ilan Horn', u'Ari Leichtberg', u'Naty Leiser', u'Yossi Matias', u'Ron Merom']
DataMiningandModeling
Abstract: Although users of online communication tools rarely categorize their contacts into groups such as "family", "co-workers", or "jogging buddies", they nonetheless implicitly cluster contacts, by virtue of their interactions with them, forming implicit groups. In this paper, we describe the implicit social graph which is formed by users' interactions with contacts and groups of contacts, and which is distinct from explicit social graphs in which users explicitly add other individuals as their "friends". We introduce an interaction-based metric for estimating a user's affinity to his contacts and groups. We then describe a novel friend suggestion algorithm that uses a user's implicit social graph to generate a friend group, given a small seed set of contacts which the user has already labeled as friends. We show experimental results that demonstrate the importance of both implicit group relationships and interaction-based affinity ranking in suggesting friends. Finally, we discuss two applications of the Friend Suggest algorithm that have been released as Gmail features.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37218.html
found
=========================
Unary Data Structures for Language Models
Interspeech 2011, International Speech Communication Association, pp. 1425-1428
[u'Jeffrey Sorensen', u'Cyril Allauzen']
DataMiningandModeling
Abstract: Language models are important components of speech recognition and machine translation systems. Trained on billions of words, and consisting of billions of parameters, language models often are the single largest components of these systems. There have been many proposed techniques to reduce the storage requirements for language models. A technique based upon pointer-free compact storage of ordinal trees shows compression competitive with the best proposed systems, while retaining the full finite state structure, and without using computationally expensive block compression schemes or lossy quantization techniques.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Simple Distant Supervision Approach for the TAC-KBP Slot Filling Task
Third Text Analysis Conference (TAC 2010)
[u'Mihai Surdeanu', u'David McClosky', u'Julie Tibshirani', u'John Bauer', u'Angel X. Chang', u'Valentin I. Spitkovsky', u'Christopher D. Manning']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
AdHeat: An Influence-based Diffusion Model for Propagating Hints to Match Ads
Proceedings of WWW2010, IW3C2, pp. 71-80
[u'Hongji Bao', u'Edward Y. Chang']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36697.html
found
=========================
Catching a Viral Video
IEEE SIASP@ICDM 2010
[u'Tom Broxton', u'Yannet Interian', u'Jon Vaver', u'Mirjam Wattenhofer']
DataMiningandModeling
Abstract: The sharing and re-sharing of videos on social sites, blogs e-mail, and other means has given rise to the phenomenon of viral videos videos that become popular through internet sharing. In this paper we seek to better understand viral videos on YouTube by analyzing sharing and its relationship to video popularity using 1.5 million YouTube videos. The socialness of a video is quantified by classifying the referrer sources for video views as social (e.g. an emailed link) or non-social (e.g. a link from related videos). By segmenting videos according to their fraction of social views, we find that viewership patterns of highly social videos is very different than less social videos. For example, the highly social videos rise to, and fall from, their peak popularity more quickly than less social videos. We also find that not all highly social videos become popular, and not all popular videos are highly social. And, despite their ability to generate large volumes of views over a short period of time, only 21% of the most popular videos (in terms of 30-day views) can be classified as viral. The observations made here lay the ground work for future work related to the creation of classification and predictive models for online videos.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36900.html
found
=========================
Confucius and Its Intelligent Disciples: Integrating Social with Search
Proceedings of VLDB 2010, 36th International Conference on Very Large Data Bases, VLDB Endowment, pp. 1505-1516
[u'Xiance Si', u'Edward Y. Chang', u'Zoltan Gyongyi', u'Maosong Sun']
DataMiningandModeling
Abstract: Q&A sites continue to flourish as a large number of users rely on them as useful substitutes for incomplete or missing search results. In this paper, we present our experience with developing Confucius, a Google Q&A service launched in 21 countries and four languages by the end of 2009. Confucius employs six data mining subroutines to harness synergy between web search and social networks. We present these subroutines design goals, algorithms, and their effects on service quality. We also describe techniques for and experience with scaling the subroutines to mine massive data sets.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36587.html
found
=========================
Improved classification through runoff elections
Proceedings of the 9th IAPR International Workshop on Document Analysis Systems, ACM, Boston (2010), pp. 59-64
[u'Oleg Golubitsky', u'Stephen M. Watt']
DataMiningandModeling
Abstract: We consider the problem of dealing with irrelevant votes when a multi-case classifier is built from an ensemble of binary classifiers. We show how run-off elections can be used to limit the effects of irrelevant votes and the occasional errors of binary classifiers, improving classification accuracy. We consider as a concrete classification problem the recognition of handwritten mathematical characters. A succinct representation of handwritten symbol curves can be obtained by computing truncated Legendre-Sobolev expansions of the coordinate functions. With this representation, symbol classes are well linearly separable in low dimension which yields fast classification algorithms based on linear support vector machines. A set of 280 different symbols was considered, which gave 1635 classes when different variants are labelled separately. With this number of classes, however, the effect of irrelevant classifiers becomes significant, often causing the correct class to be ranked lower. We introduce a general technique to correct this effect by replacing the conventional majority voting scheme with a runoff election scheme. We have found that such runoff elections further cut the top-1 mis-classification rate by about half.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36759.html
found
=========================
Mining Arabic Business Reviews
IEEE, pp. 1108-1113
[u'Mohamed Elhawary', u'Mohamed Elfeky']
DataMiningandModeling
Abstract: For languages with rich content over the web, business reviews are easily accessible via many known websites, e.g., Yelp.com. For languages with poor content over the web like Arabic, there are very few websites (we are actually aware of only one that is indeed unpopular) that provide business reviews. However, this does not mean that such reviews do not exist. They indeed exist unstructured in websites not originally intended for reviews, e.g., Forums and Blogs. Hence, there is a need to mine for those Arabic reviews from the web in order to provide them in the search results when a user searches for a business or a category of businesses. In this paper, we show how to extract the business reviews scattered on the web written in the Arabic language. The mined reviews are analyzed to also provide their sentiments (positive, negative or neutral). This way, we provide our users the information they need about the local businesses in the language they understand, and therefore provide a better search experience for the Middle East region, which mostly speaks Arabic.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Mining advertiser-specific user behavior using adfactors
WWW (2010), pp. 31-40
[u'Nikolay Archak', u'Vahab S. Mirrokni', u'S. Muthukrishnan']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36500.html
found
=========================
Overlapping Experiment Infrastructure: More, Better, Faster Experimentation
Proceedings 16th Conference on Knowledge Discovery and Data Mining, ACM, Washington, DC (2010), pp. 17-26
[u'Diane Tang', u'Ashish Agarwal', u"Deirdre O'Brien", u'Mike Meyer']
DataMiningandModeling
Abstract: At Google, experimentation is practically a mantra; we evaluate almost every change that potentially affects what our users experience. Such changes include not only obvious user-visible changes such as modifications to a user interface, but also more subtle changes such as different machine learning algorithms that might affect ranking or content selection. Our insatiable appetite for experimentation has led us to tackle the problems of how to run more experiments, how to run experiments that produce better decisions, and how to run them faster. In this paper, we describe Googles overlapping experiment infrastructure that is a key component to solving these problems. In addition, because an experiment infrastructure alone is insufficient, we also discuss the associated tools and educational processes required to use it effectively. We conclude by describing trends that show the success of this overall experimental environment. While the paper specifically describes the experiment system and experimental processes we have in place at Google, we believe they can be generalized and applied by any entity interested in using experimentation to improve search engines and other web applications. The presentation is available online.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
PSVM: Parallel Support Vector Machines with Incomplete Cholesky Factorization
Scaling Up Machine Learning, Cambridge University Press (2010)
[u'Edward Y. Chang', u'Hongjie Bai', u'Kaihua Zhu', u'Hao Wang', u'Jian Li', u'Zhihuan Qiu']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Stanford-UBC Entity Linking at TAC-KBP
Third Text Analysis Conference (TAC 2010)
[u'Angel X. Chang', u'Valentin I. Spitkovsky', u'Eric Yeh', u'Eneko Agirre', u'Christopher D. Manning']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Ad Quality On TV: Predicting Television Audience Retention
Proceedings of ADKDD (2009)
[u'Yannet Interian', u'Sundar Dorai-Raj', u'Igor Naverniouk', u'P. J. Opalinski', u'Kaustuv', u'Dan Zigmond']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
An incentive-based architecture for social recommendations
RecSys '09: Proceedings of the third ACM conference on Recommender systems, ACM, New York, NY, USA (2009), pp. 229-232
[u'Rajat Bhattacharjee', u'Ashish Goel', u'Konstantinos Kollias']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35270.html
found
=========================
Collaborative Filtering for Orkut Communities: Discovery of User Latent Behavior
18th International Conference on World Wide Web (WWW), ACM (2009), pp. 681-690
[u'Wen-Yen Chen', u'Jon Chu', u'Junyi Luan', u'Hongjie Bai', u'Edward Chang']
DataMiningandModeling
Abstract: Users of social networking services can connect with each other by forming communities for online interaction. Yet as the number of communities hosted by such websites grows over time, users have even greater need for effective community recommendations in order to meet more users. In this paper, we investigate two algorithms from very different domains and evaluate their effectiveness for personalized community recommendation. First is association rule mining (ARM), which discovers associations between sets of communities that are shared across many users. Second is latent Dirichlet allocation (LDA), which models user-community co-occurrences using latent aspects. In comparing LDA with ARM, we are interested in discovering whether modeling low-rank latent structure is more effective for recommendations than directly mining rules from the observed data. We experiment on an Orkut data set consisting of 492,104 users and 118,002 communities. We show that LDA consistently performs better than ARM using the top-k recommendations ranking metric, and we analyze examples of the latent information learned by LDA to explain this finding. To efficiently handle the large-scale data set, we parallelize LDA on distributed computers and demonstrate our parallel implementation's scalability with varying numbers of machines.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35252.html
found
=========================
Computers and iPhones and Mobile Phones, oh my! A logs-based comparison of search users on different devices
WWW 2009 MADRID, pp. 801-810
[u'Maryam Kamvar', u'Melanie Kellar', u'Rajan Patel', u'Ya Xu']
DataMiningandModeling
Abstract: We present a logs-based comparison of search patterns across three platforms: computers, iPhones and conventional mobile phones. Our goal is to understand how mobile search users differ from computer-based search users, and we focus heavily on the distribution and variability of tasks that users perform from each platform. The results suggest that search usage is much more focused for the average mobile user than for the average computer-based user. However, search behavior on high-end phones resembles computer-based search behavior more so than mobile search behavior. A wide variety of implications follow from these findings. First, there is no single search interface which is suitable for all mobile phones. We suggest that for the higher-end phones, a close integration with the standard computer-based interface (in terms of personalization and available feature set) would be beneficial for the user, since these phones seem to be treated as an extension of the users' computer. For all other phones, there is a huge opportunity for personalizing the search experience for the user's "mobile needs", as these users are likely to repeatedly search for a single type of information need on their phone.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Do Viewers Care? Understanding the impact of ad creatives on TV viewing behavior
Re:Think 2009
[u'Yannet Interian', u'Kaustuv', u'Igor Naverniouk', u'P. J. Opalinski', u'Sundar Dorai-raj', u'Dan Zigmond']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Efficient Clustering of Web-Derived Data Sets
MLDM '09: Proceedings of the 6th International Conference on Machine Learning and Data Mining in Pattern Recognition, Springer-Verlag, Berlin, Heidelberg (2009), pp. 398-412
[u'Lus Sarmento', u'Alexander Kehlenbeck', u'Eugnio C. Oliveira', u'Lyle Ungar']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Finding topic trends in digital libraries
JCDL '09: Proceedings of the 9th ACM/IEEE-CS joint conference on Digital libraries, ACM, New York, NY, USA (2009), pp. 69-72
[u'Levent Bolelli', u'Seyda Ertekin', u'Ding Zhou', u'C. Lee Giles']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Going Mini: Extreme Lightweight Spam Filters
CEAS 2009: Proceedings of the Sixth Conference on Email and Anti-Spam
[u'D. Sculley', u'Gordon V. Cormack']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
On the Predictability of Search Trends (manuscript)
Google (2009)
[u'Yair Shimshoni', u'Niv Efron', u'Yossi Matias']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36296.html
found
=========================
PLANET: Massively Parallel Learning of Tree Ensembles with MapReduce
Proceedings of the 35th International Conference on Very Large Data Bases (VLDB-2009)
[u'Biswanath Panda', u'Joshua S. Herbach', u'Sugato Basu', u'Roberto J. Bayardo']
DataMiningandModeling
Abstract: Classification and regression tree learning on massive datasets is a common data mining task at Google, yet many state of the art tree learning algorithms require training data to reside in memory on a single machine. While more scalable implementations of tree learning have been proposed, they typically require specialized parallel computing architectures. In contrast, the majority of Googles computing infrastructure is based on commodity hardware. In this paper, we describe PLANET: a scalable distributed framework for learning tree models over large datasets. PLANET defines tree learning as a series of distributed computations, and implements each one using the MapReduce model of distributed computation. We show how this framework supports scalable construction of classification and regression trees, as well as ensembles of such models. We discuss the benefits and challenges of using a MapReduce compute cluster for tree learning, and demonstrate the scalability of this approach by applying it to a real world learning task from the domain of computational advertising.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Parallel community detection on large networks with propinquity dynamics
KDD '09: Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining, ACM, New York, NY, USA (2009), pp. 997-1006
[u'Yuzhou Zhang', u'Jianyong Wang', u'Yi Wang', u'Lizhu Zhou']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Predicting Bounce Rates in Sponsored Search Advertisements
Proc. of the 15th International ACM-SIGKDD Conference on Knowledge Discovery and Data Mining, ACM (2009), pp. 1325-1334
[u'D. Sculley', u'Robert Malkin', u'Sugato Basu', u'Roberto J. Bayardo']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Preference aggregation in group recommender systems for committee decision-making
RecSys '09: Proceedings of the third ACM conference on Recommender systems, ACM, New York, NY, USA (2009), pp. 337-340
[u'Jacob P. Baskin', u'Shriram Krishnamurthi']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Pricing Guidance in Ad Sale Negotiations: The Print Ads Example
The Third Annual International Workshop on Data Mining and Audience Intelligence for Advertising (2009)
[u'Adam Juda', u'S. N. Muthukrishnan', u'Ashish Rastogi']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Rating aggregation in collaborative filtering systems
RecSys '09: Proceedings of the third ACM conference on Recommender systems, ACM, New York, NY, USA (2009), pp. 349-352
[u'Florent Garcin', u'Boi Faltings', u'Radu Jurca', u'Nadine Joswig']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34460.html
found
=========================
Scalable Attribute-Value Extraction from Semi-Structured Text
ICDM Workshop on Large-scale Data Mining: Theory and Applications (2009)
[u'Yuk Wah Wong', u'Dominic Widdows', u'Tom Lokovic', u'Kamal Nigam']
DataMiningandModeling
Abstract: This paper describes a general methodology for extracting attribute-value pairs from web pages. It consists of two phases: candidate generation, in which syntactically likely attribute-value pairs are annotated; and candidate filtering, in which semantically improbable annotations are removed. We describe three types of candidate generators and two types of candidate filters, all of which are designed to be massively parallelizable. Our methods can handle 1 billion web pages in less than 6 hours with 1,000 machines. The best generator and filter combination achieves 70% F-measure compared to a hand-annotated corpus.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Stanford-UBC at TAC-KBP
Second Text Analysis Conference (TAC 2009)
[u'Eneko Agirre', u'Angel X. Chang', u'Daniel S. Jurafsky', u'Christopher D. Manning', u'Valentin I. Spitkovsky', u'Eric Yeh']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35519.html
found
=========================
Succinct approximate counting of skewed data
IJCAI-09 Proceedings (2009), pp. 1243-1248
[u'David Talbot']
DataMiningandModeling
Abstract: Practical data analysis relies on the ability to count observations of objects succinctly and efficiently. Unfortunately the space usage of an exact estimator grows with the size of the a priori set from which objects are drawn while the time required to maintain such an estimator grows with the size of the data set. We present static and on-line approximation schemes that avoid these limitations when approximate frequency estimates are acceptable. Our Log-Frequency Sketch extends the approximate counting algorithm of Morris [1978] to estimate frequencies with bounded relative error via a single pass over a data set. It uses constant space per object when the frequencies follow a power law and can be maintained in constant time per observation. We give an (,)-approximation scheme which we verify empirically on a large natural language data set where, for instance, 95 percent of frequencies are estimated with relative error less than 0.25 using fewer than 11 bits per object in the static case and 15 bits per object on-line.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Text Classification Through Time: Efficient Label Propagation in Time-Based Graphs
International Conference on Knowledge Discovery and Information Retrieval (2009)
[u'Shumeet Baluja', u'Deepak Ravichandran', u'D. Sivakumar']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
The Unreasonable Effectiveness of Data
IEEE Intelligent Systems, vol. 24 (2009), pp. 8-12
[u'Alon Halevy', u'Peter Norvig', u'Fernando Pereira']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Tour the world: a technical demonstration of a web-scale landmark recognition engine
MM '09: Proceedings of the seventeen ACM international conference on Multimedia, ACM, New York, NY, USA (2009), pp. 961-962
[u'Yan-Tao Zheng', u'Ming Zhao', u'Yang Song', u'Hartwig Adam', u'Ulrich Buddemeier', u'Alessandro Bissacco', u'Fernando Brucher', u'Tat-Seng Chua', u'Hartmut Neven', u'Jay Yagnik']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35638.html
found
=========================
Video2Text: Learning to Annotate Video Content
ICDM Workshop on Internet Multimedia Mining (2009)
[u'Hrishikesh Aradhye', u'George Toderici', u'Jay Yagnik']
DataMiningandModeling
Abstract: This paper discusses a new method for automatic discovery and organization of descriptive concepts (labels) within large real-world corpora of user-uploaded multimedia, such as YouTube.com. Conversely, it also provides validation of existing labels, if any. While training, our method does not assume any explicit manual annotation other than the weak labels already available in the form of video title, descrip- tion, and tags. Prior work related to such auto-annotation assumed that a vocabulary of labels of interest (e.g., indoor, outdoor, city, landscape) is specied a priori. In contrast, the proposed method begins with an empty vocabulary. It analyzes audiovisual features of 25 million YouTube.com videos nearly 150 years of video data effectively searching for consistent correlation between these features and text metadata. It autonomously extends the label vocabulary as and when it discovers concepts it can reliably identify, eventually leading to a vocabulary with thousands of labels and growing. We believe that this work signicantly extends the state of the art in multimedia data mining, discovery, and organization based on the technical merit of the proposed ideas as well as the enormous scale of the mining exercise in a very challenging, unconstrained, noisy domain.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Social Query Model for Decentralized Search
Second ACM Workshop on Social Network Mining and Analysis at the KDD Conference (SNAKDD-08) (2008)
[u'Arindam Banerjee', u'Sugato Basu']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Bootstrapping Information Extraction from Semi-structured Web Pages
ECML/PKDD, Springer Lecture Notes in Computer Science Volume 5211/2008 (2008), pp. 16
[u'Andrew Carlson', u'Charles Schafer']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Constrained Clustering: Advances in Algorithms, Theory, and Applications
CRC Press (2008)
[u'Sugato Basu', u'Ian Davidson', u'Kiri Wagstaff']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Detecting Image Spam using Visual Features and Near Duplicate Detection
Proceedings of WWW 2008
[u'Bhaskar Mehta', u'Saurabh Nangia', u'Manish Gupta', u'Wolgang Nejdl']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Efficient Concept Clustering for Ontology Learning using an Event Life Cycle on the Web
Proc. 2008 ACM SYmposium on Applied Computing, ACM, Fortaleza, Brazil, pp. 2310-2314
[u'Sangsoo Sung', u'Seokkyung Chung', u'Dennis McLeod']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Exploring a Digital Library Through Key Ideas
JCDL, Pittsburgh, Pennsylvania, USA (2008), pp. 177-186
[u'Bill N. Schilit', u'Okan Kolak']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Extreme Data Mining
Proceedings 2008 ACM SIGMOD International Conference on Management of Data, ACM, Vancouver, pp. 1-2
[u'Sridhar Ramaswamy']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Modeling Online Reviews with Multi-Grain Topic Models
17th International World Wide Web Conference (2008)
[u'Ivan Titov', u'Ryan McDonald']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
PFP: Parallel FP-Growth for Query Recommendation
ACM Recommendation Systems (2008) (to appear)
[u'Haoyuan Li', u'Yi Wang', u'Dong Zhang', u'Edward Chang', u'Ming Zhang']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Video Suggestion and Discovery for YouTube: Taking Random Walks Through the View Graph
WWW-2008
[u'Shumeet Baluja', u'Rohan Seth', u'D. Sivakumar', u'Yushi Jing', u'Jay Yagnik', u'Shankar Kumar', u'Deepak Ravichandran', u'Mohamed Aly']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34327.html
found
=========================
A Support Vector Approach to Censored Targets
Seventh IEEE International Conference on Data Mining (ICDM) (2007), pp. 655-660
[u'Pannagadatta Shivaswamy', u'Wei Chu', u'Martin Jansche']
DataMiningandModeling
Abstract: Censored targets, such as the time to events in survival analysis, can generally be represented by intervals on the real line. In this paper, we propose a novel support vector technique (named SVCR) for regression on censored targets. SVCR inherits the strengths of support vector methods, such as a globally optimal solution by convex programming, fast training speed and strong generalization capacity. In contrast to ranking approaches to survival analysis, our approach is able not only to achieve superior ordering performance, but also to predict the survival time very well. Experiments show a significant performance improvement when the majority of the training data is censored. Experimental results on several survival analysis datasets demonstrate that SVCR is very competitive against classical survival analysis models.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Clustering Billions of Images with Large Scale Nearest Neighbor Search
IEEE Workshop on Applications of Computer Vision, IEEE (2007)
[u'Ting Liu', u'Chuck Rosenberg', u'Henry A. Rowley']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Google Book Search: Document Understanding on a Massive Scale
PROC. ninth International Conference on Document Analysis and Recognition (ICDAR), IEEE Computer Society, Washington, DC (2007), pp. 819-823
[u'L. Vincent']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Mining API patterns as partial orders from source code: from usage scenarios to specifications
Proc. ACM SIGSOFT Symposium on The Foundations of Software Engineering, ACM, Dubrovnik, Croatia (2007), pp. 25-34
[u'Mithun Acharya', u'Tao Xie', u'Jian Pei', u'Jun Xu']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Relational Clustering by Symmetric Convex Coding
Proc. 24th ICML, ACM, Corvalis (2007), pp. 569-576
[u'Bo Long', u'Zhongfei (Mark) Zhang', u'Xiaoyun Wu', u'Philip S. Yu']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Scaling Up All Pairs Similarity Search
Proc. of the 16th Int'l Conf. on the World Wide Web (2007)
[u'Roberto Bayardo', u'Yiming Ma', u'Ramakrishnan Srikant']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Cluster Ranking with an Application to Mining Mailbox Networks
ICDM (2006), pp. 63-74
[u'Ziv Bar-Yossef', u'Ido Guy', u'Ronny Lempel', u'Yoelle S. Maarek', u'Vladimir Soroka']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Dense Subgraph Extraction
in: Mining Graph Data, John Wiley & Sons (2006), pp. 411-441
[u'David Gibson', u'Ravi Kumar', u'Kevin S. McCurley', u'Andrew Tomkins']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Mining for proposal reviewers: lessons learned at the national science foundation
Proc. 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, ACM, Philadelphia, PA (2006), pp. 862-871
[u'Seth Hettich', u'Michael J. Pazzani']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Mining the Web to Determine Similarity Between Words, Objects, and Communities
Proceedings of the 19th International FLAIRS Conference (FLAIRS-2006)
[u'Mehran Sahami']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
New cached-sufficient statistics algorithms for quickly answering statistical questions
Proc. 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, ACM, Philadelphia, PA (2006), pp. 2
[u'Andrew Moore']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36677.html
found
=========================
STAGGER: Periodicity Mining of Data Streams Using Expanding Sliding Windows
Proceedings of the 6th IEEE International Conference on Data Mining (ICDM 2006), IEEE Computer Society, pp. 188-199
[u'Mohamed G. Elfeky', u'Walid G. Aref', u'Ahmed K. Elmagarmid']
DataMiningandModeling
Abstract: Sensor devices are becoming ubiquitous, especially in measurement and monitoring applications. Because of the real-time, append-only and semi-infinite natures of the generated sensor data streams, an online incremental approach is a necessity for mining stream data types. In this paper, we propose STAGGER: a one-pass, online and incremental algorithm for mining periodic patterns in data streams. STAGGER does not require that the user pre-specify the periodicity rate of the data. Instead, STAGGER discovers the potential periodicity rates. STAGGER maintains multiple expanding sliding windows staggered over the stream, where computations are shared among the multiple overlapping windows. Small-length sliding windows are imperative for early and real-time output, yet are limited to discover short periodicity rates. As streamed data arrives continuously, the sliding windows expand in length in order to cover the whole stream. Larger-length sliding windows are able to discover longer periodicity rates. STAGGER incrementally maintains a tree-like data structure for the frequent periodic patterns of each discovered potential periodicity rate. In contrast to the Fourier/Wavelet-based approaches used for discovering periodicity rates, STAGGER not only discovers a wider, more accurate set of periodicities, but also discovers the periodic patterns themselves. In fact, experimental results with real and synthetic data sets show that STAGGER outperforms Fourier/Wavelet-based approaches by an order of magnitude in terms of the accuracy of the discovered periodicity rates. Moreover, realdata experiments demonstrate the practicality of the discovered periodic patterns.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Adaptive Product Normalization: Using Online Learning for Record Linkage in Comparison Shopping
Proceedings of the 5th IEEE International Conference on Data Mining (2005), pp. 58-65
[u'Mikhail Bilenko', u'Sugato Basu', u'Mehran Sahami']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Evaluating similarity measures: a large-scale study in the orkut social network
Proceedings of the Eleventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD-2005), pp. 678-684
[u'Ellen Spertus', u'Mehran Sahami', u'Orkut Buyukkokten']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Unweaving a web of documents
KDD (2005), pp. 574-579
[u'R. Guha', u'Ravi Kumar', u'D. Sivakumar', u'Ravi Sundaram']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A social network caught in the Web
First Monday, vol. 8 (2003)
[u'Lada A. Adamic', u'Orkut Buyukkokten', u'Eytan Adar']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Mining Optimized Gain Rules for Numeric Attributes
IEEE Trans. Knowl. Data Eng., vol. 15 (2003), pp. 324-338
[u'Sergey Brin', u'Rajeev Rastogi', u'Kyuseok Shim']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Extracting Patterns and Relations from the World Wide Web
WebDB (1998), pp. 172-183
[u'Sergey Brin']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Scalable Techniques for Mining Causal Structures
VLDB (1998), pp. 594-605
[u'Craig Silverstein', u'Sergey Brin', u'Rajeev Motwani', u'Jeffrey D. Ullman']
DataMiningandModeling
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/DistributedSystemsandParallelComputing.html
found
http://research.google.com/pubs/pub44315.html
found
=========================
Distributed Balanced Partitioning via Linear Embedding
WSDM 2016: Ninth ACM International Conference on Web Search and Data Mining, ACM (to appear)
[u'Kevin Aydin', u'Mohammadhossein Bateni', u'Vahab Mirrokni']
DistributedSystemsandParallelComputing
Abstract: Balanced partitioning is often a crucial first step in solving large-scale graph optimization problems: in some cases, a big graph is chopped into pieces that fit on one machine to be processed independently before stitching the results together, leading to certain suboptimality from the interaction among different pieces. In other cases, links between different parts may show up in the running time and/or network communications cost, hence the desire to have small cut size. We study a distributed balanced partitioning problem where the goal is to partition the vertices of a given graph into k pieces, minimizing the total cut size. Our algorithm is composed of a few steps that are easily implementable in distributed computation frameworks, e.g., MapReduce. The algorithm first embeds nodes of the graph onto a line, and then processes nodes in a distributed manner guided by the linear embedding order. We examine various ways to find the first embedding, e.g., via a hierarchical clustering or Hilbert curves. Then we apply four different techniques such as local swaps, minimum cuts on partition boundaries, as well as contraction and dynamic programming. Our empirical study compares the above techniques with each other, and to previous work in distributed algorithms, e.g., a label propagation method [34], FENNEL [32] and Spinner [23]. We report our results both on a private map graph and several public social networks, and show that our results beat previous distributed algorithms: we notice, e.g., 15-25% reduction in cut size over [34]. We also observe that our algorithms allow for scalable distributed implementation for any number of partitions. Finally, we apply our techniques for the Google Maps Driving Directions to minimize the number of multi-shard queries with the goal of saving in CPU usage. During live experiments, we observe an 40% drop in the number of multi-shard queries when comparing our method with a standard geography-based method.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Can Traditional Programming Bridge the Ninja Performance Gap for Parallel Computing Applications?
Communications of the ACM, vol. 58 (2015), pp. 77-86
[u'Nadathur Satish', u'Changkyu Kim', u'Jatin Chhugani', u'Hideki Saito', u'Rakesh Krishnaiyer', u'Mikhail Smelyanskiy', u'Milind Girkar', u'Pradeep Dubey']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43876.html
found
=========================
Computing weak consistency in polynomial time
Proceedings of the 2015 ACM Symposium on Principles of Distributed Computing, ACM, New York, NY, USA, pp. 395-404
[u'Wojciech Golab', u'Xiaozhou (Steve) Li', u'Alejandro Lpez-Ortiz', u'Naomi Nishimura']
DistributedSystemsandParallelComputing
Abstract: The k-atomicity property can be used to describe the consistency of data operations in large distributed storage systems. The weak consistency guarantees offered by such systems are seen as a necessary compromise in view of Brewer's CAP principle. The k-atomicity property requires that every read operation obtains a value that is at most k updates (writes) old, and becomes a useful way to quantify weak consistency if k is treated as a variable that can be computed from a history of operations. Specifically, the value of k quantifies how far the history deviates from Lamport's atomicity property for read/write registers. We address the problem of computing k indirectly by solving the k-atomicity verification problem (k-AV): given a history of read/write operations and a positive integer k, decide whether the history is k-atomic. Gibbons and Korach showed that in general this problem is NP-complete when k = 1, and hence not solvable in polynomial time unless P = NP. In this paper we present two algorithms that solve the k-AV problem for any k >= 2 in special cases. Similarly to known solutions for k = 1 and k = 2, both algorithms assume that all the values written to a given object are distinct. The first algorithm places an additional restriction on the structure of the input history and solves k-AV in O(n^2 + n (k log k) time. The second algorithm does not place any additional restrictions on the input but is efficient only when k is small and when concurrency among write operations is limited. Its time complexity is O(n^2) if both k and our particular measure of write concurrency are bounded by constants.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43790.html
found
=========================
Continuous Pipelines at Google
SRECon Europe 2015, USENIX, Dublin, Ireland, pp. 12
[u'Dan Dennison']
DistributedSystemsandParallelComputing
Abstract: This article focuses on the real life challenges of managing data processing pipelines of depth and complexity. It considers the frequency continuum between periodic pipelines that run very infrequently through continuous pipelines that never stop running, and discusses the discontinuities that can produce significant operational problems. A fresh take on the masterslave model is presented as a more reliable and better scaling alternative to the periodic pipeline for processing Big Data.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43886.html
found
=========================
Dynamic iSCSI at Scale: Remote Paging at Google
Linux Plumbers Conference 2015
[u'Nick Black']
DistributedSystemsandParallelComputing
Abstract: Google is experimenting with remotely mounting jobs binaries and data packages. Each package is served as an ext4 filesystem atop an iSCSI-mounted block device fed through dm-multipath and dm-verity. A typical job might run on O(1K) machines, employing a N-to-1 multipath configuration yielding O(10K) short-lived iSCSI sessions. Google thus sees O(100K) iSCSI sessions set up and torn down every minute, a rather atypical iSCSI deployment. We will explore the challenges presented by this deployment at scale.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44310.html
found
=========================
Federated Optimization: Distributed Optimization Beyond the Datacenter
NIPS Optimization for Machine Learning Workshop (2015), pp. 5
[u'Jakub Konen', u'H. Brendan McMahan', u'Daniel Ramage']
DistributedSystemsandParallelComputing
Abstract: We introduce a new and increasingly relevant setting for distributed optimization in machine learning, where the data defining the optimization are distributed (unevenly) over an extremely large number of nodes, but the goal remains to train a high-quality centralized model. We refer to this setting as Federated Optimization. In this setting, communication efficiency is of utmost importance. A motivating example for federated optimization arises when we keep the training data locally on users' mobile devices rather than logging it to a data center for training. Instead, the mobile devices are used as nodes performing computation on their local data in order to update a global model. We suppose that we have an extremely large number of devices in our network, each of which has only a tiny fraction of data available totally; in particular, we expect the number of data points available locally to be much smaller than the number of devices. Additionally, since different users generate data with different patterns, we assume that no device has a representative sample of the overall distribution. We show that existing algorithms are not suitable for this setting, and propose a new algorithm which shows encouraging experimental results. This work also sets a path for future research needed in the context of federated optimization.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Heracles: Improving Resource Efficiency at Scale
Proceedings of the 42th Annual International Symposium on Computer Architecture (2015)
[u'David Lo', u'Liqun Cheng', u'Rama Govindaraju', u'Parthasarathy Ranganathan', u'Christos Kozyrakis']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43826.html
found
=========================
Kubernetes - Scheduling the Future at Cloud Scale
O'Reilly and Associates, 1005 Gravenstein Highway North Sebastopol, CA 95472, All
[u'David K. Rensin']
DistributedSystemsandParallelComputing
Abstract: Containers are taking over the world, but they arent full VMs and present special challenges to people build web-scale services. They need a lot of orchestration to run efficiently and resiliently. Their execution needs to be scheduled and managed. When they die (and they do), they need to be seamlessly replaced and re-balanced. An introductory mini-book designed to explain Kubernetes to IT managers, CIOs, and the otherwise cloud-curious.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43438.html
found
=========================
Large-scale cluster management at Google with Borg
Proceedings of the European Conference on Computer Systems (EuroSys), ACM, Bordeaux, France (2015)
[u'Abhishek Verma', u'Luis Pedrosa', u'Madhukar R. Korupolu', u'David Oppenheimer', u'Eric Tune', u'John Wilkes']
DistributedSystemsandParallelComputing
Abstract: Google's Borg system is a cluster manager that runs hundreds of thousands of jobs, from many thousands of different applications, across a number of clusters each with up to tens of thousands of machines. It achieves high utilization by combining admission control, efficient task-packing, over-commitment, and machine sharing with process-level performance isolation. It supports high-availability applications with runtime features that minimize fault-recovery time, and scheduling policies that reduce the probability of correlated failures. Borg simplifies life for its users by offering a declarative job specification language, name service integration, real-time job monitoring, and tools to analyze and simulate system behavior. We present a summary of the Borg system architecture and features, important design decisions, a quantitative analysis of some of its policy decisions, and a qualitative examination of lessons learned from a decade of operational experience with it.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44001.html
found
=========================
Poster Paper: Automatic Reconfiguration of Distributed Storage
The 12th International Conference on Autonomic Computing, IEEE (2015), pp. 133-134
[u'Artyom Sharov', u'Alexander Shraer', u'Arif Merchant', u'Murray Stokely']
DistributedSystemsandParallelComputing
Abstract: The configuration of a distributed storage system with multiple data replicas typically includes the set of servers and their roles in the replication protocol. The configuration can usually be changed manually, but in most cases, system administrators have to determine a good configuration by trial and error. We describe a new workload-driven optimization framework that dynamically determines the optimal configuration at run time. Applying the framework to a large-scale distributed storage system used internally in Google resulted in halving the operation latency in 17% of the tested databases, and reducing it by more than 90% in some cases.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43822.html
found
=========================
RFC7535 - AS112 Redirection Using DNAME
IETF RFCs, Internet Engineering Task Force (2015), pp. 16
[u'Warren Kumari', u'Joe Abley', u'Brian Dickson', u'George Michaelson']
DistributedSystemsandParallelComputing
Abstract: AS112 provides a mechanism for handling reverse lookups on IP addresses that are not unique (e.g., RFC 1918 addresses). This document describes modifications to the deployment and use of AS112 infrastructure that will allow zones to be added and dropped much more easily, using DNAME resource records. This approach makes it possible for any DNS zone administrator to sink traffic relating to parts of the global DNS namespace under their control to the AS112 infrastructure without coordination with the operators of AS112 infrastructure.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44314.html
found
=========================
RFC7706 - Decreasing Access Time to Root Servers by Running One on Loopback
IETF RFCs, Internet Engineering Task Force (2015), pp. 12
[u'Warren Kumari', u'Paul Hoffman']
DistributedSystemsandParallelComputing
Abstract: Some DNS recursive resolvers have longer-than-desired round-trip times to the closest DNS root server. Some DNS recursive resolver operators want to prevent snooping of requests sent to DNS root servers by third parties. Such resolvers can greatly decrease the round-trip time and prevent observation of requests by running a copy of the full root zone on a loopback address (such as 127.0.0.1). This document shows how to start and maintain such a copy of the root zone that does not pose a threat to other users of the DNS, at the cost of adding some operational fragility for the operator.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43974.html
found
=========================
RSSAC003 - RSSAC Report on Root Zone TTLs
ICANN Root Server System Advisory Committee ( RSSAC ) Reports and Advisories, Internet Corporation for Assigned Names and Numbers (ICANN) (2015), pp. 35
[u'Warren Kumari']
DistributedSystemsandParallelComputing
Abstract: Root zone TTLs have not changed since 1999. In this report, the RSSAC Caucus studies the extent to which the current root zone TTLs are still appropriate for todays Internet environment. Selecting a TTL for a given resource record involves finding the right balance between a few tradeoffs. Intuitively, shorter TTLs are beneficial for data that changes frequently, whereas longer TTLs are beneficial for data that is relatively stable. Related to this, longer TTLs provide robustness in the event of operational failures. All other things being equal, and assuming software involved in queries and responses follow the DNS protocol standards, shorter TTLs generally result in higher query rates, and longer TTLs result in lower query rates.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43999.html
found
=========================
Take me to your leader! Online Optimization of Distributed Storage Configurations
Proceedings of the 41st International Conference on Very Large Data Bases, VLDB Endowment (2015), pp. 1490-1501
[u'Artyom Sharov', u'Alexander Shraer', u'Arif Merchant', u'Murray Stokely']
DistributedSystemsandParallelComputing
Abstract: The configuration of a distributed storage system typically includes, among other parameters, the set of servers and their roles in the replication protocol. Although mechanisms for changing the configuration at runtime exist, it is usually left to system administrators to manually determine the best configuration and periodically reconfigure the system, often by trial and error. This paper describes a new workload-driven optimization framework that dynamically determines the optimal configuration at runtime. We focus on optimizing leader and quorum based replication schemes and divide the framework into three optimization tiers, dynamically optimizing different configuration aspects: 1) leader placement, 2) roles of different servers in the replication protocol, and 3) replica locations. We showcase our optimization framework by applying it to a large-scale distributed storage system used internally in Google and demonstrate that most client applications significantly benefit from using our framework, reducing average operation latency by up to 94%.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43864.html
found
=========================
The Dataflow Model: A Practical Approach to Balancing Correctness, Latency, and Cost in Massive-Scale, Unbounded, Out-of-Order Data Processing
Proceedings of the VLDB Endowment, vol. 8 (2015), pp. 1792-1803
[u'Tyler Akidau', u'Robert Bradshaw', u'Craig Chambers', u'Slava Chernyak', u'Rafael J. Fernndez-Moctezuma', u'Reuven Lax', u'Sam McVeety', u'Daniel Mills', u'Frances Perry', u'Eric Schmidt', u'Sam Whittle']
DistributedSystemsandParallelComputing
Abstract: Unbounded, unordered, global-scale datasets are increasingly common in day-to-day business (e.g. Web logs, mobile usage statistics, and sensor networks). At the same time, consumers of these datasets have evolved sophisticated requirements, such as event-time ordering and windowing by features of the data themselves, in addition to an insatiable hunger for faster answers. Meanwhile, practicality dictates that one can never fully optimize along all dimensions of correctness, latency, and cost for these types of input. As a result, data processing practitioners are left with the quandary of how to reconcile the tensions between these seemingly competing propositions, often resulting in disparate implementations and systems. We propose that a fundamental shift of approach is necessary to deal with these evolved requirements in modern data processing. We as a field must stop trying to groom unbounded datasets into finite pools of information that eventually become complete, and instead live and breathe under the assumption that we will never know if or when we have seen all of our data, only that new data will arrive, old data may be retracted, and the only way to make this problem tractable is via principled abstractions that allow the practitioner the choice of appropriate tradeoffs along the axes of interest: correctness, latency, and cost. In this paper, we present one such approach, the Dataflow Model, along with a detailed examination of the semantics it enables, an overview of the core principles that guided its design, and a validation of the model itself via the real-world experiences that led to its development.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Timely Dataflow: A Model
FORTE (2015), pp. 131-145
[u'Martn Abadi', u'Michael Isard']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Author Retrospective for A NUCA Substrate for Flexible CMP Cache Sharing
ICS 25th Anniversary Volume, ACM SIGARCH (2014)
[u'Jaehyuk Huh', u'Changkyu Kim', u'Hazim Shafi', u'Lixin Zhang', u'Doug Burger', u'Stephen W. Keckler']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42510.html
found
=========================
Characterization of Impact of Transient Faults and Detection of Data Corruption Errors in Large-Scale N-Body Programs Using Graphics Processing Units
IEEE International Parallel and Distributed Processing Symposium (IPDPS), IEEE International Parallel and Distributed Processing Symposium (IPDPS) (2014), pp. 458-467
[u'Keun Soo Yim']
DistributedSystemsandParallelComputing
Abstract: In N-body programs, trajectories of simulated particles have chaotic patterns if errors are in the initial conditions or occur during some computation steps. It was believed that the global properties (e.g., total energy) of simulated particles are unlikely to be affected by a small number of such errors. In this paper, we present a quantitative analysis of the impact of transient faults in GPU devices on a global property of simulated particles. We experimentally show that a single-bit error in non-control data can change the final total energy of a large- scale N-body program with ~2.1% probability. We also find that the corrupted total energy values have certain biases (e.g., the values are not a normal distribution), which can be used to reduce the expected number of re-executions. In this paper, we also present a data error detection technique for N-body pro- grams by utilizing two types of properties that hold in simulated physical models. The presented technique and an existing redundancy-based technique together cover many data errors (e.g., >97.5%) with a small performance overhead (e.g., 2.3%).
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Connected Components in MapReduce and Beyond
SOCC 2014
[u'Raimondas Kiveris', u'Silvio Lattanzi', u'Vahab Mirrokni', u'Vibhor Rastogi', u'Sergei Vassilvitskii']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Coupled and k-Sided Placements: Generalizing Generalized Assignment
Integer Programming and Combinatorial Optimization (IPCO) (2014)
[u'Madhukar Korupolu', u'Adam Meyerson', u'Rajmohan Rajaraman', u'Brian Tagiku']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Diff-Index: Differentiated Index in Distributed Log-Structured Data Stores
EDBT (2014) (to appear)
[u'Wei Tan', u'Sandeep Tata', u'Yuzhe Tang', u'Liana Fong']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Distributed Balanced Clustering via Mapping Coresets
NIPS, Neural Information Processing Systems Foundation (2014)
[u'Mohammadhossein Bateni', u'Aditya Bhaskara', u'Silvio Lattanzi', u'Vahab Mirrokni']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43103.html
found
=========================
Evaluating job packing in warehouse-scale computing
IEEE Cluster, Madrid, Spain (2014)
[u'Abhishek Verma', u'Madhukar Korupolu', u'John Wilkes']
DistributedSystemsandParallelComputing
Abstract: One of the key factors in selecting a good scheduling algorithm is using an appropriate metric for comparing schedulers. But which metric should be used when evaluating schedulers for warehouse-scale (cloud) clusters, which have machines of different types and sizes, heterogeneous workloads with dependencies and constraints on task placement, and long-running services that consume a large fraction of the total resources? Traditional scheduler evaluations that focus on metrics such as queuing delay, makespan, and running time fail to capture important behaviors and ones that rely on workload synthesis and scaling often ignore important factors such as constraints. This paper explains some of the complexities and issues in evaluating warehouse scale schedulers, focusing on what we find to be the single most important aspect in practice: how well they pack long-running services into a cluster. We describe and compare four metrics for evaluating the packing efficiency of schedulers in increasing order of sophistication: aggregate utilization, hole filling, workload inflation and cluster compaction.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Eventually consistent: Not what you were expecting?
Communications of the ACM, vol. 57, no. 3 (2014), pp. 38-44
[u'Wojciech Golab', u'Muntasir R. Rahman', u'Alvin AuYoung', u'Kimberly Keeton', u'Xiaozhou (Steve) Li']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42191.html
found
=========================
From Research to Practice: Experiences Engineering a Production Metadata Database for a Scale Out File System
Proceedings of the 12th USENIX Conference on File and Storage Technologies (FAST 2014), USENIX
[u'Charles Johnson', u'Kimberly Keeton', u'Charles B. Morrey III', u'Craig A. N. Soules', u'Alistair Veitch', u'Stephen Bacon', u'Oskar Batuner', u'Marcelo Condotta', u'Hamilton Coutinho', u'Patrick J. Doyle', u'Rafael Eichelberger', u'Hugo Kiehl', u'Guilherme Magalhaes', u'James McEvoy', u'Padmanabhan Nagarajan', u'Patrick Osborne', u'Joaquim Souza', u'Andy Sparkes', u'Mike Spitzer', u'Sebastien Tandel', u'Lincoln Thomas', u'Sebastian Zangaro']
DistributedSystemsandParallelComputing
Abstract: HPs StoreAll with Express Query is a scalable commercial file archiving product that offers sophisticated file metadata management and search capabilities. A new REST API enables fast, efficient searching to find all files that meet a given set of metadata criteria and the ability to tag files with custom metadata fields. The product brings together two significant systems: a scale out file system and a metadata database based on LazyBase. In designing and building the combined product, we identified several real-world issues in using a pipelined database system in a distributed environment, and overcame several interesting design challenges that were not contemplated by the original research prototype. This paper highlights our experiences.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43017.html
found
=========================
Long-term SLOs for reclaimed cloud computing resources
ACM Symposium on Cloud Computing (SoCC), ACM, Seattle, WA, USA (2014), 20:1-20:13
[u'Marcus Carvalho', u'Walfredo Cirne', u'Franciso Brasileiro', u'John Wilkes']
DistributedSystemsandParallelComputing
Abstract: The elasticity promised by cloud computing does not come for free. Providers need to reserve resources to allow users to scale on demand, and cope with workload variations, which results in low utilization. The current response to this low utilization is to re-sell unused resources with no Service Level Objectives (SLOs) for availability. In this paper, we show how to make some of these reclaimable resources more valuable by providing strong, long-term availability SLOs for them. These SLOs are based on forecasts of how many resources will remain unused during multi-month periods, so users can do capacity planning for their long-running services. By using confidence levels for the predictions, we give service providers control over the risk of violating the availability SLOs, and allow them trade increased risk for more resources to make available. We evaluated our approach using 45 months of workload data from 6 production clusters at Google, and show that 6--17% of the resources can be re-offered with a long-term availability of 98.9% or better. A conservative analysis shows that doing so may increase the profitability of selling reclaimed resources by 22--60%.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42857.html
found
=========================
Low-Overhead Network-on-Chip Support for Location-Oblivious Task Placement
IEEE Transactions on Computers, vol. Volume 63, Issue 6 (2014), pp. 1487 - 1500
[u'Gwangsun Kim', u'Lee', u'M.M.-J.', u'John Kim', u'Dennis Abts', u'Michael R. Marty']
DistributedSystemsandParallelComputing
Abstract: Many-core processors will have many processing cores with a network-on-chip (NoC) that provides access to shared resources such as main memory and on-chip caches. However, locally-fair arbitration in multi-stage NoC can lead to globally unfair access to shared resources and impact system-level performance depending on where each task is physically placed. In this work, we propose an arbitration to provide equality-of-service (EoS) in the network and provide support for location-oblivious task placement. We propose using probabilistic arbitration combined with distance-based weights to achieve EoS and overcome the limitation of round-robin arbiter. However, the complexity of probabilistic arbitration results in high area and long latency which negatively impacts performance. In order to reduce the hardware complexity, we propose an hybrid arbiter that switches between a simple arbiter at low load and a complex arbiter at high load. The hybrid arbiter is enabled by the observation that arbitration only impacts the overall performance and global fairness at a high load. We evaluate our arbitration scheme with synthetic traffic patterns and GPGPU benchmarks. Our results shows that hybrid arbiter that combines round-robin arbiter with probabilistic distance-based arbitration reduces performance variation as task placement is varied and also improves average IPC.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41892.html
found
=========================
Macaroons: Cookies with Contextual Caveats for Decentralized Authorization in the Cloud
Network and Distributed System Security Symposium, Internet Society (2014)
[u'Arnar Birgisson', u'Joe Gibbs Politz', u'lfar Erlingsson', u'Ankur Taly', u'Michael Vrable', u'Mark Lentczner']
DistributedSystemsandParallelComputing
Abstract: Controlled sharing is fundamental to distributed systems; yet, on the Web, and in the Cloud, sharing is still based on rudimentary mechanisms. More flexible, decentralized cryptographic authorization credentials have not been adopted, largely because their mechanisms have not been incrementally deployable, simple enough, or efficient enough to implement across the relevant systems and devices. This paper introduces macaroons: flexible authorization credentials for Cloud services that support decentralized delegation between principals. Macaroons are based on a construction that uses nested, chained MACs (e.g., HMACs) in a manner that is highly efficient, easy to deploy, and widely applicable. Although macaroons are bearer credentials, like Web cookies, macaroons embed caveats that attenuate and contextually confine when, where, by who, and for what purpose a target service should authorize requests. This paper describes macaroons and motivates their design, compares them to other credential systems, such as cookies and SPKI/SDSI, evaluates and measures a prototype implementation, and discusses practical security and application considerations. In particular, it is considered how macaroons can enable more fine-grained authorization in the Cloud, e.g., by strengthening mechanisms like OAuth2, and a formalization of macaroons is given in authorization logic.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42851.html
found
=========================
Mesa: Geo-Replicated, Near Real-Time, Scalable Data Warehousing
VLDB (2014)
[u'Ashish Gupta', u'Fan Yang', u'Jason Govig', u'Adam Kirsch', u'Kelvin Chan', u'Kevin Lai', u'Shuo Wu', u'Sandeep Dhoot', u'Abhilash Kumar', u'Ankur Agiwal', u'Sanjay Bhansali', u'Mingsheng Hong', u'Jamie Cameron', u'Masood Siddiqi', u'David Jones', u'Jeff Shute', u'Andrey Gubarev', u'Shivakumar Venkataraman', u'Divyakant Agrawal']
DistributedSystemsandParallelComputing
Abstract: Mesa is a highly scalable analytic data warehousing system that stores critical measurement data related to Google's Internet advertising business. Mesa is designed to satisfy a complex and challenging set of user and systems requirements, including near real-time data ingestion and queryability, as well as high availability, reliability, fault tolerance, and scalability for large data and query volumes. Specifically, Mesa handles petabytes of data, processes millions of row updates per second, and serves billions of queries that fetch trillions of rows per day. Mesa is geo-replicated across multiple datacenters and provides consistent and repeatable query answers at low latency, even when an entire datacenter fails. This paper presents the Mesa system and reports the performance and scale that it achieves.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42899.html
found
=========================
Near-Data Processing: Insights from a MICRO-46 Workshop
IEEE Micro (Special Issue on Big Data), vol. 34 (2014), pp. 36-43
[u'Rajeev Balasubramonian', u'Jichuan Chang', u'Troy Manning', u'Jaime H. Moreno', u'Richard Murphy', u'Ravi Nair', u'Steven Swanson']
DistributedSystemsandParallelComputing
Abstract: The cost of data movement in big-data systems motivates careful examination of near-data processing (NDP) frameworks. The concept of NDP was actively researched in the 1990s, but gained little commercial traction. After a decade-long dormancy, interest in this topic has spiked. A workshop on NDP was organized at MICRO-46 and was well attended. Given the interest, the organizers and keynote speakers have attempted to capture the key insights from the workshop into an article that can be widely disseminated. This article describes the many reasons why NDP is compelling today and identifies key upcoming challenges in realizing the potential of NDP.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42948.html
found
=========================
Software Defined Networking at Scale
Light Reading (2014), pp. 22
[u'Bikash Koley']
DistributedSystemsandParallelComputing
Abstract: Software Defined Networks require Software Defined Operations. Google made great progress in SDN data and control plane. This talk discusses how we are working with the industry to transform the network management plane into a software defined framework.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43121.html
found
=========================
TRAM: Optimizing Fine-grained Communication with Topological Routing and Aggregation of Messages
International Conference on Parallel Processing (2014)
[u'Lukasz Wesolowski', u'Ramprasad Venkataraman', u'A Gupta', u'Jae-Seung Yeom', u'Keith Bisset', u'Yanhua Sun', u'Pritish Jetley', u'Thomas Quinn', u'Laxmikant Kale']
DistributedSystemsandParallelComputing
Abstract: Fine-grained communication in supercomputing applications often limits performance through high communication overhead and poor utilization of network bandwidth. This paper presents Topological Routing and Aggregation Module (TRAM), a library that optimizes fine-grained communication performance by routing and dynamically combining short messages. TRAM collects units of fine-grained communication from the application and combines them into aggregated messages with a common intermediate destination. It routes these messages along a virtual mesh topology mapped onto the physical topology of the network. TRAM improves network bandwidth utilization and reduces communication overhead. It is particularly effective in optimizing patterns with global communication and large message counts, such as all to-all and many-to-many, as well as sparse, irregular, dynamic or data dependent patterns. We demonstrate how TRAM improves performance through theoretical analysis and experimental verification using benchmarks and scientific applications. We present speedups on petascale systems of 6x for communication benchmarks and up to 4x for applications.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
The wisdom of clouds
Chemistry World, vol. 11 (2014), pp. 38
[u'Kai Kohlhoff']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41685.html
found
=========================
AGILE: elastic distributed resource scaling for Infrastructure-as-a-Service
10th International Conference on Autonomic Computing (ICAC), USENIX, San Jose, CA, USA (2013), pp. 69-82
[u'Hiep Nguyen', u'Zhiming Shen', u'Xiaohui Gu', u'Sethuraman Subbiah', u'John Wilkes']
DistributedSystemsandParallelComputing
Abstract: Dynamically adjusting the number of virtual machines (VMs) assigned to a cloud application to keep up with load changes and interference from other uses typically requires detailed application knowledge and an ability to know the future, neither of which are readily available to infrastructure service providers or application owners. The result is that systems need to be over-provisioned (costly), or risk missing their performance Service Level Objectives (SLOs) and have to pay penalties (also costly). AGILE deals with both issues: it uses wavelets to provide a medium-term resource demand prediction with enough lead time to start up new application server instances before performance falls short, and it uses dynamic VM cloning to reduce application startup times. Tests using RUBiS and Google cluster traces show that AGILE can predict varying resource demands over the medium-term with up to 3.42 better true positive rate and 0.34 the false positive rate than existing schemes. Given a target SLO violation rate, AGILE can efciently handle dynamic application workloads, reducing both penalties and user dissatisfaction.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41216.html
found
=========================
Brief Announcement: Consistency and Complexity Tradeoffs for Highly-Available Multi-Cloud Store
The International Symposium on Distributed Computing (DISC) (2013)
[u'Gregory Chockler', u'Dan Dobre', u'Alexander Shraer']
DistributedSystemsandParallelComputing
Abstract: An emerging multi-cloud storage paradigm suggests replicating data across multiple cloud storage services, potentially operated by distinct providers. In this paper, we study the impact of the storage interfaces and consistency semantics exposed by individual clouds on the complexity of the reliable multi-cloud storage implementation. Our results establish several inherent space and time tradeoffs associated with emulating reliable objects over a collection of unreliable storage services with varied interfaces and consistency guarantees.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40737.html
found
=========================
CPI2: CPU performance isolation for shared compute clusters
SIGOPS European Conference on Computer Systems (EuroSys), ACM, Prague, Czech Republic (2013), pp. 379-391
[u'Xiao Zhang', u'Eric Tune', u'Robert Hagmann', u'Rohit Jnagal', u'Vrigo Gokhale', u'John Wilkes']
DistributedSystemsandParallelComputing
Abstract: Performance isolation is a key challenge in cloud computing. Unfortunately, Linux has few defenses against performance interference in shared resources such as processor caches and memory buses, so applications in a cloud can experience unpredictable performance caused by other program's behavior. Our solution, CPI2, uses cycles-per-instruction (CPI) data obtained by hardware performance counters to identify problems, select the likely perpetrators, and then optionally throttle them so that the victims can return to their expected behavior. It automatically learns normal and anomalous behaviors by aggregating data from multiple tasks in the same job. We have rolled out CPI2 to all of Google's shared compute clusters. The paper presents the analysis that lead us to that outcome, including both case studies and a large-scale evaluation of its ability to solve real production issues.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40812.html
found
=========================
Ensuring Connectivity via Data Plane Mechanisms
10th USENIX Symposium on Networked Systems Design and Implementation (2013)
[u'Junda Liu']
DistributedSystemsandParallelComputing
Abstract: We typically think of network architectures as having two basic components: a data plane responsible for forwarding packets at line-speed, and a control plane that instantiates the forwarding state the data plane needs. With this separation of concerns, ensuring connectivity is the responsibility of the control plane. However, the control plane typically operates at timescales several orders of magnitude slower than the data plane, which means that failure recovery will always be slow compared to dataplane forwarding rates. In this paper we propose moving the responsibility for connectivity to the data plane. Our design, called Data-Driven Connectivity (DDC) ensures routing connectivity via data plane mechanisms. We believe this new separation of concerns basic connectivity on the data plane, optimal paths on the control plane will allow networks to provide a much higher degree of availability, while still providing flexible routing control.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41668.html
found
=========================
EventWave: Programming Model and Runtime Support for Tightly-Coupled Elastic Cloud Applications
Proceedings of the 2013 ACM Symposium on Cloud Computing, ACM, Santa Clara, CA, USA
[u'Wei-Chiu Chuang', u'Bo Sang', u'Sunghwan Yoo', u'Rui Gu', u'Charles Killian', u'Milind Kulkarni']
DistributedSystemsandParallelComputing
Abstract: An attractive approach to leveraging the ability of cloud-computing platforms to provide resources on demand is to build elastic applications, which can dynamically scale up or down based on resource requirements. To ease the development of elastic applications, it is useful for programmers to write applications with simple sequential semantics, without considering elasticity, and rely on runtime support to provide that elasticity. While this approach has been useful in restricted domains, such as MapReduce, existing programming models for general distributed applications do not expose enough information about their inherent organization of state and computation to provide such transparent elasticity. We introduce EVENTWAVE, an event-driven programming model that allows developers to design elastic programs with inelastic semantics while naturally exposing isolated state and computation with programmatic parallelism. In addition, we describe the runtime mechanism which takes the exposed parallelism to provide elasticity. Finally, we evaluate our implementation through microbenchmarks and case studies to demonstrate that EVENTWAVE can provide efcient, scalable, transparent elasticity for applications run in the cloud.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41344.html
found
=========================
F1: A Distributed SQL Database That Scales
VLDB (2013)
[u'Jeff Shute', u'Radek Vingralek', u'Bart Samwel', u'Ben Handy', u'Chad Whipkey', u'Eric Rollins', u'Mircea Oancea', u'Kyle Littleeld', u'David Menestrina', u'Stephan Ellner', u'John Cieslewicz', u'Ian Rae', u'Traian Stancescu', u'Himani Apte']
DistributedSystemsandParallelComputing
Abstract: F1 is a distributed relational database system built at Google to support the AdWords business. F1 is a hybrid database that combines high availability, the scalability of NoSQL systems like Bigtable, and the consistency and usability of traditional SQL databases. F1 is built on Spanner, which provides synchronous cross-datacenter replication and strong consistency. Synchronous replication implies higher commit latency, but we mitigate that latency by using a hierarchical schema model with structured data types and through smart application design. F1 also includes a fully functional distributed SQL query engine and automatic change tracking and publishing.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41431.html
found
=========================
Fast Data Processing with Spark
Packt (2013)
[u'Holden Karau']
DistributedSystemsandParallelComputing
Abstract: Spark is a framework for writing fast, distributed programs. Spark solves similar problems as Hadoop MapReduce does but with a fast in-memory approach and a clean functional style API. With its ability to integrate with Hadoop and inbuilt tools for interactive query analysis (Shark), large-scale graph processing and analysis (Bagel), and real-time analysis (Spark Streaming), it can be interactively used to quickly process and query big data sets. Fast Data Processing with Spark covers how to write distributed map reduce style programs with Spark. The book will guide you through every step required to write effective distributed programs from setting up your cluster and interactively exploring the API, to deploying your job to the cluster, and tuning it for your purposes. Fast Data Processing with Spark covers everything from setting up your Spark cluster in a variety of situations (stand-alone, EC2, and so on), to how to use the interactive shell to write distributed code interactively. From there, we move on to cover how to write and deploy distributed jobs in Java, Scala, and Python. We then examine how to use the interactive shell to quickly prototype distributed programs and explore the Spark API. We also look at how to use Hive with Spark to use a SQL-like query syntax with Shark, as well as manipulating resilient distributed datasets (RDDs).
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41378.html
found
=========================
MillWheel: Fault-Tolerant Stream Processing at Internet Scale
Very Large Data Bases (2013), pp. 734-746
[u'Tyler Akidau', u'Alex Balikov', u'Kaya Bekiroglu', u'Slava Chernyak', u'Josh Haberman', u'Reuven Lax', u'Sam McVeety', u'Daniel Mills', u'Paul Nordstrom', u'Sam Whittle']
DistributedSystemsandParallelComputing
Abstract: MillWheel is a framework for building low-latency data-processing applications that is widely used at Google. Users specify a directed computation graph and application code for individual nodes, and the system manages persistent state and the continuous flow of records, all within the envelope of the framework's fault-tolerance guarantees. This paper describes MillWheel's programming model as well as its implementation. The case study of a continuous anomaly detector in use at Google serves to motivate how many of MillWheel's features are used. MillWheel's programming model provides a notion of logical time, making it simple to write time-based aggregations. MillWheel was designed from the outset with fault tolerance and scalability in mind. In practice, we find that MillWheel's unique combination of scalability, fault tolerance, and a versatile programming model lends itself to a wide variety of problems at Google.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40493.html
found
=========================
Minimizing weighted flowtime on capacitated machines
ACM-SIAM Symposium on Discrete Algorithms (SODA) (2013)
[u'Kyle Fox', u'Madhukar Korupolu']
DistributedSystemsandParallelComputing
Abstract: It is well-known that SRPT is optimal for minimizing flow time on machines that run one job at a time. However, running one job at a time is a big under- utilization for modern systems where sharing, simultane- ous execution, and virtualization-enabled consolidation are a common trend to boost utilization. Such machines, used in modern large data centers and clouds, are powerful enough to run multiple jobs/VMs at a time subject to overall CPU, memory, network, and disk capacity constraints. Motivated by this prominent trend and need, in this work, we give the first scheduling algorithms to minimize weighted flow time on such capacitated machines. To capture the difficulty of the problem, we show that without resource augmentation, no online algorithm can achieve a bounded competitive ratio. We then investigate algorithms with a small resource augmentation in speed and/or capacity. Our first result is a simple (2 + )- capacity O(1/)-competitive greedy algorithm. Using only speed augmentation, we then obtain a 1.75-speed O(1)-competitive algorithm. Our main technical result is a near-optimal (1 + )-speed, (1 + )-capacity O(1/3 )- competitive algorithm using a novel combination of knapsacks, densities, job classification into categories, and potential function methods. We show that our results also extend to the multiple unrelated capacitated machines setting.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41684.html
found
=========================
Omega: flexible, scalable schedulers for large compute clusters
SIGOPS European Conference on Computer Systems (EuroSys), ACM, Prague, Czech Republic (2013), pp. 351-364
[u'Malte Schwarzkopf', u'Andy Konwinski', u'Michael Abd-El-Malek', u'John Wilkes']
DistributedSystemsandParallelComputing
Abstract: Increasing scale and the need for rapid response to changing requirements are hard to meet with current monolithic cluster scheduler architectures. This restricts the rate at which new features can be deployed, decreases efficiency and utilization, and will eventually limit cluster growth. We present a novel approach to address these needs using parallelism, shared state, and lock-free optimistic concurrency control. We compare this approach to existing cluster scheduler designs, evaluate how much interference between schedulers occurs and how much it matters in practice, present some techniques to alleviate it, and finally discuss a use case highlighting the advantages of our approach -- all driven by real-life Google production workloads.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41097.html
found
=========================
On the k-atomicity-verification problem
The 33rd International Conference on Distributed Computing Systems, IEEE (2013)
[u'Wojciech Golab', u'Jeremy Hurwitz', u'Xiaozhou Li']
DistributedSystemsandParallelComputing
Abstract: Modern Internet-scale storage systems often provide weak consistency in exchange for better perfor- mance and resilience. An important weak consistency prop- erty is k-atomicity, which bounds the staleness of values returned by read operations. The k-atomicity-verification problem (or k-AV for short) is the problem of deciding whether a given history of operations is k-atomic. The 1-AV problem is equivalent to verifying atomicity/linearizability, a well-known and solved problem. However, for k ? 2, no polynomial-time k-AV algorithm is known. This paper makes the following contributions towards solving the k-AV problem. First, we present a simple 2- AV algorithm called LBT, which is likely to be efficient (quasilinear) for histories that arise in practice, although it is less efficient (quadratic) in the worst case. Second, we present a more involved 2-AV algorithm called FZF, which runs efficiently (quasilinear) even in the worst case. To our knowledge, these are the first algorithms that solve the 2-AV problem fully. Third, we show that the weighted k-AV problem, a natural extension of the k-AV problem, is NP-complete.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41376.html
found
=========================
Online, Asynchronous Schema Change in F1
VLDB (2013)
[u'Ian Rae', u'Eric Rollins', u'Jeff Shute', u'Sukhdeep Sodhi', u'Radek Vingralek']
DistributedSystemsandParallelComputing
Abstract: We introduce a protocol for schema evolution in a globally distributed database management system with shared data, stateless servers, and no global membership. Our protocol is asynchronousit allows different servers in the database system to transition to a new schema at different timesand onlineall servers can access and update all data during a schema change. We provide a formal model for determining the correctness of schema changes under these conditions, and we demonstrate that many common schema changes can cause anomalies and database corruption. We avoid these problems by replacing corruption-causing schema changes with a sequence of schema changes that is guaranteed to avoid corrupting the database so long as all servers are no more than one schema version behind at any time. Finally, we discuss a practical implementation of our protocol in F1, the database management system that stores data for Google AdWords.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41318.html
found
=========================
Photon: Fault-tolerant and Scalable Joining of Continuous Data Streams
SIGMOD '13: Proceedings of the 2013 international conference on Management of data, ACM, New York, NY, USA, pp. 577-588
[u'Rajagopal Ananthanarayanan', u'Venkatesh Basker', u'Sumit Das', u'Ashish Gupta', u'Haifeng Jiang', u'Tianhao Qiu', u'Alexey Reznichenko', u'Deomid Ryabkov', u'Manpreet Singh', u'Shivakumar Venkataraman']
DistributedSystemsandParallelComputing
Abstract: Web-based enterprises process events generated by millions of users interacting with their websites. Rich statistical data distilled from combining such interactions in near real-time generates enormous business value. In this paper, we describe the architecture of Photon, a geographically distributed system for joining multiple continuously flowing streams of data in real-time with high scalability and low latency, where the streams may be unordered or delayed. The system fully tolerates infrastructure degradation and datacenter-level outages without any manual intervention. Photon guarantees that there will be no duplicates in the joined output (at-most-once semantics) at any point in time, that most joinable events will be present in the output in real-time (near-exact semantics), and exactly-once semantics eventually. Photon is deployed within Google Advertising System to join data streams such as web search queries and user clicks on advertisements. It produces joined logs that are used to derive key business metrics, including billing for advertisers. Our production deployment processes millions of events per minute at peak with an average end-to-end latency of less than 10 seconds. We also present challenges and solutions in maintaining large persistent state across geographically distant locations, and highlight the design principles that emerged from our experience.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41606.html
found
=========================
The Datacenter as a Computer: An Introduction to the Design of Warehouse-Scale Machines, Second Edition
Morgan & Claypool Publishers (2013)
[u'Luiz Andr Barroso', u'Jimmy Clidaras', u'Urs Hlzle']
DistributedSystemsandParallelComputing
Abstract: As computation continues to move into the cloud, the computing platform of interest no longer resembles a pizza box or a refrigerator, but a warehouse full of computers. These new large datacenters are quite different from traditional hosting facilities of earlier times and cannot be viewed simply as a collection of co-located servers. Large portions of the hardware and software resources in these facilities must work in concert to efficiently deliver good levels of Internet service performance, something that can only be achieved by a holistic approach to their design and deployment. In other words, we must treat the datacenter itself as one massive warehouse-scale computer (WSC). We describe the architecture of WSCs, the main factors influencing their design, operation, and cost structure, and the characteristics of their software base. We hope it will be useful to architects and programmers of todays WSCs, as well as those of future many-core platforms which may one day implement the equivalent of todays WSCs on a single board. Notes for the Second Edition After nearly four years of substantial academic and industrial developments in warehouse-scale computing, we are delighted to present our first major update to this lecture. The increased popularity of public clouds has made WSC software techniques relevant to a larger pool of programmers since our first edition. Therefore, we expanded Chapter 2 to reflect our better understanding of WSC software systems and the toolbox of software techniques for WSC programming. In Chapter 3, we added to our coverage of the evolving landscape of wimpy vs. brawny server trade-offs, and we now present an overview of WSC interconnects and storage systems that was promised but lacking in the original edition. Thanks largely to the help of our new co-author, Google Distinguished Engineer Jimmy Clidaras, the material on facility mechanical and power distribution design has been updated and greatly extended (see Chapters 4 and 5). Chapters 6 and 7 have also been revamped significantly. We hope this revised edition continues to meet the needs of educators and professionals in this area.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40801.html
found
=========================
The Tail at Scale
Communications of the ACM, vol. 56 (2013), pp. 74-80
[u'Jeffrey Dean', u'Luiz Andr Barroso']
DistributedSystemsandParallelComputing
Abstract: Systems that respond to user actions very quickly (within 100 milliseconds) feel more fluid and natural to users than those that take longer [Card et al 1991]. Improvements in Internet connectivity and the rise of warehouse-scale computing systems [Barroso & Hoelzle 2009] have enabled Web services that provide fluid responsiveness while consulting multi-terabyte datasets that span thousands of servers. For example, the Google search system now updates query results interactively as the user types, predicting the most likely query based on the prefix typed so far, performing the search, and showing the results within a few tens of milliseconds. Emerging augmented reality devices such as the Google Glass prototype will need associated Web services with even greater computational needs while guaranteeing seamless interactivity. It is challenging to keep the tail of the latency distribution low for interactive services as the size and complexity of the system scales up or as overall utilization increases. Temporary high latency episodes which are unimportant in moderate size systems may come to dominate overall service performance at large scale. Just as fault-tolerant computing aims to create a reliable whole out of less reliable parts, we suggest that large online services need to create a predictably responsive whole out of less predictable parts. We refer to such systems as latency tail-tolerant, or tail-tolerant for brevity. This article outlines some of the common causes of high latency episodes in large online services and describes techniques that reduce their severity or mitigate their impact in whole system performance. In many cases, tail-tolerant techniques can take advantage of resources already deployed to achieve fault-tolerance, resulting in low additional overheads. We show that these techniques allow system utilization to be driven higher without lengthening the latency tail, avoiding wasteful over-provisioning.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40816.html
found
=========================
Verifying Cloud Services: Present and Future
Operating Systems Review (2013)
[u'Sara Bouchenak', u'Gregory Chockler', u'Hana Chockler', u'Gabriela Gheorghe', u'Nuno Santos', u'Alexander Shraer']
DistributedSystemsandParallelComputing
Abstract: As cloud-based services gain popularity in both private and enterprise domains, cloud consumers are still lacking in tools to verify that these services work as expected. Such tools should consider properties such as functional correctness, service availability, reliability, performance and security guar- antees. In this paper we survey existing work in these ar- eas and identify gaps in existing cloud technology in terms of the verication tools provided to users. We also discuss challenges and new research directions that can help bridge these gaps.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42551.html
found
=========================
Web-Scale Job Scheduling
Lecture Notes in Computer Science, vol. 7698 (2013)
[u'Walfredo Cirne', u'Eitan Frachtenberg']
DistributedSystemsandParallelComputing
Abstract: Web datacenters and clusters can be larger than the worlds largest supercomputers, and run workloads that are at least as heteroge- neous and complex as their high-performance computing counterparts. And yet little is known about the unique job scheduling challenges of these environments. This article aims to ameliorate this situation. It dis- cusses the challenges of running web infrastructure and describes several techniques to address them. It also presents some of the problems that remain open in the field.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40404.html
found
=========================
A Guided Tour of Datacenter Networking
Communications of the ACM - ACM Queue, vol. 55, number 6 (2012), pp. 44-51
[u'Dennis Abts', u'Bob Felderman']
DistributedSystemsandParallelComputing
Abstract: The magic of the cloud is that it is always on and always available from anywhere. Users have come to expect that services are there when they need them. A data center (or warehouse-scale computer) is the nexus from which all the services flow. It is often housed in a nondescript warehouse-sized building bearing no indication of what lies inside. Amidst the whirring fans and refrigerator-sized computer racks is a tapestry of electrical cables and fiber optics weaving everything togetherthe data-center network. This article provides a guided tour through the principles and central ideas surrounding the network at the heart of a data centerthe modern-day loom that weaves the digital fabric of the Internet.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
An approach to Distributed Virtual Environment performance modeling: Addressing system complexity and user behavior
Proceedings of the 2012 IEEE Virtual Reality, IEEE Computer Society, Washington, DC, USA, pp. 71-72
[u'H. Lally Singh', u'Denis Gracanin']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42552.html
found
=========================
Characterization and Comparison of Cloud versus Grid Workloads
IEEE Cluster 2012
[u'Sheng Di', u'Derrick Kondo', u'Walfredo Cirne']
DistributedSystemsandParallelComputing
Abstract: A new era of Cloud Computing has emerged, but the characteristics of Cloud load in data centers is not perfectly clear. Yet this characterization is critical for the design of novel Cloud job and resource management systems. In this paper, we comprehensively characterize the job/task load and host load in a real-world production data center at Google Inc. We use a detailed trace of over 25 million tasks across over 12,500 hosts. We study the differences between a Google data center and other Grid/HPC systems, from the perspective of both work load (w.r.t. jobs and tasks) and host load (w.r.t. machines). In particular, we study the job length, job submission frequency, and the resource utilization of jobs in the different systems, and also investigate valuable statistics of machines maximum load, queue state and relative usage levels, with different job priorities and resource attributes. We find that the Google data center exhibits finer resource allocation with respect to CPU and memory than that of Grid/HPC systems. Google jobs are always submitted with much higher frequency and they are much shorter than Grid jobs. As such, Google host load exhibits higher variance and noise.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
CloudRAMSort: fast and efficient large-scale distributed RAM sort on shared-nothing cluster
Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data, ACM, New York, NY, USA, pp. 841-850
[u'Changkyu Kim', u'Jongsoo Park', u'Nadathur Satish', u'Hongrae Lee', u'Pradeep Dubey', u'Jatin Chhugani']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
DIPLOMA: Consistent and Coherent Shared Memory over Mobile Phones
30th IEEE International Conference on Computer Design (2012)
[u'Niket Agarwal']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38125.html
found
=========================
F1 - The Fault-Tolerant Distributed RDBMS Supporting Google's Ad Business
SIGMOD (2012)
[u'Jeff Shute', u'Mircea Oancea', u'Stephan Ellner', u'Ben Handy', u'Eric Rollins', u'Bart Samwel', u'Radek Vingralek', u'Chad Whipkey', u'Xin Chen', u'Beat Jegerlehner', u'Kyle Littleeld', u'Phoenix Tong']
DistributedSystemsandParallelComputing
Abstract: Many of the services that are critical to Googles ad business have historically been backed by MySQL. We have recently migrated several of these services to F1, a new RDBMS developed at Google. F1 implements rich relational database features, including a strictly enforced schema, a powerful parallel SQL query engine, general transactions, change tracking and notication, and indexing, and is built on top of a highly distributed storage system that scales on standard hardware in Google data centers. The store is dynamically sharded, supports transactionally-consistent replication across data centers, and is able to handle data center outages without data loss. The strong consistency properties of F1 and its storage system come at the cost of higher write latencies compared to MySQL. Having successfully migrated a rich customerfacing application suite at the heart of Googles ad business to F1, with no downtime, we will describe how we restructured schema and applications to largely hide this increased latency from external users. The distributed nature of F1 also allows it to scale easily and to support signicantly higher throughput for batch workloads than a traditional RDBMS. With F1, we have built a novel hybrid system that combines the scalability, fault tolerance, transparent sharding, and cost benets so far available only in NoSQL systems with the usability, familiarity, and transactional guarantees expected from an RDBMS.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Finding Connected Components in Map-reduce in Logarithmic Rounds
ICDE, IEE (2012) (to appear)
[u'Vibhor Rastogi', u'Ashwin Machanavajjhala', u'Laukik Chitnis', u'Anish Das Sarma']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42553.html
found
=========================
Hostload prediction in a Google compute cloud with a Bayesian model
Supercomputing 2012
[u'Sheng Di', u'Derrick Kondo', u'Walfredo Cirne']
DistributedSystemsandParallelComputing
Abstract: Prediction of host load in Cloud systems is crit- ical for achieving service-level agreements. However, accurate prediction of host load in Clouds is extremely challenging because it fluctuates drastically at small timescales. We design a prediction method based on Bayes model to predict the mean load over a long-term time interval, as well as the mean load in consecutive future time intervals. We identify novel predictive features of host load that capture the expectation, predictabil- ity, trends and patterns of host load. We also determine the most effective combinations of these features for prediction. We evaluate our method using a detailed one-month trace of a Google data center with thousands of machines. Experiments show that the Bayes method achieves high accuracy with a mean squared error of 0.0014. Moreover, the Bayes method improves the load prediction accuracy by 5.6-50% compared to other state-of-the-art methods based on moving averages, auto-regression, and/or noise filters.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
JANUS: exploiting parallelism via hindsight
Proceedings of the 33rd ACM SIGPLAN conference on Programming Language Design and Implementation, ACM, New York, NY, USA (2012), pp. 145-156
[u'Omer Tripp', u'Roman Manevich', u'John Field', u'Mooly Sagiv']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41686.html
found
=========================
Obfuscatory obscanturism: making workload traces of commercially-sensitive systems safe to release
CloudMAN, IEEE, Maui, HI, USA (2012)
[u'Charles Reiss', u'John Wilkes', u'Joseph L. Hellerstein']
DistributedSystemsandParallelComputing
Abstract: Cloud providers such as Google are interested in fostering research on the daunting technical challenges they face in supporting planetary-scale distributed systems, but no academic organizations have similar scale systems on which to experiment. Fortunately, good research can still be done using traces of real-life production workloads, but there are risks in releasing such data, including inadvertently disclosing condential or proprietary information, as happened with the Netix Prize data. This paper discusses these risks, and our approach to them, which we call {\em systematic obfuscation}. It protects proprietary and personal data while leaving it possible to answer some interesting research questions. We explain and motivate some of the risks and concerns and propose how they can best be mitigated, using as an example our recent publication of a month-long trace of a production system workload on a 11k-machine cluster.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40340.html
found
=========================
Optimistic Scheduling with Geographically Replicated Services in the Cloud Environment (COLOR)
Cluster, Cloud and Grid Computing (CCGrid), 2012 12th IEEE/ACM International Symposium on, IEEE CONFERENCE PUBLICATIONS, pp. 735-740
[u'Wenbo Zhu', u'C. Murray Woodside']
DistributedSystemsandParallelComputing
Abstract: This paper proposes a system model that unifies different optimistic algorithms designed for deploying geographically replicated services in a cloud environment. The proposed model thereby enables a generalized solution (COLOR) by which well-specified safety and timeliness guarantees are achievable in conjunction with tunable performance requirements. The proposed solution explicitly takes advantage of the unique client-cloud interface in specifying how the level of consistency violation may be bounded, for instance using probabilistic rollbacks or restarts as parameters. The solution differs from traditional Eventual Consistency models in that inconsistency is solved concurrently with online client-cloud interactions over strongly connected networks. We believe that such an approach will bring clarity to the role and limitations of the ever-popular Eventual Consistency model in cloud services.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Orchestrating the deployment of computations in the cloud with conductor
Proceedings of the 9th USENIX conference on Networked Systems Design and Implementation, USENIX Association, Berkeley, CA, USA (2012), pp. 27-27
[u'Alexander Wieder', u'Pramod Bhatotia', u'Ansley Post', u'Rodrigo Rodrigues']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Overlapping clusters for distributed computation
ACM Conference on Web Search and Data Mining (WSDM) (2012)
[u'Reid Andersen', u'David Gleich', u'Vahab Mirrokni']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40465.html
found
=========================
Processing a Trillion Cells per Mouse Click
PVLDB, vol. 5 (2012), pp. 1436-1446
[u'Alex Hall', u'Olaf Bachmann', u'Robert Buessow', u'Silviu-Ionut Ganceanu', u'Marc Nunkesser']
DistributedSystemsandParallelComputing
Abstract: Column-oriented database systems have been a real game changer for the industry in recent years. Highly tuned and performant systems have evolved that provide users with the possibility of answering ad hoc queries over large datasets in an interactive manner. In this paper we present the column-oriented datastore developed as one of the central components of PowerDrill. It combines the advantages of columnar data layout with other known techniques (such as using composite range partitions) and extensive algorithmic engineering on key data structures. The main goal of the latter being to reduce the main memory footprint and to increase the efficiency in processing typical user queries. In this combination we achieve large speed-ups. These enable a highly interactive Web UI where it is common that a single mouse click leads to processing a trillion values in the underlying dataset.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37747.html
found
=========================
Projecting Disk Usage Based on Historical Trends in a Cloud Environment
ScienceCloud 2012 Proceedings of the 3rd International Workshop on Scientific Cloud Computing, ACM, pp. 63-70
[u'Murray Stokely', u'Amaan Mehrabian', u'Christoph Albrecht', u'Francois Labelle', u'Arif Merchant']
DistributedSystemsandParallelComputing
Abstract: Provisioning scarce resources among competing users and jobs remains one of the primary challenges of operating large-scale, distributed computing environments. Distributed storage systems, in particular, typically rely on hard operator-set quotas to control disk allocation and enforce isolation for space and I/O bandwidth among disparate users. However, users and operators are very poor at predicting future requirements and, as a result, tend to over-provision grossly. For three years, we collected detailed usage information for data stored in distributed filesystems in a large private cloud spanning dozens of clusters on multiple continents. Specifically, we measured the disk space usage, I/O rate, and age of stored data for thousands of different engineering users and teams. We find that although the individual timeseries often have non-stable usage trends, regional aggregations, user classification, and ensemble forecasting methods can be combined to provide a more accurate prediction of future use for the majority of users. We applied this methodology for the storage users in one geographic region and back-tested these techniques over the past three years to compare our forecasts against actual usage. We find that by classifying a small subset of users with unforecastable trend changes due to known product launches, we can generate three-month out forecasts with mean absolute errors of less than ~12%. This compares favorably to the amount of allocated but unused quota that is generally wasted with manual operator-set quotas.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37478.html
found
=========================
Recursion in Scalable Protocols via Distributed Data Flows
Languages for Distributed Algorithms (2012) (to appear)
[u'Krzysztof Ostrowski']
DistributedSystemsandParallelComputing
Abstract: This paper proposes a new approach to representing scalable hierarchical distributed multi-party protocols, and reasoning about their behavior. The established endpoint-to-endpoint message-passing abstraction provides little support for modeling distributed algorithms in hierarchical systems, in which the hierarchy and membership dynamically evolve. This paper explains how with our new Distributed Data Flow (DDF) abstraction, hierarchical architecture can be modeled via recursion in the language. This facilitates a more concise code, and it enables automated generation of scalable hierarchical implementations for heterogeneous network environments.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40366.html
found
=========================
Resource-bounded multicore emulation using Beefarm
Microprocessors and Microsystems (2012)
[u'Oriol Arcas', u'Nehir Sonmez', u'Gokhan Sayilar', u'Satnam Singh', u'Osman S. Unsal', u'Adrian Cristal', u'Ibrahim Hur', u'Mateo Valero']
DistributedSystemsandParallelComputing
Abstract: In this article, we present the Beefarm infrastructure for FPGA-based multiprocessor emulation, a popular research topic of the last few years both in FPGA and computer architecture communities. We explain how we modify and extend a MIPS-based open-source soft core, we discuss various design tradeoffs to make efficient use of the bounded resources available on chip and we demonstrate superior scalability compared to traditional software instruction set simulators through experimental results running Software Transactional Memory (STM) benchmarks. Based on our experience, we comment on the pros and cons and the future trends of using hardware-based emulation for multicore research.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37684.html
found
=========================
Science in the Cloud
IEEE Internet Computing (2012)
[u'Joseph L Hellerstein', u'Kai Kohlhoff', u'David E. Konerding']
DistributedSystemsandParallelComputing
Abstract: Scientific discovery is in transition from a focus on data collection to an emphasis on analysis and prediction using large scale computation. These computations can be done with unused cycles in commercial Clouds if there is appropriate software support. Moving science into the Cloud will promote data sharing and collaborations that will accelerate scientific discovery in the 21st century.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Spanner: Google's Globally-Distributed Database
OSDI (2012) (to appear)
[u'James C. Corbett', u'Jeffrey Dean', u'Michael Epstein', u'Andrew Fikes', u'Christopher Frost', u'JJ Furman', u'Sanjay Ghemawat', u'Andrey Gubarev', u'Christopher Heiser', u'Peter Hochschild', u'Wilson Hsieh', u'Sebastian Kanthak', u'Eugene Kogan', u'Hongyi Li', u'Alexander Lloyd', u'Sergey Melnik', u'David Mwaura', u'David Nagle', u'Sean Quinlan', u'Rajesh Rao', u'Lindsay Rolig', u'Dale Woodford', u'Yasushi Saito', u'Christopher Taylor', u'Michal Szymaniak', u'Ruth Wang']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38103.html
found
=========================
Trickle: Rate Limiting YouTube Video Streaming
Proceedings of the USENIX Annual Technical Conference (2012), pp. 6
[u'Monia Ghobadi', u'Yuchung Cheng', u'Ankur Jain', u'Matt Mathis']
DistributedSystemsandParallelComputing
Abstract: YouTube traffic is bursty. These bursts trigger packet losses and stress router queues, causing TCPs congestion-control algorithm to kick in. In this paper, we introduce Trickle, a server-side mechanism that uses TCP to rate limit YouTube video streaming. Trickle paces the video stream by placing an upper bound on TCPs congestion window as a function of the streaming rate and the round-trip time. We evaluated Trickle on YouTube production data centers in Europe and India and analyzed its impact on losses, bandwidth, RTT, and video buffer under-run events. The results show that Trickle reduces the average TCP loss rate by up to 43% and the average RTT by up to 28% while maintaining the streaming rate requested by the application.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40378.html
found
=========================
Uncertainty in Aggregate Estimates from Sampled Distributed Traces
2012 Workshop on Managing Systems Automatically and Dynamically, USENIX
[u'Nate Coehlo', u'Arif Merchant', u'Murray Stokely']
DistributedSystemsandParallelComputing
Abstract: Tracing mechanisms in distributed systems give important insight into system properties and are usually sampled to control overhead. At Google, Dapper [8] is the always-on system for distributed tracing and performance analysis, and it samples fractions of all RPC trafc. Due to difcult implementation, excessive data volume, or a lack of perfect foresight, there are times when system quantities of interest have not been measured directly, and Dapper samples can be aggregated to estimate those quantities in the short or long term. Here we nd unbiased variance estimates of linear statistics over RPCs, taking into account all layers of sampling that occur in Dapper, and allowing us to quantify the sampling uncertainty in the aggregate estimates. We apply this methodology to the problem of assigning jobs and data to Google datacenters, using estimates of the resulting cross-datacenter trafc as an optimization criterion, and also to the detection of change points in access patterns to certain data partitions.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40413.html
found
=========================
Upper and Lower Bounds on the Cost of a Map-Reduce Computation
Arxiv (2012)
[u'Foto Afrati', u'Anish Das Sarma', u'Semih Salihoglu', u'Jeffrey Ullman']
DistributedSystemsandParallelComputing
Abstract: In this paper we study the tradeoff between parallelism and communication cost in a map-reduce computation. For any problem that is not "embarrassingly parallel," the finer we partition the work of the reducers so that more parallelism can be extracted, the greater will be the total communication between mappers and reducers. We introduce a model of problems that can be solved in a single round of map-reduce computation. This model enables a generic recipe for discovering lower bounds on communication cost as a function of the maximum number of inputs that can be assigned to one reducer. We use the model to analyze the tradeoff for three problems: finding pairs of strings at Hamming distance $d$, finding triangles and other patterns in a larger graph, and matrix multiplication. For finding strings of Hamming distance 1, we have upper and lower bounds that match exactly. For triangles and many other graphs, we have upper and lower bounds that are the same to within a constant factor. For the problem of matrix multiplication, we have matching upper and lower bounds for one-round map-reduce algorithms. We are also able to explore two-round map-reduce algorithms for matrix multiplication and show that these never have more communication, for a given reducer size, than the best one-round algorithm, and often have significantly less.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40412.html
found
=========================
Vision Paper: Towards an Understanding of the Limits of Map-Reduce Computation
CloudFutures Workshop (2012)
[u'Foto Afrati', u'Anish Das Sarma', u'Semih Salihoglu', u'Jeffrey Ullman']
DistributedSystemsandParallelComputing
Abstract: A significant amount of recent research work has addressed the problem of solving various data management problems in the cloud. The major algorithmic challenges in map-reduce computations involve balancing a multitude of factors such as the number of machines available for mappers/reducers, their memory requirements, and communication cost (total amount of data sent from mappers to reducers). Most past work provides custom solutions to specific problems, e.g., performing fuzzy joins in map-reduce, clustering, graph analyses, and so on. While some problems are amenable to very efficient map-reduce algorithms, some other problems do not lend themselves to a natural distribution, and have provable lower bounds. Clearly, the ease of "map-reducability" is closely related to whether the problem can be partitioned into independent pieces, which are distributed across mappers/reducers. What makes a problem distributable? Can we characterize general properties of problems that determine how easy or hard it is to find efficient map-reduce algorithms? This is a vision paper that attempts to answer the questions described above.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Tight Unconditional Lower Bound on Distributed Random Walk Computation
ACM Symposium on Principles of Distributed Computing (PODC) (2011)
[u'Danupon Nanongkai', u'Atish Das Sarma', u'Gopal Pandurangan']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37201.html
found
=========================
Characterizing Task Usage Shapes in Google Compute Clusters
Proceedings of the 5th International Workshop on Large Scale Distributed Systems and Middleware (2011)
[u'Qi Zhang', u'Joseph Hellerstein', u'Raouf Boutaba']
DistributedSystemsandParallelComputing
Abstract: The increase in scale and complexity of large compute clus- ters motivates a need for representative workload bench- marks to evaluate the performance impact of system changes, so as to assist in designing better scheduling algorithms and in carrying out management activities. To achieve this goal, it is necessary to construct workload characterizations from which realistic performance benchmarks can be created. In this paper, we focus on characterizing run-time task resource usage for CPU, memory and disk. The goal is to find an accurate characterization that can faithfully reproduce the performance of historical workload traces in terms of key performance metrics, such as task wait time and machine resource utilization. Through experiments using workload traces from Google production clusters, we find that simply using the mean of task usage can generate synthetic work- load traces that accurately reproduce resource utilizations and task waiting time. This seemingly surprising result can be justified by the fact that resource usage for CPU, mem- ory and disk are relatively stable over time for the majority of the tasks. Our work not only presents a simple tech- nique for constructing realistic workload benchmarks, but also provides insights into understanding workload perfor- mance in production compute clusters.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
CloudScale: elastic resource scaling for multi-tenant cloud systems
Symposium on Cloud Computing (SoCC), ACM, Cascais, Portugal (2011)
[u'Zhiming Shen', u'Sethuraman Subbiah', u'Xiaohui Gu', u'John Wilkes']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Design and Implementation of FAITH, an Experimental System to Intercept and Manipulate Online Social Informatics
International Conference on Advances in Social Networks Analysis and Mining, IEEE (2011), pp. 195-202
[u'Ruaylong Lee', u'Roozbeh Nia', u'Jason Hsu', u'Karl N. Levitt', u'Jeff Rowe', u'S. Felix Wu', u'Shaozhi Ye']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37477.html
found
=========================
Diagnosing Latency in Multi-Tier Black-Box Services
5th Workshop on Large Scale Distributed Systems and Middleware (LADIS 2011) (to appear)
[u'Krzysztof Ostrowski', u'Gideon Mann', u'Mark Sandler']
DistributedSystemsandParallelComputing
Abstract: As multi-tier cloud applications become pervasive, we need better tools for understanding their performance. This paper presents a system that analyzes observed or desired changes to end-to-end latency prole in a large distributed application, and identifies their underlying causes. It recognizes changes to system conguration, workload, or performance of individual services that lead to the observed or desired outcome. Experiments on an industrial datacenter demonstrate the utility of the system.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37194.html
found
=========================
Exploiting Service Usage Information for Optimizing Server Resource Management
ACM Transactions on Internet Technology (TOIT), vol. 11 (2011), pp. 1-26
[u'Alexander Totok', u'Vijay Karamcheti']
DistributedSystemsandParallelComputing
Abstract: It is often difficult to tune the performance of modern component-based Internet services because: (1) component middleware are complex software systems that expose several independently tuned server resource management mechanisms; (2) session-oriented client behavior with complex data access patterns makes it hard to predict what impact tuning these mechanisms has on application behavior; and (3) component-based Internet services themselves exhibit complex structural organization with requests of different types having widely ranging execution complexity. In this article we show that exposing and using detailed information about how clients use Internet services enables mechanisms that achieve two interconnected goals: (1) providing improved QoS to the service clients, and (2) optimizing server resource utilization. To differentiate among levels of service usage (service access) information, we introduce the notion of the service access attribute and identify four related groups of service access attributes, encompassing different aspects of service usage information, ranging from the high-level structure of client web sessions to low-level fine-grained information about utilization of server resources by different requests. To show how the identified service usage information can be collected, we implement a request profiling infrastructure in the JBoss Java application server. In the context of four representative service management problems, we show how collected service usage information is used to improve service performance, optimize server resource utilization, or to achieve other problem-specific service management goals.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
FAWN: a fast array of wimpy nodes: technical perspective
Communications of the ACM, vol. 54 (2011), pp. 100-100
[u'Luiz Andr Barroso']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41143.html
found
=========================
HTAF: Hybrid Testing Automation Framework to Leverage Local and Global Computing Resources
Lecture Notes in Computer Science, vol. 6784 (2011), pp. 479-494
[u'Keun Soo Yim', u'David Hreczany', u'Ravishankar K. Iyer']
DistributedSystemsandParallelComputing
Abstract: In web application development, testing forms an increasingly large portion of software engineering costs due to the growing complexity and short time-to-market of these applications. This paper presents a hybrid testing automation framework (HTAF) that can automate routine works in testing and releasing web software. Using this framework, an individual software engineer can easily describe his routine software engineering tasks and schedule these described tasks by using both his local machine and global cloud computers in an efficient way. This framework is applied to commercial web software development processes. Our industry practice shows four example cases where the hybrid and decentralized architecture of HTAF is helpful at effectively managing both hardware resources and manpower required for testing and releasing web applications.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36971.html
found
=========================
Megastore: Providing Scalable, Highly Available Storage for Interactive Services
Proceedings of the Conference on Innovative Data system Research (CIDR) (2011), pp. 223-234
[u'Jason Baker', u'Chris Bond', u'James C. Corbett', u'JJ Furman', u'Andrey Khorlin', u'James Larson', u'Jean-Michel Leon', u'Yawei Li', u'Alexander Lloyd', u'Vadim Yushprakh']
DistributedSystemsandParallelComputing
Abstract: Megastore is a storage system developed to meet the requirements of today's interactive online services. Megastore blends the scalability of a NoSQL datastore with the convenience of a traditional RDBMS in a novel way, and provides both strong consistency guarantees and high availability. We provide fully serializable ACID semantics within fine-grained partitions of data. This partitioning allows us to synchronously replicate each write across a wide area network with reasonable latency and support seamless failover between datacenters. This paper describes Megastore's semantics and replication algorithm. It also describes our experience supporting a wide range of Google production services built with Megastore.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36953.html
found
=========================
Modeling and Synthesizing Task Placement Constraints in Google Compute Clusters
Symposium on Cloud Computing, ACM (2011)
[u'Victor Chudnovsky', u'Rasekh Rifaat', u'Joseph Hellerstein', u'Bikash Sharma', u'Chita Das']
DistributedSystemsandParallelComputing
Abstract: Evaluating the performance of large compute clusters requires benchmarks with representative workloads. At Google, performance benchmarks are used to obtain performance metrics such as task scheduling delays and machine resource utilizations to assess changes in application codes, machine congurations, and scheduling algorithms. Existing approaches to workload characterization for high performance computing and grids focus on task resource requirements for CPU, memory, disk, I/O, network, etc. Such resource requirements address how much resource is consumed by a task. However, in addition to resource requirements, Google workloads commonly include task placement constraints that determine which machine resources are consumed by tasks. Task placement constraints arise because of task dependencies such as those related to hardware architecture and kernel version. This paper develops methodologies for incorporating task placement constraints and machine properties into performance benchmarks of large compute clusters. Our studies of Google compute clusters show that constraints increase average task scheduling delays by a factor of 2 to 6, which often results in tens of minutes of additional task wait time. To understand why, we extend the concept of resource utilization to include constraints by introducing a new metric, the Utilization Multiplier (UM). UM is the ratio of the resource utilization seen by tasks with a constraint to the average utilization of the resource. UM provides a simple model of the performance impact of constraints in that task scheduling delays increase with UM. Last, we describe how to synthesize representative task constraints and machine properties, and how to incorporate this synthesis into existing performance benchmarks. Using synthetic task constraints and machine properties generated by our methodology, we accurately reproduce performance metrics for benchmarks of Google compute clusters with a discrepancy of only 13% in task scheduling delay and 5% in resource utilization.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Modeling the Parallel Execution of Black-Box Services
HotCloud, Usenix (2011)
[u'Gideon Mann', u'Mark Sandler', u'Darja Krushevskaja', u'Sudipto Guha', u'Eyal Even-Dar']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42554.html
found
=========================
Perspectives on cloud computing: interviews with five leading scientists from the cloud community
Journal of Internet Services and Applications (2011)
[u'Gordon Blair', u'Fabio Kon', u'Walfredo Cirne', u'Dejan Milojicic', u'Raghu Ramakrishnan', u'Dan Reed', u'Dilma Silva']
DistributedSystemsandParallelComputing
Abstract: Cloud computing is currently one of the major topics in dis- tributed systems, with large numbers of papers being writ- ten on the topic, with major players in the industry releasing a range of software platforms offering novel Internet-based services and, most importantly, evidence of real impact on end user communities in terms of approaches to provision- ing software services. Cloud computing though is at a for- mative stage, with a lot of hype surrounding the area, and this makes it difficult to see the true contribution and impact of the topic. Cloud computing is a central topic for the Journal of In- ternet Services and Applications (JISA) and indeed the most downloaded paper from the first year of JISA is concerned with the state-of-the-art and research challenges related to cloud computing [1]. The Editors-in-Chief, Fabio Kon and Gordon Blair, therefore felt it was timely to seek clarifica- tion on the key issues around cloud computing and hence invited five leading scientists from industrial organizations central to cloud computing to answer a series of questions on the topic. The five scientists taking part are: Walfredo Cirne, from Googles infrastructure group in California, USA Dejan Milojicic, Senior Researcher and Director of the Open Cirrus Cloud Computing testbed at HP Labs Raghu Ramakrishnan, Chief Scientist for Search and Cloud Platforms at Yahoo! Dan Reed, Microsofts Corporate Vice President for Tech- nology Strategy and Policy and Extreme Computing Dilma Silva, researcher at the IBM T.J. Watson Research Center, in New York
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37222.html
found
=========================
PowerNap: An Energy Efficient MAC Layer for Random Routing in Wireless Sensor Networks
IEEE SECON 2011
[u'Onur Soysal', u'Sami Ayyorgun', u'Murat Demirbas']
DistributedSystemsandParallelComputing
Abstract: Idle-listening is the biggest challenge for energyefciency and longevity of multihop wireless sensor network (WSN) deployments. While existing coordinated sleep/wakeup scheduling protocols eliminate idle-listening for simple trafc patterns, they are unsuitable to handle the complex trafc patterns of the random routing protocols. We present a novel coordinated sleep/wakeup protocol POWERNAP , which avoids the overhead of distributing complex, large sleep/wakeup scheduling information to the nodes. POWERNAP piggybacks onto the relayed data packets the seed of the pseudo-random generator that encodes the scheduling information, and enables any recipient/snooper to calculate its sleep/wakeup schedule from this seed. In essence, POWERNAP trades off doing extra computation in order to avoid expensive control packet transmissions. We show through simulations and real implementation on TelosB motes that POWERNAP eliminates the idle-listening problem efciently and achieves selfstabilizing, low-latency, and low-cost relaying of data packets for random routing protocols.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37200.html
found
=========================
Tenzing A SQL Implementation On The MapReduce Framework
Proceedings of VLDB, VLDB Endowment (2011), pp. 1318-1327
[u'Biswapesh Chattopadhyay', u'Liang Lin', u'Weiran Liu', u'Sagar Mittal', u'Prathyusha Aragonda', u'Vera Lychagina', u'Younghee Kwon', u'Michael Wong']
DistributedSystemsandParallelComputing
Abstract: Tenzing is a query engine built on top of MapReduce for ad hoc analysis of Google data. Tenzing supports a mostly complete SQL implementation (with several extensions) combined with several key characteristics such as heterogeneity, high performance, scalability, reliability, metadata awareness, low latency, support for columnar storage and structured data, and easy extensibility. Tenzing is currently used internally at Google by 1000+ employees and serves 10000+ queries per day over 1.5 petabytes of compressed data. In this paper, we describe the architecture and implementation of Tenzing, and present benchmarks of typical analytical queries.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37047.html
found
=========================
The Emerging Optical Data Center
OFC 2011, OTuH2
[u'Amin Vahdat', u'Hong Liu', u'Xiaoxue Zhao', u'Chris Johnson']
DistributedSystemsandParallelComputing
Abstract: We review the architecture of modern datacenter networks, as well as their scaling challenges; then present high-level requirements for deploying optical technologies in datacenters, particularly focusing on optical circuit switching and WDM transceivers.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37474.html
found
=========================
Thialfi: A Client Notification Service for Internet-Scale Applications
Proc. 23rd ACM Symposium on Operating Systems Principles (SOSP) (2011), pp. 129-142
[u'Atul Adya', u'Gregory Cooper', u'Daniel Myers', u'Michael Piatek']
DistributedSystemsandParallelComputing
Abstract: Ensuring the freshness of client data is a fundamental problem for applications that rely on cloud infrastructure to store data and mediate sharing. Thialfi is a notification service developed at Google to simplify this task. Thialfi supports applications written in multiple programming languages and running on multiple platforms, e.g., browsers, phones, and desktops. Applications register their interest in a set of shared objects and receive notifications when those objects change. Thialfi servers run in multiple Google data centers for availability and replicate their state asynchronously. Thialfi's approach to recovery emphasizes simplicity: all server state is soft, and clients drive recovery and assist in replication. A principal goal of our design is to provide a straightforward API and good semantics despite a variety of failures, including server crashes, communication failures, storage unavailability, and data center failures. Evaluation of live deployments confirms that Thialfi is scalable, efficient, and robust. In production use, Thialfi has scaled to millions of users and delivers notifications with an average delay of less than one second.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37206.html
found
=========================
Warehouse-scale Computing: entering the teenage decade
Association for Computing Machinery (2011)
[u'Luiz Andr Barroso']
DistributedSystemsandParallelComputing
Abstract: Video recording of a plenary talk delivered at the 2011 ACM Federated Computing Research Conference, focusing on some important challenges awaiting programmers and designers of Warehouse-scale Computers as it enters its second decade. June 8, 2011, San Jose, CA.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Analyzing and enhancing the parallel sort operation on multithreaded architectures
The Journal of Supercomputing, vol. 53 (2010), pp. 293-312
[u'Layali K. Rashid', u'Wessam Hassanein', u'Moustafa A. Hammad']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Anti-Omega: the weakest failure detector for set agreement
Distributed Computing, vol. 22 (2010), pp. 335-348
[u'Piotr Zielinski']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36737.html
found
=========================
Availability in Globally Distributed Storage Systems
Proceedings of the 9th USENIX Symposium on Operating Systems Design and Implementation, USENIX (2010)
[u'Daniel Ford', u'Francois Labelle', u'Florentina Popovici', u'Murray Stokely', u'Van-Anh Truong', u'Luiz Barroso', u'Carrie Grimes', u'Sean Quinlan']
DistributedSystemsandParallelComputing
Abstract: Highly available cloud storage is often implemented with complex, multi-tiered distributed systems built on top of clusters of commodity servers and disk drives. Sophisticated management, load balancing and recovery techniques are needed to achieve high performance and availability amidst an abundance of failure sources that include software, hardware, network connectivity, and power issues. While there is a relative wealth of failure studies of individual components of storage systems, such as disk drives, relatively little has been reported so far on the overall availability behavior of large cloud-based storage services. We characterize the availability properties of cloud storage systems based on an extensive one year study of Google's main storage infrastructure and present statistical models that enable further insight into the impact of multiple design choices, such as data placement and replication strategies. With these models we compare data availability under a variety of system parameters given the real patterns of failures observed in our fleet.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36356.html
found
=========================
Dapper, a Large-Scale Distributed Systems Tracing Infrastructure
Google, Inc. (2010)
[u'Benjamin H. Sigelman', u'Luiz Andr Barroso', u'Mike Burrows', u'Pat Stephenson', u'Manoj Plakal', u'Donald Beaver', u'Saul Jaspan', u'Chandan Shanbhag']
DistributedSystemsandParallelComputing
Abstract: Modern Internet services are often implemented as complex, large-scale distributed systems. These applications are constructed from collections of software modules that may be developed by different teams, perhaps in different programming languages, and could span many thousands of machines across multiple physical facili- ties. Tools that aid in understanding system behavior and reasoning about performance issues are invaluable in such an environment. Here we introduce the design of Dapper, Googles production distributed systems tracing infrastructure, and describe how our design goals of low overhead, application-level transparency, and ubiquitous deployment on a very large scale system were met. Dapper shares conceptual similarities with other tracing systems, particularly Magpie [3] and X-Trace [12], but certain design choices were made that have been key to its success in our environment, such as the use of sampling and restricting the instrumentation to a rather small number of common libraries. The main goal of this paper is to report on our experience building, deploying and using the system for over two years, since Dappers foremost measure of success has been its usefulness to developer and operations teams. Dapper began as a self-contained tracing tool but evolved into a monitoring platform which has enabled the creation of many different tools, some of which were not anticipated by its designers. We describe a few of the analysis tools that have been built using Dapper, share statistics about its usage within Google, present some example use cases, and discuss lessons learned so far.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36626.html
found
=========================
Datacenter-scale Computing
IEEE Micro, vol. 30 (2010), pp. 6-7
[u'Luiz Andr Barroso', u'Parthasarathy Ranganathan']
DistributedSystemsandParallelComputing
Abstract: Although the field of datacenter computing is arguably still in its relative infancy, a sizable body of work from both academia and industry is already available and some consistent technological trends have begun to emerge. This special issue presents a small sample of the work underway by researchers and professionals in this new field. The selection of articles presented reflects the key role that hardware-software codesign plays in the development of effective datacenter-scale computer systems.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36632.html
found
=========================
Dremel: Interactive Analysis of Web-Scale Datasets
Proc. of the 36th Int'l Conf on Very Large Data Bases (2010), pp. 330-339
[u'Sergey Melnik', u'Andrey Gubarev', u'Jing Jing Long', u'Geoffrey Romer', u'Shiva Shivakumar', u'Matt Tolton', u'Theo Vassilakis']
DistributedSystemsandParallelComputing
Abstract: Dremel is a scalable, interactive ad-hoc query system for analysis of read-only nested data. By combining multi-level execution trees and columnar data layout, it is capable of running aggregation queries over trillion-row tables in seconds. The system scales to thousands of CPUs and petabytes of data, and has thousands of users at Google. In this paper, we describe the architecture and implementation of Dremel, and explain how it complements MapReduce-based computing. We present a novel columnar storage representation for nested records and discuss experiments on few-thousand node instances of the system.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35650.html
found
=========================
FlumeJava: Easy, Efficient Data-Parallel Pipelines
ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI), ACM New York, NY 2010, 2 Penn Plaza, Suite 701 New York, NY 10121-0701 (2010), pp. 363-375
[u'Craig Chambers', u'Ashish Raniwala', u'Frances Perry', u'Stephen Adams', u'Robert Henry', u'Robert Bradshaw', u'Nathan']
DistributedSystemsandParallelComputing
Abstract: MapReduce and similar systems significantly ease the task of writing data-parallel code. However, many real-world computations require a pipeline of MapReduces, and programming and managing such pipelines can be difficult. We present FlumeJava, a Java library that makes it easy to develop, test, and run efficient dataparallel pipelines. At the core of the FlumeJava library are a couple of classes that represent immutable parallel collections, each supporting a modest number of operations for processing them in parallel. Parallel collections and their operations present a simple, high-level, uniform abstraction over different data representations and execution strategies. To enable parallel operations to run effi- ciently, FlumeJava defers their evaluation, instead internally constructing an execution plan dataflow graph. When the final results of the parallel operations are eventually needed, FlumeJava first optimizes the execution plan, and then executes the optimized operations on appropriate underlying primitives (e.g., MapReduces). The combination of high-level abstractions for parallel data and computation, deferred evaluation and optimization, and efficient parallel primitives yields an easy-to-use system that approaches the effi- ciency of hand-optimized pipelines. FlumeJava is in active use by hundreds of pipeline developers within Google. Categories and Subject Descriptors D.1.3 [Concurrent Programming]: Parallel Programming General Terms Algorithms, Languages, Performance Keywords data-parallel programming, MapReduce, Java
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36726.html
found
=========================
Large-scale Incremental Processing Using Distributed Transactions and Notifications
Proceedings of the 9th USENIX Symposium on Operating Systems Design and Implementation, USENIX (2010)
[u'Daniel Peng', u'Frank Dabek']
DistributedSystemsandParallelComputing
Abstract: Updating an index of the web as documents are crawled requires continuously transforming a large repository of existing documents as new documents arrive. This task is one example of a class of data processing tasks that transform a large repository of data via small, independent mutations. These tasks lie in a gap between the capabilities of existing infrastructure. Databases do not meet the storage or throughput requirements of these tasks: Google's indexing system stores tens of petabytes of data and processes billions of updates per day on thousands of machines. MapReduce and other batch-processing systems cannot process small updates individually as they rely on creating large batches for efficiency. We have built Percolator, a system for incrementally processing updates to a large data set, and deployed it to create the Google web search index. By replacing a batch-based indexing system with an indexing system based on incremental processing using Percolator, we process the same number of documents per day, while reducing the average age of documents in Google search results by 50%.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36682.html
found
=========================
Mahout in Action
Manning, Manning Publications Co. Sound View Ct. #3B Greenwich, CT 06830 (2010), pp. 350
[u'Robin Anil', u'Sean Owen', u'Ted Dunning', u'Ellen Friedman']
DistributedSystemsandParallelComputing
Abstract: A computer system that learns and adapts as it collects data is an extraordinarily interesting and powerful concept. With new technologies to capture, store, and process information, machine learning has moved from the academic edges of computer science to the middle of the mainstream. Mahout, an open source machine learning library, captures the core algorithms of recommendation systems, classification, and clustering in ready-to-use, scalable libraries. With Mahout, you can immediately apply the machine learning techniques that drive Amazon, Netflix, and other data-centric businesses to your own projects. Mahout in Action explores machine learning through Apache's scalable machine learning project, Mahout. Following real-world examples, it introduces practical use cases, and then illustrates how Mahout can be applied to solve them. It places particular focus on issues of scalability, and how to apply these techniques against large data sets using the Apache Hadoop framework. In this book, you'll use Mahout to dive into three practical applications of machine learning: Recommendations. Using group user history and preferences you can make accurate recommendations for individual users. This is an extremely powerful principle, because accurate recommendations are beneficial both to customers and vendors. Clustering. Learn to automatically discover logical groupings with groups of data or data sets, such as documents or lists. This technique is especially useful to search and data mining applications. Classification. Determining on the fly whether a thing fits a category based on its attributes and previous history can help instantaneously organize unstructured groups. For instance, you'll learn about filtering techniques that decide whether email messages should be considered "spam." Mahout in Action is written primarily for developers who need to become better practitioners of machine learning techniques. It is also appropriate for researchers who understand the techniques and want to understand how to apply them effectively at scale. It assumes familiarity with Java, and some basic grounding in machine learning techniques, but no previous exposure to Mahout is necessary.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
MapReduce: a flexible data processing tool
Commun. ACM, vol. 53 (2010), pp. 72-77
[u'Jeffrey Dean', u'Sanjay Ghemawat']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36941.html
found
=========================
Optimizing Utilization of Resource Pools in Web Application Servers
Concurrency and Computation: Practice and Experience, vol. 22 (2010), pp. 2421-2444
[u'Alexander Totok', u'Vijay Karamcheti']
DistributedSystemsandParallelComputing
Abstract: Among the web application server resources, most critical for its performance are those that are held exclusively by a service request for the duration of its execution (or some significant part of it). Such exclusively-held server resources become performance bottleneck points, with failures to obtain such a resource constituting a major portion of request rejections under server overload conditions. In this paper, we propose a methodology that computes the optimal pool sizes for two such critical resources: web server threads and database connections. Our methodology uses information about incoming request flow and about fine-grained server resource utilization by service requests of different types, obtained through offline and online request profiling. In our methodology, we advocate (and show its benefits) the use of a database connection pooling mechanism that caches database connections for the duration of a service request execution (so-called request-wide database connection caching). We evaluate our methodology by testing it on the TPC-W web application. Our method is able to accurately compute the optimal number of server threads and database connections, and the value of sustainable request throughput computed by the method always lies within a 5% margin of the actual value determined experimentally.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41688.html
found
=========================
PRESS: PRedictive Elastic ReSource Scaling for cloud systems
6th IEEE/IFIP International Conference on Network and Service Management (CNSM 2010), Niagara Falls, Canada
[u'Zhenhuan Gong', u'Xiaohui Gu', u'John Wilkes']
DistributedSystemsandParallelComputing
Abstract: Cloud systems require elastic resource allocation to minimize resource provisioning costs while meeting service level objectives (SLOs). In this paper, we present a novel {\em PRedictive Elastic reSource Scaling} (PRESS) scheme for cloud systems. PRESS unobtrusively extracts ne-grained dynamic patterns in application resource demands and adjust their resource allocations automatically. Our approach leverages light-weight signal processing and statistical learning algorithms to achieve online predictions of dynamic application resource requirements. We have implemented the PRESS system on Xen and tested it using RUBiS and an application load trace from Google. Our experiments show that we can achieve good resource prediction accuracy with less than 5\% over-estimation error and near zero under-estimation error, and elastic resource scaling can both signicantly reduce resource waste and SLO violations.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Warehouse Scale Computing - A keynote address to SIGMOD'10
Proceedings of the 2010 ACM SIGMOD International Conference on Management of data (2010)
[u'Luiz Andr Barroso']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36232.html
found
=========================
A unified format for traces of peer-to-peer systems
LSAP '09: Proceedings of the 1st ACM workshop on Large-Scale system and application performance, ACM, New York, NY, USA (2009), pp. 27-34
[u'Boxun Zhang', u'Alexandru Iosup', u'Pawel Garbacki', u'Johan Pouwelse']
DistributedSystemsandParallelComputing
Abstract: Peer-to-Peer (P2P) systems have recently emerged as a scalable platform for which costs are shared between the system users. Today, P2P technology is serving millions of users world-wide, with applications such as file sharing, video streaming, grid computing, and massively multiplayer online games. Such diversity and scale pose important research and technical problems, which in turn require a much better understanding of the usage patterns and of the performance bottlenecks. However, the large amounts of P2P monitoring and measurement data that already exist have not been made public, for fear of lack of anonymity and in lack of a standard format. To address this problem, in this work we propose a unified format for workloads of P2P systems. Our format stores information coming from many types of P2P applications at several levels of detail, has a structure that balances generic and application-specific data, and protects the anonymity of the peers whose personal information was captured in monitoring and measurement data. Using two large traces taken from real P2P systems we show evidence of the usefulness of the proposed format, and substantiate the hope that our unified format has the potential to become a standard for sharing P2P traces.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35127.html
found
=========================
Causeway: a message-oriented distributed debugger
HP Labs (2009)
[u'Terry Stanley', u'Tyler Close', u'Mark S. Miller']
DistributedSystemsandParallelComputing
Abstract: An increasing number of developers face the difficult task of debugging distributed asynchronous programs. This trend has outpaced the development of adequate debugging tools and currently, the best option for many is an ad hoc patchwork of sequential tools and printf debugging. This paper presents Causeway, a postmortem distributed debugger that demonstrates a novel approach to understanding the behavior of a distributed program. Our message-oriented approach borrows an effective strategy from sequential debugging: To find the source of unintended side- effects, start with the chain of expressed intentions. We show how Causeway's integrated views - describing both distributed and sequential computation - help users navigate causal pathways as they pursue suspicions. We highlight Causeway's innovative features which include adaptive, customizable event abstraction mechanisms and graphical views that follow message flow across process and machine boundaries.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Machine Learning-Based Prefetch Optimization for Data Center Applications
Proceedings of Supercomputing (2009)
[u'Shih-wei Liao', u'Tzu-Han Hung', u'Donald Nguyen', u'Chinyen Chou', u'Chiaheng Tu', u'Hucheng Zhou']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36249.html
found
=========================
MapReduce: The programming model and practice
SIGMETRICS (2009)
[u'Jerry Zhao', u'Jelena Pjesivac-Grbovic']
DistributedSystemsandParallelComputing
Abstract: Inspired by similar concepts in functional languages dated as early as 60's, Google first introduced MapReduce in 2004. Now, MapReduce has become the most popular framework for large-scale data processing at Google and it is becoming the framework of choice on many off-the-shelf clusters. In this tutorial, we first introduce the MapReduce programming model, illustrating its power by couple of examples. We discuss the MapReduce and its relationship to MPI and DBMS. Performance is a key feature of the Google MapReduce implementation and we will discus a few techniques used to achieve this goal. Google MapReduce exploits data locality to reduce network overhead. We utilize different scheduling techniques to ensure a job is progressing in the presence of variable system load. Finally, since failures are common in our data centers, we provide a number of failure avoidance and recovery features to ensure the job completion in such environment.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Parallel algorithms for mining large-scale rich-media data
MM '09: Proceedings of the seventeen ACM international conference on Multimedia, ACM, New York, NY, USA (2009), pp. 917-918
[u'Edward Y. Chang', u'Hongjie Bai', u'Kaihua Zhu']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Prefetch optimizations on large-scale applications via parameter value prediction
ICS (2009), pp. 519-520
[u'Shih-wei Liao', u'Tzu-Han Hung', u'Donald Nguyen', u'Hucheng Zhou', u'Chinyen Chou', u'Chiaheng Tu']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Pregel: A System for Large-Scale Graph Processing
28th ACM Symposium on Principles of Distributed Computing (2009), pp. 6-6
[u'Grzegorz Malewicz', u'Matthew H. Austern', u'Aart J.C. Bik', u'James C. Dehnert', u'Ilan Horn', u'Naty Leiser', u'Grzegorz Czajkowski']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
The Best of CCGrid'2007: A Snapshot of an 'Adolescent' Area
Concurrency and Computation: Practice and Experience, vol. 21 (2009)
[u'Walfredo Cirne', u'Bruno Schulze']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35115.html
found
=========================
Using a Market Economy to Provision Compute Resources Across Planet-wide Clusters
Proceedings for the International Parallel and Distributed Processing Symposium 2009, IEEE, pp. 1-8
[u'Murray Stokely', u'Jim Winget', u'Ed Keyes', u'Carrie Grimes', u'Benjamin Yolken']
DistributedSystemsandParallelComputing
Abstract: We present a practical, market-based solution to the resource provisioning problem in a set of heterogeneous resource clusters. We focus on provisioning rather than immediate scheduling decisions to allow users to change long-term job specifications based on market feedback. Users enter bids to purchase quotas, or bundles of resources for long-term use. These requests are mapped into a simulated clock auction which determines uniform, fair resource prices that balance supply and demand. The reserve prices for resources sold by the operator in this auction are set based on current utilization, thus guiding the users as they set their bids towards under-utilized resources. By running these auctions at regular time intervals, prices fluctuate like those in a real-world economy and provide motivation for users to engineer systems that can best take advantage of available resources. These ideas were implemented in an experimental resource market at Google. Our preliminary results demonstrate an efficient transition of users from more congested resource pools to less congested resources. The disparate engineering costs for users to reconfigure their jobs to run on less expensive resource pools was evidenced by the large price premiums some users were willing to pay for more expensive resources. The final resource allocations illustrated how this framework can lead to significant, beneficial changes in user behavior, reducing the excessive shortages and surpluses of more traditional allocation methods.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42243.html
found
=========================
Why Locally-Fair Maximal Flows in Client-Server Networks Perform Well
Computing and Combinatorics, Springer Berlin Heidelberg, 12715 NE 81st PL (2009), pp. 368-377
[u'Chad Yoshikawa', u'Ken Berman']
DistributedSystemsandParallelComputing
Abstract: Maximal flows reach at least a 1/2 approximation of the maximum flow in client-server networks. By adding only 1 additional time round to any distributed maximal flow algorithm we show how this 1/2-approximation can be improved on bounded-degree networks. We call these modified maximal flows locally fair since there is a measure of fairness prescribed to each client and server in the network. Let N=(U,V,E,b) represent a client-server network with clients U, servers V, network links E, and node capacities b, where we assume that each capacity is at least one unit. Let d(u) denote the b-weighted degree of any node uUV, = max {d(u) | uU } and = min { d(v) | vV }. We show that a locally-fair maximal flow f achieves an approximation to the maximum flow of min{1,222 }, and this result is sharp for any given integers and . This results are of practical importance since local-fairness loosely models the steady-state behavior of TCP/IP and these types of degree-bounds often occur naturally (or are easy to enforce) in real client-server systems.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Anti-Omega: the weakest failure detector for set agreement
27th ACM Symposium on Principles of Distributed Computing (PODC 2008)
[u'Piotr Zielinski']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Enhancing Community Authorization Services
16th Euromicro International Conference on Parallel, Distributed and network-based Processing, IEEE Computer Society (2008) (to appear)
[u'Kumar Abhishek', u'Kumar Kapil']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Extending IC-Scheduling via the Sweep Algorithm
16th Euromicro International Conference on Parallel, Distributed and Network-Based Processing (2008), pp. 366-373
[u'Gennaro Cordasco', u'Grzegorz Malewicz', u'Arnold L. Rosenberg']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
MapReduce: Simplified Data Processing on Large Clusters
Communications of the ACM, vol. 51, no. 1 (2008), pp. 107-113
[u'Jeffrey Dean', u'Sanjay Ghemawat']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34703.html
found
=========================
Parallel Spectral Clustering
European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML/PKDD), Springer (2008), pp. 374-389
[u'Yangqiu Song', u'Wen-Yen Chen', u'Hongjie Bai', u'Chih-Jen Lin', u'Edward Chang']
DistributedSystemsandParallelComputing
Abstract: Spectral clustering algorithm has been shown to be more eective in nding clusters than most traditional algorithms. However, spectral clustering suers from a scalability problem in both memory use and computational time when a dataset size is large. To perform clustering on large datasets, we propose to parallelize both memory use and computation on distributed computers. Through an empirical study on a large document dataset of 193,844 data instances and a large photo dataset of 637,137, we demonstrate that our parallel algorithm can effectively alleviate the scalability problem.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Physics Aware Programming Paradigm: Approach and Evaluation
Proc. 6th International Workshop on Challenges of Large Applications in Distributed Environments, ACM, Boston (2008), pp. 1-6
[u'Salim Hariri', u'Yaser Jararweh', u'Yeliang Zhang', u'Talal Moukabary']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
RaWMS - Random Walk based Lightweight Membership Service for Wireless Ad Hoc Networks
ACM Transactions on Computer Systems, vol. 26 (2008), pp. 1-66
[u'Ziv Bar-Yossef', u'Roy Friedman', u'Gabi Kliot']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub33386.html
found
=========================
Age-based Packet Arbitration in Large k-ary n-cubes
SC (2007)
[u'Dennis Abts', u'Deborah Weisser']
DistributedSystemsandParallelComputing
Abstract: As applications scale to increasingly large processor counts, the interconnection network is frequently the limiting factor in application performance. In order to achieve application scalability, the interconnect must maintain high bandwidth while minimizing variation in packet latency. As the offered load in the network increases with growing problem sizes and processor counts, so does the expected maximum packet latency in the network, directly impacting performance of applications with any synchronized communication. Age-based packet arbitration reduces the variance in packet latency as well as average latency. This paper describes the Cray XT router packet aging algorithm which allows globally fair arbitration by incorporating age in the packet output arbitration. We describe the parameters of the aging algorithm and how to arrive at appropriate settings. We show that an efficient aging algorithm reduces both the average packet latency and the variance in packet latency on communication-intensive benchmarks.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Applying IC-Scheduling Theory to Familiar Classes of Computations
Workshop on Large-Scale and Volatile Desktop Grids in conjunction with IPDPS'07 (2007), pp. 1-8
[u'Gennaro Cordasco', u'Grzegorz Malewicz', u'Arnold L. Rosenberg']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Architect's dream or developer's nightmare?
Proc. 2007 inaugural international conference on distributed event-based systems, ACM, Toronto, pp. 188-188
[u'Gregor Hohpe']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Distributed Programming with MapReduce
Beautiful Code, O'Reilly (2007), Chapter 23
[u'Jeffrey Dean', u'Sanjay Ghemawat']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub32583.html
found
=========================
Engineering Reliability into Web Sites: Google SRE
Proceedings of LinuxWorld (2007)
[u'Alexander R. Perry']
DistributedSystemsandParallelComputing
Abstract: This talk introduces Site Reliability Engineering (SRE) at Google, explaining its purpose and describing the challenges it addresses. SRE teams in Mountain View, Zrich, New York, Santa Monica, Dublin and Kirkland manage Google's many services and websites. They draw upon the Linux based computing resources that are distributed in data centers around the world.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Large Language Models in Machine Translation
Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), pp. 858-867
[u'Thorsten Brants', u'Ashok C. Popat', u'Peng Xu', u'Franz J. Och', u'Jeffrey Dean']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Let's Have a Conversation
IEEE Internet Computing, vol. 11, no. 3 (2007), pp. 78-81
[u'Gregor Hohpe']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37207.html
found
=========================
MRPSO: MapReduce Particle Swarm Optimization
Proceedings of the Genetic and Evolutionary Computation Conference (GECCO 2007), IEEE
[u'Andrew W. McNabb', u'Christopher K. Monson', u'Kevin D. Seppi']
DistributedSystemsandParallelComputing
Abstract: Abstract In optimization problems involving large amounts of data, such as web content, commercial transaction information, or bioinformatics data, individual function evaluations may take minutes or even hours. Particle Swarm Optimization (PSO) must be parallelized for such functions. However, large-scale parallel programs must communicate efciently, balance work across all processors, and address problems such as failed nodes. We present MapReduce Particle Swarm Optimization (MRPSO), a PSO implementation based on the MapReduce parallel programming model. We describe MapReduce and show how PSO can be naturally expressed in this model, without explicitly addressing any of the details of parallelization. We present a benchmark function for evaluating MRPSO and note that MRPSO is not appropriate for optimizing easily evaluated functions. We demonstrate that MRPSO scales to 256 processors on moderately difcult problems and tolerates node failures.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Parallel Approximate Matrix Factorization for Kernel Methods
IEEE International Conference on Multimedia and Expo(ICME) (2007)
[u'Kaihua Zhu', u'Hang Cui', u'Hongjie Bai', u'Jian Li', u'Zhihuan Qiu', u'Hao Wang', u'Hui Xu', u'Edward Y. Chang']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Parallel PSO Using MapReduce
Proceedings of the IEEE Congress on Evolutionary Computation, IEEE Press (2007), pp. 7-14
[u'Andrew W. McNabb', u'Christopher K. Monson', u'Kevin D. Seppi']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34638.html
found
=========================
Parallelizing Support Vector Machines on Distributed Computers
Neural Information Processing Systems (NIPS) (2007)
[u'Edward Y. Chang', u'Kaihua Zhu', u'Hao Wang', u'Hongjie Bai', u'Jian Li', u'Zhihuan Qiu', u'Hang Cui']
DistributedSystemsandParallelComputing
Abstract: We also open-source this work at: http://code.google.com/p/psvm/.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub33002.html
found
=========================
Paxos Made Live - An Engineering Perspective (2006 Invited Talk)
Proceedings of the 26th Annual ACM Symposium on Principles of Distributed Computing, ACM press (2007)
[u'Tushar Deepak Chandra', u'Robert Griesemer', u'Joshua Redstone']
DistributedSystemsandParallelComputing
Abstract: We describe our experience in building a fault-tolerant data-base using the Paxos consensus algorithm. Despite the existing literature in the field, building such a database proved to be non-trivial. We describe selected algorithmic and engineering problems encountered, and the solutions we found for them. Our measurements indicate that we have built a competitive system.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Tool for Prioritizing DAGMan Jobs and Its Evaluation
Proceedings of the IEEE International Symposium on High-Performance Distributed Computing (HPDC06), Paris, France (2006), pp. 156-167
[u'Grzegorz Malewicz', u'Ian Foster', u'Arnold Rosenberg', u'Michael Wilde']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
An Autonomic Routing Framework for Sensor Networks
Cluster Computing, Special Issue on Autonomic Computing (Kluwer Academic Pulishers), vol. 9 (2006), pp. 191-200
[u'Yu He', u'Cauligi S. Raghavendra', u'Steven Berson', u'Robert Braden']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
An Experimental Study of the Skype Peer-to-Peer VoIP System
Proceedings of The 5th International Workshop on Peer-to-Peer Systems (IPTPS '06), Santa Barbara, CA (2006)
[u'Saikat Guha', u'Neil Daswani', u'Ravi Jain']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Bigtable: A Distributed Storage System for Structured Data
7th USENIX Symposium on Operating Systems Design and Implementation (OSDI), {USENIX} (2006), pp. 205-218
[u'Fay Chang', u'Jeffrey Dean', u'Sanjay Ghemawat', u'Wilson C. Hsieh', u'Deborah A. Wallach', u'Mike Burrows', u'Tushar Chandra', u'Andrew Fikes', u'Robert E. Gruber']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Data Management for Internet-Scale Single-Sign-On
Proceedings of the 3rd Workshop on Real, Large Distributed Systems, Usenix (2006)
[u'Sharon E. Perl', u'Margo Seltzer']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Experiences with MapReduce, an abstraction for large-scale computation
Proc. 15th International Conference on Parallel Architectures and Compilation Techniques, ACM, Seattle, WA (2006), pp. 1
[u'Jeffrey Dean']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Java Concurrency in Practice
Addison-Wesley, Boston, MA (2006)
[u'Brian Goetz', u'Tim Peierls', u'Joshua Bloch', u'Joseph Bowbeer', u'David Holmes', u'Doug Lea']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Minimizing the Stretch when Scheduling Flows of Biological Requests
Proceedings of the 18th ACM Symposium on Parallelism in Algorithms and Architectures (2006)
[u'Arnaud Legrand', u'Alan Su', u'Frdric Vivien']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
On Scheduling Expansive and Reductive Dags for Internet-Based Computing
26th IEEE International Conference on Distributed Computing Systems (2006), pp. 29
[u'Gennaro Cordasco', u'Grzegorz Malewicz', u'Arnold L. Rosenberg']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Simple Efficient Load-Balancing Algorithms for Peer-to-Peer Systems
Theory of Computing Systems, vol. 39, no. 6 (2006), pp. 787-804
[u'David R. Karger', u'Matthias Ruhl']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
The Chubby lock service for loosely-coupled distributed systems
7th USENIX Symposium on Operating Systems Design and Implementation (OSDI), {USENIX} (2006)
[u'Mike Burrows']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Decentralized algorithms using both local and random probes for P2P load balancing
SPAA 2005 (17th ACM Symposium on Parallelism in Algorithms an Architectures), pp. 135-144
[u'Krishnaram Kenthapadi', u'Gurmeet Singh Manku']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub61.html
found
=========================
Interpreting the Data: Parallel Analysis with Sawzall
Scientific Programming Journal, vol. 13 (2005), pp. 277-298
[u'Rob Pike', u'Sean Dorward', u'Robert Griesemer', u'Sean Quinlan']
DistributedSystemsandParallelComputing
Abstract: Very large data sets often have a flat but regular structure and span multiple disks and machines. Examples include telephone call records, network logs, and web document repositories. These large data sets are not amenable to study using traditional database techniques, if only because they can be too large to fit in a single relational database. On the other hand, many of the analyses done on them can be expressed using simple, easily distributed computations: filtering, aggregation, extraction of statistics, and so on. We present a system for automating such analyses. A filtering phase, in which a query is expressed using a new programming language, emits data to an aggregation phase. Both phases are distributed over hundreds or even thousands of computers. The results are then collated and saved to a file. The design -- including the separation into two phases, the form of the programming language, and the properties of the aggregators -- exploits the parallelism inherent in having data and computation distributed across many machines. Animation: The paper references this movie showing how the distribution of requests to google.com around the world changed through the day on August 14, 2003.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Papillon: Greedy Routing in Rings
DISC (2005), pp. 514-515
[u'Ittai Abraham', u'Dahlia Malkhi', u'Gurmeet Singh Manku']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
MapReduce: Simplified Data Processing on Large Clusters
OSDI'04: Sixth Symposium on Operating System Design and Implementation, San Francisco, CA (2004), pp. 137-150
[u'Jeffrey Dean', u'Sanjay Ghemawat']
DistributedSystemsandParallelComputing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub49.html
found
=========================
Web Search for a Planet: The Google Cluster Architecture
IEEE Micro, vol. 23 (2003), pp. 22-28
[u'Luiz Andre Barroso', u'Jeffrey Dean', u'Urs Hlzle']
DistributedSystemsandParallelComputing
Abstract: Amenable to extensive parallelization, Google's Web search application lets different queries run on different processors and, by partitioning the overall index, also lets a single query use multiple processors. To handle this workload, Google's architecture features clusters of more than 15,000 commodity class PCs with fault-tolerant software. This architecture achieves superior performance at a fraction of the cost of a system built from fewer, but more expensive, high-end servers.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/EconomicsandElectronicCommerce.html
found
http://research.google.com/pubs/pub43457.html
found
=========================
AAPOR standard definition 8th edition
AAPOR (2015)
[u'Tom E. Smith', u'Rob Daves', u'Paul J. Lavrakas', u'Mick P. Couper', u'Timothy P. Johnson', u'Sara Zuckerbraun', u'Katherine Morton', u'David Dutwin', u'Mario Callegaro', u'Mansour Fahimi']
EconomicsandElectronicCommerce
Abstract: Background: For a long time, survey researchers have needed more comprehensive and reliable diagnostic tools to understand the components of total survey error. Some of those components, such as margin of sampling error, are relatively easily calculated and familiar to many who use survey research. Other components, such as the influence of question wording on responses, are more difficult to ascertain. Groves (1989) catalogues error into three other major potential areas in which it can occur in sample surveys. One is coverage, where error can result if some members of the population under study do not have a known nonzero chance of being included in the sample. Another is measurement effect, such as when the instrument or items on the instrument are constructed in such a way to produce unreliable or invalid data. The third is nonresponse effect, where nonrespondents in the sample that researchers originally drew differ from respondents inways that are germane to the objectives of the survey. Defining final disposition codes and calculating survey outcome rates is the topic for this booklet. Often it is assumed correctly or not that the lower the response rate, the more question there is about the validity of the sample. Although response rate information alone is not sufficient for determining how much nonresponse error exists in a survey, or even whether it exists, calculating the rates is a critical first step to understanding the presence of this component of potential survey error. By knowing the disposition of every element drawn in a survey sample, researchers can assess whether their sample might contain nonresponse error and the potential reasons for that error. With this report AAPOR offers a tool that can be used as a guide to one important aspect of a survey's quality. It is a comprehensive, well-delineated way of describing the final disposition of cases and calculating outcome rates for surveys conducted by telephone (landline and cell), for personal interviews in a sample of households, for mail surveys of specifically named persons (i.e., a survey in which named persons are the sampled elements), and for Web surveys. AAPOR urges all practitioners to use these standardized sample disposition codes in all reports of survey methods, no matter if the project is proprietary work for private sector clients or a public, government or academic survey. This will enable researchers to find common ground on which to compare the outcome rates for different surveys. The eighth edition (2015) was edited by Smith who chaired the committee of Daves, Lavrakas, Couper, and Johnson. The revised section on establishment surveys was developed by Sara Zuckerbraun and Katherine Morton. The new section on dual-frame telephone surveys was prepared by a sub-committee headed by Daves with Smith, David Dutwin, Mario Callegaro, and Mansour Fahimi as members.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44291.html
found
=========================
Advertising on YouTube and TV: A Meta-analysis of Optimal Media-mix Planning
Google, Inc. (2015), pp. 1-28 (to appear)
[u'Georg M. Goerg', u'Christoph Best', u'Sheethal Shobowale', u'Jim Koehler', u'Nicolas Remy']
EconomicsandElectronicCommerce
Abstract: In this work we investigate under what circumstances a TV campaign should be complemented with online advertising to increase combined reach. First, we use probabilistic models to derive necessary and sufficient conditions. We then test these optimality conditions on empirical findings of a large collection of TV campaigns to answer two important questions: i) which characteristics of a TV campaign make it favorable to shift part of its budget to online advertising?; and ii) if it should shift, how much cost savings and additional reach can advertisers expect? First, we use classification methods such as linear discriminant analysis, logistic regression, and decision trees to decide whether a TV campaign should add online advertising; secondly, we train linear and support vector regression models to predict optimal budget allocation, cost savings, or additional reach. To train these models we use optimization results on roughly 26,000 campaigns. We do not only achieve excellent out-of-sample predictive power, but also obtain simple, interpretable, and actionable rules that improve the understanding of media mix advertising.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43787.html
found
=========================
Cardinal Contests
Proceedings of the 24th International Conference on the World Wide Web (WWW) (2015), pp. 377-387
[u'Arpita Ghosh', u'Patrick Hummel']
EconomicsandElectronicCommerce
Abstract: Contests are widely used as a means for effort elicitation in settings ranging from government R&D contests to online crowdsourcing contests on platforms such as Kaggle, Innocentive, or TopCoder. Such rank-order mechanisms where agents' rewards depend only on the relative ranking of their submissions' qualitiesare natural mechanisms for incentivizing effort when it is easier to obtain ordinal, rather than cardinal, information about agents' outputs, or where absolute measures of quality are unverifiable. An increasing number of online contests, however, rank entries according to some numerical evaluation of their absolute qualityfor instance, the performance of an algorithm on a test dataset, or the performance of an intervention in a randomized trial. Can the contest designer incentivize higher effort by making the rewards in an ordinal rank-order mechanism contingent on such cardinal information? We model and analyze cardinal contests, where a principal running a rank-order tournament has access to an absolute measure of the qualities of agents' submissions in addition to their relative rankings, and ask how modifying the rank-order tournament to incorporate cardinal information can improve incentives for effort. Our main result is that a simple threshold mechanisma mechanism that awards the prize for a rank if and only if the absolute quality of the agent at that rank exceeds a certain thresholdis optimal amongst all mixed cardinal-ordinal mechanisms where the fraction of the j-th prize awarded to the j-th-ranked agent is any arbitrary non-decreasing function of her submission's quality. Further, the optimal threshold mechanism uses exactly the same threshold for each rank. We study what contest parameters determine the extent of the benefit from incorporating such cardinal information into an ordinal rank-order contest, and investigate the extent of improvement in equilibrium effort via numerical simulations.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43887.html
found
=========================
Focus on the Long-Term: It's better for Users and Business
Proceedings 21st Conference on Knowledge Discovery and Data Mining, ACM, Sydney, Australia (2015)
[u'Henning Hohnhold', u"Deirdre O'Brien", u'Diane Tang']
EconomicsandElectronicCommerce
Abstract: Over the past 10+ years, online companies large and small have adopted widespread A/B testing as a robust data-based method for evaluating potential product improvements. In online experimentation, it is straightforward to measure the short-term effect, i.e., the impact observed during the experiment. However, the short-term effect is not always predictive of the long-term effect, i.e., the final impact once the product has fully launched and users have changed their behavior in response. Thus, the challenge is how to determine the long-term user impact while still being able to make decisions in a timely manner. We tackle that challenge in this paper by first developing experiment methodology for quantifying long-term user learning. We then apply this methodology to ads shown on Google search, more specifically, to determine and quantify the drivers of ads blindness and sightedness, the phenomenon of users changing their inherent propensity to click on or interact with ads. We use these results to create a model that uses metrics measurable in the short-term to predict the long-term. We learn that user satisfaction is paramount: ads blindness and sightedness are driven by the quality of previously viewed or clicked ads, as measured by both ad relevance and landing page quality. Focusing on user satisfaction both ensures happier users but also makes business sense, as our results illustrate. We describe two major applications of our findings: a conceptual change to our search ads auction that further increased the importance of ads quality, and a 50% reduction of the ad load on Googles mobile search interface. The results presented in this paper are generalizable in two major ways. First, the methodology may be used to quantify user learning effects and to evaluate online experiments in contexts other than ads. Second, the ads blindness/sightedness results indicate that a focus on user satisfaction could help to reduce the ad load on the internet at large with long-term neutral, or even positive, business impact.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43451.html
found
=========================
How Many Millenials Visit YouTube? Estimating Unobserved Events From Incomplete Panel Data Conditioned on Demographic Covariates
TBD, Google, Inc. (2015), pp. 1-27 (to appear)
[u'Georg M. Goerg', u'Yuxue Jin', u'Nicolas Remy', u'Jim Koehler']
EconomicsandElectronicCommerce
Abstract: Many socio-economic studies rely on panel data as they also provide detailed demographic information about consumers. For example, advertisers use TV and web metering panels to estimate ads effectiveness in selected target demographics. However, panels often record only a fraction of all events due to non-registered devices, technical problems, or work usage. Goerg et al. (2015) present a beta-binomial negative-binomial hurdle (BBNBH) model to impute missing events in count data with excess zeros. In this work, we study empirical properties of the MLE for the BBNBH model, extend it to categorical covariates, introduce a penalized maximum likelihood estimator (MLE) to get accurate estimates by demographic group, and apply the methodology to a German media panel to learn about demographic patterns in the YouTube viewership.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43286.html
found
=========================
How Many People Visit YouTube? Imputing Missing Events in Panels With Excess Zeros
Google Inc. (2015), pp. 1-6
[u'Georg M. Goerg', u'Yuxue Jin', u'Nicolas Remy', u'Jim Koehler']
EconomicsandElectronicCommerce
Abstract: Media-metering panels track TV and online usage of people to analyze viewing behavior. However, panel data is often incomplete due to non-registered devices, non-compliant panelists, or work usage. We thus propose a probabilistic model to impute missing events in data with excess zeros using a negative-binomial hurdle model for the unobserved events and beta-binomial sub-sampling to account for missingness. We then use the presented models to estimate the number of people in Germany who visit YouTube.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41854.html
found
=========================
Inferring causal impact using Bayesian structural time-series models
Annals of Applied Statistics, vol. 9 (2015), pp. 247-274
[u'Kay H. Brodersen', u'Fabian Gallusser', u'Jim Koehler', u'Nicolas Remy', u'Steven L. Scott']
EconomicsandElectronicCommerce
Abstract: An important problem in econometrics and marketing is to infer the causal impact that a designed market intervention has exerted on an outcome metric over time. In order to allocate a given budget optimally, for example, an advertiser must assess to what extent different campaigns have contributed to an incremental lift in web searches, product installs, or sales. This paper proposes to infer causal impact on the basis of a diffusion-regression state-space model that predicts the counterfactual market response that would have occurred had no intervention taken place. In contrast to classical difference-in-differences schemes, state-space models make it possible to (i) infer the temporal evolution of attributable impact, (ii) incorporate empirical priors on the parameters in a fully Bayesian treatment, and (iii) flexibly accommodate multiple sources of variation, including the time-varying influence of contemporaneous covariates, i.e., synthetic controls. Using a Markov chain Monte Carlo algorithm for model inversion, we illustrate the statistical properties of our approach on synthetic data. We then demonstrate its practical utility by evaluating the effect of an online advertising campaign on search-related site visits. We discuss the strengths and limitations of state-space models in enabling causal attribution in those settings where a randomised experiment is unavailable. The CausalImpact R package provides an implementation of our approach.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43804.html
notfound
http://research.google.com/pubs/pub44167.html
notfound
=========================
Profile CBC: Using Conjoint Analysis for Consumer Profiles
Proceedings of the 18th Sawtooth Software Conference, Orlando, FL (2015), pp. 1-12
[u'Chris Chapman', u'Kate Krontiris', u'John Webb']
EconomicsandElectronicCommerce
Abstract: We investigate the usage of choice-based conjoint analysis (CBC) for sizing consumer profiles for a technology product area. Traditionally, technology research has often relied upon qualitative personas approaches that are difficult to assess quantitatively. We demonstrate that Profile CBC is able to find consumer profiles from tradeoffs of attributes derived from qualitative research, and yields replicable, specifically sized groups that are well differentiated on both intra-method and extra-method variables. We conclude that Profile CBC is a potentially useful addition to analysts' tools for investigating consumer profiles.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
R for marketing research and analytics: discussion
Joint Statistical Meetings (JSM) 2015, Seattle, WA
[u'Chris Chapman', u'Elea McDonnell Feit']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44262.html
notfound
=========================
Recent Books and Journals Articles in Public Opinion, Survey Methods, and Survey Statistics. 2015 Update
Survey Practice, vol. 8 (2015)
[u'Mario Callegaro']
EconomicsandElectronicCommerce
Abstract: Welcome to the 7th edition of this column on recent books and journal articles in the field of public opinion, survey methods, and survey statistics. This year I had the chance to visit the London book fair, so I was able actually to see some of the new books in our field. This article is an update of the April 2014 article. Like the previous year, the books are organized by topic; this should help the readers to focus on their interests. It is unlikely to list all new books in the field; I did my best scouting different resources and websites, but I take full responsibility for any omission. The list is also focusing only on books published in English language and available for purchase (as an Ebook or in print) at the time of this review (June 2015). Books are listed based on the relevance to the topic, and no judgment is made in terms of quality of the content. We let the readers do so. Given our field is becoming more and more interdisciplinary, this year I added a new section called big data, social media and other relevant books to capture areas that are overlapping more and more with public opinion, survey research, and survey statistics.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43815.html
found
=========================
Revenue Maximization for Selling Multiple Correlated Items
23rd Annual European Symposium on Algorithms (ESA), Springer-Verlag (2015)
[u'Mohammadhossein Bateni', u'Sina Dehghani', u'MohammadTaghi Hajiaghayi', u'Saeed Seddighin']
EconomicsandElectronicCommerce
Abstract: We study the problem of selling $n$ items to a single buyer with an additive valuation function. We consider the valuation of the items to be correlated, i.e., desirabilities of the buyer for the items are not drawn independently. Ideally, the goal is to design a mechanism to maximize the revenue. However, it has been shown that a revenue optimal mechanism might be very complicated and as a result inapplicable to real-world auctions. Therefore, our focus is on designing a simple mechanism that achieves a constant fraction of the optimal revenue. Babaioff et al. (FOCS'14) propose a simple mechanism that achieves a constant fraction of the optimal revenue for independent setting with a single additive buyer. However, they leave the following problem as an open question: "Is there a simple, approximately optimal mechanism for a single additive buyer whose value for $n$ items is sampled from a common base-value distribution?" Babaioff et al. show a constant approximation factor of the optimal revenue can be achieved by either selling the items separately or as a whole bundle in the independent setting. We show a similar result for the correlated setting when the desirabilities of the buyer are drawn from a common base-value distribution. It is worth mentioning that the core decomposition lemma which is mainly the heart of the proofs for efficiency of the mechanisms does not hold for correlated settings. Therefore we propose a modified version of this lemma which is applicable to the correlated settings as well. Although we apply this technique to show the proposed mechanism can guarantee a constant fraction of the optimal revenue in a very weak correlation, this method alone can not directly show the efficiency of the mechanism in stronger correlations. Therefore, via a combinatorial approach we reduce the problem to an auction with a weak correlation to which the core decomposition technique is applicable. In addition, we introduce a generalized model of correlation for items and show the proposed mechanism achieves an $O(\log k)$ approximation factor of the optimal revenue in that setting.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Revenue Maximization with Nonexcludable Goods
Transactions on Economics and Computation (2015)
[u'Mohammadhossein Bateni', u'Nima Haghpanah', u'Balasubramanian Sivan', u'Morteza Zadimoghaddam']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43811.html
notfound
=========================
Web Survey Methodology
Sage, London (2015), pp. 344
[u'Mario Callegaro', u'Katja Lozar Manfreda', u'Vasja Vehovar']
EconomicsandElectronicCommerce
Abstract: Web Survey Methodology guides the reader through the past fifteen years of research in web survey methodology. It both provides practical guidance on the latest techniques for collecting valid and reliable data and offers a comprehensive overview of research issues. Core topics from preparation to questionnaire design, recruitment testing to analysis and survey software are all covered in a systematic and insightful way. The reader will be exposed to key concepts and key findings in the literature, covering measurement, non-response, adjustments, paradata, and cost issues. The book also discusses the hottest research topics in survey research today, such as internet panels, virtual interviewing, mobile surveys and the integration with passive measurements, e-social sciences, mixed modes and business intelligence. The book is intended for students, practitioners, and researchers in fields such as survey and market research, psychological research, official statistics and customer satisfaction research. REVIEWS Comprehensive and thoughtful! Those two words beautifully describe this terrific book. Internet surveys will be at the centre of survey research for many decades to come, and this book is a must-read handbook for anyone serious about doing online surveys well or using data from such surveys. No stone is left unturned - the authors address every essential topic and do so with a remarkable command of the big picture and the subtleties involved. Readers will walk away with a clear understanding of the many challenges inherent in conducting online studies and with an appropriate sense of optimism about the promise of the methodology and how best to implement it. Jon Krosnick Frederic O. Glover Professor in Humanities and Social Sciences, Stanford University This is an excellent, academic standard, book that every serious market researcher should own and consult. The authors have compiled an immense amount of useful and well-referenced information about every aspect of web surveys, creating an invaluable resource. Ray Poynter Managing Director, The Future Place
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44183.html
notfound
=========================
What you should know about R
Marketing Insights (2015), pp. 12-13
[u'Chris Chapman']
EconomicsandElectronicCommerce
Abstract: A primer on the industrys open-source statistical analysis language.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43788.html
notfound
=========================
When Does Improved Targeting Increase Revenue?
Proceedings of the 24th International Conference on the World Wide Web (WWW) (2015), pp. 462-472
[u'Patrick Hummel', u'Preston McAfee']
EconomicsandElectronicCommerce
Abstract: In second-price auctions with symmetric bidders, we find that improved targeting via enhanced information disclosure decreases revenue when there are two bidders and increases revenue if there are at least four bidders. With asymmetries, improved targeting increases revenue if the most frequent winner wins less than 30.4% of the time, but can decrease revenue otherwise. We derive analogous results for position auctions. Finally, we show that revenue can vary non-monotonically with the number of bidders who are able to take advantage of improved targeting.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43431.html
notfound
=========================
Yesno answers versus check-all in self-administered modes. A systematic review and analyses
International Journal of Market Research, vol. 57 (2015), pp. 203-223
[u'Mario Callegaro', u'Mike Murakami', u'Ziv Tepman', u'Vani Henderson']
EconomicsandElectronicCommerce
Abstract: When writing questions with dichotomous response options, those administering surveys on the web or on paper can choose from a variety of formats, including a check-all-that-apply or a forced-choice format (e.g. yes-no) in self-administered questionnaires. These two formats have been compared and evaluated in many experimental studies. In this paper, we conduct a systematic review and a few meta-analyses of different aspects of the available research that compares these two formats. We find that endorsement levels increase by a factor of 1.42 when questions are posed in a forced-choice rather than check-all format. However, when comparing across a battery of questions, the rank order of endorsement rates remains the same for both formats. While most authors hypothesise that respondents endorse more alternatives presented in a forced-choice (versus check-all-that-apply) format because they process that format at a deeper cognitive level, we introduce the acquiescence bias hypothesis as an alternative and complementary explanation. Further research is required to identify which format elicits answers closer to the true level of endorsement, since the few validation studies have proved inconclusive.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
2014 Recent Books and Journals in Public Opinion, Survey Methods, and Survey Statistics
Survey Practice, vol. 7 (2014)
[u'Mario Callegaro']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43156.html
found
=========================
A Game-Theoretic Analysis of Rank-Order Mechanisms for User-Generated Content
Journal of Economic Theory, vol. 154 (2014), pp. 349-374
[u'Arpita Ghosh', u'Patrick Hummel']
EconomicsandElectronicCommerce
Abstract: We investigate the widely-used rank-order mechanism for displaying user-generated content, where contributions are displayed on a webpage in decreasing order of their ratings, in a game-theoretic model where strategic contributors benefit from attention and have a cost to quality. We show that the lowest quality elicited by this rank-order mechanism in any mixed-strategy equilibrium becomes optimal as the available attention diverges. Additionally, these equilibrium qualities are higher, with probability tending to 1 in the limit of diverging attention, than those elicited by a more equitable proportional mechanism which distributes attention in proportion to the positive ratings a contribution receives, but the proportional mechanism elicits a greater number of contributions than the rank-order mechanism.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42494.html
found
=========================
A critical review of studies investigating the quality of data obtained with online panels based on probability and nonprobability samples
Online Panel Research: A Data Quality Perspective, Wiley (2014), pp. 23-53
[u'Mario Callegaro', u'Ana Villar', u'David S. Yeager', u'Jon A. Krosnick']
EconomicsandElectronicCommerce
Abstract: his chapter provides an overview of studies comparing the quality of data collected by online survey panels by looking at three criteria: (1) comparisons of point estimates from online panels to high-quality, established population benchmarks; (2) comparisons of the relationship among variables; and (3) the reproducibility of results for online survey panels conducted on probability samples to panels conducted on nonprobability samples. When looking at point estimates, all online survey panels differed to some extent from the population benchmarks. However, the largest comparison studies suggest that point estimates from online panels of nonprobability samples have higher differences as compared to benchmarks than online panels of probability samples. This finding is consistent across time and across studies conducted in different countries. Moreover, post-stratification weighting strategies helped little and in an inconsistent way to reduce such differences for data coming from online panels of nonprobability samples, whereas these strategies did bring estimates from online panels of probability samples consistently closer to the benchmarks. When comparing relationships among variables, it was found that researchers would reach different conclusions when using online panels of nonprobability samples versus panels of probability samples. When looking at reproducibility of results, the limited evidence found suggests that there are no substantial differences in replication and effect size across probability and nonprobability samples for question wording experiments and when comparing students samples to other samples. It is worth noting that in pre-election polls, an area where abundant prior knowledge exists, online panels of nonprobability samples have consistently performed as well and in some cases better than polls based on probability samples in predicting election winners.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Biobjective Online Bipartite Matching
Workshop in Internet and Network Economics, Springer (2014), pp. 218-231
[u'Gagan Aggarwal', u'Yang Cai', u'Aranyak Mehta', u'George Pierrakos']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Clinching auctions beyond hard budget constraints
EC, ACM (2014)
[u'Gagan Goel', u'Vahab Mirrokni', u'Renato Paes Leme']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41926.html
found
=========================
Collaboration in the Cloud at Google
research.google.com (2014), pp. 1-13
[u'Yunting Sun', u'Diane Lambert', u'Makoto Uchida', u'Nicolas Remy']
EconomicsandElectronicCommerce
Abstract: Through a detailed analysis of logs of activity for all Google employees, this paper shows how the Google Docs suite (documents, spreadsheets and slides) enables and increases collaboration within Google. In particular, visualization and analysis of the evolution of Googles collaboration network show that new employees, have started collaborating more quickly and with more people as usage of Docs has grown. Over the last two years, the percentage of new employees who collaborate on Docs per month has risen from 70% to 90% and the percentage who collaborate with more than two people has doubled from 35% to 70%. Moreover, the culture of collaboration has become more open, with public sharing within Google overtaking private sharing.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Concise Bid Optimization Strategies with Multiple Budget Constraints
WINE, The 10th Conference on Web and Internet Economics (2014)
[u'Arash Asadpour', u'Mohammadhossein Bateni', u'Kshipra Bhawalkar', u'Vahab Mirrokni']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42246.html
found
=========================
Data enrichment for incremental reach estimation
Google Inc. (2014), pp. 1-21 (to appear)
[u'Aiyou Chen', u'Jim Koehler', u'Art Owen', u'Nicolas Remy', u'Minghui Shi']
EconomicsandElectronicCommerce
Abstract: There is increasing interest in measuring the overlap and/or incremental reach of cross-media campaigns. The direct method is to use a cross-media panel but these are expensive to scale across all media. Typically, the cross-media panel is too small to produce reliable estimates when the interest comes down to subsets of the population. An alternative is to combine information from a small cross-media panel with a larger, cheaper but potentially biased single media panel. In this article, we develop a data enrichment approach specifically for incremental reach estimation. The approach not only integrates information from both panels that takes into account potential panel bias, but borrows strength from modeling conditional dependence of cross-media reaches. We demonstrate the approach with data from six campaigns for estimating YouTube video ad incremental reach over TV. In a simulation directly modeled on the actual data, we find that data enrichment yields much greater accuracy than one would get by either ignoring the larger panel, or by using it in a data fusion.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43218.html
found
=========================
Estimating reach curves from one data point
Google Inc. (2014), pp. 1-7
[u'Georg M. Goerg']
EconomicsandElectronicCommerce
Abstract: Reach curves arise in advertising and media analysis as they relate the number of content impressions to the number of people who have seen it. This is especially important for measuring the effectiveness of an ad on TV or websites. For a mathematical and data-driven analysis, it would be very useful to know the entire reach curve; advertisers, however, often only know its last data point, i.e., the total number of impressions and the total reach. In this work I present a new method to estimate the entire curve using only this last data point. Furthermore, analytic derivations reveal a surprisingly simple, yet insightful relationship between marginal cost per reach, average cost per impression, and frequency. Thus, advertisers can estimate the cost of an additional reach point by just knowing their total number of impressions, reach, and cost. A comparison of the proposed one-data point method to two competing regression models on TV reach curve data, shows that the proposed methodology performs only slightly poorer than regression fits to a collection of several points along the curve.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42495.html
found
=========================
Internet and mobile ratings panels
Online Panel Research: A Data Quality Perspective, Wiley (2014), pp. 387-407
[u'Philip M. Napoli', u'Paul J. Lavrakas', u'Mario Callegaro']
EconomicsandElectronicCommerce
Abstract: This chapter examines how Internet (PC and mobile) ratings panels are constructed, managed, and utilized. We provide an overview of the history and evolution of Internet/mobile ratings panels and examines the methodological challenges associated with creating and maintaining accurate and reliable Internet/mobile ratings panels. The research that has assessed the accuracy and validity of online panel data is critically discussed; as well as research that illustrates the type of scholarly and applied research questions that can be investigated using online ratings panel data. The chapter concludes with a discussion of the future of online ratings panels within the rapidly evolving field of Internet audience measurement.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Mechanism Design for Crowdsourcing Markets with Heterogeneous Tasks
HCOMP (2014)
[u'Gagan Goel', u'Afshin Nikzad', u'Adish Singla']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Mechanism Design for Crowdsourcing: An Optimal 1-1/e Competitive Budget-Feasible Mechanism for Large Markets.
FOCS (2014)
[u'Nima Anari', u'Gagan Goel', u'Afshin Nikzad']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Multiplicative Bidding in Online Advertising
ACM Conference on Economics and Computation (EC) (2014)
[u'Mohammadhossein Bateni', u'Jon Feldman', u'Vahab Mirrokni', u'Sam Chiu-wai Wong']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Network Cournot Competition
WINE, The 10th Conference on Web and Internet Economics (2014)
[u'Melika Abolhasani', u'Mohammadhossein Bateni', u'MohammadTaghi Hajiaghayi', u'Hamid Mahini', u'Anshul Sawant']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42492.html
found
=========================
Online Panel Research: A Data Quality Perspective
Wiley (2014), pp. 512
[u'Mario Callegaro', u'Reg Baker', u'Jelke Bethlehem', u'Anja S. Goritz', u'Jon A. Krosnick', u'Paul J. Lavrakas']
EconomicsandElectronicCommerce
Abstract: This edited volume provides new insights into the accuracy and value of online panels for completing surveys Over the last decade, there has been a major global shift in survey and market research towards data collection, using samples selected from online panels. Yet despite their widespread use, remarkably little is known about the quality of the resulting data. This edited volume is one of the first attempts to carefully examine the quality of the survey data being generated by online samples. It describes some of the best empirically-based research on what has become a very important yet controversial method of collecting data. Online Panel Research presents 19 chapters of previously unpublished work addressing a wide range of topics, including coverage bias, nonresponse, measurement error, adjustment techniques, the relationship between nonresponse and measurement error, impact of smartphone adoption on data collection, Internet rating panels, and operational issues. The datasets used to prepare the analyses reported in the chapters are available on the accompanying website: www.wiley.com/go/online_panel
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42493.html
found
=========================
Online panel research: History, concepts, applications and a look at the future
Online Panel Research: A Data Quality Perspective, Wiley (2014), pp. 1-22
[u'Mario Callegaro', u'Reg Baker', u'Jelke Bethlehem', u'Anja S. Goritz', u'Jon A. Krosnick', u'Paul J. Lavrakas']
EconomicsandElectronicCommerce
Abstract: In this introductory chapter, written by the six editors of this volume, we introduce and attempt to systematize the key concepts used when discussing online panels. The connection between Internet penetration and the evolution of panels is discussed as are the different types of online panels, their composition, and how they are built. Most online panels do not use probability-based methods, but some do and the differences are discussed. The chapter also describes in some detail the process of joining a panel, answering initial profiling questions, and becoming an active panel member. We discuss the most common sampling techniques, highlighting their strengths and limitations, and touch on techniques to increase representativeness when using a non-probability panel. The variety of incentive methods in current use also is described. Panel maintenance is another key issue, since attrition often is substantial and a panel must be constantly refreshed. Online panels can be used to support a wide range of study designs, some cross-sectional or and others longitudinal, where the same sample members are surveyed multiple times on the same topic. We also discuss industry standards and professional association guidelines for conducting research using online panels. The chapter concludes with a look to the future of online panels and more generally online sampling via means other than classic panels.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Predicting the Present with Bayesian Structural Time Series
International Journal of Mathematical Modelling and Numerical Optimisation, vol. 5 (2014), pp. 4-23
[u'Steven L. Scott', u'Hal Varian']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42806.html
notfound
=========================
Preemptive Policy Experimentation
Econometrica, vol. 82 (2014), pp. 1509-1528
[u'Steven Callander', u'Patrick Hummel']
EconomicsandElectronicCommerce
Abstract: We develop a model of experimentation and learning in policymaking when control of power is temporary. We demonstrate how an early office holder who would otherwise not experiment is nonetheless induced to experiment when his hold on power is temporary. This preemptive policy experiment is profitable for the early office holder as it reveals information about the policy mapping to his successor, information that shapes future policy choices. Thus policy choices today can cast a long shadow over future choices purely through information transmission and absent any formal institutional constraints or real state variables. The model we develop utilizes a recent innovation that represents the policy mapping as the realized path of a Brownian motion. We provide a precise characterization of when preemptive experimentation emerges in equilibrium and the form it takes. We apply the model to several well known episodes of policymaking, reinterpreting the policy choices as preemptive experiments.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42258.html
found
=========================
Price Competition in Online Combinatorial Markets
Proceedings of the 23st World Wide Web Conference 2014
[u'Moshe Babaioff', u'Renato Paes Leme', u'Noam Nisan']
EconomicsandElectronicCommerce
Abstract: We consider a single buyer with a combinatorial preference that would like to purchase related products and services from different vendors, where each vendor supplies exactly one product. We study the general case where subsets of products can be substitutes as well as complementary and analyze the game that is induced on the vendors, where a vendor's strategy is the price that he asks for his product. This model generalizes both Bertrand competition (where vendors are perfect substitutes) and Nash bargaining (where they are perfect complements), and captures a wide variety of scenarios that can appear in complex crowd sourcing or in automatic pricing of related products. We study the equilibria of such games and show that a pure efficient equilibrium always exists. In the case of submodular buyer preferences we fully characterize the set of pure Nash equilibria, essentially showing uniqueness. For the even more restricted "substitutes" buyer preferences we also prove uniqueness over {\em mixed} equilibria. Finally we begin the exploration of natural generalizations of our setting such as when services have costs, when there are multiple buyers or uncertainty about the the buyer's valuation, and when a single vendor supplies multiple products.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Randomized Revenue Monotone Mechanisms for Online Advertising.
WINE (2014)
[u'Gagan Goel', u'MohammadTaghi Hajiaghayi', u'Reza Khani']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Reduce and aggregate: similarity ranking in multi-categorical bipartite graphs
WWW (2014), pp. 349-360
[u'Alessandro Epasto', u'Jon Feldman', u'Silvio Lattanzi', u'Stefano Leonardi', u'Vahab Mirrokni']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Revenue monotone mechanisms for online advertising
WWW (2014)
[u'Gagan Goel', u'Reza Khani']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Secretary Problems and Online Auctions
Encyclopedia of Algorithms, Springer (2014), pp. 1-4
[u'Mohammadhossein Bateni']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42521.html
notfound
=========================
Social media in public opinion research
AAPOR, AAPOR (2014), pp. 57
[u'Michael Link', u'Joe Muphy', u'Michael F. Schober', u'Trent D. Buskirk', u'Jennifer Hunter Childs', u'Casey Langer Tesfaye', u'Mario Callegaro', u'Jon Cohen', u'Elizabeth Dean', u'Paul Harwood', u'Josh Pasek', u'Michael Stern']
EconomicsandElectronicCommerce
Abstract: AAPOR announces the release of an important report, Social Media in Public Opinion Research, authored by the Emerging Technologies Task Force. As social media platforms such as Facebook, Twitter, and LinkedIn to name a few expand and proliferate, so does access to users thoughts, feelings and actions expressed instantaneously, organically, and often publicly, across these platforms. At question is how researchers and others interested in public opinion derive reliable and valid insights from the data generated by social media users. The report, Social Media in Public Opinion Research, highlights the use of social media as a vehicle for facilitating the survey research process (i.e., questionnaire development, recruitment, locating, etc.) and as a way of potentially supplementing or replacing traditional survey methods (i.e., content analysis of existing data). It offers an initial set of guidelines and considerations for researchers and consumers of social media-based studies, noting the opportunities and challenges in this new area.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43128.html
notfound
=========================
Sui sondaggi politici in Italia
Il Mulino, vol. 5 (2014), pp. 827-838
[u'Piergiorgio Corbetta', u'Mario Callegaro']
EconomicsandElectronicCommerce
Abstract: In this discussion piece, Piergiorgio Corbetta and Mario Callegaro analyse the results of Italian pre-election polls for the European election of May 2014. The paper is in Italian language.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42895.html
notfound
=========================
Value of Targeting
Proceedings of the 7th International Symposium on Algorithmic Game Theory (SAGT) (2014), pp. 194-205
[u'Kshipra Bhawalkar', u'Patrick Hummel', u'Sergei Vassilvitskii']
EconomicsandElectronicCommerce
Abstract: We undertake a formal study of the value of targeting data to an advertiser. As expected, this value is increasing in the utility difference between realizations of the targeting data and the accuracy of the data, and depends on the distribution of competing bids. However, this value may vary non-monotonically with an advertisers budget. Similarly, modeling the values as either private or correlated, or allowing other advertisers to also make use of the data, leads to unpredictable changes in the value of data. We address questions related to multiple data sources, show that utility of additional data may be non-monotonic, and provide tradeoffs between the quality and the price of data sources. In a game-theoretic setting, we show that advertisers may be worse off than if the data had not been available at all. We also ask whether a publisher can infer the value an advertiser would place on targeting data from the advertisers bidding behavior and illustrate that this is impossible.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42522.html
found
=========================
Web Surveys for the General Population: How, why and when?
Natcen (2014), pp. 22
[u'Gerri Nicolaas', u'Lisa Calderwood', u'Peter Lynn', u'Caroline Roberts', u'Mario Callegaro']
EconomicsandElectronicCommerce
Abstract: Cultural and technological change has made the web a possible and even desirable mode for complex social surveys, but the financial challenges faced by the Research Councils and the UK Government has accelerated this shift, creating an urgent need to explore both its potential and hazards for a range of studies. While some progress in carrying out large-scale complex social surveys on the web has been made, there is still no consensus about how this can best be achieved while maintaining population representativeness and preserving data quality. To address this problem, the NCRM funded a network of methodological innovation Web Surveys for the General Population: How, Why and When? (also known by its acronym GenPopWeb). A key objective of the networks activities was to review and synthesise existing knowledge about the use of web-based data collection for general population samples and to identify areas where new research is needed. The network Web Surveys for the General Population: Why, How and When? was supported with funding from the ESRC National Centre for Research Methods under the initiative Networks for Methodological Innovation 2012. We are also grateful to the Institute of Education and the University of Essex for hosting the two main events of the network. We would like to thank all of the presenters at the events as well as the participants for their contribution. Particular thanks are due to the UK Core Group for their time, advice and support: Bill Blyth, TNS Global Mario Callegaro, Google UK Ed Dunn & Laura Wilson, ONS Rory Fitzgerald, City University London Joanna Lake, ESRC Carli Lessof & Joel Williams, TNS BMRB Nick Moon, GfK NOP Patten Smith, Ipsos MORI Professor Patrick Sturgis, NCRM Joe Twyman & Michael Wagstaff, YouGov UK
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
2013 Recent Books and Journals in Public Opinion, Survey Methods, and Survey Statistics
Survey Practice, vol. 1 (2013)
[u'Mario Callegaro']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41089.html
notfound
=========================
A Method for Measuring Online Audiences
Google Inc (2013), pp. 1-24 (to appear)
[u'Jim Koehler', u'Evgeny Skvortsov', u'Wiesner Vos']
EconomicsandElectronicCommerce
Abstract: We present a method for measuring the reach and frequency of online ad campaigns by audience attributes. This method uses a combination of data sources, including ad server logs, publisher provided user data (PPD), census data, and a representative online panel. It adjusts for known problems with cookie data and potential non-representative and inaccurate PPD. It generalizes for multiple publishers and for targeting based on the PPD. The method includes the conversion of adjusted cookie counts to unique audience counts. The benefit of our method is that we get both reduced variance from server logs and reduced bias from the panel. Simulation results and a case study are presented.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41159.html
notfound
=========================
Ad Click Prediction: a View from the Trenches
Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD) (2013)
[u'H. Brendan McMahan', u'Gary Holt', u'D. Sculley', u'Michael Young', u'Dietmar Ebner', u'Julian Grady', u'Lan Nie', u'Todd Phillips', u'Eugene Davydov', u'Daniel Golovin', u'Sharat Chikkerur', u'Dan Liu', u'Martin Wattenberg', u'Arnar Mar Hrafnkelsson', u'Tom Boulos', u'Jeremy Kubica']
EconomicsandElectronicCommerce
Abstract: Predicting ad click--through rates (CTR) is a massive-scale learning problem that is central to the multi-billion dollar online advertising industry. We present a selection of case studies and topics drawn from recent experiments in the setting of a deployed CTR prediction system. These include improvements in the context of traditional supervised learning based on an FTRL-Proximal online learning algorithm (which has excellent sparsity and convergence properties) and the use of per-coordinate learning rates. We also explore some of the challenges that arise in a real-world system that may appear at first to be outside the domain of traditional machine learning research. These include useful tricks for memory savings, methods for assessing and visualizing performance, practical methods for providing confidence estimates for predicted probabilities, calibration methods, and methods for automated management of features. Finally, we also detail several directions that did not turn out to be beneficial for us, despite promising results elsewhere in the literature. The goal of this paper is to highlight the close relationship between theoretical advances and practical engineering in this industrial setting, and to show the depth of challenges that appear when applying traditional machine learning methods in a complex dynamic system.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42473.html
found
=========================
Best-response dynamics out of sync: complexity and characterization
EC, ACM (2013), pp. 379-396
[u'Roee Engelberg', u'Alex Fabrikant', u'Michael Schapira', u'David Wajc']
EconomicsandElectronicCommerce
Abstract: In many computational and economic models of multi-agent interaction, each participant repeatedly "best-responds" to the others' actions. Game theory research on the prominent "best-response dynamics" model typically relies on the premise that the interaction between agents is somehow synchronized. However, in many real-life settings, e.g., internet protocols and large-scale markets, the interaction between participants is asynchronous. We tackle the following important questions: (1) When are best-response dynamics guaranteed to converge to an equilibrium even under asynchrony? (2) What is the (computational and communication) complexity of verifying guaranteed convergence? We show that, in general, verifying guaranteed convergence is intractable. In fact, our main negative result establishes that this task is undecidable. We exhibit, in contrast, positive results for several environments of interest, including complete, computationally-tractable, characterizations of convergent systems. We discuss the algorithmic implications of our results, which extend beyond best-response dynamics to applications such as asynchronous Boolean circuits.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40464.html
found
=========================
Clinching Auctions with Online Supply
SODA (2013), pp. 605-619
[u'Gagan Goel', u'Vahab Mirrokni', u'Renato Paes Leme']
EconomicsandElectronicCommerce
Abstract: Auctions for perishable goods such as internet ad inventory need to make real-time allocation and pricing decisions as the supply of the good arrives in an online manner, without knowing the entire supply in advance. These allocation and pricing decisions get complicated when buyers have some global constraints. In this work, we consider a multi-unit model where buyers have global {\em budget} constraints, and the supply arrives in an online manner. Our main contribution is to show that for this setting there is an individually-rational, incentive-compatible and Pareto-optimal auction that allocates these units and calculates prices on the fly, without knowledge of the total supply. We do so by showing that the Adaptive Clinching Auction satisfies a {\em supply-monotonicity} property. We also analyze and discuss, using examples, how the insights gained by the allocation and payment rule can be applied to design better ad allocation heuristics in practice. Finally, while our main technical result concerns multi-unit supply, we propose a formal model of online supply that captures scenarios beyond multi-unit supply and has applications to sponsored search. We conjecture that our results for multi-unit auctions can be extended to these more general models.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Conjoint Analysis in R Now with Individual-Level Utilities and Survey Mockups
American Marketing Association Advanced Research Techniques Forum (2013), Poster
[u'Chris Chapman', u'Steven Ellis']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Designing Markets for Daily Deals
Conference on Web and Internet Economics (WINE) (2013) (to appear)
[u'Yang Cai', u'Mohammad Mahdian', u'Aranyak Mehta', u'Bo Waggoner']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41682.html
notfound
=========================
EXPERTS AND THEIR RECORDS
Economic Inquiry (2013) (to appear)
[u'Michael Schwarz', u'Alex Frankel']
EconomicsandElectronicCommerce
Abstract: A market where short-lived customers interact with long-lived experts is considered. Experts privately observe which treatment best serves a customer, but are free to choose more or less profitable treatments. Customers only observe records of experts' past actions. If experts are homogeneous there exists an equilibrium where experts always choose the customer's preferred treatment (play truthfully). Experts are incentivized with the promise of future business: new customers tend to choose experts who performed less profitable treatments in the past. If expert payoffs are private information, experts can never always be truthful. But sufficiently patient experts may be truthful almost always.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41334.html
notfound
=========================
Incremental Clicks Impact of Mobile Search Advertising
Google, Inc. (2013)
[u'Shaun Lysen']
EconomicsandElectronicCommerce
Abstract: In this research, we examine how the number of mobile organic clicks changes when advertisers significantly change their mobile ad spend. This continues the line of research of search ads pause by applying it to the mobile platform. We utilize a statistical model to estimate the fraction of clicks that can be attributed to mobile search advertising. A metastudy of 327 advertisers reveals that 88% of ad clicks are incremental, in the sense that the visits to the advertisers site would not have occurred without the mobile ad campaigns.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42185.html
found
=========================
Mechanism Design for Fair Division: Allocating Divisible Items without Payments
EC 2013, ACM
[u'Richard Cole', u'Vasilis Gkatzelis', u'Gagan Goel']
EconomicsandElectronicCommerce
Abstract: We revisit the classic problem of fair division from a mechanism design perspective, using Proportional Fairness as a benchmark. In particular, we aim to allocate a collection of divisible items to a set of agents while incentivizing the agents to be truthful in reporting their valuations. For the very large class of homogeneous valuations, we design a truthful mechanism that provides every agent with at least 0.368 fraction of her Proportionally Fair valuation. To complement this result, we show that no truthful mechanism can guarantee more than a 0.5 fraction, even for the restricted class of additive linear valuations. We also propose another mechanism for additive linear valuations that works really well when every item is highly demanded. To guarantee truthfulness, our mechanisms discard a carefully chosen fraction of the allocated resources; we conclude by uncovering interesting connections between our mechanisms and known mechanisms that use money instead.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Nine things clients get wrong about conjoint analysis
Proceedings of the 2013 Sawtooth Software Conference, Sawtooth Software
[u'Chris Chapman']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42472.html
found
=========================
On the structure of weakly acyclic games
Theory of Computing Systems, vol. 53 (2013), pp. 107-122
[u'Alex Fabrikant', u'Aaron D Jaggard', u'Michael Schapira']
EconomicsandElectronicCommerce
Abstract: The class of weakly acyclic games, which includes potential games and dominance-solvable games, captures many practical application domains. In a weakly acyclic game, from any starting state, there is a sequence of better-response moves that leads to a pure Nash equilibrium; informally, these are games in which natural distributed dynamics, such as better-response dynamics, cannot enter inescapable oscillations. We establish a novel link between such games and the existence of pure Nash equilibria in subgames. Specifically, we show that the existence of a unique pure Nash equilibrium in every subgame implies the weak acyclicity of a game. In contrast, the possible existence of multiple pure Nash equilibria in every subgame is insufficient for weak acyclicity in general; here, we also systematically identify the special cases (in terms of the number of players and strategies) for which this is sufficient to guarantee weak acyclicity.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Online Matching and Ad Allocation
Foundations and Trends in Theoretical Computer Science, vol. 8 (4) (2013), pp. 265-368
[u'Aranyak Mehta']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40804.html
found
=========================
Optimizing Budget Constrained Spend in Search Advertising
Sixth ACM International Conference on Web Search and Data Mining, WSDM 2013, ACM, pp. 697-706
[u'Chinmay Karande', u'Aranyak Mehta', u'Ramakrishnan Srikant']
EconomicsandElectronicCommerce
Abstract: Search engine ad auctions typically have a significant fraction of advertisers who are budget constrained, i.e., if allowed to participate in every auction that they bid on, they would spend more than their budget. This yields an important problem: selecting the ad auctions in which these advertisers participate, in order to optimize different system objectives such as the return on investment for advertisers, and the quality of ads shown to users. We present a system and algorithms for optimizing such budget constrained spend. The system is designed be deployed in a large search engine, with hundreds of thousands of advertisers, millions of searches per hour, and with the query stream being only partially predictable. We have validated the system design by implementing it in the Google ads serving system and running experiments on live traffic. We have also compared our algorithm to previous work that casts this problem as a large linear programming problem limited to popular queries, and show that our algorithms yield substantially better results.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41884.html
found
=========================
Performance tournaments with crowdsourced judges
Proceedings of the American Statistical Association, section on marketing statistics, American Statistical Association, 732 North Washtington Street, Alexandria, VA 22314-1943 (2013)
[u'Daryl Pregibon', u'Williiam D Heavlin']
EconomicsandElectronicCommerce
Abstract: A performance slam is a competition among a fixed set of performances whereby pairs of performances are judged by audience participants. When performances are recorded on electronic media, performance slams become amenable to audiences that watch online and judge asynchronously (crowdsourced). In order to better entertain the audience, we want to show the better performances (exploitation). In order to identify the good videos, we want to glean a least some information about all videos (exploration). Our approach has three elements: (1) We take our preference model from Bradley and Terry (1952). (2) Its parameters we calculate by rewriting the likelihood gradient into a fixed point estimate, one which mimics the estimate of Mantel and Haenszel (1959). (3) Each pair of performances is chosen sequentially, always chosen to minimize the weighted variance of (the logarithms of) the Bradley-Terry parameter estimates. Our preferred weights consist of the logrank weights proposed by Savage (1956).
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Positive Results for Mechanism Design without Money
AAMAS (2013)
[u'Richard Cole', u'Vasilis Gkatzelis', u'Gagan Goel']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Revenue Maximization with Nonexcludable Goods
Internet and Network Economics - 9th International Workshop, WINE 2013, Springer
[u'Mohammadhossein Bateni', u'Nima Haghpanah', u'Balasubramanian Sivan', u'Morteza Zadimoghaddam']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Submodular secretary problems with extensions
ACM Transactions on Algorithms, vol. 9 (4) (2013)
[u'Mohammadhossein Bateni', u'MohammadTaghi Hajiaghayi', u'Morteza Zadimoghaddam']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42035.html
notfound
=========================
The Network Value of Products
Journal of Marketing, vol. 77(3) (2013), pp. 1-14
[u'Gal Oestreicher-Singer', u'Barak Libai', u'Liron Sivan', u'Eyal Carmi', u'Ohad Yassin']
EconomicsandElectronicCommerce
Abstract: Traditionally, the value of a product has been assessed according to the direct revenues the product creates. However, products do not exist in isolation but rather influence one anothers sales. Such influence is especially evident in e-commerce environments, in which products are often presented as a collection of web pages linked by recommendation hyperlinks, creating a large-scale product network. The authors present a systematic approach to estimate products true value to a firm in such a product network. Their approach, which is in the spirit of the PageRank algorithm, uses available data from large-scale e-commerce sites and separates a products value into its own intrinsic value, the value it receives from the network, and the value it contributes to the network. The authors demonstrate their approach using data collected from the product network of books on Amazon.com. Specifically, they show that the value of low sellers may be underestimated, whereas the value of best sellers may be overestimated. The authors explore the sources of this discrepancy and discuss the implications for managing products in the growing environment of product networks.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41669.html
found
=========================
The Optimal Mix of TV and Online Ads to Maximize Reach
research.google.com, 76 Ninth Avenue (2013), pp. 1-16
[u'Yuxue Jin', u'Jim Koehler', u'Georg M. Goerg', u'Nicolas Remy']
EconomicsandElectronicCommerce
Abstract: Brand marketers often wonder how they should allocate budget between TV and online ads in order to maximize reach or maintain the same reach at a lower cost. We use probability models based on historical cross media panel data to suggest the optimal budget allocation between TV and online ads to maximize reach to the target demographics. We take a historical TV campaign and estimate the reach and GRPs of a hypothetical cross-media campaign if some budget was shifted from TV to online. The models are validated against simulations and historical cross-media campaigns. They are illustrated on one case study to show how an optimized cross-media campaign can obtain a higher reach at the same cost or maintain the same reach at a lower cost than the TV-only campaign.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Unlocking the Potential of Conjoint Analysis/Discrete Choice Modeling and MaxDiff Scaling in Public Opinion and Survey Research
American Association for Public Opinion Research (2013), Panel
[u'Steven Ellis', u'Mario Callegaro', u'Chris Chapman']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41149.html
notfound
=========================
Web Coverage in the UK and its Potential Impact on General Population Web Surveys
Web surveys for the general population: How, why and when?, 25-26 February 2013. Institute of Education, London (2013)
[u'Mario Callegaro']
EconomicsandElectronicCommerce
Abstract: Mario Callegaro (Google UK) provided some data on internet access in the UK and the digital divide. He concluded that the UK internet access is steadily increasing and is likely to soon reach a level of almost universal coverage. But high coverage does not imply that everyone with access would be capable or willing to take part in web surveys. Furthermore, internet access is becoming mobile (e.g. Smartphone) and respondents are using a wide variety of devices to answer web surveys. Making web surveys
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Whole-page optimization and submodular welfare maximization with online bidders
ACM Conference on Electronic Commerce (EC) 2013, pp. 305-322
[u'Nikhil Devanur', u'Zhiyi Huang', u'Nitish Korula', u'Vahab Mirrokni', u'Qiqi Yan']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
2012: Recent Books and Journals in Public Opinion, Survey Methods, and Survey Statistics
Survey Practice, vol. April (2012)
[u'Mario Callegaro']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Theoretical Examination of Practical Game Playing: Lookahead Search
SAGT (2012), pp. 251-262
[u'Vahab S. Mirrokni', u'Nithum Thain', u'Adrian Vetta']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Ad auctions with data
INFOCOM Workshops (2012), pp. 184-189
[u'Hu Fu', u'Patrick R. Jordan', u'Mohammad Mahdian', u'Uri Nadav', u'Inbal Talgam-Cohen', u'Sergei Vassilvitskii']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Ad serving using a compact allocation plan
Proceedings of the 13th ACM Conference on Electronic Commerce, ACM, New York, NY, USA (2012), pp. 319-336
[u'Peiji Chen', u'Wenjing Ma', u'Srinath Mandalapu', u'Chandrashekhar Nagarjan', u'Jayavel Shanmugasundaram', u'Sergei Vassilvitskii', u'Erik Vee', u'Manfai Yu', u'Jason Zien']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40755.html
notfound
=========================
An Overview of Practical Exchange Design
Current Science, vol. 103, no.9 (2012), pp. 1056-1063
[u'R. Preston McAfee', u'Sergei Vassilvitskii']
EconomicsandElectronicCommerce
Abstract: We consider the problem of designing an online exchange. We identify the goals of exchange design, and present key techniques for accomplishing these goals along with the tradeoffs inherent in the choices.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Budget Optimization for Online Campaigns with Positive Carryover Effects
WINE (2012), pp. 86-99
[u'Nikolay Archak', u'Vahab S. Mirrokni', u'S. Muthukrishnan']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38395.html
found
=========================
Budget-Constrained Auctions with Heterogeneous Items
Theory of Computing, vol. 8 (2012), pp. 429-460
[u'Sayan Bhattacharya', u'Gagan Goel', u'Sreenivas Gollapudi', u'Kamesh Munagala']
EconomicsandElectronicCommerce
Abstract: We present the rst approximation algorithms for designing revenue-optimal incentive-compatible mechanisms in the following setting: There are multiple (heterogeneous) items, and bidders have arbitrary demand and budget constraints (and additive valuations). Furthermore, the type of a bidder (which species her valuations for each item) is private knowledge, and the types of different bidders are drawn from publicly known mutually independent distributions. Our mechanisms are surprisingly simple. First, we assume that the type of each bidder is drawn from a discrete distribution with polynomially bounded support size. This restriction on the type-distribution, however, allows the random variables corresponding to a bidders valuations for different items to be arbitrarily correlated. In this model, we describe a sequential all-pay mechanism that is truthful in expectation and Bayesian incentive compatible. The outcome of our all-pay mechanism can be computed in polynomial time, and its revenue is a 4-approximation to the revenue of the optimal truthful-in-expectation Bayesian incentive-compatible mechanism. Next, we assume that the valuations of each bidder for different items are drawn from mutually independent discrete distributions satisfying the monotone hazard-rate condition. In this model, we present a sequential posted-price mechanism that is universally truthful and incentive compatible in dominant strategies. The outcome of the mechanism is computable in polynomial time, and its revenue is a O(1)-approximation to the revenue of the optimal truthful-in-expectation Bayesian incentive-compatible mechanism. If the monotone hazard-rate condition is removed, then we show a logarithmic approximation, and we complete the picture by proving that no sequential posted-price scheme can achieve a sub-logarithmic approximation. Finally, if the distributions are regular, and if the space of mechanisms is restricted to sequential posted-price schemes, then we show that there is a O(1)-approximation within this space. Our results are based on formulating novel LP relaxations for these problems, and developing generic rounding schemes from rst principles.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Convergence and approximation in potential games
Theor. Comput. Sci., vol. 438 (2012), pp. 13-27
[u'George Christodoulou', u'Vahab S. Mirrokni', u'Anastasios Sidiropoulos']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
How to approximate optimal auctions
SIGecom Exchanges, vol. 11 (2012), pp. 30-33
[u'Nima Haghpanah', u'Nicole Immorlica', u'Vahab S. Mirrokni', u'Kamesh Munagala']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
How well can congestion pricing neutralize denial of service attacks?
Proceedings of the 12th ACM SIGMETRICS/PERFORMANCE joint international conference on Measurement and Modeling of Computer Systems, ACM, New York, NY, USA (2012), pp. 137-150
[u'Ashish Vulimiri', u'Gul A. Agha', u'Philip Brighten Godfrey', u'Karthik Lakshminarayanan']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40655.html
found
=========================
Italy
Telephone surveys in Europe: Research and practice, Springer, Berlin (2012), pp. 59-72
[u'Teresio Poggio', u'Mario Callegaro']
EconomicsandElectronicCommerce
Abstract: This chapter highlights the current Italian situation about telephone surveys. Table of contents: Introduction The reality of phone surveys in Italy Main recent changes in the technological and social context Coverage error as the big issue in phone surveys Conclusions: no way to skip the low cost-low quality vicious cycle?
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Matching with our Eyes Closed
FOCS (2012)
[u'Gagan Goel', u'Pushkar Tripathi']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
On Fixed-Price Marketing for Goods with Positive Network Externalities
WINE (2012), pp. 532-538
[u'Vahab S. Mirrokni', u'Sebastien Roch', u'Mukund Sundararajan']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
On the Non-progressive Spread of Influence through Social Networks
LATIN (2012)
[u'MohammadAmin Fazli', u'Mohammad Ghodsi', u'Jafar Habibi', u'Pooya Jalaly Khalilabad', u'Vahab Mirrokni', u'Sina Sadeghian']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40363.html
found
=========================
Online Matching with Stochastic Rewards
Symposium on Foundations of Computer Science (FOCS), IEEE (2012)
[u'Aranyak Mehta', u'Debmalya Panigrahi']
EconomicsandElectronicCommerce
Abstract: The online matching problem has received significant attention in recent years because of its connections to allocation problems in Internet advertising, crowd-sourcing, etc. In these real-world applications, the typical goal is not to maximize the number of allocations, rather it is to maximize the number of successful allocations, where success of an allocation is governed by a stochastic process which follows the allocation. To address such applications, we propose and study the online matching problem with stochastic rewards (called the Online Stochastic Matching problem) in this paper. Our problem also has close connections to the existing literature on stochastic packing problems, in fact, our work initiates the study of online stochastic packing problems. We give a deterministic algorithm for the Online Stochastic Matching problem whose competitive ratio converges to (approximately) 0.567 for uniform and vanishing probabilities. We also give a randomized algorithm which outperforms the deterministic algorithm for higher probabilities. Finally, we complement our algorithms by giving an upper bound on the competitive ratio of any algorithm for this problem. This result shows that the best achievable competitive ratio for the Online Stochastic Matching problem is provably worse than that for the (non-stochastic) online matching problem.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Online allocation of display ads with smooth delivery
KDD (2012), pp. 1213-1221
[u'Anand Bhalgat', u'Jon Feldman', u'Vahab S. Mirrokni']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38356.html
notfound
=========================
Periodic Measurement of Advertising Effectiveness Using Multiple-Test-Period Geo Experiments
Google Inc. (2012)
[u'Jon Vaver', u'Jim Koehler']
EconomicsandElectronicCommerce
Abstract: In a previous paper [6] we described the application of geo experiments to the measurement of advertising effectiveness. One reason this method of measurement is attractive is that it provides the rigor of a randomized experiment. However, related decisions, such as where and how to spend advertising budget, are not static. To address this issue, we extend this methodology to provide periodic (ongoing) measurement of ad effectiveness. In this approach, the test and control assignments of each geographic region rotate across multiple test periods, and these rotations provide the opportunity to generate a sequence of measurements of campaign effectiveness. The data across test periods can also be pooled to create a single aggregate measurement of campaign effectiveness. These sequential and pooled measurements have smaller confidence intervals than measurements from a series of geo experiments with a single test period. Alternatively, the same confidence interval can be achieved with a reduced magnitude and/or duration of ad spend change, thereby lowering the cost of measurement. The net result is a better method for periodic and isolated measurement of ad effectiveness.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Polyhedral clinching auctions and the adwords polytope
STOC, ACM (2012), pp. 107-122
[u'Gagan Goel', u'Vahab Mirrokni', u'Renato Paes Leme']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Quantum money from knots
Proceedings of the 3rd Innovations in Theoretical Computer Science Conference, ACM, New York, NY, USA (2012), pp. 276-289
[u'Edward Farhi', u'David Gosset', u'Avinatan Hassidim', u'Andrew Lutomirski', u'Peter Shor']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Risk-Aware Revenue Maximization in Display Advertising
WWW (2012) (to appear)
[u'William D. Heavlin', u'Ana Radovanovic']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38097.html
found
=========================
Smart Pricing Grows the Pie
Google, Inc (2012)
[u'Guy Calvert']
EconomicsandElectronicCommerce
Abstract: Some publisher advertising networks provide features intended to help advertisers bid more efficiently with a single bid in many publishers click auctions at once Smart Pricing on the Google Display Network is one example. Typically such features involve discounting advertiser bids or prices for clicks on publisher websites according to how click values vary across sites (for some appropriate measure of advertiser value). Contrary to concerns that such features necessarily result in reduced publisher (and network) revenue we find that, in many simple cases, the modified auction dynamics produce rational incentives for advertisers to bid more and spend more than they would without the benefit of these features. So if advertisers act in their own interest then publishers and networks stand to make more revenue as well.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40426.html
found
=========================
The Incremental Reach and Cost Efficiency of Online Video Ads over TV Ads
Google Inc (2012), pp. 1-17
[u'Yuxue Jin', u'Sheethal Shobowale', u'Jim Koehler', u'Harry Case']
EconomicsandElectronicCommerce
Abstract: As people spend more time online, an increasing number of brand marketers are including video ads in their advertising campaigns. These advertisers would like to know the incremental reach and cost efficiency of their video and display ads compared to their TV ads. In this paper, we measure the incremental reach to a target demographic and estimate the cost per incremental reach point of YouTube (YT) and the Google Display Network (GDN) compared to TV ad campaigns. We consider two media planning scenarios: what it would have cost for the TV ad campaign to have delivered the equivalent of the online incremental reach, and what saving could have been achieved by having spent less on TV ads and complementing them with online ads for a given reach goal.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44182.html
notfound
=========================
The landscape of digital media research: big data, big research, right impact
Digital Media Education Foundation Conference, Las Vegas, NV (2012)
[u'Chris Chapman']
EconomicsandElectronicCommerce
Abstract: Invited keynote
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
To match or not to match: economics of cookie matching in online advertising
Proceedings of the 13th ACM Conference on Electronic Commerce, ACM, New York, NY, USA (2012), pp. 741-753
[u'Mohammad Mahdian', u'Arpita Ghosh', u'Preston McAfee', u'Sergei Vassilvitskii']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
2011 Recent Books and Journals in Public Opinion, Survey Methods, and Survey Statistics
Survey Practice, vol. April (2011)
[u'Mario Callegaro']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Crowdsourcing the process of scientific publishing
Google, Inc. (2011)
[u'Atish Das Sarma', u'Luca de Alfaro']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Incentives for Answering Hypothetical Questions
Workshop on Social Computing and User Generated Content (2011)
[u'Radu Jurca', u'Boi Faltings']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38334.html
notfound
=========================
Incremental Clicks: The Impact of Search Advertising
Journal of Advertising Research, vol. 51, no. 4 (2011), pp. 643-647
[u'David X. Chan', u'Yuan Yuan', u'Jim Koehler', u'Deepak Kumar']
EconomicsandElectronicCommerce
Abstract: In this research, the authors examined how the number of organic clicks changed when search ads were present and when search ad campaigns were turned off. The authors developed a statistical model to estimate the fraction of total clicks that could be attributed to search advertising. A meta-analysis of several hundred of these studies revealed that more than 89 percent of the ads clicks were incremental, in the sense that those visits to the advertiser's site would not have occurred without the ad campaigns.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38355.html
notfound
=========================
Measuring Ad Effectiveness Using Geo Experiments
Google Inc. (2011)
[u'Jon Vaver', u'Jim Koehler']
EconomicsandElectronicCommerce
Abstract: Advertisers have a fundamental need to quantify the effectiveness of their advertising. For search ad spend, this information provides a basis for formulating strategies related to bidding, budgeting, and campaign design. One approach that Google has successfully employed to measure advertising effectiveness is geo experiments. In these experiments, non-overlapping geographic regions are randomly assigned to a control or treatment condition, and each region realizes its assigned condition through the use of geo-targeted advertising. This paper describes the application of geo experiments and demon- strates that they are conceptually simple, have a systematic and effective design process, and provide results that are easy to interpret.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Multitaskers May be Advertisers' Best Audience
Harvard Business Review, vol. January--February (2011)
[u'Dan Zigmond', u'Horst Stipp', u'Open']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37653.html
notfound
=========================
Non-Price Equilibria in Markets of Discrete Goods
EC (2011)
[u'Avinatan Hassidim', u'Haim Kaplan', u'Yishay Mansour', u'Noam Nisan']
EconomicsandElectronicCommerce
Abstract: We study markets of indivisible items in which price-based (Walrasian) equilibria often do not exist due to the discrete non-convex setting. Instead we consider Nash equilibria of the market viewed as a game, where players bid for items, and where the highest bidder on an item wins it and pays his bid. We first observe that pure Nash-equilibria of this game excatly correspond to price-based equilibiria (and thus need not exist), but that mixed-Nash equilibria always do exist, and we analyze their structure in several simple cases where no price-based equilibrium exists. We also undertake an analysis of the welfare properties of these equilibria showing that while pure equilibria are always perfectly efficient (first welfare theorem), mixed equilibria need not be, and we provide upper and lower bounds on their amount of inefficiency.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Online Stochastic Weighted Matching: Improved Approximation Algorithms
Workshop of Network and Internet Economics (WINE) 2011
[u'Bernard Haeupler', u'Vahab Mirrokni', u'Morteza Zadimoghaddam']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Optimal Auctions with Positive Network Externalities
ACM Conference on Electronic Commerce (2011)
[u'Nima Haghpanah', u'Nicole Immorlica', u'Vahab Mirrokni', u'K. Munagala']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36975.html
found
=========================
Yield Optimization of Display Advertising with Ad Exchange
ACM Conference on Electronic Commerce (2011)
[u'Santiago Balseiro', u'Jon Feldman', u'Vahab Mirrokni', u'S. Muthukrishnan']
EconomicsandElectronicCommerce
Abstract: In light of the growing market of Ad Exchanges for the real-time sale of advertising slots, publishers face new challenges in choosing between the allocation of contract-based reservation ads and spot market ads. In this setting, the publisher should take into account the tradeoff between short-term revenue from an Ad Exchange and quality of allocating reservation ads. In this paper, we formalize this combined optimization problem as a stochastic control problem and derive an efficient policy for online ad allocation in settings with general joint distribution over placement quality and exchange bids. We prove asymptotic optimality of this policy in terms of any trade-off between quality of delivered reservation ads and revenue from the exchange, and provide a rigorous bound for its convergence rate to the optimal policy. We also give experimental results on data derived from real publisher inventory, showing that our policy can achieve any pareto-optimal point on the quality vs. revenue curve. Finally, we study a parametric training-based algorithm in which instead of learning the dual variables from a sample data (as is done in non-parametric training-based algorithms), we learn the parameters of the distribution and construct those dual variables from the learned parameter values. We compare parametric and non-parametric ways to estimate from data both analytically and experimentally in the special case without the ad exchange, and show that though both methods converge to the optimal policy as the sample size grows, our parametric method converges faster, and thus performs better on smaller samples.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
2010 Recent Books in Public Opinion, Survey Methods, and Survey Statistics
Survey Practice, vol. April (2010)
[u'Mario Callegaro']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub39974.html
notfound
=========================
Assessing a New Advertising Effect: Measurement of the Impact of Television Commercials on Internet Search Queries
Journal of Advertising Research, vol. 50 (2010), pp. 162-168
[u'Dan Zigmond', u'Horst Stipp']
EconomicsandElectronicCommerce
Abstract: Most Americans today use both television and the Internet on a daily basis, and studies have shown that many are frequently online or in proximity of a computer while they are watching television. One result of these multi-platform media use patterns is a new television advertising effect: Todays consumer can easily obtain more information on an advertised product by searching for more information on the Web. This article demonstrates the measurement of such an effect by introducing a new metrica measure of changes in Google search queriesthat can show how TV commercials or sponsorships can trigger Internet searches by consumers. We believe this metric is a valuable addition to the researchers toolkit for assessing advertising effects and regions of interest as it measures an actual behavioral advertising response.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Auctions with intermediaries: extended abstract
ACM Conference on Electronic Commerce (2010), pp. 23-32
[u'Jon Feldman', u'Vahab S. Mirrokni', u'S. Muthukrishnan', u'Mallesh M. Pai']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Equilibrium Pricing with Positive Externalities (Extended Abstract)
WINE (2010), pp. 424-431
[u'Nima Anari', u'Shayan Ehsani', u'Mohammad Ghodsi', u'Nima Haghpanah', u'Nicole Immorlica', u'Hamid Mahini', u'Vahab Mirrokni']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36915.html
notfound
=========================
Media agenda setting and online search traffic: Influences of online and traditional media
American Political Science Association, American Political Science Association (2010)
[u'Laura Ann Granka']
EconomicsandElectronicCommerce
Abstract: This paper addresses the patterns of influence between the news media and the public, by specifically targeting breaking stories, or shocks, to a news system. Specifically, we assess media agenda setting and selective exposure by looking at the relative public attention spans to hard and soft news (as measured by query volume), in comparison with the volume of news coverage (in print, broadcast, and Web content) for these selected news events. We measure the dynamic distribution of issue coverage in the news media, and how this volume of coverage ultimately influences online search traffic. In order to assess sustained interest in a given topic, distributions of query volume and news coverage were fit with Gamma distributions of appropriate parameters. Findings indicate that there are significant differences in the public attention spans for hard and soft news issues, particularly relative to what news coverage might predict. Soft news events produced a slower rate of decline in query volume, matching the slow tapering off of issue coverage found in Web content. Conversely, for hard, substantive news issues, query volume drops off quite quickly, more closely paralleling the distribution of coverage in broadcast news.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Mining advertiser-specific user behavior using adfactors
WWW (2010), pp. 31-40
[u'Nikolay Archak', u'Vahab S. Mirrokni', u'S. Muthukrishnan']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Online Stochastic Packing Applied to Display Ad Allocation
ESA (1) (2010), pp. 182-194
[u'Jon Feldman', u'Monika Henzinger', u'Nitish Korula', u'Vahab S. Mirrokni', u'Clifford Stein']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Optimal Iterative Pricing over Social Networks (Extended Abstract)
WINE (2010), pp. 415-423
[u'Hessameddin Akhlaghpour', u'Mohammad Ghodsi', u'Nima Haghpanah', u'Vahab Mirrokni', u'Hamid Mahini', u'Afshin Nikzad']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Optimal marketing and pricing over social networks
WWW (2010), pp. 1349-1350
[u'Nicole Immorlica', u'Vahab S. Mirrokni']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Quasi-Proportional Mechanisms: Prior-free Revenue Maximization
Latin (2010), to appear
[u'Vahab S. Mirrokni', u'S. Muthukrishnan', u'Uri Nadav']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36924.html
notfound
=========================
RDRP: Reward-Driven Request Prioritization for e-Commerce Web Sites
Electronic Commerce Research and Applications, vol. 9 (2010), pp. 549-561
[u'Alexander Totok', u'Vijay Karamcheti']
EconomicsandElectronicCommerce
Abstract: Meeting client Quality-of-Service (QoS) expectations proves to be a difficult task for the providers of e-Commerce services, especially when web servers experience overload conditions, which cause increased response times and request rejections, leading to user frustration, lowered usage of the service and reduced revenues. In this paper, we propose a server-side request scheduling mechanism that addresses these problems. Our Reward-Driven Request Prioritization (RDRP) algorithm gives higher execution priority to client web sessions that are likely to bring more service profit (or any other application-specific reward). The method works by predicting future session structure by comparing its requests seen so far with aggregated information about recent client behavior, and using these predictions to preferentially allocate web server resources. Our experiments using the TPC-W benchmark application with an implementation of the RDRP techniques in the JBoss web application server show that RDRP can significantly boost profit attained by the service, while providing better QoS to clients that bring more profit.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Reporting Incentives and Biases in Online Review Forums.
ACM Transactions on the Web (TWEB), vol. 4 (2010)
[u'Radu Jurca', u'Florent Garcin', u'Arjun Talwar', u'Boi Faltings']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Single Parameter Combinatorial Auctions with Partially Public Valuations
SAGT 2010
[u'Gagan Goel', u'Chinmay Karande', u'Lei Wang']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42217.html
notfound
=========================
Whos calling? The impact of Caller ID on telephone survey response
Field Methods, vol. 22 (2010), pp. 175-191
[u'Mario Callegaro', u'Allan L. McCutcheon', u'Jack Ludwig']
EconomicsandElectronicCommerce
Abstract: The Gallup Organization conducted a caller ID randomized study with a pre-and postexperimental design to test the impact of different caller ID displays (names) on the response, contact, and cooperation rates for telephone surveys. This research focuses on the impact of caller ID listing on the frequency of final dialing dispositions. The authors find initial evidence for the hypothesis that the caller ID transmission works as a sort of condensed survey research organization business card that can trigger brand awareness, thus legitimating the survey and diminishing suspicions of collector or telemarketing calls.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Modular Approach to Roberts' Theorem
SAGT '09: Proceedings of the 2nd International Symposium on Algorithmic Game Theory, Springer-Verlag, Berlin, Heidelberg (2009), pp. 14-23
[u'Shahar Dobzinski', u'Noam Nisan']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Ad Exchanges: Research Issues
Wine 2009: Proceedings of the 5th International Workkshop on Internet and Network Economics, Springer-Verlag, Heidelberg, pp. 1-12
[u'S. N. Muthukrishnan']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
An Online Mechanism for Ad Slot Reservations with Cancellations
Fourth Workshop on Ad Auctions; Symposium on Discrete Algorithms (SODA) (2009)
[u'Florin Constantin', u'Jon Feldman', u'S. Muthukrishnan', u'Martin Pal']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Bid optimization for broad match ad auctions
WWW (2009), pp. 231-240
[u'Eyal Even-Dar', u'Vahab S. Mirrokni', u'S. Muthukrishnan', u'Yishay Mansour', u'Uri Nadav']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Bidding on Configurations in Internet Ad Auctions
COCOON '09: Proceedings of the 15th Annual International Conference on Computing and Combinatorics, Springer-Verlag, Berlin, Heidelberg (2009), pp. 1-6
[u'S. N. Muthukrishnan']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Coordination mechanisms for selfish scheduling
Theor. Comput. Sci., vol. 410 (2009), pp. 1589-1598
[u'Nicole Immorlica', u'Li (Erran) Li', u'Vahab S. Mirrokni', u'Andreas S. Schulz']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Efficiency of (Revenue-)Optimal Mechanisms
Proceedings of the 10th ACM Conference on Electronic Commerce (2009)
[u'Gagan Aggarwal', u'Gagan Goel', u'Aranyak Mehta']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Free-Riding and Free-Labor in Combinatorial Agency
SAGT '09: Proceedings of the 2nd International Symposium on Algorithmic Game Theory, Springer-Verlag, Berlin, Heidelberg (2009), pp. 109-121
[u'Moshe Babaioff', u'Michal Feldman', u'Noam Nisan']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35113.html
notfound
=========================
Googles Auction for Radio and TV Ads
Google, Inc. (2009)
[u'Noam Nisan', u'Jason Bayer', u'Deepak Chandra', u'Tal Franji', u'Robert Gardner', u'Yossi Matias', u'Neil Rhodes', u'Misha Seltzer', u'Danny Tom', u'Hal Varian', u'Dan Zigmond']
EconomicsandElectronicCommerce
Abstract: This document describes the auction system used by Google for allocation and pricing of TV ads and Radio ads. It is based on a simultaneous ascending auction, and has been in use since September 2008.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
On the Predictability of Search Trends (manuscript)
Google (2009)
[u'Yair Shimshoni', u'Niv Efron', u'Yossi Matias']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
On the complexity of nash dynamics and sink equilibria
ACM Conference on Electronic Commerce (2009), pp. 1-10
[u'Vahab S. Mirrokni', u'Alexander Skopalik']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Online Ad Assignment with Free Disposal
Workshop of Internet Economics (WINE) (2009), pp. 374-385
[u'Jon Feldman', u'Nitish Korula', u'Vahab S. Mirrokni', u'S. Muthukrishnan', u'Martin Pl']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Online Stochastic Matching: Beating 1-1/e
Symposium on the Foundations of Computer Science (FOCS) (2009)
[u'Jon Feldman', u'Aranyak Mehta', u'Vahab Mirrokni', u'S. Muthukrishnan']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Tutorial summary: Convergence of natural dynamics to equilibria
ICML (2009), pp. 173
[u'Eyal Even-Dar', u'Vahab S. Mirrokni']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Truthful Mechanism for Offline Ad Slot Scheduling
Symposium on Algorithmic Game Theory (2008)
[u'Jon Feldman', u'S. Muthukrishnan', u'Evdokia Nikolova', u'Martin Pal']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Algorithmic Methods for Sponsored Search Advertising
Performance Modeling and Engineering (Proc. SIGMETRICS 2008 Tutorial Sessions), Springer, pp. 91-124
[u'Jon Feldman', u'S. Muthukrishnan']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Asynchronous Best-Reply Dynamics
WINE '08: Proceedings of the 4th International Workshop on Internet and Network Economics, Springer-Verlag, Berlin, Heidelberg (2008), pp. 531-538
[u'Noam Nisan', u'Michael Schapira', u'Aviv Zohar']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Income Inequality in the Attention Economy
Google, Inc. (2008)
[u'Kevin S. McCurley']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Online budgeted matching in random input models with applications to Adwords
Proc. 19th ACM-SIAM Symposium on Discrete Algorithms, SIAM, San Francisco (2008), pp. 982-991
[u'Gagan Goel', u'Aranyak Mehta']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Position Auctions with Bidder-Specific Minimum Prices
Fourth Workshop on Ad Auctions; Workshop on Internet and Network Economics (WINE) (2008)
[u'Eyal Even-Dar', u'Jon Feldman', u'Yishay Mansour', u'S. Muthukrishnan']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Sponsored Search Auctions for Markovian Users
Fourth Workshop on Ad Auctions; Workshop on Internet and Network Economics (WINE). (2008)
[u'Gagan Aggarwal', u'Jon Feldman', u'Martin Pal', u'S. Muthukrishnan']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Truthful opinions from the crowds
SIGecom Exch., vol. 7 (2008), pp. 1-4
[u'Radu Jurca', u'Boi Faltings']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Note on Maximizing the Spread of Influence in Social Networks
Internet and Network Economics (WINE), Springer, San Diego (2007), pp. 281-286
[u'Eyal Even-Dar', u'Asaf Shapira']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Adwords Auctions with Decreasing Valuation Bids
Internet and Network Economics (WINE), Springer, San Diego (2007), pp. 335-340
[u'Gagan Goel', u'Aranyak Mehta']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Budget Optimization in Search-Based Advertising Auctions
Proc. ACM Conference on Electronic Commerce, ACM, San Diego (2007)
[u'Jon Feldman', u'S. Muthukrishnan', u'Martin Pl', u'Cliff Stein']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Sponsored Search with Contexts
Internet and Network Economics (WINE), Springer, San Diego (2007), pp. 312-317
[u'Eyal Even-Dar', u'Michael Kearns', u'Jennifer Wortman']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Stochastic Models for Budget Optimization in Search-Based Advertising
Internet and Network Economics (WINE), Springer, San Diego (2007), pp. 131-142
[u'S. Muthukrishnan', u'Martin Pl', u'Zoya Svitkina']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Bidding to the Top: VCG and Equilibria of Position-Based Auctions
Proceedings of the Fourth Workshop on Approximation and Online Algorithms (WAOA) (2006)
[u'Gagan Aggarwal', u'Jon Feldman', u'S. Muthukrishnan']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub27880.html
notfound
=========================
How Friendships Form
The Quarterly Journal of Economics, vol. 121 (2006)
[u'David Marmaros', u'Bruce Sacerdote']
EconomicsandElectronicCommerce
Abstract: We examine how people form social networks among their peers. We use a unique data set that tells us the volume of email between any two people in the sample. The data are from students and recent graduates of Dartmouth College. First-year students interact with peers in their immediate proximity and form long-term friendships with a subset of these people. This result is consistent with a model in which the expected value of interacting with an unknown person is low (making traveling solely to meet new people unlikely), while the benefits from interacting with the same person repeatedly are high. Geographic proximity and race are greater determinants of social interaction than are common interests, majors, or family background.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Playing games in many possible worlds
ACM Conference on Electronic Commerce (2006), pp. 150-159
[u'Matt Lepinski', u'David Liben-Nowell', u'Seth Gilbert', u'April Rasala Lehman']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Truthful auctions for pricing search keywords
ACM Conference on Electronic Commerce (2006), pp. 1-7
[u'Gagan Aggarwal', u'Ashish Goel', u'Rajeev Motwani']
EconomicsandElectronicCommerce
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/EducationInnovation.html
found
http://research.google.com/pubs/pub43424.html
notfound
=========================
Adding Third-Party Authentication to Open edX: A Case Study
Proceedings of the Second (2015) ACM Conference on Learning @ Scale, ACM, New York, NY, USA, pp. 277-280
[u'John Cox', u'Pavel Simakov']
EducationInnovation
Abstract: In this document, we describe the third-party authentication system we added to Open edX. With this system, Open edX administrators can allow their users to sign in with a large array of external authentication providers. We outline the features and advantages of the system, describe how it can be extended and customized, and highlight reusable design principles that can be applied to other authentication implementations in online education.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43820.html
notfound
=========================
Gender Differences in Factors Influencing Pursuit of Computer Science and Related Fields
Proceedings of the 20th ACM Conference on Innovation and Technology in Computer Science Education, ACM (2015) (to appear)
[u'Jennifer Wang', u'Hai Hong', u'Jason Ravitz', u'Marielena Ivory']
EducationInnovation
Abstract: Increasing womens participation in computer science is a critical workforce and equity concern. The technology industry has committed to reversing negative trends for women in computer science as well as engineering and information technology computing fields. Building on previously published research, this paper identifies factors that influence young womens decisions to pursue computer science-related degrees and the ways in which these factors differ for young men. It is based on a survey of 1,739 high school students and recent college graduates. Results identified encouragement and exposure as the leading factors influencing this critical choice for women, while the influence of these factors is different for men. In particular, the influence of family is found to play a critical role in encouragement and exposure, and outreach efforts should focus on ways to engage parents.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43401.html
notfound
=========================
Gender Differences in High School Students Decisions to Study Computer Science and Related Fields
Proceedings of the 46th ACM Technical Symposium on Computer Science Education, ACM (2015)
[u'Hai Hong', u'Jennifer Wang', u'Jason Ravitz', u'Mo-Yun Lei Fong']
EducationInnovation
Abstract: Increasing womens participation in Computer Science (CS) is a critical workforce and equity concern. The technology industry has committed to reversing negative trends for women in CS, engineering, and related fields. Building on previous research, we surveyed 1,739 high school students and recent college graduates to understand factors influencing decisions to pursue CS-related college degrees. Results indicate social encouragement, career perception, academic exposure, and self perception are the leading factors for women, while the influence of these factors is different for men. These factors are actionable, and understanding differences in their influence on men and women will inform our approaches to achieving gender parity in tech.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44007.html
notfound
=========================
Research skills matter: How to teach them
Moonshots in Education: Launching Blended Learning in the Classroom, Pacific Research Institute, San Francisco, CA (2015)
[u'Daniel Martin Russell']
EducationInnovation
Abstract: Theres always been a gap between those who know how to use information resources and those who dont. Students who knew the ways to leverage a library for research could consistently do better research than those who couldnt. This chapter is about why teaching research skills is a necessary step in the development of students.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
An Antidote to Impostor Syndrome
XRDS, vol. Volume 21, No. 2 (2014), pp. 12-13
[u'Dean Jackson', u'Taliver Heath']
EducationInnovation
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42855.html
notfound
=========================
Corporate learning at scale: Lessons from a large online course at Google
Learning at Scale (2014)
[u'Arthur Asuncion', u'Jac de Haan', u'Mehryar Mohri', u'Kayur Patel', u'Afshin Rostamizadeh', u'Umar Syed', u'Lauren Wong']
EducationInnovation
Abstract: Google Research recently tested a massive online class model for an internal engineering education program, with machine learning as the topic, that blended theoretical concepts and Google-specific software tool tutorials. The goal of this training was to foster engineering capacity to leverage machine learning tools in future products. The course was delivered both synchronously and asynchronously, and students had the choice between studying independently or participating with a group. Since all students are company employees, unlike most publicly offered MOOCs we can continue to measure the students behavioral change long after the course is complete. This paper describes the course, outlines the available data set and presents directions for analysis.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41928.html
notfound
=========================
Self-evaluation in Advanced Power Searching and Mapping with Google MOOCs
ACM Learning at Scale (2014)
[u'Julia Wilkowski', u'Daniel M. Russell', u'Amit Deutsch']
EducationInnovation
Abstract: While there is a large amount of work on creating autograded massive open online courses (MOOCs), some kinds of complex, qualitative exam questions are still beyond the current state of the art. For MOOCs that need to deal with these kinds of questions, it is not possible for a small course staff to grade students qualitative work. To test the efficacy of self-evaluation as a method for complex-question evaluation, students in two Google MOOCs have submitted projects and evaluated their own work. For both courses, teaching assistants graded a random sample of papers and compared their grades with self-evaluated student grades. We found that many of the submitted projects were of very high quality, and that a large majority of self-evaluated projects were accurately evaluated, scoring within just a few points of the gold standard grading.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41929.html
notfound
=========================
Student Skill and Goal Achievement in the Mapping with Google MOOC
ACM Learning at Scale (2014)
[u'Julia Wilkowski', u'Amit Deutsch', u'Daniel M. Russell']
EducationInnovation
Abstract: Students who registered for the Mapping with Google massive open online course (MOOC) were asked several questions during the registration process to identify prior experience with eleven skills as well as their goals for registering for the course. Students selected goals from a list; they were periodically reminded of these goals during the course. At the end of the course, we compared students self report of goal achievement on a post-course survey with behavioral click-stream analysis. In addition, we compared whether possessing skills at the outset of the course or completing course activities had a larger effect on course completion. We discovered that prior skill had no significant predictive value on certification, but students who completed course activities were more likely to earn certificates of completion than peers who did not complete activities.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40591.html
notfound
=========================
Online Python Tutor: Embeddable Web-Based Program Visualization for CS Education
Proceedings of the ACM Technical Symposium on Computer Science Education (SIGCSE), ACM (2013) (to appear)
[u'Philip Guo']
EducationInnovation
Abstract: This paper presents Online Python Tutor, a web-based program visualization tool for Python, which is becoming a popular language for teaching introductory CS courses. Using this tool, teachers and students can write Python programs directly in the web browser (without installing any plugins), step forwards and backwards through execution to view the run-time state of data structures, and share their program visualizations on the web. In the past three years, over 200,000 people have used Online Python Tutor to visualize their programs. In addition, instructors in a dozen universities such as UC Berkeley, MIT, the University of Washington, and the University of Waterloo have used it in their CS1 courses. Finally, Online Python Tutor visualizations have been embedded within three web-based digital Python textbook projects, which collectively attract around 16,000 viewers per month and are being used in at least 25 universities. Online Python Tutor is free and open source software, available at pythontutor.com
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41881.html
notfound
=========================
The Google Technical Interview
XRDS, vol. Volume 20, No. 2 (2013), pp. 12-14
[u'Dean Jackson']
EducationInnovation
Abstract: A review of the Google technical interviews, intended for students of computer science and related disciplines.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Will Massive Open Online Courses (MOOCs) Change Education?
Proc. CHI Conference 2013, ACM
[u'Daniel M Russell', u'Scott Klemmer', u'Armando Fox', u'Celine Latulipe']
EducationInnovation
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Google summer of code and google code-in BoF (abstract only)
Proceedings of the 43rd ACM technical symposium on Computer Science Education, ACM, New York, NY, USA (2012), pp. 771-771
[u'Carol Smith']
EducationInnovation
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Jutge.org: an educational programming judge
Proceedings of the 43rd ACM technical symposium on Computer Science Education, ACM, New York, NY, USA (2012), pp. 445-450
[u'Jordi Petit', u'Omer Gimenez', u'Salvador Roura']
EducationInnovation
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40561.html
notfound
=========================
Programming Interviews Exposed
Wrox, an imprint of John Wiley & Sons, Inc., 111 River Street Hoboken, NJ 07030-5774 (2012)
[u'John Mongan', u'Eric Giguere', u'Noah Kindler']
EducationInnovation
Abstract: Landing a great programming job isn't a matter of luck; it's a matter of being prepared for the unique challenges of the technical job search. Programming interviews require a different set of skills than day-to-day programming, so even expert programmers often struggle if they don't know what to expect. This thoroughly revised and expanded third edition teaches you the skills you need to apply your programming expertise to the types of problems most frequently encountered in interviews at top tech companies today. Step-by-step solutions to an extensive set of sample interview questions simulate the interview experience to hone the skills you've learned. After you've worked through this book, you'll approach your interviews with confidence, knowing you can solve any problem that stands between you and the job you really want.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
The Broad Value of a PhD in Political Science
PS: Political Science and Politics, vol. 45 (2012), pp. 812-814
[u'Michael Hughes Murakami']
EducationInnovation
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Through the looking glass: talking about the world with visualization
Proceedings of the 43rd ACM technical symposium on Computer Science Education, ACM, New York, NY, USA (2012), pp. 655-656
[u'Fernanda Viegas', u'Martin Wattenberg']
EducationInnovation
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37227.html
notfound
=========================
App Inventor
O'Reilly Media, Inc, 1005 Gravenstein Hwy N, Sebastopol, CA 95472 (2011), pp. 384
[u'David Wolber', u'Hal Abelson', u'Ellen Spertus', u'Liz Looney']
EducationInnovation
Abstract: Yes, you can create your own apps for Android phonesand it's easy to do. This extraordinary book introduces App Inventor for Android, a powerful visual tool that lets anyone build apps for Android-based devices. Learn the basics of App Inventor with step-by-step instructions for more than a dozen fun projects, such as creating location-aware apps, data storage, and apps that include decision-making logic. The second half of the book features an Inventor's manual to help you understand the fundamentals of app building and computer science. App Inventor makes an excellent textbook for beginners and experienced developers alike. Design games and other apps with 2D graphics and animation Create custom multi-media quizzes and study guides Create a custom tour of your city, school, or workplace Use an Android phone to control a LEGO MINDSTORMS NXT robot Build location-aware apps by working with your phones sensors Explore apps that incorporate information from the Web Learn computer science as you build your apps
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37654.html
notfound
=========================
Can a 2-hour Visit to a Hi-Tech Company Increase Interest in and Change Perceptions about Computer Science?
ACM Inroads, vol. 2, Issue 3 (2011)
[u'Larisa Eidelman', u'Orit Hazzan', u'Tami Lapidot', u'Yossi Matias', u'Daniela Raijman', u'Michal Segalov']
EducationInnovation
Abstract: This paper presents the "Mind the Gap" initiative that aims to encourage female high school pupils to study computer science (CS) in high school. This is achieved by increasing their awareness to what CS is, and exposing them to the essence of a hi-tech environment and to same gender role models. The initiative was undertaken by female software engineers at Google's Israel R&D Center in collaboration with the Israeli National Center for Computer Science Teachers. We describe the initiative and its impact on the female pupils' interest in CS. One of our conclusions is that even a short visit to a hi-tech company, in this case Google, has the potential to change pupils' perception of what CS is and to increase their interest in CS and their desire to study it. Our initiative can be easily adapted by other companies and can be scaled to impact a rather large population.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37212.html
notfound
=========================
Web 2.0 and Performance: Using Social Media to Facilitate Learning at Google
Michael Allen's e-Learning Annual 2012, Pfeiffer, 989 Market St, San Francisco, CA 94103 (2011), pp. 171-179
[u'Julia Bulkowski']
EducationInnovation
Abstract: Are you leveraging Web 2.0 technologies to solve performance problems? Google has tapped the power of online collaboration to solve business problems and engage learners. It is easier than you might think to leverage scalable and free technologies to address your organization's needs. In this hands-on session, explore case studies of how Google is using blogs, wikis, shared documents, RSS readers, and online video sharing to transform learning and performance.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36661.html
notfound
=========================
JavaSpaces NetBeans: a linda workbench for distributed programming course
Proceedings of the fifteenth annual conference on Innovation and technology in computer science education, ACM, New York, NY, USA (2010), pp. 23-27
[u'Magdalena Dukielska', u'Jacek Sroka']
EducationInnovation
Abstract: In this paper we introduce the JavaSpaces NetBeans IDE (JSN) which integrates the JavaSpaces technology, an implementation of Linda principles in Java, with the NetBeans IDE. JSN is a didactic tool for practical assignments during distributed programming courses. It hides advanced aspects of JavaSpaces configuration and lets students focus on interprocess coordination. An important component of JSN is a distributed debugger which can help to make concurrent programming classes easier to understand and more compelling.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34908.html
notfound
=========================
Learning to be a software engineer in a complex organization: A case study focusing on apprenticeship/practice based learning for getting new engineers productive in contributing to the Google codebase
Journal of Workplace Learning, vol. 22, no. 3 (2010), pp. 180-194
[u'Maggie Johnson', u'Max Senges']
EducationInnovation
Abstract: Purpose This paper seeks to analyse the effectiveness and impact of how Google currently trains its new software engineers (Nooglers) to become productive in the software engineering community. The research focuses on the institutions and support for practice-based learning and cognitive apprenticeship in the Google environment. Design/methodology/approach The study uses a series of semi-structured interviews with 24 Google stakeholders. These interviews are complemented by observations, document analysis, and review of existing survey and statistical data. Findings It is found that Google offers a state-of-the-art onboarding program and benchmark qualities that provide legitimate peripheral participation. The research reveals how Google empowers programmers to feel at home using company coding practices, as well as maximizing peer-learning and collaborative practices. These practices reduce isolation, enhance collegiality, and increase employee morale and job satisfaction. Research limitations/implications The case study describes the practices in one company. Practical implications The research documented in the paper can be used as a benchmark for other onboarding and practice-based learning set-ups. Originality/value This is the first research that gives insights into the practice-based learning and onboarding practices at Google. The practices are assessed to be state-of-the-art and the insights therefore relevant for benchmarking exercises of other companies.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36234.html
notfound
=========================
Reducing dominance in multiple-mouse learning activities
CSCL'09: Proceedings of the 9th international conference on Computer supported collaborative learning, International Society of the Learning Sciences (2009), pp. 360-364
[u'Andrea Moed', u'Owen Otto', u'Joyojeet Pal', u'Udai Pawar Singh', u'Matthew Kam', u'Kentaro Toyama']
EducationInnovation
Abstract: In resource-constrained classrooms in the developing world, it is common for several students to share each computer. Unfortunately, dominance behavior often naturally emerges in these situations, when one child monopolizes the mouse and keyboard. One way to mitigate this phenomenon is by providing each child with a mouse and a corresponding on-screen cursor so that everyone can interact. Though such multiple-mouse configurations reduce the possibility of total domination by one individual, they do not automatically eliminate dominance behavior completely. We propose the use of a design for small-group learning on shared computers based on enforced turn-taking in a split-screen, multiple-mouse environment. In an evaluation with 104 rural schoolchildren in India, we found that dominance behavior was indeed reduced through these design choices.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Cluster Computing for Web-Scale Data Processing
Proceedings of the 39th SIGCSE Technical Symposiumo on Computer Science Education, ACM, Portland, OR (2008), pp. 116-120
[u'Aaron Kimball', u'Sierra Michels-Slettvet', u'Christophe Bisciglia']
EducationInnovation
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub33476.html
notfound
=========================
Educating Learning Technology Designers: Guiding and Inspiring Future Creators of Innovative Educational Tools
Routledge, Taylor & Francis Group, New York, New York (2008), pp. 300
[u'Chris DiGiano', u'Shelley Goldman', u'Mike Chorost']
EducationInnovation
Abstract: This is an edited book about preparing the next generation of technology designers and developers to create compelling and effective learning technologies. It is a compilation of lessons learned from college courses across the U.S. and instructional resources such as tips and tricks and sample student projects.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Innovation, Design, and Simplicity at Google
Proceedings of the 39th SIGCSE Technical Symposium on Computer Science Education, ACM, Portland, OR (2008), pp. 199
[u'Marrisa Mayer']
EducationInnovation
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/GeneralScience.html
found
http://research.google.com/pubs/pub43419.html
found
=========================
Associating Locations with Healthcare Events
Defensive Publications Series, Technical Disclosure Commons (2015)
[u'Daniel V. Klein', u'Dean Jackson']
GeneralScience
Abstract: The disclosed subject matter relates to computer implemented methods for associating locations with healthcare events. In one aspect, a method includes receiving location data from a location-aware client device. The location data includes latitude and longitude information. The method further includes determining, based on the received location data, a routine travel pattern of a user associated with the location-aware client device. The method further includes detecting an anomaly in the routine travel pattern. The method further includes detecting a healthcare event. The healthcare event can be a visit to a healthcare facility and/or a healthcare transaction. The method further includes correlating the anomaly in the routine travel pattern of the user with the healthcare event. The method further includes associating one or more healthcare event locations to the healthcare event based on the correlation.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43885.html
notfound
=========================
Atoms, Bits, and Cells
Applied and Translational Genomics (2015)
[u'David Glazer']
GeneralScience
Abstract: Biology is entering the world of data. Data brings great potential for understanding all of us and improving the health of each of us. But making sense of data also brings challenges. To realize the potential, we must build on advances in data science, and learn from the experiences of other fields.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43288.html
notfound
=========================
Directed Enzymatic Activation of 1-D DNA Tiles
ACS Nano (2015)
[u'Sudhanshu Garg', u'Harish Chandran', u'Nikhil Gopalkrishnan', u'Thomas H. LaBean', u'John Reif']
GeneralScience
Abstract: The tile assembly model is a Turing universal model of self-assembly where a set of square shaped tiles with programmable sticky sides undergo coordinated self-assembly to form arbitrary shapes, thereby computing arbitrary functions. Activatable tiles are a theoretical extension to the Tile assembly model that enhances its robustness by protecting the sticky sides of tiles until a tile is partially incorporated into a growing assembly. In this article, we experimentally demonstrate a simplified version of the Activatable tile assembly model. In particular, we demonstrate the simultaneous assembly of protected DNA tiles where a set of inert tiles are activated via a DNA polymerase to undergo linear assembly. We then demonstrate stepwise activated assembly where a set of inert tiles are activated sequentially one after another as a result of attachment to a growing 1-D assembly. We hope that these results will pave the way for more sophisticated demonstrations of activated assemblies.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43402.html
notfound
=========================
Fast quantum methods for optimization
The European Physical Journal Special Topics, vol. 224 (2015), pp. 35
[u'S. Boixo', u'G. Ortiz', u'R. Somma']
GeneralScience
Abstract: Discrete combinatorial optimization consists in finding the optimal configuration that minimizes a given discrete objective function. An interpretation of such a function as the energy of a classical system allows us to reduce the optimization problem into the preparation of a low-temperature thermal state of the system. Motivated by the quantum annealing method, we present three strategies to prepare the low-temperature state that exploit quantum mechanics in remarkable ways. We focus on implementations without uncontrolled errors induced by the environment. This allows us to rigorously prove a quantum advantage. The first strategy uses a classical-to-quantum mapping, where the equilibrium properties of a classical system in d spatial dimensions can be determined from the ground state properties of a quantum system also in d spatial dimensions. We show how such a ground state can be prepared by means of quantum annealing, including quantum adiabatic evolutions. This mapping also allows us to unveil some fundamental relations between simulated and quantum annealing. The second strategy builds upon the first one and introduces a technique called spectral gap amplification to reduce the time required to prepare the same quantum state adiabatically. If implemented on a quantum device that exploits quantum coherence, this strategy leads to a quadratic improvement in complexity over the well-known bound of the classical simulated annealing method. The third strategy is not purely adiabatic; instead, it exploits diabatic processes between the low-energy states of the corresponding quantum system. For some problems it results in an exponential speedup (in the oracle model) over the best classical algorithms.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Massively Multitask Networks for Drug Discovery
arXiv:1502.02072 [stat.ML] (2015)
[u'Bharath Ramsundar', u'Steven Kearnes', u'Patrick Riley', u'Dale Webster', u'David Konerding', u'Vijay Pande']
GeneralScience
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43834.html
found
=========================
Probabilistic Analysis of Localized DNA Hybridization Circuits
ACS Synthetic Biology (2015)
[u'Neil Dalchau', u'Harish Chandran', u'Nikhil Gopalkrishnan', u'Andrew Phillips', u'John Reif']
GeneralScience
Abstract: Molecular devices made of nucleic acids can perform complex information processing tasks at the nanoscale, with potential applications in biofabrication and smart therapeutics. However, limitations in the speed and scalability of such devices in a well-mixed setting can significantly affect their performance. In this paper, we propose designs for localized circuits involving DNA molecules that are arranged on addressable substrates and interact via hybridization reactions. We propose designs for localized elementary logic circuits, which we compose to produce more complex devices, including a circuit for computing the square root of a four bit number. We develop an efficient method for probabilistic model-checking of localized circuits, which we implement within the Visual DSD design tool. We use this method to prove the correctness of our circuits with respect to their functional specifications, and to analyze their performance over a broad range of local rate parameters. Specifically, we analyze the extent to which our localized designs can overcome the limitations of well-mixed circuits, with respect to speed and scalability. To provide an estimate of local rate parameters, we propose a biophysical model of localized hybridization. Finally, we use our analysis to identify constraints in the rate parameters that enable localized circuits to retain their advantages in the presence of unintended interferences between strands.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Quantum Algorithms for Discrete Optimization
Quantum Optimization: Fields Institute Communications, Springer (2015) (to appear)
[u'Sergio Boixo', u'Rolando Somma']
GeneralScience
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43941.html
found
=========================
Quantum Simulation of Helium Hydride Cation in a Solid-State Spin Register
ACS Nano, vol. 9 (2015), 77697774
[u'Ya Wang', u'Florian Dolde', u'Jacob Biamonte', u'Ryan Babbush', u'Ville Bergholm', u'Sen Yang', u'Ingmar Jakobi', u'Philipp Neumann', u'Aln Aspuru-Guzik', u'James Whitfield', u'Jrg Wrachtrup']
GeneralScience
Abstract: Ab initio computation of molecular properties is one of the most promising applications of quantum computing. While this problem is widely believed to be intractable for classical computers, efficient quantum algorithms exist which have the potential to vastly accelerate research throughput in fields ranging from material science to drug discovery. Using a solid-state quantum register realized in a nitrogen-vacancy (NV) defect in diamond, we compute the bond dissociation curve of the minimal basis helium hydride cation, HeH+. Moreover, we report an energy uncertainty (given our model basis) of the order of 1e14 hartree, which is 10 orders of magnitude below the desired chemical precision. As NV centers in diamond provide a robust and straightforward platform for quantum information processing, our work provides an important step toward a fully scalable solid-state implementation of a quantum chemistry simulator.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44314.html
found
=========================
RFC7706 - Decreasing Access Time to Root Servers by Running One on Loopback
IETF RFCs, Internet Engineering Task Force (2015), pp. 12
[u'Warren Kumari', u'Paul Hoffman']
GeneralScience
Abstract: Some DNS recursive resolvers have longer-than-desired round-trip times to the closest DNS root server. Some DNS recursive resolver operators want to prevent snooping of requests sent to DNS root servers by third parties. Such resolvers can greatly decrease the round-trip time and prevent observation of requests by running a copy of the full root zone on a loopback address (such as 127.0.0.1). This document shows how to start and maintain such a copy of the root zone that does not pose a threat to other users of the DNS, at the cost of adding some operational fragility for the operator.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43973.html
notfound
=========================
RSSAC002 - RSSAC Advisory on Measurements of the Root Server System
ICANN Root Server System Advisory Committee ( RSSAC ) Reports and Advisories, Internet Corporation for Assigned Names and Numbers (ICANN) (2015), pp. 15
[u'Warren Kumari']
GeneralScience
Abstract: RSSAC has begun work to determine a list of parameters that define the desired service trends for the root zone system. These parameters include the measured latency in the distribution of the root zone, the frequency of the updates, and their size. With knowledge of these parameters in hand, RSSAC can then seek to produce estimates of acceptable root zone size dynamics to ensure the overall system works within a set of parameters. The future work to define these parameters will involve RSSAC working closely with the root server operators to gather best practice estimates for the size and update frequency of the root zone. It must be well understood that the measurements described in this document are a response to the current awareness, experience, and understanding of the Root Zone System. As time progresses more, less, or entirely different metrics may be required to investigate new concerns or defined problem statements.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43974.html
found
=========================
RSSAC003 - RSSAC Report on Root Zone TTLs
ICANN Root Server System Advisory Committee ( RSSAC ) Reports and Advisories, Internet Corporation for Assigned Names and Numbers (ICANN) (2015), pp. 35
[u'Warren Kumari']
GeneralScience
Abstract: Root zone TTLs have not changed since 1999. In this report, the RSSAC Caucus studies the extent to which the current root zone TTLs are still appropriate for todays Internet environment. Selecting a TTL for a given resource record involves finding the right balance between a few tradeoffs. Intuitively, shorter TTLs are beneficial for data that changes frequently, whereas longer TTLs are beneficial for data that is relatively stable. Related to this, longer TTLs provide robustness in the event of operational failures. All other things being equal, and assuming software involved in queries and responses follow the DNS protocol standards, shorter TTLs generally result in higher query rates, and longer TTLs result in lower query rates.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43821.html
notfound
=========================
SAC070 - SSAC Advisory on the Use of Static TLD / Suffix Lists
ICANN Security and Stability Advisory Committee (SSAC) Reports and Advisories, ICANN (2015), pp. 32
[u'Warren Kumari', u'Jaap Akkerhuis', u'Patrik Fltstrm']
GeneralScience
Abstract: This advisory investigates the security and stability needs surrounding the growing use of public suffix lists on the Internet. For the purposes of this Advisory, a public suffix is defined as a domain under which multiple parties that are unaffiliated with the owner of the Public Suffix domain may register subdomains. Examples of Public Suffix domains include "org", "co.uk", "k12.wa.us" and "uk.com". There is no programmatic way to determine the boundary where a Domain Name System (DNS) label changes stewardship from a public suffix, yet tracking the boundary accurately is critically important for security, privacy, and usability issues in many modern systems and applications, such as web browsers. One method of determining this boundary is by use of public suffix lists (PSLs), which are static files listing the known public suffixes.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43468.html
notfound
=========================
The interacting effects of distributed work arrangements and individual dispositions on willingness to engage in sensemaking behaviors
Journal of the Association for Information Science and Technology (2015)
[u'Peter Gray', u'Brian Butler', u'Nikhil Sharma']
GeneralScience
Abstract: Faced with highly competitive and dynamic environments, organizations are increasingly investing in technologies that provide them with new options for structuring work. At the same time, firms are increasingly dependent on employees' willingness and ability to make sense of novel tasks, problems, and rapidly changing situations. Yet, in spite of its importance, the impact of technology-enabled distributed work arrangements on sensemaking behavior is largely unknown. Sensemaking remains something that is perceived by many to be an idiosyncratic behavior that is, at best, loosely related to sociotechnical context and culture. Drawing on previous studies of cognitive dispositions (need for cognition, tendency for decisiveness, intolerance for ambiguity, and close-mindedness) and research on how technology-enabled distributed work arrangements affect interpersonal interaction, we theorize how workgroup geographic distribution interacts with individual cognitive differences to affect employees' willingness to engage in the core sociocognitive activities of sensemaking. Our results show that the consequences of individual tendencies can vary under different work arrangements, suggesting that managers seeking to facilitate sensemaking activities must make careful choices about the composition of distributed work groups, as well as how collaboration technologies can be used to encourage sensemaking behaviors.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43831.html
notfound
=========================
Advanced DSP for 400 Gb/s and Beyond Optical Networks
J. Lightwave Technology, vol. 32 (2014), pp. 2716-2725
[u'Xiang Zou', u'Lynn Nelson']
GeneralScience
Abstract: This paper presents a systematic review of several digital signal processing (DSP)-enabled technologies recently proposed and demonstrated for high spectral efficiency (SE) 400 Gb/sclass and beyond optical networks. These include 1) a newly proposed SE-adaptable optical modulation technologytime-domain hybrid quadrature amplitude modulation (QAM), 2) two advanced transmitter side digital spectral shaping technologiesNyquist signaling (for spectrally-efficient multiplexing) and digital preequalization (for improving tolerance toward channel narrowing effects), and 3) a newly proposed training-assisted two-stage carrier phase recovery algorithm that is designed to address the detrimental cyclic phase slipping problem with minimal training overhead. Additionally, this paper presents a novel DSP-based method for mitigation of equalizer-enhanced phase noise impairments. It is shown that performance degradation caused by the interaction between the long-memory chromatic dispersion compensating filter/equalizer and local oscillator laser phase noise can be effectively mitigated by replacing the commonly used fast single-tap phaserotation-based equalizer (for typical carrier phase recovery) with a fast multi-tap linear equalizer. Finally, brief reviews of two high-SE 400 Gb/s-class WDM transmission experiments employing these advanced DSP algorithms are presented.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44204.html
notfound
=========================
Advanced DSP for 400Gb/s and beyond Optical Networks
JOURNAL OF LIGHTWAVE TECHNOLOGY, vol. Vol. 32 (2014), pp. 2716-2725
[u'Xiang Zhou', u'Lynn Nelson']
GeneralScience
Abstract: This paper presents a systematic review of several digital signal processing (DSP)-enabled technologies recently proposed and demonstrated for high spectral efficiency (SE) 400Gb/s class and beyond optical networks. These include 1) a newly proposed SE-adaptable optical modulation technology time-domain hybrid quadrature amplitude modulation (QAM), 2) two advanced transmitter side digital spectral shaping technologies Nyquist signaling (for spectrally-efficient multiplexing) and digital pre-equalization (for improving tolerance toward channel narrowing effects), and 3) a newly proposed training-assisted two-stage carrier phase recovery algorithm that is designed to address the detrimental cyclic phase slipping problem with minimal training overhead. Additionally, this paper presents a novel DSP-based method for mitigation of equalizer-enhanced phase noise impairments. It is shown that performance degradation caused by the interaction between the long-memory chromatic dispersion (CD) compensating filter/equalizer and local oscillator (LO) laser phase noise can be effectively mitigated by replacing the commonly used fast single-tap phase-rotation-based equalizer (for typical carrier phase recovery) with a fast multi-tap linear equalizer. Finally, brief reviews of two high-SE 400Gb/s-class WDM transmission experiments employing these advanced DSP algorithms are presented.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43934.html
notfound
=========================
Bayesian Sampling using Stochastic Gradient Thermostats
Advances in Neural Information Processing Systems (2014), pp. 3203-3211
[u'Nan Ding', u'Youhan Fang', u'Ryan Babbush', u'Changyou Chen', u'Robert Skeel', u'Hartmut Neven']
GeneralScience
Abstract: Dynamics-based sampling methods, such as Hybrid Monte Carlo (HMC) and Langevin dynamics (LD), are commonly used to sample target distributions. Recently, such approaches have been combined with stochastic gradient techniques to increase sampling efficiency when dealing with large datasets. An outstanding problem with this approach is that the stochastic gradient introduces an unknown amount of noise which can prevent proper sampling after discretization. To remedy this problem, we show that one can leverage a small number of additional variables to stabilize momentum fluctuations induced by the unknown noise. Our method is inspired by the idea of a thermostat in statistical physics and is justified by a general theory.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42510.html
found
=========================
Characterization of Impact of Transient Faults and Detection of Data Corruption Errors in Large-Scale N-Body Programs Using Graphics Processing Units
IEEE International Parallel and Distributed Processing Symposium (IPDPS), IEEE International Parallel and Distributed Processing Symposium (IPDPS) (2014), pp. 458-467
[u'Keun Soo Yim']
GeneralScience
Abstract: In N-body programs, trajectories of simulated particles have chaotic patterns if errors are in the initial conditions or occur during some computation steps. It was believed that the global properties (e.g., total energy) of simulated particles are unlikely to be affected by a small number of such errors. In this paper, we present a quantitative analysis of the impact of transient faults in GPU devices on a global property of simulated particles. We experimentally show that a single-bit error in non-control data can change the final total energy of a large- scale N-body program with ~2.1% probability. We also find that the corrupted total energy values have certain biases (e.g., the values are not a normal distribution), which can be used to reduce the expected number of re-executions. In this paper, we also present a data error detection technique for N-body pro- grams by utilizing two types of properties that hold in simulated physical models. The presented technique and an existing redundancy-based technique together cover many data errors (e.g., >97.5%) with a small performance overhead (e.g., 2.3%).
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41893.html
notfound
=========================
Cloud-based simulations on Google Exacycle reveal ligand modulation of GPCR activation pathways
Nature Chemistry, vol. 6 (2014), 1521
[u'Kai Kohlhoff', u'Diwakar Shukla', u'Morgan Lawrenz', u'Gregory Bowman', u'David Konerding', u'Dan Belov', u'Russ Altman', u'Vijay Pande']
GeneralScience
Abstract: Simulations can provide tremendous insight into the atomistic details of biological mechanisms, but micro- to millisecond timescales are historically only accessible on dedicated supercomputers. We demonstrate that cloud computing is a viable alternative that brings long-timescale processes within reach of a broader community. We used Google's Exacycle cloud-computing platform to simulate two milliseconds of dynamics of a major drug target, the G-protein-coupled receptor 2AR. Markov state models aggregate independent simulations into a single statistical model that is validated by previous computational and experimental results. Moreover, our models provide an atomistic description of the activation of a G-protein-coupled receptor and reveal multiple activation pathways. Agonists and inverse agonists interact differentially with these pathways, with profound implications for drug design.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43349.html
notfound
=========================
Computational complexity of time-dependent density functional theory
New Journal of Physics, vol. 16 (2014), pp. 083035
[u'J D Whitfield', u'M-H Yung', u'D G Templ', u'S Boixo', u'A Aspuru-Guzik']
GeneralScience
Abstract: Time-dependent density functional theory (TDDFT) is rapidly emerging as a premier method for solving dynamical many-body problems in physics and chemistry. The mathematical foundations of TDDFT are established through the formal existence of a fictitious non-interacting system (known as the KohnSham system), which can reproduce the one-electron reduced probability density of the actual system. We build upon these works and show that on the interior of the domain of existence, the KohnSham system can be efficiently obtained given the time-dependent density. We introduce a V-representability parameter which diverges at the boundary of the existence domain and serves to quantify the numerical difficulty of constructing the KohnSham potential. For bounded values of V-representability, we present a polynomial time quantum algorithm to generate the time-dependent KohnSham potential with controllable error bounds.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43944.html
notfound
=========================
Construction of non-convex polynomial loss functions for training a binary classifier with quantum annealing
arXiv preprint 1406.4203 (2014)
[u'Ryan Babbush', u'Vasil Denchev', u'Nan Ding', u'Sergei Isakov', u'Hartmut Neven']
GeneralScience
Abstract: Quantum annealing is a heuristic quantum algorithm which exploits quantum resources to minimize an objective function embedded as the energy levels of a programmable physical system. To take advantage of a potential quantum advantage, one needs to be able to map the problem of interest to the native hardware with reasonably low overhead. Because experimental considerations constrain our objective function to take the form of a low degree PUBO (polynomial unconstrained binary optimization), we employ non-convex loss functions which are polynomial functions of the margin. We show that these loss functions are robust to label noise and provide a clear advantage over convex methods. These loss functions may also be useful for classical approaches as they compile to regularized risk expressions which can be evaluated in constant time with respect to the number of training examples.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Current status and dynamics of mangrove forests of South Asia
Journal of Environmental Management (2014)
[u'Chandra Giri', u'Jordan Long', u'Sawaid Abbas', u'R. Mani Murali', u'Faisal M. Qamer', u'David Thau']
GeneralScience
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
DNA Computing
Computing Handbook (2014)
[u'Hieu Bui', u'Harish Chandran', u'Sudhanshu Garg', u'Nikhil Gopalkrishnan', u'Reem Mokhtar', u'John H. Reif', u'Tianqi Song']
GeneralScience
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42862.html
notfound
=========================
Defining and detecting quantum speedup
Science, vol. 345 (2014), pp. 420-424
[u'Troels F. Rnnow', u'Zhihui Wang', u'Joshua Job', u'Sergio Boixo', u'Sergei V. Isakov', u'David Wecker', u'John M. Martinis', u'Daniel A. Lidar', u'Matthias Troyer']
GeneralScience
Abstract: The development of small-scale quantum devices raises the question of how to fairly assess and detect quantum speedup. Here, we show how to define and measure quantum speedup and how to avoid pitfalls that might mask or fake such a speedup. We illustrate our discussion with data from tests run on a D-Wave Two device with up to 503 qubits. By using random spin glass instances as a benchmark, we found no evidence of quantum speedup when the entire data set is considered and obtained inconclusive results when comparing subsets of instances on an instance-by-instance basis. Our results do not rule out the possibility of speedup for other classes of problems and illustrate the subtle nature of the quantum speedup question. How to benchmark a quantum computer: Quantum machines offer the possibility of performing certain computations much faster than their classical counterparts. However, how to define and measure quantum speedup is a topic of debate. Rnnow et al. describe methods for fairly evaluating the difference in computational power between classical and quantum processors. They define various types of quantum speedup and consider quantum processors that are designed to solve a specific class of problems. Science, this issue p. 420
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43463.html
notfound
=========================
Easy Does It: More Usable CAPTCHAs
CHI '14 Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, ACM, 1600 Amphitheatre Pkwy (2014), pp. 2637-2646
[u'Elie Bursztein', u'Angelika Moscicki', u'Celine Fabry', u'Steven Bethard', u'John C. Mitchell', u'Dan Jurafasky']
GeneralScience
Abstract: Websites present users with puzzles called CAPTCHAs to curb abuse caused by computer algorithms masquerading as people. While CAPTCHAs are generally effective at stopping abuse, they might impair website usability if they are not properly designed. In this paper we describe how we designed two new CAPTCHA schemes for Google that focus on maximizing usability. We began by running an evaluation on Amazon Mechanical Turk with over 27,000 respondents to test the us- ability of different feature combinations. Then we studied user preferences using Googles consumer survey infrastructure. Finally, drawing on the insights gleaned during those studies, we tested our new captcha schemes first on Mechanical Turk and then on a fraction of production traffic. The resulting scheme is now an integral part of our production system and is served to millions of users. Our scheme achieved a 95.3% human accuracy, a 6.7% improvement.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42556.html
notfound
=========================
Entanglement in a Quantum Annealing Processor
Physical Review X, vol. 4 (2014), pp. 021041
[u'T. Lanting', u'A. J. Przybysz', u'A. Yu. Smirnov', u'F.M. Spedalieri', u'M. H. Amin', u'A. J. Berkley', u'R. Harris', u'F. Altomare', u'S. Boixo', u'P. Bunyk', u'N. Dickson', u'C. Enderud', u'J. P. Hilton', u'E. Hoskinson', u'M. W. Johnson', u'E. Ladizinsky', u'N. Ladizinsky', u'R. Neufeld', u'T. Oh', u'I. Perminov', u'C. Rich', u'M. C. Thom', u'E. Tolkacheva', u'S. Uchaikin', u'A. B. Wilson', u'G. Rose']
GeneralScience
Abstract: Entanglement lies at the core of quantum algorithms designed to solve problems that are intractable by classical approaches. One such algorithm, quantum annealing (QA), provides a promising path to a practical quantum processor. We have built a series of architecturally scalable QA processors consisting of networks of manufactured interacting spins (qubits). Here, we use qubit tunneling spectroscopy to measure the energy eigenspectrum of two- and eight-qubit systems within one such processor, demonstrating quantum coherence in these systems. We present experimental evidence that, during a critical portion of QA, the qubits become entangled and entanglement persists even as these systems reach equilibrium with a thermal environment. Our results provide an encouraging sign that QA is a viable technology for large-scale quantum computing.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42872.html
notfound
=========================
Hearing the Shape of the Ising Model with a Programmable Superconducting-Flux Annealer
Scientific Reports, vol. 4 (2014)
[u'Walter Vinci', u'Klas Markstrm', u'Sergio Boixo', u'Aidan Roy', u'Federico M. Spedalieri', u'Paul A. Warburton', u'Simone Severini']
GeneralScience
Abstract: Two objects can be distinguished if they have different measurable properties. Thus, distinguishability depends on the Physics of the objects. In considering graphs, we revisit the Ising model as a framework to define physically meaningful spectral invariants. In this context, we introduce a family of refinements of the classical spectrum and consider the quantum partition function. We demonstrate that the energy spectrum of the quantum Ising Hamiltonian is a stronger invariant than the classical one without refinements. For the purpose of implementing the related physical systems, we perform experiments on a programmable annealer with superconducting flux technology. Departing from the paradigm of adiabatic computation, we take advantage of a noisy evolution of the device to generate statistics of low energy states. The graphs considered in the experiments have the same classical partition functions, but different quantum spectra. The data obtained from the annealer distinguish non-isomorphic graphs via information contained in the classical refinements of the functions but not via the differences in the quantum spectra.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Meta-DNA
Systems and Synthetic Biology: A Systematic Approach (2014)
[u'Harish Chandran', u'Nikhil Gopalkrishnan', u'Bernard Yurke', u'John H. Reif']
GeneralScience
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43140.html
notfound
=========================
Neural Networks and Neuroscience-Inspired Computer Vision
Current Biology, vol. 24 (2014), pp. 921-929
[u'David Cox', u'Tom Dean']
GeneralScience
Abstract: Brains are, at a fundamental level, biological computing machines. They transform a torrent of complex and ambiguous sensory information into coherent thought and action, allowing an organism to perceive and model its environment, synthesize and make decisions from disparate streams of information, and adapt to a changing environment. Against this backdrop, it is perhaps not surprising that computer science, the science of building artificial computational systems, has long looked to biology for inspiration. However, while the opportunities for cross-pollination between neuroscience and computer science are great, the road to achieving brain-like algorithms has been long and rocky. Here, we review the historical connections between neuroscience and computer science, and we look forward to a new era of potential collaboration, enabled by recent rapid advances in both biologically-inspired computer vision and in experimental neuroscience methods. In particular, we explore where neuroscience-inspired algorithms have succeeded, where they still fail, and we identify areas where deeper connections are likely to be fruitful.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43149.html
notfound
=========================
Norming to Performing: Failure Analysis and Deployment Automation of Big Data Software Developed by Highly Iterative Models
IEEE International Symposium on Software Reliability Engineering, IEEE International Symposium on Software Reliability Engineering (2014), pp. 144-155
[u'Keun Soo Yim']
GeneralScience
Abstract: We observe many interesting failure characteristics from Big Data software developed and released using some kinds of highly iterative development models (e.g., agile). ~16% of failures occur due to faults in software deployments (e.g., packaging and pushing to production). Our analysis shows that many such production outages are at least partially due to some human errors rooted in the high frequency and complexity of software deployments. ~51% of the observed human errors (e.g., transcription, education, and communication error types) are avoidable through automation. We thus develop a fault-tolerant automation framework to make it efficient to automate end-to-end software deployment procedures. We apply the framework to two Big Data products. Our case studies show the complexity of the deployment procedures of multi-homed Big Data applications and help us to study the effectiveness of the validation and verification techniques for user-provided automation programs. We analyze the production failures of the two products again after the automation. Our experimental data shows how the automation and the associated procedure improvements reduce the deployment faults and overall failure rate, and improve the feature launch velocity. Automation facilitates more formal, procedure-driven software engineering practices which not only reduce the manual work and human-oriented, avoidable production outages but also help engineers to better understand overall software engineering procedures, making them more auditable, predictable, reliable, and efficient. We discuss two novel metrics to evaluate progress in mitigating human errors and the conditions indicating points to start such transition from owner-driven deployment practice.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42897.html
notfound
=========================
RFC7304 - A Method for Mitigating Namespace Collisions
IETF RFCs, Internet Engineering Task Force (2014)
[u'Warren Kumari']
GeneralScience
Abstract: This document outlines a possible, but not recommended, method to mitigate the effect of collisions in the DNS namespace by providing a means for end users to disambiguate the conflict.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42190.html
notfound
=========================
SSAC Advisory on Search List Processing
ICANN Security and Stability Advisory Committee (SSAC) Reports and Advisories, ICANN (2014), pp. 17
[u'Warren Kumari', u'Jaap Akkerhuis', u'Don Blumenthal']
GeneralScience
Abstract: This advisory examines how current operating systems and applications process search lists. It outlines the issues related to the current search list behavior, and proposes both a strawman to improve search list processing in the long term and mitigation options for the Internet Corporation for Assigned Names and Numbers (ICANN) and the Internet community to consider in the short term. The purpose of these proposals is to help introduce new generic Top Level Domains (gTLDs) in a secure and stable manner with minimum disruptions to currently deployed systems.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42848.html
notfound
=========================
Sources of Traffic Demand Variability and Use of Monte Carlo for Network Capacity Planning
Performance and Capacity 2014 by CMG Conference, Performance and Capacity 2014 by CMG Conference, Performance and Capacity 2014 by CMG Conference
[u'Alexander Gilgur', u'Brian Eck']
GeneralScience
Abstract: When sizing any network capacity, several factors, such as Traffic, Quality of Service (QoS), and Total Cost of Ownership (TCO) are usually taken into account. Generally, it boils down to a joint minimization of cost and maximization of traffic subject to the constraints of protocol and QoS requirements. Stochastic nature of network traffic and link saturation queueing issues add uncertainty to the already complex optimization problem. In this paper, we examine the sources of traffic demand variability and dive into Monte-Carlo methodology as an efficient way for solving these problems. Other sources of uncertainty in network capacity forecasting are briefly discussed in the Attachment.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43135.html
notfound
=========================
The Data on Diversity: It's not just about being fair
Communications of the ACM, vol. 57, number 11 (2014), pp. 86-95
[u'Beryl Nelson']
GeneralScience
Abstract: Teams and organizations whose members are heterogeneous in meaningful ways have a higher potential for innovation than teams whose members are homogeneous. However, making such teams effective requires addressing a number of barriers. Social science experiments using quantitative methods show bias, stereotype threat, and methods to combat them. The effectiveness of diverse teams depends on trusting and supportive cultures. Data publication is one of the most important tools to identify and combat identity threat and biased decision making. Despite the challenges, there is hope! There are tools that have been shown to combat bias and identity threat effectively.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43141.html
notfound
=========================
The atoms of neural computation
Science, vol. 346 (2014), pp. 551-552
[u'Gary Marcus', u'Adam Marblestone', u'Tom Dean']
GeneralScience
Abstract: The human cerebral cortex is central to a wide array of cognitive functions, from vision to language, reasoning, decision-making, and motor control. Yet, nearly a century after the neuroanatomical organization of the cortex was first defined, its basic logic remains unknown. One hypothesis is that cortical neurons form a single, massively repeated canonical circuit, characterized as a kind of a nonlinear spatiotemporal filter with adaptive properties (1). In this classic view, it was assumed that theseproperties are identical for all neocortical areas. Nearly four decades later, there is still no consensus about whether such a canonical circuit exists, either in terms of its anatomical basis or its function. Likewise, there is little evidence that such uniform architectures can capture the diversity of cortical function in simple mammals, let alone characteristically human processes such as language and abstract thinking (2). Analogous software implementations in artificial intelligence (e.g., deep learning networks) have proven effective in certain pattern classification tasks, such as speech and image recognition, but likewise have made little inroads in areas such as reasoning and natural language understanding. Is the search for a single canonical cortical circuit misguided?
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
The wisdom of clouds
Chemistry World, vol. 11 (2014), pp. 38
[u'Kai Kohlhoff']
GeneralScience
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42966.html
found
=========================
Topology-Driven Trajectory Synthesis with an Example on Retinal Cell Motions
14th Workshop on Algorithms in Bioinformatics, Springer, Wroclaw, Poland (2014), pp. 326-339
[u'Chen Gu', u'Leonidas Guibas', u'Michael Kerber']
GeneralScience
Abstract: We design a probabilistic trajectory synthesis algorithm for generating time-varying sequences of geometric configuration data. The algorithm takes a set of observed samples (each may come from a different trajectory) and simulates the dynamic evolution of the patterns in O(n^2 log n) time. To synthesize geometric configurations with indistinct identities, we use the pair correlation function to summarize point distribution, and alpha-shapes to maintain topological shape features based on a fast persistence matching approach. We apply our method to build a computational model for the geometric transformation of the cone mosaic in retinitis pigmentosa --- an inherited and currently untreatable retinal degeneration.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42486.html
notfound
=========================
Trust, transparency & control in inferred user interest models
CHI '14 Extended Abstracts on Human Factors in Computing Systems, ACM, New York, NY, USA (2014), pp. 2449-2454
[u'Sebastian Schnorf', u'Martin Ortlieb', u'Nikhil Sharma']
GeneralScience
Abstract: This paper explores the importance of transparency and control to users in the context of inferred user interests. More specifically, we illustrate the association between various levels of control the users have on their inferred interests and users' trust in organizations that provide corresponding content. Our results indicate that users value transparency and control very differently. We segment users in two groups, one who states to not care about their personal interest model and another group that desires some level of control. We found substantial differences in trust impact between segments, depending on actual control option provided.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43326.html
notfound
=========================
What It Would Really Take to Reverse Climate Change
IEEE Spectrum December 2014, IEEE, 3 Park Ave, 17th floor, New York, NY 10016-5997, pp. 30-35
[u'Ross Koningstein', u'David K Fork']
GeneralScience
Abstract: What two Googlers learned from a failed attempt to find the renewable energy source of tomorrow.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42925.html
notfound
=========================
APOSTLE: Longterm Transit Monitoring and Stability Analysis of XO-2b
The Astrophysical Journal, vol. 770 (2013), pp. 36
[u'Praveen Kundurthy', u'Rory Barnes', u'Andrew C Becker', u'Eric Agol', u'Benjamin F Williams', u'Noel Gorelick', u'Amy Rose']
GeneralScience
Abstract: The Apache Point Survey of Transit Lightcurves of Exoplanets (APOSTLE) observed 10 transits of XO-2b over a period of 3 yr. We present measurements that confirm previous estimates of system parameters like the normalized semi-major axis (a/R), stellar density (), impact parameter (b), and orbital inclination (iorb). Our errors on system parameters like a/R and have improved by 40% compared to previous best ground-based measurements. Our study of the transit times show no evidence for transit timing variations (TTVs) and we are able to rule out co-planar companions with masses 0.20 M in low order mean motion resonance with XO-2b. We also explored the stability of the XO-2 system given various orbital configurations of a hypothetical planet near the 2:1 mean motion resonance. We find that a wide range of orbits (including Earth-mass perturbers) are both dynamically stable and produce observable TTVs. We find that up to 51% of our stable simulations show TTVs that are smaller than the typical transit timing errors (20 s) measured for XO-2b, and hence remain undetectable. Key
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41396.html
notfound
=========================
Advisory on Internal Name Certificates
ICANN SSAC Reports and Advisories, ICANN (Internet Corporation for Assigned Names and Numbers) (2013)
[u'Warren Kumari', u'Steve Crocker', u'Patrik Fltstrm', u'Ondrej Filip', u'James Galvin', u'Danny McPherson', u'Ram Mohan', u'Doron Shikmoni']
GeneralScience
Abstract: The SSAC has identified a Certificate Authority (CA) practice that, if widely exploited, could pose a significant risk to the privacy and integrity of secure Internet communications. This CA practice could impact the new gTLD program. The SSAC thus advises ICANN take immediate steps to mitigate the risks.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41346.html
notfound
=========================
Behavior-Oriented Data Resource Management in Medical Sensing Systems
ACM Transactions on Sensor Networks (TOSN), vol. 9 (2013), 12:1-12:26
[u'Hyduke Noshadi', u'Foad Dabiri', u'Saro Meguerdichian', u'Miodrag Potkonjak', u'Majid Sarrafzadeh']
GeneralScience
Abstract: Wearable sensing systems have recently enabled a variety of medical monitoring and diagnostic applications in wireless health. The need for multiple sensors and constant monitoring leads these systems to be power hungry and expensive with short operating lifetimes. We introduce a novel methodology that takes advantage of contextual and semantic properties in human behavior to enable efficient design and optimization of such systems from the data and information point of view. This, in turn, directly influences the wireless communication and local processing power consumption. We exploit intrinsic space and temporal correlations between sensor data while considering both user and system contextual behavior. Our goal is to select a small subset of sensors that accurately capture and/or predict all possible signals of a fully instrumented wearable sensing system. Our approach leverages novel modeling, partitioning, and behavioral optimization, which consists of signal characterization, segmentation and time shifting, mutual signal prediction, and a simultaneous minimization composed of subset sensor selection and opportunistic sampling. We demonstrate the effectiveness of the technique on an insole instrumented with 99 pressure sensors placed in each shoe, which cover the bottom of the entire foot, resulting in energy reduction of 72% to 97% for error rates of 5% to 17.5%.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Bridging the Gap Between Industry and Academia
The 14th Annual Meeting of the Society for Personality and Social Psychology, New Orleans, Louisiana (2013)
[u'Joshua Tabak']
GeneralScience
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43319.html
notfound
=========================
DNA Nanorobotics
Nanorobotics (2013), pp. 355-382
[u'Harish Chandran', u'Nikhil Gopalkrishnan', u'John H. Reif']
GeneralScience
Abstract: This chapter overviews the current state of the emerging discipline of DNA nanorobotics that make use of synthetic DNA to self-assemble operational molecular-scale devices. Recently there have been a series of quite astonishing experimental resultswhich have taken the technology from a state of intriguing possibilities into demonstrated capabilities of quickly increasing scale and complexity. We first state the challenges in molecular robotics and discuss why DNA as a nanoconstruction material is ideally suited to overcome these. We then review the design and demonstration of a wide range of molecular-scale devices; from DNA nanomachines that change conformation in response to their environment to DNA walkers that can be programmed to walk along predefined paths on nanostructures while carrying cargo or performing computations, to tweezers that can repeatedly switch states. We conclude by listing major challenges in the field along with some possible future directions.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41762.html
notfound
=========================
Herschel/PACS Survey of protoplanetary disks in Taurus/Auriga - Observations of [OI] and [CII], and far infrared continuum
The Astrophysical Journal, vol. 776 (2013), pp. 21-45
[u'Christian Howard']
GeneralScience
Abstract: The Herschel Space Observatory was used to observe ~ 120 pre-main-sequence stars in Taurus as part of the GASPS Open Time Key project. PACS was used to measure the continuum as well as several gas tracers such as [OI] 63 m, [OI] 145 m, [CII] 158 m, OH, H2O and CO. The strongest line seen is [OI] at 63 m. We find a clear correlation between the strength of the [OI] 63 m line and the 63 m continuum for disk sources. In outflow sources, the line emission can be up to 20 times stronger than in disk sources, suggesting that the line emission is dominated by the outflow. The tight correlation seen for disk sources suggests that the emission arises from the inner disk (< 50 AU) and lower surface layers of the disk where the gas and dust are coupled. The [OI] 63 m is fainter in transitional stars than in normal Class II disks. Simple SED models indicate that the dust responsible for the continuum emission is colder in these disks, leading to weaker line emission. [CII] 158 m emission is only detected in strong outflow sources. The observed line ratios of [OI] 63 m to [OI] 145 m are in the regime where we are insensitive to the gas-to-dust ratio, neither can we discriminate between shock or PDR emission. We detect no Class III object in [OI] 63 m and only three in continuum, at least one of which is a candidate debris disk.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42119.html
notfound
=========================
High-Resolution Global Maps of 21st-Century Forest Cover Change
Science, vol. 342 (2013), pp. 850-853
[u'Rebecca Moore', u'Matt Hancher', u'David Thau']
GeneralScience
Abstract: Quantification of global forest change has been lacking despite the recognized importance of forest ecosystem services. In this study, Earth observation satellite data were used to map global forest loss (2.3 million square kilometers) and gain (0.8 million square kilometers) from 2000 to 2012 at a spatial resolution of 30 meters. The tropics were the only climate domain to exhibit a trend, with forest loss increasing by 2101 square kilometers per year. Brazils well-documented reduction in deforestation was offset by increasing forest loss in Indonesia, Malaysia, Paraguay, Bolivia, Zambia, Angola, and elsewhere. Intensive forestry practiced within subtropical forests resulted in the highest rates of forest change globally. Boreal forest loss due largely to fire and forestry was second to that in the tropics in absolute and proportional terms. These results depict a globally consistent and locally relevant record of forest change.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41324.html
notfound
=========================
On the Technology Prospects and Investment Opportunities for Scalable Neuroscience
ArXiv (2013)
[u'Thomas Dean', u'Biafra Ahanonu', u'Mainak Chowdhury', u'Anjali Datta', u'Andre Esteva', u'Daniel Eth', u'Nobie Redmon', u'Oleg Rumyantsev', u'Ysis Tarter']
GeneralScience
Abstract: Two major initiatives to accelerate research in the brain sciences have focused attention on developing a new generation of scientific instruments for neuroscience. These instruments will be used to record static (structural) and dynamic (behavioral) information at unprecedented spatial and temporal resolution and report out that information in a form suitable for computational analysis. We distinguish between recording taking measurements of individual cells and the extracellular matrix and reporting transcoding, packaging and transmitting the resulting information for subsequent analysis as these represent very different challenges as we scale the relevant technologies to support simultaneously tracking the many neurons that comprise neural circuits of interest. We investigate a diverse set of technologies with the purpose of anticipating their development over the span of the next 10 years and categorizing their impact in terms of short-term [1-2 years], medium-term [2-5 years] and longer-term [5-10 years] deliverables.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Optical design of a color-corrected 2.75 g visual loupe
J. Optical Engineering, vol. 52(11) (2013)
[u'Ozan Cakmakci']
GeneralScience
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41343.html
notfound
=========================
PRIME: Probabilistic Initial 3D Model Generation for Single-Particle Cryo-Electron Microscopy
Structure, vol. 21 (2013), pp. 1299-1306
[u'Hans Elmlund', u'Dominika Elmlund', u'Samy Bengio']
GeneralScience
Abstract: Low-dose electron microscopy of cryo-preserved individual biomolecules (single-particle cryo-EM) is a powerful tool for obtaining information about the structure and dynamics of large macromolecular assemblies. Acquiring images with low dose reduces radiation damage, preserves atomic structural details, but results in low signal-to-noise ratio of the individual images. The projection directions of the two-dimensional images are random and unknown. The grand challenge is to achieve the precise three-dimensional (3D) alignment of many (tens of thousands to millions) noisy projection images, which may then be combined to obtain a faithful 3D map. An accurate initial 3D model is critical for obtaining the precise 3D alignment required for high-resolution (<10 ) map reconstruction. We report a method (PRIME) that, in a single step and without prior structural knowledge, can generate an accurate initial 3D map directly from the noisy images.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41587.html
notfound
=========================
Physically-based Grasp Quality Evaluation under Pose Uncertainty
IEEE Transactions on Robotics (2013)
[u'Junggon Kim', u'Kunihiro Iwamoto', u'James J.Kuffner', u'Yasuhiro Ota', u'Nancy S. Pollard']
GeneralScience
Abstract: Although there has been great progress in robot grasp planning, automatically generated grasp sets using a quality metric are not as robust as human generated grasp sets when applied to real problems. Most previous research on grasp quality metrics has focused on measuring the quality of established grasp contacts after grasping, but it is difcult to reproduce the same planned nal grasp conguration with a real robot hand, which makes the quality evaluation less useful in practice. In this study we focus more on the grasping process which usually involves changes in contact and object location, and explore the efcacy of using dynamic simulation in estimating the likely success or failure of a grasp in the real environment. Among many factors that can possibly affect the result of grasping, we particularly investigated the effect of considering object dynamics and pose uncertainty on the performance in estimating the actual grasp success rates measured from experiments. We observed that considering both dynamics and uncertainty improved the performance signicantly and, when applied to automatic grasp set generation, this method generated more stable and natural grasp sets compared to a commonly used method based on kinematic simulation and force-closure analysis.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42959.html
notfound
=========================
SAC062 - SSAC Advisory Concerning the Mitigation of Name Collision Risk
ICANN Security and Stability Advisory Committee (SSAC) Reports and Advisories, ICANN (2013)
[u'Warren Kumari']
GeneralScience
Abstract: The term name collision refers to the situation in which a name that is properly defined in one operational domain or naming scope may appear in another domain (in which it is also syntactically valid), where users, software, or other functions in that domain may misinterpret it as if it correctly belonged there. The circumstances that may cause this can be accidental or malicious. In the context of Top Level Domains (TLDs), the conflicting namespaces are the DNS namespace defined in the root zone as published by the root management partners (ICANN, U.S. Dept. of Commerce National Telecommunications Information Administration (NTIA), and VeriSign) and any privately defined namespace, whether that namespace is defined only for the Domain Name System (DNS) or is also intended to work for other namespaces such as Active Directory
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42949.html
notfound
=========================
SAC063: SSAC Advisory on DNSSEC Key Rollover in the Root Zone
ICANN Security and Stability Advisory Committee (SSAC) Reports and Advisories, ICANN (2013)
[u'Warren Kumari', u'Russ Mundy', u'Matt Larson', u'Jaap Akkerhuis']
GeneralScience
Abstract: There is consensus in the security and domain name system (DNS) communities that the root zone DNS Security Extensions (DNSSEC) system poses unique challenges for standard DNSSEC practices. While there is agreement that an eventual root zone Key-Signing Key (KSK) rollover is inevitable regardless of whether that rollover is caused by a key compromise or other factors, there is no solid consensus in the technical community regarding the frequency of routine, scheduled KSK rollovers. In this Advisory the SSAC addresses the following topics: * Terminology and definitions relating to DNSSEC key rollover in the root zone; * Key management in the root zone; * Motivations for root zone KSK rollover; * Risks associated with root zone KSK rollover; * Available mechanisms for root zone KSK rollover; * DNS response size considerations; * Quantifying the risk of failed trust anchor update; and * DNS response size considerations
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41398.html
notfound
=========================
Systematic Analysis of Challenge-Driven Improvements in Molecular Prognostic Models for Breast Cancer
Science Translational Medicine, vol. 5.181 (2013), 181re1-181re1
[u'Adam Margolin', u'Erhan Bilal', u'Erich Huang', u'Ben Sauerwine', u'Nicole Deflaux', u'Lamia Youseff', u'Tyler Pirtle', u'Craig Citro', u'Joseph L. Hellerstein']
GeneralScience
Abstract: Although molecular prognostics in breast cancer are among the most successful examples of translating genomic analysis to clinical applications, optimal approaches to breast cancer clinical risk prediction remain controversial. The Sage BionetworksDREAM Breast Cancer Prognosis Challenge (BCC) is a crowdsourced research study for breast cancer prognostic modeling using genome-scale data. The BCC provided a community of data analysts with a common platform for data access and blinded evaluation of model accuracy in predicting breast cancer survival on the basis of gene expression data, copy number data, and clinical covariates. This approach offered the opportunity to assess whether a crowdsourced community Challenge would generate models of breast cancer prognosis commensurate with or exceeding current best-in-class approaches. The BCC comprised multiple rounds of blinded evaluations on held-out portions of data on 1981 patients, resulting in more than 1400 models submitted as open source code. Participants then retrained their models on the full data set of 1981 samples and submitted up to five models for validation in a newly generated data set of 184 breast cancer patients. Analysis of the BCC results suggests that the best-performing modeling strategy outperformed previously reported methods in blinded evaluations; model performance was consistent across several independent evaluations; and aggregating community-developed models achieved performance on par with the best-performing individual models.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41642.html
notfound
=========================
Triple Wollaston-prism complete-Stokes imaging polarimeter
Optics Letters, vol. 38 (2013), pp. 3874-3877
[u'John D. Perreault']
GeneralScience
Abstract: Imaging polarimetry is emerging as a powerful tool for remote sensing in space science, Earth science, biology, defense, national security, and industry. Polarimetry provides complementary information about a scene in the visible and infrared wavelengths. For example, surface texture, material composition, and molecular structure will affect the polarization state of reflected, scattered, or emitted light. We demonstrate an imaging polarimeter design that uses three Wollaston prisms, addressing several technical challenges associated with moving remote-sensing platforms. This compact design has no moving polarization elements and separates the polarization components in the pupil (or Fourier) plane, analogous to the way a grating spectrometer works. In addition, this concept enables simultaneous characterization of unpolarized, linear, and circular components of optical polarization. The results from a visible-wavelength prototype of this imaging polarimeter are presented, demonstrating remote sensitivity to material properties. This work enables new remote sensing capabilities and provides a viable design concept for extensions into infrared wavelengths.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Unlocking the Potential of Conjoint Analysis/Discrete Choice Modeling and MaxDiff Scaling in Public Opinion and Survey Research
American Association for Public Opinion Research (2013), Panel
[u'Steven Ellis', u'Mario Callegaro', u'Chris Chapman']
GeneralScience
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42544.html
notfound
=========================
When the Cloud Goes Local: The Global Problem with Data Localization
Computer, vol. 46, No. 12 (2013), pp. 54-59
[u'Patrick Ryan', u'Sarah Falvey', u'Ronak Merchant']
GeneralScience
Abstract: Ongoing efforts to legally define cloud computing and regulate separate parts of the Internet are unlikely to address underlying concerns about data security and privacy. Data localization initiatives, led primarily by European countries, could actually bring the cloud to the ground and make the Internet less secure.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42027.html
notfound
=========================
You Are What You Emote: Emotional Facial Expressions Impact Sexual Orientation Judgments
In the symposium, Beyond Right/Wrong: Novel Approaches to Understanding Accuracy and Consensus in Social Perception, chairs: Joshua A. Tabak and David J. Lick, 25th Annual Convention of the Association for Psychological Science, Washington, D.C. (2013)
[u'Joshua Tabak', u'Sapna Cheryan']
GeneralScience
Abstract: Emotions convey more than sentiment. We found that gendered emotional expressions modulated sexual orientation judgments from faces, consistent with stereotypes of gay individuals as gender-atypical. This is the first research on accuracy of person perceptions at the intersection of stable (sexual orientation) and fleeting (emotion) person characteristics.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A unified multitask architecture for predicting local protein properties
PLoS ONE (2012) (to appear)
[u'Yanjun Qi', u'Merja Osh', u'Jason Weston', u'William Stafford Noble']
GeneralScience
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41397.html
notfound
=========================
Advisory on Impacts of Content Blocking via the Domain Name System
ICANN Security and Stability Advisory Committee (SSAC) Reports and Advisories, ICANN (Internet Corporation for Assigned Names and Numbers) (2012)
[u'Warren Kumari', u'Alain Aina', u'Jaap Akkerhuis', u'Don Blumenthal', u'KC Claffy', u'David Conrad', u'Patrik Fltstrm', u'James Galvin', u'Jason Livingood', u'Danny McPherson', u'Ram Mohan', u'Paul Vixie']
GeneralScience
Abstract: The use of Domain Name System (DNS) blocking to limit access to resources on the Internet has become a topic of interest in numerousInternet governance venues. Several governments around the world, whether by law, treaty, court order, law enforcement action, or other actions or agreements, have either implemented DNS blocking or are actively considering doing so. However, due to the Internets architecture, blocking by domain name can be easily bypassed by end users and is thus likely to be largely ineffective in the long term and fraught with unanticipated consequences in the near term. In addition, DNS blocking can present conflicts with the adoption of DNS Security Extensions(DNSSEC) and could promote balkanization of the Internet into a country-by-country view of the Internets name space.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub39973.html
found
=========================
Algorithmic Thermodynamics
Mathematical Structures in Computer Science, vol. 22 (2012), pp. 771-787
[u'John Baez', u'Michael Stay']
GeneralScience
Abstract: Algorithmic entropy can be seen as a special case of entropy as studied in statistical mechanics. This viewpoint allows us to apply many techniques developed for use in thermodynamics to the subject of algorithmic information theory. In particular, suppose we fix a universal prefix-free Turing machine and let X be the set of programs that halt for this machine. Then we can regard X as a set of 'microstates', and treat any function on X as an 'observable'. For any collection of observables, we can study the Gibbs ensemble that maximizes entropy subject to constraints on expected values of these observables. We illustrate this by taking the log runtime, length, and output of a program as observables analogous to the energy E, volume V and number of molecules N in a container of gas. The conjugate variables of these observables allow us to define quantities which we call the 'algorithmic temperature' T, 'algorithmic pressure' P and algorithmic potential' mu, since they are analogous to the temperature, pressure and chemical potential. We derive an analogue of the fundamental thermodynamic relation dE = T dS - P d V + mu dN, and use it to study thermodynamic cycles analogous to those for heat engines. We also investigate the values of T, P and mu for which the partition function converges. At some points on the boundary of this domain of convergence, the partition function becomes uncomputable. Indeed, at these points the partition function itself has nontrivial algorithmic entropy.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38149.html
notfound
=========================
Google's Hybrid Approach to Research
Communications of the ACM, vol. 55 Issue 7 (2012), pp. 34-37
[u'Alfred Spector', u'Peter Norvig', u'Slav Petrov']
GeneralScience
Abstract: In this viewpoint, we describe how we organize computer science research at Google. We focus on how we integrate research and development and discuss the benefits and risks of our approach. A video about this paper is also available.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub39969.html
notfound
=========================
Life Estimation of Pressurized-Air Solar-Thermal Receiver Tubes
ASME Journal of Solar Energy Engineering (2012) (to appear)
[u'David Fork', u'John Fitch', u'Shawn Ziaei', u'Robert I. Jetter']
GeneralScience
Abstract: The operational conditions of the solar thermal receiver for a Brayton-cycle engine are challenging, and lack a large body of operational data unlike steam plants. We explore the receivers fundamental element, a pressurized tube in time varying solar flux for a series of 30 year service missions based on hypothetical power plant designs. We developed and compared two estimation methods to predict the receiver tube lifetime based on available creep life and fatigue data for alloy 617. We show that the choice of inelastic strain model and the level of conservatism applied through design rules will vary the lifetime predictions by orders of magnitude. Based on current data and methods, a turbine inlet temperature of 850 C is a necessary 30-year-life-design condition for our receiver. We also showed that even though the time at operating temperature is about three times longer for fossil fuel powered (steady) operation, the damage is always lower than cyclic operation using solar power .
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Molli: Interactive Visualization for Exploratory Protein Analysis
IEEE Computer Graphics & Applications, vol. 32 (2012), pp. 62-69
[u'Sara L. Su', u'Connor Gramazio', u'Megan Strait', u'Caitlin Crumm', u'Daniela Extrum-Fernandez', u'Matt Menke', u'Lenore Cowen']
GeneralScience
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38318.html
notfound
=========================
Norovirus Disease Surveillance Using Google Internet Query Share Data
Clinical Infectious Diseases (2012)
[u'Rishi Desai', u'Aron J. Hall', u'Benjamin A. Lopman', u'Yair Shimshoni', u'Marcus Rennick', u'Niv Efron', u'Yossi Matias', u'Manish M. Patel', u'Umesh D. Parashar']
GeneralScience
Abstract: Google Internet query share (IQS) data for gastroenteritis-related search terms correlated strongly with contemporaneous national (R2 = 0.70) and regional (R2 = 0.74) norovirus surveillance data in the United States. IQS data may facilitate rapid identification of norovirus season onset, elevated peak activity, and potential emergence of novel strains.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Search Inside Yourself
HarperOne (2012)
[u'Chade-Meng Tan']
GeneralScience
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41353.html
notfound
=========================
Semantics-driven sensor configuration for energy reduction in medical sensor networks
Proceedings of the 2012 ACM/IEEE international symposium on Low power electronics and design, ACM, pp. 303-308
[u'James Wendt', u'Saro Meguerdichian', u'Hyduke Noshadi', u'Miodrag Potkonjak']
GeneralScience
Abstract: Traditional optimization methods for large multisensory networks often use sensor array reduction and sampling techniques that attempt to reduce energy while retaining full predictability of the raw sensed data. For systems such as medical sensor networks, raw data prediction is unnecessary, rather, only relevant semantics derived from the raw data are essential. We present a new method for sensor fusion, array reduction, and subsampling that reduces both energy and cost through semantics-driven system configuration. Using our method, we reduce the energy requirements of a medical shoe by a factor of 17.9 over the original system configuration while maintaining semantic relevance.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42957.html
notfound
=========================
Sistema GaitGrabber na captao de dados cinemticos durante a marcha
Motriz: Revista de Educao Fsica, vol. 18 (2012), pp. 505-514
[u'Scott Alexander Kirkwood']
GeneralScience
Abstract: The purpose of this study was to develop and test the validity and reliability of the GaitGrabber System in measuring kinematic variables in the sagittal plane during gait. Eighteen individuals participated in the reliability study and 28 in the concurrent validity study. The Qualisys Pro-Reflex System used as a gold standard reference system. The GaitGrabber calculates the relative angles at the hip, knee and ankle in the sagittal plane. The Intraclass Correlation Coefficient (ICC) was used to compare the average of the angular peaks between visits. The principal component analysis was used to test the validity of the system. The ICC ranged from moderate to excellent and the validity of the system was proved for the ankle. There were significant differences in the range of motion for the hip and knee joints which were attributed to different instrumental characteristics. The GaitGrabber system is valid and reliable and can be clinically used to analyze kinematics during gait in the sagittal plane.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41352.html
notfound
=========================
Spatiotemporal Assignment of Energy Harvesters on a Self-Sustaining Medical Shoe
2012 IEEE Sensors, IEEE, pp. 1-4
[u'James Wendt', u'Vishwa Goudar', u'Hyduke Noshadi', u'Miodrag Potkonjak']
GeneralScience
Abstract: We present a new method for spatiotemporal assignment and scheduling of energy harvesters on a medical shoe tasked with measuring gait diagnostics. While prior work exists on the application of dielectric elastomers (DEs) for energy scavenging on shoes, current literature does not address the issues of placement and timing of these harvesters, nor does it address integration into existing sensing systems. We solve these issues and present a self-sustaining medical shoe that harvests energy from human ambulation while simultaneously measuring gait characteristics most relevant to medical diagnosis.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38144.html
notfound
=========================
Team Geek: A Software Developer's Guide to Working Well with Others
O'Reilly Media, 1005 Gravenstein Highway North, Sebastopol, CA 95472 (2012), pp. 180
[u'Brian W. Fitzpatrick', u'Ben Collins-Sussman']
GeneralScience
Abstract: As a software engineer, youre great with computer languages, compilers, debuggers, and algorithms. And in a perfect world, those who produce the best code are the most successful. But in our perfectly messy world, success also depends on how you work with people to get your job done. In this highly entertaining book, Brian Fitzpatrick and Ben Collins-Sussman cover basic patterns and anti-patterns for working with other people, teams, and users while trying to develop software. Its valuable information from two respected software engineers whose popular video series, "Working with Poisonous People", has attracted hundreds of thousands of viewers. Youll learn how to deal with imperfect peoplethose irrational and unpredictable beingsin the course of your work. And youll discover why playing well with others is at least as important as having great technical skills. By internalizing the techniques in this book, youll get more software written, be more influential, be happier in your career.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37117.html
notfound
=========================
Channeling the data deluge
Nature Methods, vol. 8 (2011), pp. 463
[u'Jason Swedlow', u'Gianluigi Zanetti', u'Christoph Best']
GeneralScience
Abstract: With vast increases in biological data generation, mechanisms for data storage and analysis have become limiting. A data structure, semantically typed data hypercubes (SDCubes), that combines hierarchical data format version 5 (HDF5) and extensible markup language (XML) file formats, now permits the flexible storage, annotation and retrieval of large and heterogenous datasets.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Detecting remote evolutionary relationships among proteins by large-scale semantic embedding
PLoS Computational Biology (2011)
[u'Iain Melvin', u'Jason Weston', u'Christina Leslie', u'William Stafford Noble']
GeneralScience
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41469.html
notfound
=========================
Entrepreneurial Innovation at Google
IEEE: Computer, vol. 0018-9162/11 (2011), pp. 7
[u'Patrick Copeland', u'Alberto Savoia']
GeneralScience
Abstract: Large organizations have enormous innovation potential at their disposal. However, the innovation actually realized in successful products and services is usually only a small fraction of that potential. The amount and type of innovation a company achieves are directly related to the way it approaches, fosters, selects, and funds innovation efforts. To maximize innovation and avoid the dilemmas that mature companies face, Google complements the time-proven model of topdown innovation with its own brand of entrepreneurial innovation.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
How is it done? A multinational survey of YouTube user satisfaction
University of Washington, Seattle, WA (2011)
[u'Joshua Tabak']
GeneralScience
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42927.html
notfound
=========================
Planet-Planet Scattering Leads to Tightly Packed Planetary Systems.
The Astrophysical Journal, Letters, vol. 696 (2011), pp. 98-101
[u'Sean N. Raymond', u'Rory Barnes', u'Dimitri Veras', u'Philip J. Armitage', u'Noel Gorelick', u'Richard Greenberg']
GeneralScience
Abstract: The known extrasolar multiple-planet systems share a surprising dynamical attribute: they cluster just beyond the Hill stability boundary. Here we show that the planet-planet scattering model, which naturally explains the observed exoplanet eccentricity distribution, can reproduce the observed distribution of dynamical configurations. We calculated how each of our scattered systems would appear over an appropriate range of viewing geometries; as Hill stability is weakly dependent on the masses, the mass-inclination degeneracy does not significantly affect our results. We consider a wide range of initial planetary mass distributions and find that some are poor fits to the observed systems. In fact, many of our scattering experiments overproduce systems very close to the stability boundary. The distribution of dynamical configurations of two-planet systems actually may provide better discrimination between scattering models than the distribution of eccentricity. Our results imply that, at least in their inner regions which are weakly affected by gas or planetesimal disks, planetary systems should be "packed", with no large gaps between planets.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42926.html
notfound
=========================
Secular Behavior of Exoplanetary Systems: Self-Consistency and Comparisons With The Planet-Planet Scattering Hypothesis
The Astrophysics Journal, vol. 146 (2011), pp. 53
[u'Miles Timpe', u'Rory Barnes', u'Ravikumar Kopparapu', u'Sean N. Raymond', u'Richard Greenberg', u'Noel Gorelick']
GeneralScience
Abstract: Planet-planet scattering has been suggested as a mechanism to explain the disproportionate number of planet-planet pairs found to lie on or near an apsidal separatrix, in which one planet's eccentricity periodically drops to near-zero. We present the results of numerical simulations of 2-planet systems having arisen from dynamically unstable 3-planet systems. We show that the distribution of near-separatrix systems arising after an instability is consistent with the observed systems, further strengthening the planet-planet scattering hypothesis. We also note that many observed systems have been found near their extreme eccentricity values. Such a pattern may suggest a bias in exoplanet observations, as planets should have an equal probability of being discovered at any point in their secular cycle. We test this possibility by numerically integrating known multiplanet systems and determining the relative time each planet spends in a given eccentricity range and then comparing this distribution of eccentricity values to the observational uncertainty. We find that planets tend to spend more time near their minimum and maximum values as they represent turning points in the oscillations. Moreover, the uncertainties for many eccentricities are so large that we cannot make strong statements regarding the possibility that planets are being discovered at their extreme eccentricities too often. However, as uncertainties become smaller and more multiplanet systems are discovered, this potential bias should be revisited.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37236.html
notfound
=========================
Sticking Together: Handcrafting Personalized Communication Interfaces.
ACM International Conference on Interaction Design and Children (IDC) 2011, ACM
[u'Natalie Freed', u'Jie Qi', u'Adam Stephenson', u'Hayes Raffle', u'Leah Buechley', u'Cynthia Breazeal']
GeneralScience
Abstract: We present I/O Stickers, adhesive sensors and actuators thatchildren can use to create personalized remote communicationinterfaces. By attaching I/O Stickers to special greeting cards,children can invent ways to communicate with long-distanceloved ones with personalized, connected messages. Childrendecorate these cards with their choice of craft materials, creativelyexpressing themselves while making a functioning interface. Thelow-bandwidth connections leave room for children to design notonly the look and function, but also the signification of theconnections. We describe the design of the I/O Stickers, a varietyof artifacts children have created, and future directions for thetoolkit. Preliminary results indicate that I/O Stickers are beginningto make a space for creative learning about communication and tomake keeping in touch playful and meaningful.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37209.html
notfound
=========================
Using Web Search Query Data to Monitor Dengue Epidemics: A New Model for Neglected Tropical Disease Surveillance
PLoS Neglected Tropical Diseases, vol. 5 Issue 5 (2011)
[u'Emily H. Chan', u'Vikram Sahai', u'Corrie Conrad', u'John S. Brownstein']
GeneralScience
Abstract: Background A variety of obstacles including bureaucracy and lack of resources have interfered with timely detection and reporting of dengue cases in many endemic countries. Surveillance efforts have turned to modern data sources, such as Internet search queries, which have been shown to be effective for monitoring influenza-like illnesses. However, few have evaluated the utility of web search query data for other diseases, especially those of high morbidity and mortality or where a vaccine may not exist. In this study, we aimed to assess whether web search queries are a viable data source for the early detection and monitoring of dengue epidemics. Methodology/Principal Findings Bolivia, Brazil, India, Indonesia and Singapore were chosen for analysis based on available data and adequate search volume. For each country, a univariate linear model was then built by fitting a time series of the fraction of Google search query volume for specific dengue-related queries from that country against a time series of official dengue case counts for a time-frame within 20032010. The specific combination of queries used was chosen to maximize model fit. Spurious spikes in the data were also removed prior to model fitting. The final models, fit using a training subset of the data, were cross-validated against both the overall dataset and a holdout subset of the data. All models were found to fit the data quite well, with validation correlations ranging from 0.82 to 0.99. Conclusions/Significance Web search query data were found to be capable of tracking dengue activity in Bolivia, Brazil, India, Indonesia and Singapore. Whereas traditional dengue data from official sources are often not available until after some substantial delay, web search query data are available in near real-time. These data represent valuable complement to assist with traditional dengue surveillance.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
EMI Failure Analysis Techniques: II. Joint Time-Frequency Analysis
IEEE EMC Society Newsletters, vol. 226 (2010), pp. 31-34
[u'Weifeng Pan']
GeneralScience
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
EMI Failure Analysis Techniques: III. Correlation Analysis
IEEE EMC Society Newsletters, vol. 227 (2010), pp. 45-49
[u'Weifeng Pan']
GeneralScience
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41366.html
notfound
=========================
Energy Optimization in Wireless Medical Systems Using Physiological Behavior
In Proceedings of the ACM, BMES conference of Wireless Health, ACM (2010), pp. 128-136
[u'Hyduke Noshadi', u'Foad Dabiri', u'Saro Meguerdichian', u'Miodrag Potkonjak', u'Majid Sarrafzadeh']
GeneralScience
Abstract: Wearable sensing systems are becoming widely used for a variety of applications, including sports, entertainment, and military. These systems have recently enabled a variety of medical monitoring and diagnostic applications in Wireless Health. The need for multiple sensors and constant monitoring lead these systems to be power hungry and expensive, with short operating lifetimes. In this paper, we introduce a novel methodology that takes advantage of the influence of human behavior on signal properties and reduces those three metrics from the data size point of view. This, in turn, directly influences the wireless communication and local processing power consumption. We exploit intrinsic space and temporal correlations between sensor data while considering both user and system behavior. Our goal is to select a small subset of sensors to accurately capture and/or predict all possible signals of a fully instrumented wearable sensing system. Our approach leverages novel modeling, partitioning, and behavioral optimization, which consists of signal characterization, segmentation and time shifting, mutual signal prediction, and subset sensor selection. We demonstrate the effectiveness of the technique on an insole instrumented with 99 pressure sensors placed in each shoe, which cover the bottom of the entire foot, resulting in energy reduction of 56% to 96% for error rates of 5% to 17.5%.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41672.html
notfound
=========================
Googles Innovation Factory: Testing, Culture, And Infrastructure
IEEE International Conference on Software Testing, Verification and Validation (2010), pp. 4
[u'Patrick Copeland']
GeneralScience
Abstract: Google takes quality seriously and is reinventing how software is created, tested, released, and maintained.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Minimizing off-target signals in RNA fluorescent in situ hybridization
Nucleic Acids Research (2010)
[u'Aaron Arvey', u'Anita Hermann', u'Cheryl C. Hsia', u'Eugene Ie', u'Yoav Freund', u'William McGinnis']
GeneralScience
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Planet-Planet Scattering in Planetesimal Disks. II. Predictions for Outer Extrasolar Planetary Systems
The Astrophysical Journal, vol. 711 (2010), pp. 772-795
[u'Sean N. Raymond', u'Philip J. Armitage', u'Noel Gorelick']
GeneralScience
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Semi-Supervised Multi-Task Learning for Predicting Interactions between HIV-1 and Human Proteins
ECCB (2010)
[u'Yanjun Qi', u'Oznur Tastan', u'Jaime Carbonell', u'Judith Klein-Seetharaman', u'Jason Weston']
GeneralScience
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36914.html
notfound
=========================
The Politics of Search: A Decade Retrospective.
The Information Society Journal, vol. 26 (2010), pp. 364-374
[u'Laura Ann Granka']
GeneralScience
Abstract: In Shaping theWeb:Why the Politics of Search Engines Matters, Introna and Nissenbaum (2000) introduced scholars to the political, as well as technical, issues central to the development of online search engines. Since that time, scholars have critically evaluated the role that search engines play in structuring the scope of online information access for the rest of society, with an emphasis on the implications for a democratic and diverseWeb. This article describes the thought behind search engine regulation, online diversity, and information bias, and it places these issues within the context of the technical and societal changes that have occurred in the online search industry. The author assesses which of the initial concerns expressed about online search engines remain relevant today and discusses how technical changes demand a new approach to measuring online diversity and democracy. The author concludes with a proposal to direct the research and thought in online search going forward.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36625.html
notfound
=========================
Using Bezier Curve to Improve the Accuracy in Integrated Circuit Design Analysis
International Conference on Convergence and Hybrid Information Technology, ACM Press (2010)
[u'Eric Y. Chen', u'May Huang']
GeneralScience
Abstract: In this paper, we introduce a method for the application of Bezier curve algorithms to lookup-table-based interpolations, particularly for the use of timing, power, and noise analysis in integrated circuit design. Bzier curves can replace conventional piecewise linear functions for accuracy enhancement. Selecting control points with physical implications and forcing curves to pass through sampled points are critical for achieving the envisioned improvements. This method can be easily applied to the interpolation of splines.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36366.html
notfound
=========================
A transcription factor affinity-based code for mammalian transcription initiation
Genome Research, vol. 19 (2009), pp. 644-56
[u'M Megraw', u'F Pereira', u'ST Jensen', u'U Ohler', u'AG Hatzigeorgiou']
GeneralScience
Abstract: The recent arrival of large-scale cap analysis of gene expression (CAGE) data sets in mammals provides a wealth of quantitative information on coding and noncoding RNA polymerase II transcription start sites (TSS). Genome-wide CAGE studies reveal that a large fraction of TSS exhibit peaks where the vast majority of associated tags map to a particular location ( approximately 45%), whereas other active regions contain a broader distribution of initiation events. The presence of a strong single peak suggests that transcription at these locations may be mediated by position-specific sequence features. We therefore propose a new model for single-peaked TSS based solely on known transcription factors (TFs) and their respective regions of positional enrichment. This probabilistic model leads to near-perfect classification results in cross-validation (auROC = 0.98), and performance in genomic scans demonstrates that TSS prediction with both high accuracy and spatial resolution is achievable for a specific but large subgroup of mammalian promoters. The interpretable model structure suggests a DNA code in which canonical sequence features such as TATA-box, Initiator, and GC content do play a significant role, but many additional TFs show distinct spatial biases with respect to TSS location and are important contributors to the accurate prediction of single-peak transcription initiation sites. The model structure also reveals that CAGE tag clusters distal from annotated gene starts have distinct characteristics compared to those close to gene 5'-ends. Using this high-resolution single-peak model, we predict TSS for approximately 70% of mammalian microRNAs based on currently available data.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
ACM's annual report
Commun. ACM, vol. 52 (2009), pp. 33-37
[u'Stuart I. Feldman']
GeneralScience
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34503.html
notfound
=========================
Detecting influenza epidemics using search engine query data
Nature, vol. 457 (2009), pp. 1012-1014
[u'Jeremy Ginsberg', u'Matthew Mohebbi', u'Rajan Patel', u'Lynnette Brammer', u'Mark Smolinski', u'Larry Brilliant']
GeneralScience
Abstract: Seasonal influenza epidemics are a major public health concern, causing tens of millions of respiratory illnesses and 250,000 to 500,000 deaths worldwide each year. In addition to seasonal influenza, a new strain of influenza virus against which no previous immunity exists and that demonstrates human-to-human transmission could result in a pandemic with millions of fatalities. Early detection of disease activity, when followed by a rapid response, can reduce the impact of both seasonal and pandemic influenza. One way to improve early detection is to monitor health-seeking behaviour in the form of queries to online search engines, which are submitted by millions of users around the world each day. Here we present a method of analysing large numbers of Google search queries to track influenza-like illness in a population. Because the relative frequency of certain queries is highly correlated with the percentage of physician visits in which a patient presents with influenza-like symptoms, we can accurately estimate the current level of weekly influenza activity in each region of the United States, with a reporting lag of about one day. This approach may make it possible to use search queries to detect influenza epidemics in areas with a large population of web search users. Self-archived manuscript (PDF)
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
EMI Failure Analysis Techniques: I. Frequency Spectrum Analysis
IEEE EMC Society Newsletters, vol. 223 (2009), pp. 65-70
[u'Weifeng Pan']
GeneralScience
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36219.html
notfound
=========================
Haplotype Inference Constrained by Plausible Haplotype Data
CPM '09: Proceedings of the 20th Annual Symposium on Combinatorial Pattern Matching, Springer-Verlag, Berlin, Heidelberg (2009), pp. 339-352
[u'Michael R. Fellows', u'Tzvika Hartman', u'Danny Hermelin', u'Gad M. Landau', u'Frances Rosamond', u'Liat Rozenberg']
GeneralScience
Abstract: The haplotype inference problem (HIP) asks to find a set of haplotypes which resolve a given set of genotypes. This problem is of enormous importance in many practical fields, such as the investigation of diseases, or other types of genetic mutations. In order to find the haplotypes that are as close as possible to the real set of haplotypes that comprise the genotypes, two models have been suggested which by now have become widely accepted: The perfect phylogeny model and the pure parsimony model. All known algorithms up till now for the above problem may find haplotypes that are not necessarily plausible, i.e. very rare haplotypes or haplotypes that were never observed in the population. In order to overcome this disadvantage we study in this paper, for the first time, a new constrained version of HIP under the above mentioned models. In this new version, a pool of plausible haplotypes ~H is given together with the set of genotypes G, and the goal is to find a subset $H \subseteq \widetilde{H}$ that resolves G. For the constrained perfect phylogeny haplotyping (CPPH) problem we provide initial insights and polynomial-time algorithms for some restricted cases that help understanding the complexity of that problem. We also prove that the constrained parsimony haplotyping (CPH) problem is fixed parameter tractable by providing a parameterized algorithm that applies an interesting dynamic programming technique for solving the problem.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Methodological Review: Empirical distributional semantics: Methods and biomedical applications
Journal of Biomedical Informatics, vol. 42 (2009), pp. 390-405
[u'Trevor Cohen', u'Dominic Widdows']
GeneralScience
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42928.html
notfound
=========================
Planet-Planet Scattering in Planetesimal Disks
Astrophysical Journal Letters, vol. 699 (2009), L88-L92
[u'Sean N. Raymond', u'Philip J. Armitage', u'Noel Gorelick']
GeneralScience
Abstract: We study the final architecture of planetary systems that evolve under the combined effects of planet-planet and planetesimal scattering. Using N-body simulations we investigate the dynamics of marginally unstable systems of gas and ice giants both in isolation and when the planets form interior to a planetesimal belt. The unstable isolated systems evolve under planet-planet scattering to yield an eccentricity distribution that matches that observed for extrasolar planets. When planetesimals are included the outcome depends upon the total mass of the planets. For M tot gsim 1 MJ the final eccentricity distribution remains broad, whereas for M tot lsim 1 MJ a combination of divergent orbital evolution and recircularization of scattered planets results in a preponderance of nearly circular final orbits. We also study the fate of marginally stable multiple planet systems in the presence of planetesimal disks, and find that for high planet masses the majority of such systems evolve into resonance. A significant fraction leads to resonant chains that are planetary analogs of Jupiter's Galilean satellites. We predict that a transition from eccentric to near-circular orbits will be observed once extrasolar planet surveys detect sub-Jovian mass planets at orbital radii of a sime 5-10 AU.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Reflective Random Indexing and Indirect Inference: A Scalable Method for Discovery of Implicit Connections
Journal of Biomedical Informatics (2009)
[u'Trevor Cohen', u'Roger Schaneveldt', u'Dominic Widdows']
GeneralScience
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34936.html
notfound
=========================
Timing properties of gene expression responses to environmental changes
J. Computational Biology, vol. 9 (2009)
[u'Gal Chechik', u'Daphne Koller']
GeneralScience
Abstract: http://www.liebertonline.com/doi/pdfplus/10.1089/cmb.2008.13TT
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A dynamical perspective on additional planets in 55 Cancri
The Astrophysical Journal, vol. 689, Issue 1 (2008), pp. 478-491
[u'Sean N. Raymond', u'Rory Barnes', u'Noel Gorelick']
GeneralScience
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A new beginning, a fond farewell
Commun. ACM, vol. 51 (2008), pp. 5-5
[u'Stuart I. Feldman']
GeneralScience
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
ACM annual report for FY07
Commun. ACM, vol. 51 (2008), pp. 27-34
[u'Stuart I. Feldman']
GeneralScience
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34617.html
notfound
=========================
Activity Motifs Reveal Principles of Timing in Transcriptional Control of the Yeast Metabolic Network
Nature Biotechnology, vol. 26 (11) (2008), pp. 1251-1259
[u'Gal Chechik', u'Eugene Oh', u'Oliver Rando', u'Jonathan Weissman', u'Aviv Regev', u'Daphne Koller']
GeneralScience
Abstract: Significant insight about biological networks arises from the study of network motifsoverly abundant network subgraphs, but such wiring patterns do not specify when and how potential routes within a cellular network are used. To address this limitation, we introduce activity motifs, which capture patterns in the dynamic use of a network. Using this framework to analyze transcription in Saccharomyces cerevisiae metabolism, we find that cells use different timing activity motifs to optimize transcription timing in response to changing conditions: forward activation to produce metabolic compounds efficiently, backward shutoff to rapidly stop production of a detrimental product and synchronized activation for co-production of metabolites required for the same reaction. Measuring protein abundance over a time course reveals that mRNA timing motifs also occur at the protein level. Timing motifs significantly overlap with binding activity motifs, where genes in a linear chain have ordered binding affinity to a transcription factor, suggesting a mechanism for ordered transcription. Finely timed transcriptional regulation is therefore abundant in yeast metabolism, optimizing the organism's adaptation to new environmental conditions.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Every Last Drop: Managing our way out of the water crisis
Boston Review, vol. 33 (2008), pp. 7-12
[u'Rijsberman', u'Frank R']
GeneralScience
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Fifty years and still growing
Commun. ACM, vol. 51 (2008), pp. 23-23
[u'Stuart I. Feldman']
GeneralScience
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
GO Based Hierarchical Framework for Inference of Gene Regulatory Networks
WORLDCOMP'08 (2008) (to appear)
[u'Kumar Abhishek', u'Dr. Harish Karnick']
GeneralScience
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Mean Motion Resonances from Planet-Planet Scattering
The Astrophysical Journal,, vol. 687, Issue 2 (2008), pp. 107-110
[u'Raymond', u'Sean N', u'Barnes', u'Rory', u'Armitage', u'Philip J', u'Gorelick, Noel']
GeneralScience
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
North polar region of Mars: Advances in stratigraphy, structure, and erosional modification
Icarus, vol. 196 (2008), pp. 318-358
[u'Ken L. Tanaka', u'J. Alexis P. Rodriguez', u'James A. Skinner Jr', u'Mary C. Bourke', u'Corey M. Fortezzo', u'Kenneth E. Herkenhoff', u'Eric J. Kolb', u'Chris H. Okubo']
GeneralScience
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A multi-agent based framework for the simulation of human and social behaviors during emergency evacuations
AI & Society, vol. 22, no. 2 (2007)
[u'Xiaoshan Pan', u'Charles S. Han', u'Ken Dauber', u'Kincho H. Law']
GeneralScience
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
ACM's Past Helps Steer Its Future
Communications of the ACM, vol. 50, no. 5 (2007), pp. 10
[u'Stuart I. Feldman']
GeneralScience
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
GO Based Inference of Gene Regulatory Networks from Gene Expression Data
WORLDCOMP '07 (2007)
[u'Kumar Abhishek', u'Harish Karnick']
GeneralScience
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
The rewards of ACM's awards
Commun. ACM, vol. 50 (2007), pp. 17-18
[u'Stuart I. Feldman']
GeneralScience
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub33331.html
notfound
=========================
Why There's Antifreeze in Your Toothpaste: The Chemistry of Household Ingredients
Chicago Review Press, 814 N. Franklin St. 814 N. Franklin St. Chicago, IL 60610 (2007), pp. 240
[u'Simon Quellen Field']
GeneralScience
Abstract: Explaining why antifreeze is a component of toothpaste and how salt works in shampoo, this fascinating handbook delves into the chemistry of everyday household products. Decoding more than 150 cryptic ingredients, the guide explains each component's structural formula, offers synonymous names, and describes its common uses. This informative resource can serve curious readers as a basic primer to commercial chemistry or as an indexed reference for specific compounds found on a product label. Grouped according to type, these chemical descriptions will dissolve common misunderstandings and help make consumers more product savvy.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Predicting EMG Data from M1 Neurons with Variational Bayesian Least Squares
Advances in Neural Information Processing Systems 18, MIT Press (2006)
[u'Jo-Anne Ting', u"Aaron D'Souza", u'Kenji Yamamoto', u'Toshinori Yoshioka', u'Donna Hoffman', u'Shinji Kakei', u'Lauren Sergio', u'John Kalaska', u'Mitsuo Kawato', u'Peter Strick', u'Stefan Schaal']
GeneralScience
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub28009.html
notfound
=========================
Return of Gonzo Gizmos
Chicago Review Press, 814 North Franklin Street, Chicago, Illinois, 60610 (2006), pp. 1-147
[u'Simon Quellen Field']
GeneralScience
Abstract: Book Description This fresh collection of more than 20 science projectsfrom hydrogen fuel cells to computer-controlled radio transmittersis perfect for the tireless tinkerer. Innovative activities include taking detailed plant cell photographs through a microscope using a disposable camera; building a rocket engine out of aluminum foil, paper clips, and kitchen matches; and constructing a geodesic dome out of gumdrops and barbecue skewers. Organized by scientific topic, each chapter includes explanations of the physics, chemistry, biology, or mathematics behind the projects. Most of the devices can be built using common household products or components available at hardware or electronic stores, and each experiment contains illustrated step-by-step instructions with photographs and diagrams that make construction easy. No workbench warrior, science teacher, or grown-up geek should be without this idea-filled resource.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Simple Reconstruction of Binary Near-Perfect Phylogenetic Trees
International Conference on Computational Science (2) (2006), pp. 799-806
[u'Srinath Sridhar', u'Kedar Dhamdhere', u'Guy E. Blelloch', u'Eran Halperin', u'R. Ravi', u'Russell Schwartz']
GeneralScience
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Oral Mucosal Microvascular Network Abnormalities in De Novo Mutation Achondroplasia
Fractals, vol. 13 (2005)
[u'C. D. Felice', u'S. Parrini', u'G. D. Maggio', u'R. N. Laurini', u'K. Shirriff']
GeneralScience
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Finite-State Transducers in Computational Biology
Tutorial presented at the 13th Annual International Conference on Intelligent Systems for Molecular Biology (ISMB 2005), Detroit, MI
[u'Corinna Cortes', u'Mehryar Mohri']
GeneralScience
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Computers, Use Of
Encyclopedia of Space Sciences: Macmillan Science Library (2002)
[u'Peter Norvig']
GeneralScience
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/HardwareandArchitecture.html
found
=========================
Can Traditional Programming Bridge the Ninja Performance Gap for Parallel Computing Applications?
Communications of the ACM, vol. 58 (2015), pp. 77-86
[u'Nadathur Satish', u'Changkyu Kim', u'Jatin Chhugani', u'Hideki Saito', u'Rakesh Krishnaiyer', u'Mikhail Smelyanskiy', u'Milind Girkar', u'Pradeep Dubey']
HardwareandArchitecture
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43890.html
notfound
=========================
Full-Chip Simulations, Keys to Success
SNUG Silicon Valley 2015 Proceedings, Silicon Valley
[u'Dan Steinberg']
HardwareandArchitecture
Abstract: As designs continue to grow larger and ever more complex, full-chip simulations remain a critical component of design verification. These simulations pose a unique set of challenges that require different approaches than those used at the block or sub-chip level. This paper defines the key goals of full-chip simulations and outlines guiding principles to follow when developing a new environment. Special attention is paid to architecting for speed, both speed of simulation as well as speed of debug. Lessons learned over the years along with specific recommendations are presented.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Heracles: Improving Resource Efficiency at Scale
Proceedings of the 42th Annual International Symposium on Computer Architecture (2015)
[u'David Lo', u'Liqun Cheng', u'Rama Govindaraju', u'Parthasarathy Ranganathan', u'Christos Kozyrakis']
HardwareandArchitecture
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Author Retrospective for A NUCA Substrate for Flexible CMP Cache Sharing
ICS 25th Anniversary Volume, ACM SIGARCH (2014)
[u'Jaehyuk Huh', u'Changkyu Kim', u'Hazim Shafi', u'Lixin Zhang', u'Doug Burger', u'Stephen W. Keckler']
HardwareandArchitecture
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Author Retrospective for Cooperative Cache Partitioning for Chip Multiprocessors
ICS 25th Anniversary Volume, 2014, ACM SIGARCH
[u'Jichuan Chang', u'Gurindar S Sohi']
HardwareandArchitecture
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Dynamically Detecting and Tolerating IF-Condition Data Races
International Symposium on High Performance Computer Architecture (HPCA), IEEE (2014)
[u'Shanxiang Qi', u'Abdullah A. Muzahid', u'Wonsun Ahn', u'Josep Torrellas']
HardwareandArchitecture
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
HaPPy: Hyperthread-aware Power Profiling Dynamically
USENIX Annual Technical Conference 2014
[u'Yan Zhai', u'Xiao Zhang', u'Stephane Eranian', u'Lingjia Tang', u'Jason Mars']
HardwareandArchitecture
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42857.html
found
=========================
Low-Overhead Network-on-Chip Support for Location-Oblivious Task Placement
IEEE Transactions on Computers, vol. Volume 63, Issue 6 (2014), pp. 1487 - 1500
[u'Gwangsun Kim', u'Lee', u'M.M.-J.', u'John Kim', u'Dennis Abts', u'Michael R. Marty']
HardwareandArchitecture
Abstract: Many-core processors will have many processing cores with a network-on-chip (NoC) that provides access to shared resources such as main memory and on-chip caches. However, locally-fair arbitration in multi-stage NoC can lead to globally unfair access to shared resources and impact system-level performance depending on where each task is physically placed. In this work, we propose an arbitration to provide equality-of-service (EoS) in the network and provide support for location-oblivious task placement. We propose using probabilistic arbitration combined with distance-based weights to achieve EoS and overcome the limitation of round-robin arbiter. However, the complexity of probabilistic arbitration results in high area and long latency which negatively impacts performance. In order to reduce the hardware complexity, we propose an hybrid arbiter that switches between a simple arbiter at low load and a complex arbiter at high load. The hybrid arbiter is enabled by the observation that arbitration only impacts the overall performance and global fairness at a high load. We evaluate our arbitration scheme with synthetic traffic patterns and GPGPU benchmarks. Our results shows that hybrid arbiter that combines round-robin arbiter with probabilistic distance-based arbitration reduces performance variation as task placement is varied and also improves average IPC.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42899.html
found
=========================
Near-Data Processing: Insights from a MICRO-46 Workshop
IEEE Micro (Special Issue on Big Data), vol. 34 (2014), pp. 36-43
[u'Rajeev Balasubramonian', u'Jichuan Chang', u'Troy Manning', u'Jaime H. Moreno', u'Richard Murphy', u'Ravi Nair', u'Steven Swanson']
HardwareandArchitecture
Abstract: The cost of data movement in big-data systems motivates careful examination of near-data processing (NDP) frameworks. The concept of NDP was actively researched in the 1990s, but gained little commercial traction. After a decade-long dormancy, interest in this topic has spiked. A workshop on NDP was organized at MICRO-46 and was well attended. Given the interest, the organizers and keynote speakers have attempted to capture the key insights from the workshop into an article that can be widely disseminated. This article describes the many reasons why NDP is compelling today and identifies key upcoming challenges in realizing the potential of NDP.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44271.html
notfound
=========================
Profiling a warehouse-scale computer
ISCA '15 Proceedings of the 42nd Annual International Symposium on Computer Architecture, ACM (2014), pp. 158-169
[u'Svilen Kanev', u'Juan Darago', u'Kim Hazelwood', u'Parthasarathy Ranganathan', u'Tipp Moseley', u'Gu-Yeon Wei', u'David Brooks']
HardwareandArchitecture
Abstract: With the increasing prevalence of warehouse-scale (WSC) and cloud computing, understanding the interactions of server applications with the underlying microarchitecture becomes ever more important in order to extract maximum performance out of server hardware. To aid such understanding, this paper presents a detailed microarchitectural analysis of live datacenter jobs, measured on more than 20,000 Google machines over a three year period, and comprising thousands of different applications. We first find that WSC workloads are extremely diverse, breeding the need for architectures that can tolerate application variability without performance loss. However, some patterns emerge, offering opportunities for co-optimization of hardware and software. For example, we identify common building blocks in the lower levels of the software stack. This "datacenter tax" can comprise nearly 30% of cycles across jobs running in the fleet, which makes its constituents prime candidates for hardware specialization in future server systems-on-chips. We also uncover opportunities for classic microarchitectural optimizations for server processors, especially in the cache hierarchy. Typical workloads place significant stress on instruction caches and prefer memory latency over bandwidth. They also stall cores often, but compute heavily in bursts. These observations motivate several interesting directions for future warehouse-scale computers.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43448.html
notfound
=========================
Security Vulnerability in Processor-Interconnect Router Design
Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security, ACM, New York, NY, pp. 358-368
[u'WonJun Song', u'John Kim', u'Jae W. Lee', u'Dennis Abts']
HardwareandArchitecture
Abstract: Servers that consist of multiple nodes and sockets are interconnected together with a high-bandwidth, low latency processor interconnect network, such as Intel QPI or AMD Hypertransport technologies. The different nodes exchange packets through routers which communicate with other routers. A key component of a router is the routing table which determines which output port an arriving packet should be forwarded through. However, because of the flexibility (or programmability) of the routing tables, we show that it can result in security vulnerability. We describe the procedures for how the routing tables in a processor-interconnect router can be modified. Based on these modifications, we propose new system attacks in a server, which include both performance attacks by degrading the latency and/or the bandwidth of the processor interconnect as well as a livelock attack that hangs the system. We implement these system on an 8-node AMD server and show how performance can be significantly degraded. Based on this vulnerability, we propose alternative solutions that provide various trade-off in terms of flexibility and cost while minimizing the routing table security vulnerability.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42922.html
notfound
=========================
The Power of Smartphones
IEEE Pervasive Computing, vol. 13-03 (2014), pp. 76-79
[u'Roy Want']
HardwareandArchitecture
Abstract: If youre new to power monitoring in the mobile design process, either when building mobile hardware or writing software-based applications, this article will point you in the right direction, helping you identify what characteristics to consider and what test equipment to use.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42523.html
notfound
=========================
Towards Energy Proportionality for Large-Scale Latency-Critical Workloads
Proceedings of the 41th Annual International Symposium on Computer Architecture, ACM (2014)
[u'David Lo', u'Liqun Cheng', u'Rama Govindaraju', u'Luiz Andr Barroso', u'Christos Kozyrakis']
HardwareandArchitecture
Abstract: Reducing the energy footprint of warehouse-scale computer (WSC) systems is key to their affordability, yet difficult to achieve in practice. The lack of energy proportionality of typical WSC hardware and the fact that important workloads (such as search) require all servers to remain up regardless of traffic intensity renders existing power management techniques ineffective at reducing WSC energy use. We present PEGASUS, a feedback-based controller that significantly improves the energy proportionality of WSC systems, as demonstrated by a real implementation in a Google search cluster. PEGASUS uses request latency statistics to dynamically adjust server power management limits in a fine-grain manner, running each server just fast enough to meet global service-level latency objectives. In large cluster experiments, PEGASUS reduces power consumption by up to 20%. We also estimate that a distributed version of PEGASUS can nearly double these savings.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41605.html
notfound
=========================
A Green Display for the Internet
Renewable Energy and the Environment, Optical Society of America (2013)
[u'Ken Foo', u'Bill Hamburgen', u'Jim Zhuang']
HardwareandArchitecture
Abstract: In typical use, a liquid crystal display (LCD) with high resolution, brightness and color saturation can consume over half the total system power in a modern mobile device. This paper examines LCD optical transmittance and system electrical design to extend battery run time. By applying a solid understanding of critical optical parameters and complementary system design, a low power Green display can be achieved. The LCD in the Pixel Chromebook [1], will be used as a baseline for discussion.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41415.html
notfound
=========================
Concurrency-aware compiler optimizations for hardware description languages
ACM Transactions on Design Automation of Electronic Systems (TODAES), vol. Volume 18, Issue 1 (2013), 10:1-10:16
[u'Harikumar Somakumar']
HardwareandArchitecture
Abstract: In this article, we discuss the application of compiler technology for eliminating redundant computation in hardware simulation. We discuss how concurrency in hardware description languages (HDLs) presents opportunities for expression reuse across different threads. While accounting for discrete event simulation semantics, we extend the data flow analysis framework to concurrent threads. In this process, we introduce a rewriting scheme named VF and a graph representation to model sensitivity relationships among threads. An algorithm for identifying common sub-expressions as applied to HDLs is presented. Related issues, such as scheduling correctness, are also considered.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Optimizing Google's Warehouse Scale Computers: The NUMA Experience
The 19th IEEE International Symposium on High Performance Computer Architecture (2013)
[u'Lingjia Tang', u'Jason Mars', u'Xiao Zhang', u'Robert Hagmann', u'Robert Hundt', u'Eric Tune']
HardwareandArchitecture
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41606.html
found
=========================
The Datacenter as a Computer: An Introduction to the Design of Warehouse-Scale Machines, Second Edition
Morgan & Claypool Publishers (2013)
[u'Luiz Andr Barroso', u'Jimmy Clidaras', u'Urs Hlzle']
HardwareandArchitecture
Abstract: As computation continues to move into the cloud, the computing platform of interest no longer resembles a pizza box or a refrigerator, but a warehouse full of computers. These new large datacenters are quite different from traditional hosting facilities of earlier times and cannot be viewed simply as a collection of co-located servers. Large portions of the hardware and software resources in these facilities must work in concert to efficiently deliver good levels of Internet service performance, something that can only be achieved by a holistic approach to their design and deployment. In other words, we must treat the datacenter itself as one massive warehouse-scale computer (WSC). We describe the architecture of WSCs, the main factors influencing their design, operation, and cost structure, and the characteristics of their software base. We hope it will be useful to architects and programmers of todays WSCs, as well as those of future many-core platforms which may one day implement the equivalent of todays WSCs on a single board. Notes for the Second Edition After nearly four years of substantial academic and industrial developments in warehouse-scale computing, we are delighted to present our first major update to this lecture. The increased popularity of public clouds has made WSC software techniques relevant to a larger pool of programmers since our first edition. Therefore, we expanded Chapter 2 to reflect our better understanding of WSC software systems and the toolbox of software techniques for WSC programming. In Chapter 3, we added to our coverage of the evolving landscape of wimpy vs. brawny server trade-offs, and we now present an overview of WSC interconnects and storage systems that was promised but lacking in the original edition. Thanks largely to the help of our new co-author, Google Distinguished Engineer Jimmy Clidaras, the material on facility mechanical and power distribution design has been updated and greatly extended (see Chapters 4 and 5). Chapters 6 and 7 have also been revamped significantly. We hope this revised edition continues to meet the needs of educators and professionals in this area.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41187.html
notfound
=========================
Whare-Map: Heterogeneity in Homogeneous Warehouse-Scale Computers
Proceedings of the 2013 ACM/IEEE International Symposium on Computer Architecture (ISCA), IEEE (to appear)
[u'Jason Mars', u'Lingjia Tang', u'Robert Hundt']
HardwareandArchitecture
Abstract: Modern warehouse scale computers (WSCs) continue to be embraced as homogeneous computing platforms. However, due to frequent machine replacements and upgrades, modern WSCs are in fact composed of diverse commodity microarchitectures and machine congurations. Yet, current WSCs are architected with the assumption of homogeneity, leaving a potentially signicant performance opportunity unexplored. In this paper, we expose and quantify the performance impact of the homogeneity assumption for modern production WSCs using industry-strength large-scale web-service workloads. In addition, we argue for, and evaluate the benets of, a heterogeneity-aware WSC using commercial web-service production workloads including Googles websearch. We also identify key factors impacting the available performance opportunity when exploiting heterogeneity and introduce a new metric, opportunity factor, to quantify an applications sensitivity to the heterogeneity in a given WSC. To exploit heterogeneity in homogeneous WSCs, we propose Whare-Map, the WSC Heterogeneity Aware Mapper that leverages already in-place continuous proling subsystems found in production environments. When employing Whare-Map, we observe a cluster-wide performance improvement of 15% on average over heterogeneityoblivious job placement and up to an 80% improvement forweb-service applications that are particularly sensitive to heterogeneity
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub39976.html
notfound
=========================
A Fault Detection and Protection Scheme for Three-Level DCDC Converters Based on Monitoring Flying Capacitor Voltage
IEEE Transactions on Power Electronics, vol. 27 (2012), pp. 685-697
[u'Honggang Sheng', u'Fred Wang', u'C.W. Tipton']
HardwareandArchitecture
Abstract: Fault detection and protection is an important design aspect for any power converter, especially in high-power high-voltage applications, where cost of failure can be high. The three-level dc-dc converter and its varied derivatives are attractive topologies in high-voltage high-power converter applications. The protection method can not only prevent the system failure against unbalanced voltage stresses on the switches, but also provide a remedy for the system as faults occur and save the remaining components. The three-level converter is subject to voltage unbalance in certain abnormal conditions, which can result in switch overvoltage and system failure. The reasons for the unbalanced voltage stresses are fully investigated and categorized. The solutions to each abnormal condition are introduced. In addition to the voltage unbalance, the three-level converters can be protected against multiple faults by the proposed protection method through monitoring the flying capacitor voltage. Phenomena associated with each fault are thoroughly analyzed and summarized. The protection circuit is simple and can be easily implemented, while it can effectively protect the three-level converters and its derivatives, which has been verified by the experiment with a three-level parallel resonant converter.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
ADEL: An automatic detector of energy leaks for smartphone applications
Proceeding of International Conference on Hardware/Software Codesign and System Synthesis, (2012) (to appear)
[u'Lide Zhang', u'M. S. Gordon', u'Robert P. Dick', u'Z. Morley Mao', u'Peter Dinda', u'Lei Yang']
HardwareandArchitecture
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37671.html
notfound
=========================
Accelerator Compiler for the VENICE Vector Processor
FPGA, ACM (2012)
[u'Zhiduo Liu', u'Aaron Severance', u'Guy G.F. Lemieux', u'Satnam Singh']
HardwareandArchitecture
Abstract: This paper describes the compiler design for VENICE, a new soft vector processor (SVP). The compiler is a new back-end target for Microsoft Accelerator, a high-level data parallel library for C++ and C#. This allows us to automatically compile high-level programs into VENICE assembly code, thus avoiding the process of writing assembly code used by previous SVPs. Experimental results show the compiler can generate scalable parallel code with execution times that are comparable to hand-written VENICE assembly code. On data-parallel applications, VENICE at 100MHz on an Altera DE3 platform runs at speeds comparable to one core of a 3.5GHz Intel Xeon W3690 processor, beating it in performance on four of six benchmarks by up to 3.2%.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub39964.html
notfound
=========================
Managing Distributed UPS Energy for Effective Power Capping in Data Centers
International Symposium on Computer Architecture (2012), pp. 488-499
[u'Vasileios Kontorinis', u'Liuyi Eric Zhang', u'Baris Aksanli', u'Jack Sampson', u'Houman Homayoun', u'Eddie Pettis', u'Dean M. Tullsen', u'Tajana Simunic Rosing']
HardwareandArchitecture
Abstract: Power over-subscription can reduce costs for modern data centers. However, designing the power infrastructure for a lower operating power point than the aggregated peak power of all servers requires dynamic techniques to avoid high peak power costs and, even worse, tripping circuit breakers. This work presents an architecture for distributed per-server UPSs that stores energy during low activity periods and uses this energy during power spikes. This work leverages the distributed nature of the UPS batteries and develops policies that prolong the duration of their usage. The specific approach shaves 19.4% of the peak power for modern servers, at no cost in performance, allowing the installation of 24% more servers within the same power budget. More servers amortize infrastructure costs better and, hence, reduce total cost of ownership per server by 6.3%.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40366.html
found
=========================
Resource-bounded multicore emulation using Beefarm
Microprocessors and Microsystems (2012)
[u'Oriol Arcas', u'Nehir Sonmez', u'Gokhan Sayilar', u'Satnam Singh', u'Osman S. Unsal', u'Adrian Cristal', u'Ibrahim Hur', u'Mateo Valero']
HardwareandArchitecture
Abstract: In this article, we present the Beefarm infrastructure for FPGA-based multiprocessor emulation, a popular research topic of the last few years both in FPGA and computer architecture communities. We explain how we modify and extend a MIPS-based open-source soft core, we discuss various design tradeoffs to make efficient use of the bounded resources available on chip and we demonstrate superior scalability compared to traditional software instruction set simulators through experimental results running Software Transactional Memory (STM) benchmarks. Based on our experience, we comment on the pros and cons and the future trends of using hardware-based emulation for multicore research.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38226.html
notfound
=========================
Runtime adaptation: a case for reactive code alignment
Proceedings of the 2nd International Workshop on Adaptive Self-Tuning Computing Systems for the Exaflop Era, ACM, New York, NY, USA (2012), pp. 1-11
[u'Michelle McDaniel', u'Kim Hazelwood']
HardwareandArchitecture
Abstract: Static alignment techniques are well studied and have been incorporated into compilers in order to optimize code locality for the instruction fetch unit in modern processors. However, current static alignment techniques have several limitations that cannot be overcome. In the exascale era, it becomes even more important to break from static techniques and develop adaptive algorithms in order to maximize the utilization of every processor cycle. In this paper, we explore those limitations and show that reactive realignment, a method where we dynamically monitor running applications, react to symptoms of poor alignment, and adapt alignment to the current execution environment and program input, is more scalable than static alignment. We present fetches-per-instruction as a runtime indicator of poor alignment. Additionally, we discuss three main opportunities that static alignment techniques cannot leverage, but which are increasingly important in large scale computing systems: microarchitectural differences of cores, dynamic program inputs that exercise different and sometimes alternating code paths, and dynamic branch behavior, including indirect branch behavior and phase changes. Finally, we will present several instances where our trigger for reactive realignment may be incorporated in practice, and discuss the limitations of dynamic alignment.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37675.html
notfound
=========================
Bubble-Up: Increasing Utilization In Modern Warehouse Scale Computers Via Sensible Co-Locations
Proceedings of the 44th Annual IEEE/ACM International Symposium on Microarchitecture, 2011, IEEE, New York, NY, USA
[u'Jason Mars', u'Linjia Tang', u'Robert Hundt', u'Kevin Skadron', u'Mary Lou Souffa']
HardwareandArchitecture
Abstract: As much of the worlds computing continues to move into the cloud, the over-provisioning of computing resources to ensure the performance isolation of latency-sensitive tasks, such as web search, in modern datacenters is a major contributor to low machine utilization. Being unable to accurately predict performance degradation due to contention for shared resources on multicore systems has led to the heavy handed approach of simply disallowing the co-location of high-priority, latency-sensitive tasks with other tasks. Performing this precise prediction has been a challenging and unsolved problem. In this paper, we present Bubble-Up, a characterization methodology that enables the accurate prediction of the performance degradation that results from contention for shared resources in the memory subsystem. By using a bubble to apply a tunable amount of pressure to the memory subsystem on processors in production datacenters, our methodology can predict the performance interference between co-locate applications with an accuracy within 1% to 2% of the actual performance degradation. Using this methodology to arrive at sensible co-locations in Googles production datacenters with real-world large-scale applications, we can improve the utilization of a 500-machine cluster by 50% to 90% while guaranteeing a high quality of service of latency-sensitive applications.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37659.html
notfound
=========================
Dynamic cache contention detection in multi-threaded applications
VEE 2011; Proceedings of the 7th ACM SIGPLAN/SIGOPS International conference on virtual execution environments, ACM, New York, NY, pp. 27-37
[u'Qin Zhao', u'David Koh', u'Syed Raza', u'Derek Bruening', u'Weng-Fai Wong']
HardwareandArchitecture
Abstract: In today's multi-core systems, cache contention due to true and false sharing can cause unexpected and significant performance degradation. A detailed understanding of a given multi-threaded application's behavior is required to precisely identify such performance bottlenecks. Traditionally, however, such diagnostic information can only be obtained after lengthy simulation of the memory hierarchy. In this paper, we present a novel approach that efficiently analyzes interactions between threads to determine thread correlation and detect true and false sharing. It is based on the following key insight: although the slowdown caused by cache contention depends on factors including the thread-to-core binding and parameters of the memory hierarchy, the amount of data sharing is primarily a function of the cache line size and application behavior. Using memory shadowing and dynamic instrumentation, we implemented a tool that obtains detailed sharing information between threads without simulating the full complexity of the memory hierarchy. The runtime overhead of our approach --- a 5x slowdown on average relative to native execution --- is significantly less than that of detailed cache simulation. The information collected allows programmers to identify the degree of cache contention in an application, the correlation among its threads, and the sources of significant false sharing. Using our approach, we were able to improve the performance of some applications up to a factor of 12x. For other contention-intensive applications, we were able to shed light on the obstacles that prevent their performance from scaling to many cores.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
FAWN: a fast array of wimpy nodes: technical perspective
Communications of the ACM, vol. 54 (2011), pp. 100-100
[u'Luiz Andr Barroso']
HardwareandArchitecture
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37676.html
notfound
=========================
Heterogeneity in Homogeneous Warehouse-Scale Computers: A Performance Opportunity
IEEE Computer Architecture Letters (CAL), vol. Vol. 10 No. 2 (2011), pp. 29-32
[u'Jason Mars', u'Lingjia Tang', u'Robert Hundt']
HardwareandArchitecture
Abstract: The class of modern datacenters recently coined as warehouse scale computers (WSCs) has traditionally been embraced as homogeneous computing platforms. However, due to frequent machine replacements and upgrades, modern WSCs are in fact composed of diverse commodity microarchitectures and machine configurations. Yet, current WSCs are designed with an assumption of homogeneity, leaving a potentially significant performance opportunity unexplored. In this paper, we investigate the key factors impacting the available heterogeneity in modern WSCs, and the benefit of exploiting this heterogeneity to maximize overall performance. We also introduce a new metric, opportunity factor, which can be used to quantify an applications sensitivity to the heterogeneity in a given WSC. For applications that are sensitive to heterogeneity, we observe a performance improvement of up to 70% when employing our approach. In a WSC composed of state-of-the-art machines, we can improve the overall performance of the entire datacenter by 16% over the status quo.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37069.html
notfound
=========================
High Performance Datacenter Networks: Architectures, Algorithms, and Opportunities
Morgan & Claypool, San Rafael, California (2011)
[u'Dennis Abts', u'John Kim']
HardwareandArchitecture
Abstract: Datacenter networks provide the communication substrate for large parallel computer systems that form the ecosystem for high performance computing (HPC) systems and modern Internet applications. The design of new datacenter networks is motivated by an array of applications ranging from communication intensive climatology, complex material simulations and molecular dynamics to such Internet applications as Web search, language translation, collaborative Internet applications, streaming video and voice-over-IP. For both Supercomputing and Cloud Computing the network enables distributed applications to communicate and interoperate in an orchestrated and efficient way. This book describes the design and engineering tradeoffs of datacenter networks. It describes interconnection networks from topology and network architecture to routing algorithms, and presents opportunities for taking advantage of the emerging technology trends that are influencing router microarchitecture. With the emergence of "many-core" processor chips, it is evident that we will also need "many-port" routing chips to provide a bandwidth-rich network to avoid the performance limiting effects of Amdahl's Law. We provide an overview of conventional topologies and their routing algorithms and show how technology, signaling rates and cost-effective optics are motivating new network topologies that scale up to millions of hosts. The book also provides detailed case studies of two high performance parallel computer systems and their networks.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37062.html
notfound
=========================
Power Management of Online Data-Intensive Services
Proceedings of the 38th ACM International Symposium on Computer Architecture (2011)
[u'David Meisner', u'Christopher M. Sadler', u'Luiz Andr Barroso', u'Wolf-Dietrich Weber', u'Thomas F. Wenisch']
HardwareandArchitecture
Abstract: Much of the success of the Internet services model can be attributed to the popularity of a class of workloads that we call Online Data-Intensive (OLDI) services. These workloads perform significant computing over massive data sets per user request but, unlike their offline counterparts (such as MapReduce computations), they require responsiveness in the sub-second time scale at high request rates. Large search products, online advertising, and machine translation are examples of workloads in this class. Although the load in OLDI services can vary widely during the day, their energy consumption sees little variance due to the lack of energy proportionality of the underlying machinery. The scale and latency sensitivity of OLDI workloads also make them a challenging target for power management techniques. We investigate what, if anything, can be done to make OLDI systems more energy-proportional. Specifically, we evaluate the applicability of active and idle low-power modes to reduce the power consumed by the primary server components (processor, memory, and disk), while maintaining tight response time constraints, particularly on 95th-percentile latency. Using Web search as a representative example of this workload class, we first characterize a production Web search workload at cluster-wide scale. We provide a fine-grain characterization and expose the opportunity for power savings using low-power modes of each primary server component. Second, we develop and validate a performance model to evaluate the impact of processor- and memory-based low-power modes on the search latency distribution and consider the benefit of current and foreseeable low-power modes. Our results highlight the challenges of power management for this class of workloads. In contrast to other server workloads, for which idle low-power modes have shown great promise, for OLDI workloads we find that energy-proportionality with acceptable query latency can only be achieved using coordinated, full-system active low-power modes.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42859.html
found
=========================
Simultaneous Technology Mapping and Placement for Delay Minimization
IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS, vol. 30 (2011), pp. 416-426
[u'Yifang Liu', u'Rupesh S. Shelar', u'Jiang Hu']
HardwareandArchitecture
Abstract: AbstractTechnology mapping and placement have a significant impact on delays in standard cell-based very large scale integrated circuits. Traditionally, these steps are applied separately to optimize the delays, possibly since efficient algorithms that allow the simultaneous exploration of the mapping and placement solution spaces are unknown. In this paper, we present an exact polynomial time algorithm for delay-optimal placement of a tree and extend the same to simultaneous technology mapping and placement for the optimal delay in the tree. We extend the algorithm by employing Lagrangian relaxation technique, which assesses the timing criticality of paths beyond a tree, to optimize the delays in directed acyclic graphs. Experimental results on benchmark circuits in a 70 nm technology show that our algorithms improve timing significantly with remarkably less runtimes compared to a competitive approach of iterative conventional timing-driven mapping and multilevel placement. Index Termsalgorithms, directed acyclic graph, physical synthesis, placement, technology mapping, tree.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36896.html
notfound
=========================
The Cray XT4 and Seastar 3-D Torus Interconnect
Encyclopedia of Parallel Computing, Springer (2011)
[u'Dennis Abts']
HardwareandArchitecture
Abstract: The Cray XT4 system is a distributed memory multiprocessor combining an aggressive superscalar processor (AMD64) with a bandwidth-rich 3-D torus interconnection network that scales up to 32K processing nodes. This chapter provides an overview of the Cray XT4 system architecture and a detailed discussion of its interconnection network.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40496.html
notfound
=========================
The Future of Computing Performance: Game Over or Next Level?
The National Academies Press (2011), pp. 200
[u'Samuel H. Fuller', u'Luiz Andr Barroso', u'Robert P. Colwell', u'William J. Dally', u'Dan Dobberpuhl', u'Pradeep Dubey', u'Mark D. Hill', u'Mark Horowitz', u'David Kirk', u'Monica Lam', u'Kathryn S. McKinley', u'Charles Moore', u'Katherine Yelick']
HardwareandArchitecture
Abstract: The end of dramatic exponential growth in single-processor performance marks the end of the dominance of the single microprocessor in computing. The era of sequential computing must give way to a new era in which parallelism is at the forefront. Although important scientific and engineering challenges lie ahead, this is an opportune time for innovation in programming systems and computing architectures. We have already begun to see diversity in computer designs to optimize for such considerations as power and throughput. The next generation of discoveries is likely to require advances at both the hardware and software levels of computing systems. There is no guarantee that we can make parallel computing as common and easy to use as yesterday's sequential single-processor computer systems, but unless we aggressively pursue efforts suggested by the recommendations in this book, it will be "game over" for growth in computing performance. If parallel programming and related software efforts fail to become widespread, the development of exciting new applications that drive the computer industry will stall; if such innovation stalls, many other parts of the economy will follow suit. The Future of Computing Performance describes the factors that have led to the future limitations on growth for single processors that are based on complementary metal oxide semiconductor (CMOS) technology. It explores challenges inherent in parallel computing and architecture, including ever-increasing power consumption and the escalated requirements for heat dissipation. The book delineates a research, practice, and education agenda to help overcome these challenges. The Future of Computing Performance will guide researchers, manufacturers, and information technology professionals in the right direction for sustainable growth in computer performance, so that we may all enjoy the next level of benefits to society.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37124.html
notfound
=========================
The Impact of Memory Subsystem Resource Sharing on Datacenter Applications
ISCA, ACM (2011)
[u'Lingjia Tang', u'Jason Mars', u'Neil Vachharajani', u'Robert Hundt', u'Mary-Lou Soffa']
HardwareandArchitecture
Abstract: In this paper we study the impact of sharing memory resources on ve Google datacenter applications: a web search engine, bigtable, content analyzer, image stitching, and protocol buer. While prior work has found neither positive nor negative eects from cache sharing across the PARSEC benchmark suite, we nd that across these datacenter applications, there is both a sizable benet and a potential degradation from improperly sharing resources. In this paper, we rst present a study of the importance of thread-tocore mappings for applications in the datacenter as threads can be mapped to share or to not share caches and bus bandwidth. Second, we investigate the impact of co-locating threads from multiple applications with diverse memory behavior and discover that the best mapping for a given application changes depending on its co-runner. Third, we investigate the application characteristics that impact performance in the various thread-to-core mapping scenarios. Finally, we present both a heuristics-based and an adaptive approach to arrive at good thread-to-core decisions in the datacenter. We observe performance swings of up to 25% for web search and 40% for other key applications, simply based on how application threads are mapped to cores. By employing our adaptive thread-to-core mapper, the performance of the datacenter applications presented in this work improved by up to 22% over status quo thread-to-core mapping and performs within 3% of optimal.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub39990.html
notfound
=========================
Accurate Online Power Estimation and Automatic Battery Behavior Based Power Model Generation for Smartphones
Proceeding of Internation Conference on Hardware/Software Codesign and System Synthesis (2010), pp. 105-114
[u'Lide Zhang', u'Birjodh Tiwana', u'Zhiyun Qian', u'Zhaoguang Wang', u'Robert P. Dick', u'Z. Morley Mao', u'Lei Yang']
HardwareandArchitecture
Abstract: This paper describes PowerBooter, an automated power model construction technique that uses built-in battery voltage sensors and knowledge of battery discharge behavior to monitor power consumption while explicitly controlling the power management and activity states of individual components. It requires no external measurement equipment. We also describe PowerTutor, a component power management and activity state introspection based tool that uses the model generated by PowerBooter for online power estimation. PowerBooter is intended to make it quick and easy for application developers and end users to generate power models for new smartphone variants, which each have different power consumption properties and therefore require different power models. PowerTutor is intended to ease the design and selection of power efficient software for embedded systems. Combined, PowerBooter and PowerTutor have the goal of opening power modeling and analysis for more smartphone variants and their users.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Brawny cores still beat wimpy cores, most of the time
IEEE MICRO (2010)
[u'Urs Hlzle']
HardwareandArchitecture
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36740.html
notfound
=========================
Efficient Topologies for Large-Scale Cluster Networks
2010 Conference on OFC/NFOEC, IEEE, pp. 1-3
[u'John Kim', u'William J. Dally', u'Dennis Abts']
HardwareandArchitecture
Abstract: Increasing integrated-circuit pin bandwidth has motivated a corresponding increase in the degree or radix of interconnection networks and their routers. This paper describes the flattened butterfly, a cost-efficient topology for high-radix networks. On benign (load-balanced) traffic, the flattened butterfly approaches the cost/performance of a butterfly network and has roughly half the cost of a comparable performance Clos network. The advantage over the Clos is achieved by eliminating redundant hops when they are not needed for load balance. On adversarial traffic, the flattened butterfly matches the cost/performance of a folded-Clos network and provides an order of magnitude better performance than a conventional butterfly. In this case, global adaptive routing is used to switch the flattened butterfly from minimal to non-minimal routing using redundant hops only when they are needed. Different routing algorithms are evaluated on the flattened butterfly and compared against alternative topologies. We also provide a detailed cost model for an interconnection network and compare the cost of the flattened butterfly to alternative topologies to show the cost advantages of the flattened butterfly.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36462.html
notfound
=========================
Energy Proportional Datacenter Networks
Proceedings of the International Symposium on Computer Architecture, ACM (2010), pp. 338-347
[u'Dennis Abts', u'Mike Marty', u'Philip Wells', u'Peter Klausler', u'Hong Liu']
HardwareandArchitecture
Abstract: Numerous studies have shown that datacenter computers rarely operate at full utilization, leading to a number of proposals for creating servers that are energy proportional with respect to the computation that they are performing. In this paper, we show that as servers themselves become more energy proportional, the datacenter network can become a significant fraction (up to 50%) of cluster power. In this paper we propose several ways to design a high-performance datacenter network whose power consumption is more proportional to the amount of traffic it is moving --- that is, we propose energy proportional datacenter networks. We first show that a flattened butterfly topology itself is inherently more power efficient than the other commonly proposed topology for high-performance datacenter networks. We then exploit the characteristics of modern plesiochronous links to adjust their power and performance envelopes dynamically. Using a network simulator, driven by both synthetic workloads and production datacenter traces, we characterize and understand design tradeoffs, and demonstrate an 85% reduction in power --- which approaches the ideal energy-proportionality of the network. Our results also demonstrate two challenges for the designers of future network switches: 1) We show that there is a significant power advantage to having independent control of each unidirectional channel comprising a network link, since many traffic patterns show very asymmetric use, and 2) system designers should work to optimize the high-speed channel designs to be more energy efficient by choosing optimal data rate and equalization technology. Given these assumptions, we demonstrate that energy proportional datacenter communication is indeed possible.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36897.html
notfound
=========================
Probabilistic Distance-based Arbitration: Providing Equality of Service for Many-core CMPs
MICRO43: Proceedings of the 43rd Annual International Symposium on Microarchitecture, IEEE/ACM (2010)
[u'Michael M. Lee', u'John Kim', u'Dennis Abts', u'Michael Marty', u'Jae W. Lee']
HardwareandArchitecture
Abstract: Emerging many-core chip multiprocessors will integrate dozens of small processing cores with an on-chip interconnect consisting of point-to-point links. The interconnect enables the processing cores to not onl communicate, but to share common resources such as main memory resources and I/O controllers. In this work, we propose an arbitration scheme to enable equality of service (EoS) in access to a chip's shared resources. That is, we seek to remove any bias in a core's access to a shared resource based on its location within the CMP. We propose using probabilistic arbitration combined with distance-based weights to achieve EoSand overcome the limitation of conventional round-robin arbiter. We describe how nonlinear weights need to be used with probabilistic arbiters and propose three different arbitration weight metrics -- fixed weight, constantly increasing weight, and variably increasing weight. By only modifying the arbitration of an on-chip router, we do not require any additional buffers or virtual channels and create a simple, low-cost mechanism for achieving EoS. We evaluate our arbitration scheme across a wide range of traffic patterns. In addition to providing EoS, the proposed arbitration has additional benefits which include providing quality-of-service features (such as differentiated service) and providing fairness in terms of both throughput and latency that approaches the global fairness achieved with age-base arbitration -- thus, providing a more stable network by achieving high sustained throughput beyond saturation.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36755.html
notfound
=========================
Scalable Thread Scheduling and Global Power Management for Heterogeneous Many-Core Architectures
Proceedings of the Nineteenth International Conference on Parallel Architectures and Compilation Techniques (PACT), Association for Computing Machinery, 2 Penn Plaza, Suite 701, New York, NY, 10121-0701 (2010), pp. 29-39
[u'Jonathan A. Winter', u'David H. Albonesi', u'Christine A. Shoemaker']
HardwareandArchitecture
Abstract: Future many-core microprocessors are likely to be heterogeneous, by design or due to variability and defects. The latter type of heterogeneity is especially challenging due to its unpredictability. To minimize the performance and power impact of these hardware imperfections, the runtime thread scheduler and global power manager must be nimble enough to handle such random heterogeneity. With hundreds of cores expected on a single die in the future, these algorithms must provide high power-performance efficiency, yet remain scalable with low runtime overhead. This paper presents a range of scheduling and power management algorithms and performs a detailed evaluation of their effectiveness and scalability on heterogeneous many-core architectures with up to 256 cores. We also conduct a limit study on the potential benefits of coordinating scheduling and power management and demonstrate that coordination yields little benefit. We highlight the scalability limitations of previously proposed thread scheduling algorithms that were designed for small-scale chip multiprocessors and propose a Hierarchical Hungarian Scheduling Algorithm that dramatically reduces the scheduling overhead without loss of accuracy. Finally, we show that the high computational requirements of prior global power management algorithms based on linear programming make them infeasible for many-core chips, and that an algorithm that we call Steepest Drop achieves orders of magnitude lower execution time without sacrificing power-performance efficiency.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Warehouse Scale Computing - A keynote address to SIGMOD'10
Proceedings of the 2010 ACM SIGMOD International Conference on Management of data (2010)
[u'Luiz Andr Barroso']
HardwareandArchitecture
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35156.html
notfound
=========================
Achieving Predictable Performance through Better Memory Controller Placement in Many-Core CMPs
Proceedings of the International Symposium on Computer Architecture, ACM (2009)
[u'Dennis Abts', u'Natalie Engright Jerger', u'John Kim', u'Dan Gibson', u'Mikko Lipasti']
HardwareandArchitecture
Abstract: In the near term, Moore's law will continue to provide an increasing number of transistors and therefore an increasing number of on-chip cores. Limited pin bandwidth prevents the integration of a large number of memory controllers on-chip. With many cores, and few memory controllers, where to locate the memory controllers in the on-chip interconnection fabric becomes an important and as yet unexplored question. In this paper, we show how the location of the memory controllers can reduce contention (hot spots) in the on-chip fabric, as well as lower the variance in reference latency which provides for predictable performance of memory-intensive applications regardless of the processing core on which a thread is scheduled. We explore the design space of on-chip fabrics to find optimal memory controller placement relative to different topologies (i.e. mesh and torus), routing algorithms, and workloads.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Dynamic Heterogeneity and the Need for Multicore Virtualization
ACM SIGOPS Operating Systems Review, vol. 43 (2009), pp. 5-14
[u'Philip M Wells', u'Koushik Chakraborty', u'Gurindar S Sohi']
HardwareandArchitecture
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35290.html
notfound
=========================
The Datacenter as a Computer: An Introduction to the Design of Warehouse-Scale Machines
Morgan & Claypool Publishers (2009)
[u'Luiz Andr Barroso', u'Urs Hlzle']
HardwareandArchitecture
Abstract: As computation continues to move into the cloud, the computing platform of interest no longer resembles a pizza box or a refrigerator, but a warehouse full of computers. These new large datacenters are quite different from traditional hosting facilities of earlier times and cannot be viewed simply as a collection of co-located servers. Large portions of the hardware and software resources in these facilities must work in concert to efficiently deliver good levels of Internet service performance, something that can only be achieved by a holistic approach to their design and deployment. In other words, we must treat the datacenter itself as one massive warehouse-scale computer (WSC). We describe the architecture of WSCs, the main factors influencing their design, operation, and cost structure, and the characteristics of their software base. We hope it will be useful to architects and programmers of today's WSCs, as well as those of future many-core platforms which may one day implement the equivalent of today's WSCs on a single board.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34400.html
notfound
=========================
Amdahl's Law in the Multicore Era
IEEE Computer, vol. 41 (2008), pp. 33-38
[u'Mark D. Hill', u'Michael R. Marty']
HardwareandArchitecture
Abstract: Augmenting Amdahls Law with a corollary for multicore hardware makes it relevant to future generations of chips with multiple processor cores. Obtaining optimal multicore performance will require further research in both extracting more parallelism and making sequential cores faster.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Incrementally Parallelizing Database Transactions with Thread-Level Speculation
ACM Transactions on Computer Systems (TOCS), vol. 26 (2008)
[u'Christopher B. Colohan', u'Anastassia Ailamaki', u'J. Gregory Steffan', u'Todd C. Mowry']
HardwareandArchitecture
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34926.html
notfound
=========================
Technology-Driven, Highly-Scalable Dragonfly Topology
Proceedings of the 35th International Symposium on Computer Architecture, IEEE Computer Society, Washington, DC USA (2008), pp. 77-88
[u'John Kim', u'William J. Dally', u'Steve Scott', u'Dennis Abts']
HardwareandArchitecture
Abstract: Evolving technology and increasing pin-bandwidth motivate the use of high-radix routers to reduce the diameter, latency, and cost of interconnection networks. High-radix networks, however, require longer cables than their low-radix counterparts. Because cables dominate network cost, the number of cables, and particularly the number of long, global cables should be minimized to realize an efficient network. In this paper, we introduce the dragonfly topology which uses a group of high-radix routers as a virtual router to increase the effective radix of the network. With this organization, each minimally routed packet traverses at most one global channel. By reducing global channels, a dragonfly reduces cost by 20% compared to a flattened butterfly and by 52% compared to a folded Clos network in configurations with 16K nodes.We also introduce two new variants of global adaptive routing that enable load-balanced routing in the dragonfly. Each router in a dragonfly must make an adaptive routing decision based on the state of a global channel connected to a different router. Because of the indirect nature of this routing decision, conventional adaptive routing algorithms give degraded performance. We introduce the use of selective virtual-channel discrimination and the use of credit round-trip latency to both sense and signal channel congestion. The combination of these two methods gives throughput and latency that approaches that of an ideal adaptive routing algorithm.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
All Watts Considered
Keynote address, International Symposium on Low Power Electronics and Design, ACM, Portland, OR (2007)
[u'Luiz Andre Barroso']
HardwareandArchitecture
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub32980.html
notfound
=========================
Power Provisioning for a Warehouse-sized Computer
The 34th ACM International Symposium on Computer Architecture (2007)
[u'Xiaobo Fan', u'Wolf-Dietrich Weber', u'Luiz Andr Barroso']
HardwareandArchitecture
Abstract: Large-scale Internet services require a computing infrastructure that can be appropriately described as a warehouse-sized computing system. The cost of building datacenter facilities capable of delivering a given power capacity to such a computer can rival the recurring energy consumption costs themselves. Therefore, there are strong economic incentives to operate facilities as close as possible to maximum capacity, so that the non-recurring facility costs can be best amortized. That is difficult to achieve in practice because of uncertainties in equipment power ratings and because power consumption tends to vary significantly with the actual computing activity. Effective power provisioning strategies are needed to determine how much computing equipment can be safely and efficiently hosted within a given power budget. In this paper we present the aggregate power usage characteristics of large collections of servers (up to 15 thousand) for different classes of applications over a period of approximately six months. Those observations allow us to evaluate opportunities for maximizing the use of the deployed power capacity of datacenters, and assess the risks of over-subscribing it. We find that even in well-tuned applications there is a noticeable gap (7 - 16%) between achieved and theoretical aggregate peak power usage at the cluster level (thousands of servers). The gap grows to almost 40% in whole datacenters. This headroom can be used to deploy additional compute equipment within the same power budget with minimal risk of exceeding it. We use our modeling framework to estimate the potential of power management schemes to reduce peak power and energy usage. We find that the opportunities for power and energy savings are significant, but greater at the cluster-level (thousands of servers) than at the rack-level (tens). Finally we argue that systems need to be power efficient across the activity range, and not only at peak performance levels.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub33387.html
notfound
=========================
The Case for Energy-Proportional Computing
IEEE Computer, vol. 40 (2007)
[u'Luiz Andr Barroso', u'Urs Hlzle']
HardwareandArchitecture
Abstract: In current servers, the lowest energy-efficiency region corresponds to their most common operating mode. Addressing this perfect mismatch will require significant rethinking of components and systems. To that end, we propose that energy proportionality should become a primary design goal. Energy-proportional designs would enable large energy savings in servers, potentially doubling their efficiency in real-life use. Achieving energy proportionality will require significant improvements in the energy usage profile of every system component, particularly the memory and disk subsystems. Although our experience in the server space motivates these observations, we believe that energy-proportional computing also will benefit other types of computing devices.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub32467.html
notfound
=========================
High-efficiency power supplies for home computers and servers
Google (2006), pp. 1-3
[u'Urs Hlzle', u'Bill Weihl']
HardwareandArchitecture
Abstract: The focus of our message is efficiency: power efficiency and programming efficiency. There are several hard technical problems surrounding power efficiency of computers, but we've found one that is actually not particularly challenging and could have a huge impact on the energy used by home computers and low-end servers: increasing power supply efficiency.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
The Price of Performance: An Economic Case for Chip Multiprocessing
ACM Queue, vol. 3 (2005), pp. 48-53
[u'Luiz Andre Barroso']
HardwareandArchitecture
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Model for Battery Lifetime Analysis for Organizing Applications on a Pocket Computer
IEEE Transactions on Very Large Scale Integration Systems, vol. 11 (2003), pp. 1019-1030
[u'Daler N. Rakhmatov', u'Sarma B. K. Vrudhula', u'Deborah A. Wallach']
HardwareandArchitecture
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/Human-ComputerInteractionandVisualization.html
found
http://research.google.com/pubs/pub43933.html
notfound
=========================
"Not some trumped up beef": Assessing Credibility of Online Restaurant Reviews
Human-Computer Interaction INTERACT 2015, Springer
[u'Marina Kobayashi', u'Victoria Schwanda Sosik', u'David Huffaker']
Human-ComputerInteractionandVisualization
Abstract: Online reviews, or electronic word of mouth (eWOM), are an essential source of information for people making decisions about products and services, however they are also susceptible to abuses such as spamming and defamation. Therefore when making decisions, readers must determine if reviews are credible. Yet relatively little research has investigated how people make credibility judgments of online reviews. This paper presents quantitative and qualitative results from a survey of 1,979 respondents, showing that attributes of the reviewer and review content influence credibility ratings. Especially important for judging credibility is the level of detail in the review, whether or not it is balanced in sentiment, and whether the reviewer demonstrates expertise. Our findings contribute to the understanding of how people judge eWOM credibility, and we suggest how eWOM platforms can be designed to coach reviewers to write better reviews and present reviews in a manner that facilitates credibility judgments.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43865.html
notfound
=========================
8 Things to Consider when Designing Interactive TV Experiences
TVX 2015 - ACM International Conference on Interactive Experiences for Television and Online Video
[u'Noor Ali-Hasan', u'Bianca Soto']
Human-ComputerInteractionandVisualization
Abstract: TV viewing is a universal leisure and informational activity but technological advancements have changed the experience drastically in the past decade. Nonetheless, despite all of the technological developments in the TV space, there is still very little guidance for user experience professionals around how best to build and design TV products and interfaces. In this paper, we will present 8 things we have learned to keep in mind when designing interactive TV experiences.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
And Now for Something Completely Different: Improving Crowdsourcing Workflows with Micro-Diversions
CSCW (2015) (to appear)
[u'Peng Dai', u'Jeffrey Rzeszotarski', u'Praveen Paritosh', u'Ed H. Chi']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43975.html
notfound
=========================
Attitudes Toward Vehicle-Based Sensing and Recording
Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing, ACM, pp. 1017-1028
[u'Manya Sleeper', u'Sebastian Schnorf', u'Brian Kemler', u'Sunny Consolvo']
Human-ComputerInteractionandVisualization
Abstract: Vehicles increasingly include features that rely on hi-tech sensors and recording; however, little is known of public attitudes toward such recording. We use two studies, an online survey (n=349) and an interview-based study (n=15), to examine perceptions of vehicle-based sensing and recording. We focus on: 1) how vehicle-based recording and sensing may differ from perceptions of current recording; 2) factors that impact comfort with vehicle-based recording for hypothetical drivers versus bystanders; and 3) perceptions of potential privacy-preserving techniques. We find that vehicle-based recording challenges current mental models of recording awareness. Comfort tends to depend on perceived bene- fits, which can vary by stakeholder type. Perceived privacy in spaces near cars can also impact comfort and reflect mental models of private spaces as well as the range of potentially sensitive activities people perform in and near cars. Privacy-preserving techniques may increase perceived comfort but may require addressing trust and usability issues.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43889.html
found
=========================
Crowdsourcing and the Semantic Web: A Research Manifesto
Human Computation, vol. 2 (2015)
[u'Cristina Sarasua', u'Elena Simperl', u'Natasha Noy', u'Abraham Bernstein', u'Jan Marco Leimeister']
Human-ComputerInteractionandVisualization
Abstract: Our goal with this research manifesto is to define a roadmap to guide the evolution of the new research field that is emerging at the intersection between crowdsourcing and the Semantic Web. We analyze the confluence of these two disciplines by exploring their relationship. First, we focus on how the application of crowdsourcing techniques can enhance the machine-driven execution of Semantic Web tasks. Second, we look at the ways in which machine-processable semantics can benefit the design and management of crowdsourcing projects. As a result, we are able to describe a list of successful or promising scenarios for both perspectives, identify scientific and technological challenges, and compile a set of recommendations to realize these scenarios effectively. This research manifesto is an outcome of the Dagstuhl Seminar 14282: Crowdsourcing and the Semantic Web.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43803.html
notfound
=========================
Designing Surveys for HCI Research
CHI '15 Extended Abstracts on Human Factors in Computing Systems, ACM, New York, NY, USA (2015), pp. 2485-2486
[u'Hendrik Mller', u'Aaron Sedley']
Human-ComputerInteractionandVisualization
Abstract: Online surveys are widely used in human-computer interaction (HCI) to gather feedback and measure satisfaction; at a glance many tools are available and the cost of conducting surveys appears low. However, there is a wide gap between quick-and-dirty surveys, and surveys that are properly planned, constructed, and analyzed. This course examines survey research approaches that meet HCI goals, selecting the appropriate sampling method, questionnaire design best practices, identifying and avoiding common survey biases, and questionnaire evaluation. Attendees will gain an appreciation for the breadth and depth of surveys in HCI, combined with keys to conducting valid, reliable, and impactful survey research themselves.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43272.html
notfound
=========================
Effects of Language Modeling and its Personalization on Touchscreen Typing Performance
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI 2015), ACM, New York, NY, USA, pp. 649-658
[u'Andrew Fowler', u'Kurt Partridge', u'Ciprian Chelba', u'Xiaojun Bi', u'Tom Ouyang', u'Shumin Zhai']
Human-ComputerInteractionandVisualization
Abstract: Modern smartphones correct typing errors and learn userspecific words (such as proper names). Both techniques are useful, yet little has been published about their technical specifics and concrete benefits. One reason is that typing accuracy is difficult to measure empirically on a large scale. We describe a closed-loop, smart touch keyboard (STK) evaluation system that we have implemented to solve this problem. It includes a principled typing simulator for generating human-like noisy touch input, a simple-yet-effective decoder for reconstructing typed words from such spatial data, a large web-scale background language model (LM), and a method for incorporating LM personalization. Using the Enron email corpus as a personalization test set, we show for the first time at this scale that a combined spatial/language model reduces word error rate from a pre-model baseline of 38.4% down to 5.7%, and that LM personalization can improve this further to 4.6%.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Efficient Evaluation of Object-Centric Exploration Queries for Visualization
PVLDB (2015), pp. 1752-1763
[u'You Wu', u'Boulos Harb', u'Jun Yang', u'Cong Yu']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Ein Accessibility (a11y)-Konzept fr Google Calendar Schritt fr Schritt zum Inclusive Design
Mensch und Computer 2015 Usability Professionals, Anja Endmann, Holger Fischer, Malte Krkel, pp. 184-191
[u'Mitch Hatscher', u'Astrid Weber']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Enhancing Android Accessibility for Users with Hand Tremor by Reducing Fine Pointing and Steady Tapping
Web4All, Florence, Italy (2015), pp. 10
[u'Yu Zhong', u'Astrid Weber', u'Casey Burkhardt', u'Phil Weaver', u'Jeffrey P. Bigham']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43421.html
notfound
=========================
Filtering Media Posts
Defensive Publications Series, Technical Disclosure Commons (2015)
[u'Dean Jackson', u'Daniel V. Klein']
Human-ComputerInteractionandVisualization
Abstract: A social media filtering system filters social media posts based on criteria specified by a user. The system receives a request from a user to hide social media posts associated with a specified criteria. The specified criteria can be location criteria, event criteria, person criteria, and/or time criteria. Further, the system identifies a set of social media posts on a social media website. Then, the system determines social media posts from the set of social media posts that meet the specified criteria. The system further modifies the set of social media posts by removing or otherwise hiding the social media posts that meet the specified criteria. The system presents the modified set of social media posts to the user.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43348.html
notfound
=========================
From Dorms to Cubicles: How Recent Graduates Communicate
48th Hawaii International Conference on System Sciences, IEEE (2015), pp. 2013-2022
[u'David Choi', u'Judy Chen', u'Stephanie Wu', u'Debra Lauterbach', u'Aruna Balakrishnan']
Human-ComputerInteractionandVisualization
Abstract: In a two-part field study, we studied the communication tool use of 29 college students and 20 recent college graduates. In comparing the two groups communication choices, we explored how transitioning from attending college to working full time impacts communication. We discuss how communication changes for recent college graduates in terms of both the content of their conversations, as well as the communication methods they use. We found that convenience plays a major role in the adoption and usage of communication tools, with participants preferring methods that were easily accessible at work, at home and in transit. We identify life changes recent graduates experience as they transition into emerging adulthood: the effect of being on a computer at work all day, changing social circles and scenes, being geographically distant from friends and family, and the desire for a professional persona. We discuss the impact of these changes on communication.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44263.html
notfound
=========================
Gesture On: Always-On Touch Gestures for Fast Mobile Access from Device Standby Mode
CHI 2015: ACM Conference on Human Factors in Computing Systems, ACM, pp. 3355-3364
[u'Hao Lu', u'Yang Li']
Human-ComputerInteractionandVisualization
Abstract: Contributes a system that overrides the mobile platform kernel behavior to enable touchscreen gesture shortcuts in standby mode. A user can issue a gesture on the touchscreen before the screen is even turned on.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43453.html
notfound
=========================
Google+ Communities as Plazas and Topic Boards
Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems (CHI '15), ACM, New York, NY (2015), pp. 3779-3788
[u'Michael J. Brzozowski', u'Phil Adams', u'Ed H. Chi']
Human-ComputerInteractionandVisualization
Abstract: Researchers have recently been focusing on understanding online communities in social networks that offer easy access to new audiences. In this work, we conducted a mixed-method study of public Google+ Communities and found two major types evident in both how users talk about them and how they appear to use them: plazas to meet new people, and topic boards to discuss common interests. This reflects two common motivations users cite in describing Communities: "meeting like minded people" and "finding great content". We characterize these two types of Communities within Google+ using mixed methods including surveys, interviews, and quantitative analytics, and expose differences in user behaviors between them.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43127.html
notfound
=========================
GyroPen: Gyroscopes for Pen-input with Mobile Phones
IEEE Transactions on Human-Machine Systems, vol. 45 (2015), pp. 263-271
[u'Thomas Deselaers', u'Daniel Keysers', u'Jan Hosang', u'Henry Rowley']
Human-ComputerInteractionandVisualization
Abstract: We present GyroPen, a method for text entry into mobile devices using pen-like writing interaction reconstructed from standard built-in sensors. The key idea is to reconstruct a representation of the trajectory of the phone's corner that is touching a writing surface from the measurements obtained from the phone's gyroscopes and accelerometers. We propose to directly use the angular trajectory for this reconstruction, which removes the necessity for accurate absolute 3D position estimation, a task that can be difficult using low-cost accelerometers. Recognition is then performed using an off-the-shelf handwriting recognition system, allowing easy extension to new languages and scripts. In a small user study (n=10), the average novice participant was able to write the first word only 37 seconds after the starting to use GyroPen for the first time. With some experience, users were able to write at the speed of 3-4s for one English word and with a character error rate of 18%.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43835.html
notfound
=========================
How Developers Search for Code: A Case Study
Joint Meeting of the European Software Engineering Conference and the Symposium on the Foundations of Software Engineering (ESEC/FSE ), 1600 Amphitheatre Parkway (2015) (to appear)
[u'Caitlin Sadowski', u'Kathryn T. Stolee', u'Sebastian Elbaum']
Human-ComputerInteractionandVisualization
Abstract: With the advent of large code repositories and sophisticated search capabilities, code search is increasingly becoming a key software development activity. In this work we shed some light into how developers search for code through a case study performed at Google, using a combination of survey and log-analysis methodologies. Our study provides insights into what developers are doing and trying to learn when performing a search, search scope, query properties, and what a search session under different contexts usually entails. Our results indicate that programmers search for code very frequently, conducting an average of five search sessions with 12 total queries each workday. The search queries are often targeted at a particular code location and programmers are typically looking for code with which they are somewhat familiar. Further, programmers are generally seeking answers to questions about how to use an API, what code does, why something is failing, or where code is located.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43265.html
notfound
=========================
Improving SSL Warnings: Comprehension and Adherence
Proceedings of the Conference on Human Factors and Computing Systems, ACM (2015)
[u'Adrienne Porter Felt', u'Alex Ainslie', u'Robert W. Reeder', u'Sunny Consolvo', u'Somas Thyagaraja', u'Alan Bettes', u'Helen Harris', u'Jeff Grimes']
Human-ComputerInteractionandVisualization
Abstract: Browsers warn users when the privacy of an SSL/TLS connection might be at risk. An ideal SSL warning would empower users to make informed decisions and, failing that, guide confused users to safety. Unfortunately, users struggle to understand and often disregard real SSL warnings. We report on the task of designing a new SSL warning, with the goal of improving comprehension and adherence. We designed a new SSL warning based on recommendations from warning literature and tested our proposal with microsurveys and a field experiment. We ultimately failed at our goal of a well-understood warning. However, nearly 30% more total users chose to remain safe after seeing our warning. We attribute this success to opinionated design, which promotes safety with visual cues. Subsequently, our proposal was released as the new Google Chrome SSL warning. We raise questions about warning comprehension advice and recommend that other warning designers use opinionated design.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43467.html
notfound
=========================
IsoMatch: Creating Informative Grid Layouts
Computer Graphics Forum (Proceedings of Eurographics), vol. 34(2) (2015) (to appear)
[u'Ohad Fried', u'Stephen DiVerdi', u'Maciej Halber', u'Elena Sizikova', u'Adam Finkelstein']
Human-ComputerInteractionandVisualization
Abstract: Collections of objects such as images are often presented visually in a grid because it is a compact representation that lends itself well for search and exploration. Most grid layouts are sorted using very basic criteria, such as date or filename. In this work we present a method to arrange collections of objects respecting an arbitrary distance measure. Pairwise distances are preserved as much as possible, while still producing the specific target arrangement which may be a 2D grid, the surface of a sphere, a hierarchy, or any other shape. We show that our method can be used for infographics, collection exploration, summarization, data visualization, and even for solving problems such as where to seat family members at a wedding. We present a fast algorithm that can work on large collections and quantitatively evaluate how well distances are preserved.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43967.html
notfound
=========================
Measuring User Rated Language Quality: Development and Validation of the User Interface Language Quality Survey (LQS)
International Journal of Human-Computer Studies, vol. 86 (2015), pp. 1-10
[u'Javier A. Bargas-Avila', u'Florian Bruehlmann']
Human-ComputerInteractionandVisualization
Abstract: Written text plays a special role in user interfaces. Key information in interaction elements and content are mostly conveyed through text. The global context, where software has to run in multiple geographical and cultural regions, requires software developers to translate their interfaces into many different languages. This translation process is prone to errors therefore the question of how language quality can be measured is important. This article presents the development of a questionnaire to measure user interface language quality (LQS). After a first validation of the instrument with 843 participants, a final set of 10 items remained, which was tested again (N=690). The survey showed a high internal consistency (Cronbach's ) of .82, acceptable discriminatory power coefficients (.34 .47), as well as a moderate average homogeneity of .36. The LQS also showed moderate correlation to UMUX, an established usability metric (convergent validity), and it successfully distinguished high and low language quality (discriminative validity). The application to three different products (YouTube, Google Analytics, Google AdWords) revealed similar key statistics, providing evidence that this survey is product-independent. Meanwhile, the survey has been translated and applied to more than 60 languages.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43420.html
notfound
=========================
Modified Alerts for Off Hour Calendar Events
Defensive Publications Series, Technical Disclosure Commons (2015)
[u'Dean Jackson', u'Daniel V. Klein']
Human-ComputerInteractionandVisualization
Abstract: A modified alert triggering system modifies alerts associated with calendar events. The system identifies a users normal calendar hours. Further, the system determines that a calendar event is scheduled outside of users normal calendar hours. Based on determining that the calendar event is scheduled outside of users normal calendar hours, the system modifies an alert for the calendar event. For example, the modified alert can be louder than a normal alert, the modified alert can be a different alert tone than the normal alert tone, etc. The system then triggers the modified alert for the calendar event.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44164.html
notfound
=========================
Next Steps for Value Sensitive Design? A Practitioner's Progress
Human Computer Interaction Consortium, HCIC (2015)
[u'Jill Palzkill Woelfer']
Human-ComputerInteractionandVisualization
Abstract: Over the last 20 years, value sensitive design (VSD) as a framework and approach based in theory has been widely applied, and also contested, in HCI. In this presentation, I draw on 8 years of practice to show how VSD is a suitable and productive methodological framework for research on social change and social impact. My goal is to promote discussion at HCIC of the connection of theory and practice, and how bridging the gap between theory and practice can, in turn, bridge the gap between academic and industry research.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43271.html
notfound
=========================
Optimizing Touchscreen Keyboards for Gesture Typing
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI 2015), ACM, New York, NY, USA, pp. 3365-3374
[u'Brian Smith', u'Xiaojun Bi', u'Shumin Zhai']
Human-ComputerInteractionandVisualization
Abstract: Despite its growing popularity, gesture typing suffers from a major problem not present in touch typing: gesture ambiguity on the Qwerty keyboard. By applying rigorous mathematical optimization methods, this paper systematically investigates the optimization space related to the accuracy, speed, and Qwerty similarity of a gesture typing keyboard. Our investigation shows that optimizing the layout for gesture clarity (a metric measuring how unique word gestures are on a keyboard) drastically improves the accuracy of gesture typing. Moreover, if we also accommodate gesture speed, or both gesture speed and Qwerty similarity, we can still reduce error rates by 52% and 37% over Qwerty, respectively. In addition to investigating the optimization space, this work contributes a set of optimized layouts such as GK-D and GK-T that can immediately benefit mobile device users.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43994.html
notfound
=========================
Perceived Frequency of Advertising Practices
Symposium on Usable Privacy and Security (SOUPS), Privacy Personas and Segmentation Workshop, Usenix (2015)
[u'Sai Teja Peddinti', u'Allen Collins', u'Aaron Sedley', u'Nina Taft', u'Anna Turner', u'Allison Woodruff']
Human-ComputerInteractionandVisualization
Abstract: In this paper, we introduce a new construct for measur- ing individuals privacy-related beliefs and understandings, namely their perception of the frequency with which information about individuals is gathered and used by others for advertising purposes. We introduce a preliminary instrument for measuring this perception, called the Ad Practice Frequency Perception Scale. We report data from a survey using this instrument, as well as the results of an initial clustering of participants based on this data. Our results, while preliminary, suggest that this construct may have future potential to characterize and segment individuals, and is worthy of further exploration.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44167.html
found
=========================
Profile CBC: Using Conjoint Analysis for Consumer Profiles
Proceedings of the 18th Sawtooth Software Conference, Orlando, FL (2015), pp. 1-12
[u'Chris Chapman', u'Kate Krontiris', u'John Webb']
Human-ComputerInteractionandVisualization
Abstract: We investigate the usage of choice-based conjoint analysis (CBC) for sizing consumer profiles for a technology product area. Traditionally, technology research has often relied upon qualitative personas approaches that are difficult to assess quantitatively. We demonstrate that Profile CBC is able to find consumer profiles from tradeoffs of attributes derived from qualitative research, and yields replicable, specifically sized groups that are well differentiated on both intra-method and extra-method variables. We conclude that Profile CBC is a potentially useful addition to analysts' tools for investigating consumer profiles.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44313.html
notfound
=========================
RFC 7646 -Definition and Use of DNSSEC Negative Trust Anchors
IETF RFCs, Internet Engineering Task Force (2015), pp. 15
[u'Warren Kumari', u'Jason Livingood', u'Chris Griffiths']
Human-ComputerInteractionandVisualization
Abstract: DNS Security Extensions (DNSSEC) is now entering widespread deployment. However, domain signing tools and processes are not yet as mature and reliable as those for non-DNSSEC-related domain administration tools and processes. This document defines Negative Trust Anchors (NTAs), which can be used to mitigate DNSSEC validation failures by disabling DNSSEC validation at specified domains.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44007.html
found
=========================
Research skills matter: How to teach them
Moonshots in Education: Launching Blended Learning in the Classroom, Pacific Research Institute, San Francisco, CA (2015)
[u'Daniel Martin Russell']
Human-ComputerInteractionandVisualization
Abstract: Theres always been a gap between those who know how to use information resources and those who dont. Students who knew the ways to leverage a library for research could consistently do better research than those who couldnt. This chapter is about why teaching research skills is a necessary step in the development of students.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Scalable and interpretable data representation for high-dimensional complex data
AAAI Conference on Artificial Intelligence (2015)
[u'Been Kim', u'Kayur Patel', u'Afshin Rostamizadeh', u'Julie Shah']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43828.html
notfound
=========================
SpecTrans: Versatile Material Classification for Interaction with Textureless, Specular and Transparent Surfaces
SIGCHI Conference on Human Factors in Computing Systems, ACM (2015), pp. 2191-2200
[u'Munehiko Sato', u'Shigeo Yoshida', u'Alex Olwal', u'Boxin Shi', u'Atsushi Hiyama', u'Tomohiro Tanikawa', u'Michitaka Hirose', u'Ramesh Raskar']
Human-ComputerInteractionandVisualization
Abstract: Surface and object recognition is of significant importance in ubiquitous and wearable computing. While various techniques exist to infer context from material properties and appearance, they are typically neither designed for real-time applications nor for optically complex surfaces that may be specular, textureless, and even transparent. These materials are, however, becoming increasingly relevant in HCI for transparent displays, interactive surfaces, and ubiquitous computing. We present SpecTrans, a new sensing technology for surface classification of exotic materials, such as glass, transparent plastic, and metal. The proposed technique extracts optical features by employing laser and multi-directional, multispectral LED illumination that leverages the materials optical properties. The sensor hardware is small in size, and the proposed classification method requires significantly lower computational cost than conventional image-based methods, which use texture features or reflectance analysis, thereby providing real-time performance for ubiquitous computing. Our evaluation of the sensing technique for nine different transparent materials, including air, shows a promising recognition rate of 99.0%. We demonstrate a variety of possible applications using SpecTrans capabilities.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44195.html
notfound
=========================
Supporting Privacy-Conscious App Update Decisions with User Reviews
Proceedings of the 5th Annual ACM CCS Workshop on Security and Privacy in Smartphones and Mobile Devices, ACM, New York, NY, USA (2015), pp. 51-61
[u'Yuan Tian', u'Bin Liu', u'Weisi Dai', u'Blase Ur', u'Patrick Tague', u'Lorrie Faith Cranor']
Human-ComputerInteractionandVisualization
Abstract: Smartphone app updates are critical to user security and privacy. New versions may fix important security bugs, which is why users should usually update their apps. However, occasionally apps turn malicious or radically change features in a way users dislike. Users should not necessarily always update in those circumstances, but current update processes are largely automatic. Therefore, it is important to understand user behaviors around updating apps and help them to make security-conscious choices. We conducted two related studies in this area. First, to understand users' current update decisions, we conducted an online survey of user attitudes toward updates. Based on the survey results, we then designed a notification scheme integrating user reviews, which we tested in a field study. Participants installed an Android app that simulated update notifications, enabling us to collect users' update decisions and reactions. We compared the effectiveness of our review-based update notifications with the permission-based notifications. Compared to notifications with permission descriptions only, we found our review-based update notification was more effective at alerting users of invasive or malicious app updates, especially for less trustworthy apps.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43422.html
found
=========================
Temporal/Spatial Calendar Events and Triggers
Defensive Publications Series, Technical Disclosure Commons (2015)
[u'Daniel V. Klein', u'Dean Jackson']
Human-ComputerInteractionandVisualization
Abstract: Spatial and/or temporal triggers may be established so that when actuated, one or more notifications such as reminders may be provided to one or more users. These triggers may be established manually, e.g., by a user operating a user interface, automatically, e.g., by scraping calendar and/or email data to ascertain and/or predict various aspects of upcoming appointments such as start times, duration, date, location, and so forth, or a combination of the two. Spatial triggers may be actuated based on a determination that a user is, or will be, at a particular location. Temporal triggers may be actuated at particular points in time, e.g., at the scheduled time of an event or at some predetermined time interval before or after the event. Using one or more triggers, it is possible to provide notifications to a user at some predetermined time interval prior to a scheduled event, so that the user has sufficient time to make appropriate arrangements, such as buying tickets, making a reservation, scheduling a rendezvous with a friend, and so forth. A calendar system may also be interfaced with to manually or automatically establish triggers.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
The Power of Random Neighbors in Social Networks
WSDM (2015)
[u'Silvio Lattanzi', u'Yaron Singer']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43468.html
found
=========================
The interacting effects of distributed work arrangements and individual dispositions on willingness to engage in sensemaking behaviors
Journal of the Association for Information Science and Technology (2015)
[u'Peter Gray', u'Brian Butler', u'Nikhil Sharma']
Human-ComputerInteractionandVisualization
Abstract: Faced with highly competitive and dynamic environments, organizations are increasingly investing in technologies that provide them with new options for structuring work. At the same time, firms are increasingly dependent on employees' willingness and ability to make sense of novel tasks, problems, and rapidly changing situations. Yet, in spite of its importance, the impact of technology-enabled distributed work arrangements on sensemaking behavior is largely unknown. Sensemaking remains something that is perceived by many to be an idiosyncratic behavior that is, at best, loosely related to sociotechnical context and culture. Drawing on previous studies of cognitive dispositions (need for cognition, tendency for decisiveness, intolerance for ambiguity, and close-mindedness) and research on how technology-enabled distributed work arrangements affect interpersonal interaction, we theorize how workgroup geographic distribution interacts with individual cognitive differences to affect employees' willingness to engage in the core sociocognitive activities of sensemaking. Our results show that the consequences of individual tendencies can vary under different work arrangements, suggesting that managers seeking to facilitate sensemaking activities must make careful choices about the composition of distributed work groups, as well as how collaboration technologies can be used to encourage sensemaking behaviors.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43862.html
notfound
=========================
Thwarting Fake OSN Accounts by Predicting their Victims
AI-Sec'2015, ACM (to appear)
[u'Yazan Boshmaf', u'Matei Ripeanu', u'Konstantin Beznosov', u'Elizeu Santos-Neto']
Human-ComputerInteractionandVisualization
Abstract: Traditional defense mechanisms for fighting against automated fake accounts in online social networks are victim-agnostic. Even though victims of fake accounts play an important role in the viability of subsequent attacks, there is no work on utilizing this insight to improve the status quo. In this position paper, we take the first step and propose to incorporate predictions about victims of unknown fakes into the workflows of existing defense mechanisms. In particular, we investigated how such an integration could lead to more robust fake account defense mechanisms. We also used real world datasets from Facebook and Tuenti to evaluate the feasibility of predicting victims of fake accounts using supervised machine learning.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44180.html
notfound
=========================
Understanding Americas Interested Bystander: A Complicated Relationship with Civic Duty
Google, Mountain View, CA (2015)
[u'Kate Krontiris', u'John Webb', u'Chris Chapman']
Human-ComputerInteractionandVisualization
Abstract: Among those who are interested in improving democracy in the United States, a question that often comes up is how to engage the unengaged. To support the broader ecosystem of individuals and institutions working hard to make our civic life more inclusive and meaningful, we sought to contribute to these efforts by undertaking needed and detailed user research about the attitudes and behaviors of average Americans. In particular, this paper outlines a joint qualitative and quantitative study for understanding Interested Bystanders, or that portion of the population that is paying attention to the world around them, but not regularly voicing their opinions or taking action. These are the findings of this research, conducted by the Google Civic Innovation Team in 2014. As applied research, this work sought to inform the design of civic-related products and services at Google and across the civic technology community more broadly. In reporting what we learned, we also have attempted to share how we learned it, and offer a case study for the use of human-centered research to inform civic interventions.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43846.html
notfound
=========================
Understanding Your Users: A Practical Guide to User Research Methods
Morgan Kaufmann (2015), pp. 1-531
[u'Kathy Baxter', u'Catherine Courage', u'Kelly Caine']
Human-ComputerInteractionandVisualization
Abstract: This new and completely updated edition is a comprehensive, easy-to-read, "how-to" guide on user research methods. You'll learn about many distinct user research methods and also pre- and post-method considerations such as recruiting, facilitating activities or moderating, negotiating with product developments teams/customers, and getting your results incorporated into the product. For each method, you'll understand how to prepare for and conduct the activity, as well as analyze and present the data - all in a practical and hands-on way. Each method presented provides different information about the users and their requirements (e.g., functional requirements, information architecture). The techniques can be used together to form a complete picture of the users' needs or they can be used separately throughout the product development lifecycle to address specific product questions. These techniques have helped product teams understand the value of user experience research by providing insight into how users behave and what they need to be successful. You will find brand new case studies from leaders in industry and academia that demonstrate each method in action. This book has something to offer whether you are new to user experience or a seasoned UX professional. After reading this book, you'll be able to choose the right user research method for your research question and conduct a user research study. Then, you will be able to apply your findings to your own products.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44200.html
notfound
=========================
Understanding and Comparing Smartphone and Tablet Use: Insights from a Large-Scale Diary
Proceedings of the 27th Australian Computer-Human Interaction Conference (OzCHI 2015), ACM, New York, NY, USA, pp. 427-436
[u'Hendrik Mller', u'Jennifer L. Gove', u'John S. Webb', u'Aaron Cheang']
Human-ComputerInteractionandVisualization
Abstract: In recent years, smartphone and tablet ownership has shown continued growth; however, there is a lack of research thoroughly investigating the use of these devices within the general public. This paper describes a large-scale diary study with U.S. mobile device owners, examining details of smartphone and tablet use. Results provide a comprehensive breakdown of frequent activities and contexts of use, highlighting key differences in smartphone and tablet use. Activities on smartphones were found to be dominated by communication needs, while tablets were frequently used for consumption and entertainment. Both devices were most often used at home, with tablets rarely leaving the home. Within the home, smartphones were used mostly in the bedroom, and tablets in the living room. Both devices were used frequently while doing something else, such as using tablets primarily while watching TV. Conclusions discuss implications for enriching the experience of mobile devices and opportunities for future research.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44006.html
notfound
=========================
Understanding user behavior at three scales: The AGoogleADay story
Computer Games and Software Engineering, Taylor & Francis, Taylor & Francis Group, Abingdon, Oxon, UK (2015), pp. 199-214
[u'Daniel Martin Russell']
Human-ComputerInteractionandVisualization
Abstract: How people behave is the central question for data analytics, and a single approach to understanding user behavior is often limiting. The way people play, the ways they interact, the kinds of behaviors they bring to the game, these factors all ultimately drive how our systems perform, and what we can understand about why users do what they do. I suggest that looking at user data at three different scales of time and sampling resolution shows us how looking at behavior data at the micro-, meso-, and macro levels is a superb way to understand what people are doing in our systems, and why. Knowing this lets you not just understand whats going on, but also how to improve the user experience for the next design cycle
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43844.html
notfound
=========================
VIP: Finding Important People in Images
Computer Vision and Pattern Recognition, Computer Vision and Pattern Recognition, Computer Vision and Pattern Recognition (2015), pp. 4858-4966
[u'Clint Solomon Mathialagan', u'Andrew C. Gallagher', u'Dhruv Batra']
Human-ComputerInteractionandVisualization
Abstract: People preserve memories of events such as birthdays, weddings, or vacations by capturing photos, often depicting groups of people. Invariably, some individuals in the image are more important than others given the context of the event. This paper analyzes the concept of the importance of individuals in group photographs. We address two specific questions Given an image, who are the most important individuals in it? Given multiple images of a person, which image depicts the person in the most important role? We introduce a measure of importance of people in images and investigate the correlation between importance and visual saliency. We find that not only can we automatically predict the importance of people from purely visual cues, incorporating this predicted importance results in signifi- cant improvement in applications such as im2text (generating sentences that describe images of groups of people).
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Virtual Door Knock
Defensive Publications Series, Technical Disclosure Commons (2015)
[u'Daniel V. Klein', u'Dean Jackson']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44264.html
notfound
=========================
Weave: Scripting Cross-Device Wearable Interaction
CHI 2015: ACM Conference on Human Factors in Computing Systems, ACM, pp. 3923-3932
[u'Pei-Yu (Peggy) Chi', u'Yang Li']
Human-ComputerInteractionandVisualization
Abstract: Provides a set of high-level APIs, based on JavaScript, and integrated tool support for developers to easily distribute UI output and combine user input and sensing events across devices for cross-device interaction.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43963.html
notfound
=========================
...no one can hack my mind: Comparing Expert and Non-Expert Security Practices
Proceedings of the Eleventh Symposium On Usable Privacy and Security, USENIX (2015), pp. 327-346
[u'Iulia Ion', u'Rob Reeder', u'Sunny Consolvo']
Human-ComputerInteractionandVisualization
Abstract: The state of advice given to people today on how to stay safe online has plenty of room for improvement. Too many things are asked of them, which may be unrealistic, time consuming, or not really worth the effort. To improve the security advice, our community must find out what practices people use and what recommendations, if messaged well, are likely to bring the highest benefit while being realistic to ask of people. In this paper, we present the results of a study which aims to identify which practices people do that they consider most important at protecting their security online. We compare self-reported security practices of non-experts to those of security experts (i.e., participants who reported having five or more years of experience working in computer security). We report on the results of two online surveysone with 231 security experts and one with 294 MTurk participantson what the practices and attitudes of each group are. Our findings show a discrepancy between the security practices that experts and non-experts report taking. For instance, while experts most frequently report installing software updates, using two-factor authentication and using a password manager to stay safe online, non-experts report using antivirus software, visiting only known websites, and changing passwords frequently.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42558.html
notfound
=========================
A Comparison of Six Sample Providers Regarding Online Privacy Benchmarks
SOUPS Workshop on Privacy Personas and Segmentation (2014)
[u'Sebastian Schnorf', u'Aaron Sedley', u'Martin Ortlieb', u'Allison Woodruff']
Human-ComputerInteractionandVisualization
Abstract: Researchers increasingly utilize online tools to gather insights. We show how privacy comfort as measured by questionnaires differs across various survey sample providers. To investigate potential differences depending on provider, we fielded a small set of privacy-related benchmark questions regarding past experience, present and future concerns to six major US survey providers. We found substantial differences depending on privacy benchmark and provider population, illustrating that privacy-related research may yield different insights depending on provider choice.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A case of computational thinking: The subtle effect of hidden dependencies on the user experience of version control
Psychology of Programming Interest Group Annual Conference 2014, pp. 123-128
[u'Luke Church', u'Emma Soederberg', u'Elayabharath Elango']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
An efficient reconciliation algorithm for social networks.
PVLDB (2014), pp. 377-388
[u'Nitish Korula', u'Silvio Lattanzi']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43261.html
notfound
=========================
Applying a Sunburst Visualization to Summarize User Navigation Sequences
IEEE Computer Graphics and Applications, vol. 34 (2014), pp. 36-40
[u'Kerry Rodden']
Human-ComputerInteractionandVisualization
Abstract: For many Web-based applications, it's important to be able to analyze the paths users have taken through a site--for example, to understand how they're discovering engaging content. These paths are difficult to summarize visually because of the underlying data's complexity. A Google researcher applied a sunburst visualization to this problem, after simplifying the data into a hierarchical format. The resulting visualization was successful in YouTube and is widely referenced and accessed. The code for the visualization is available as open source.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Both Complete and Correct? Multi-Objective Optimization of Touchscreen Keyboard
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI 2014), ACM, New York, NY, USA, pp. 2297-2306
[u'Xiaojun Bi', u'Tom Ouyang', u'Shumin Zhai']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43423.html
notfound
=========================
Context Sensitive Paste
Prior Art Database, IP.COM LLC (2014)
[u'Dean Jackson', u'Daniel V. Klein']
Human-ComputerInteractionandVisualization
Abstract: A paste system can be used to generate hypertext based on determining context of a paste command. The paste system receives a selection of certain text in a document. The paste system then receives a paste command from a user of the paste system. The paste command can include data temporarily stored in memory, e.g., stored in a clipboard. The data can be stored as a result of a past copy command from the user. For example, the data can be a URL of a website. The paste system analyzes the data and determines if the data includes a URL. The system does this by, e.g., recognizing if the data includes http and/or www. If the system recognizes the data as URL, then the system generates hypertext from a combination of the selection of the text and the data. The user can then click on the generated hypertext and the hypertext system will automatically direct the user to the website identified by the URL.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42482.html
notfound
=========================
Designing Unbiased Surveys for HCI Research
CHI '14 Extended Abstracts on Human Factors in Computing Systems, ACM, New York, NY, USA (2014), pp. 1027-1028
[u'Hendrik Mller', u'Aaron Sedley', u'Elizabeth Ferrall-Nunge']
Human-ComputerInteractionandVisualization
Abstract: Surveys are a commonly used method within HCI research. While it initially appears easy and inexpensive to conduct surveys, overlooking key considerations in questionnaire design and the survey research process can yield skewed, biased, or entirely invalid survey results. Fortunately decades of academic research and analysis exist on optimizing the validity and reliability of survey data, from which this course will draw. To enable the creation of unbiased surveys, this course demonstrates questionnaire design biases and pitfalls, provides best practices for minimizing these, and reviews different uses of surveys within HCI.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42513.html
notfound
=========================
Designing Usable Web Forms - Empirical Evaluation of Web Form Improvement Guidelines
Proceedings of the 2014 annual conference on Human factors in computing systems (2014), pp. 1275-1284
[u'Mirjam Seckler', u'Silvia Heinz', u'Javier Bargas-Avila', u'Klaus Opwis', u'Alexandre Tuch']
Human-ComputerInteractionandVisualization
Abstract: This study reports a controlled eye tracking experiment (N = 65) that shows the combined effectiveness of 20 guidelines to improve interactive online forms when applied to forms found on real company websites. Results indicate that improved web forms lead to faster completion times, fewer form submission trials, and fewer eye movements. Data from subjective questionnaires and interviews further show increased user satisfaction. Overall, our findings highlight the importance for web designers to improve their web forms using UX guidelines.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42488.html
notfound
=========================
Designing for Healthy Lifestyles: Design Considerations for Mobile Technologies to Encourage Consumer Health and Wellness
Foundations and Trends in Human-Computer Interaction, vol. 6 (2014), 167315
[u'Sunny Consolvo', u'Predrag Klasnja', u'David W. McDonald', u'James A. Landay']
Human-ComputerInteractionandVisualization
Abstract: As the rates of lifestyle diseases such as obesity, diabetes, and heart disease continue to rise, the development of eective tools that can help people adopt and sustain healthier habits is becoming ever more important. Mobile computing holds great promise for providing eective support for helping people manage their health in everyday life. Yet, for this promise to be realized, mobile wellness systems need to be well designed, not only in terms of how they implement specic behavior-change techniques but also, among other factors, in terms of how much burden they put on the user, how well they integrate into the users daily life, and how they address the users privacy concerns. Designing for all of these constraints is dicult, and it is often not clear what tradeos particular design decisions have on how a wellness application is experienced and used. In this monograph, we provide an account of dierent design approaches to common features of mobile wellness applications and we discuss the tradeos inherent in those approaches. We also outline the key challenges that HCI researchers and designers will need to address to move the state of the art for mobile wellness technologies forward.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42549.html
notfound
=========================
Designing the Chromecast Out-of-Box Experience
TVX14, ACM (2014)
[u'Noor Ali-Hasan']
Human-ComputerInteractionandVisualization
Abstract: Chromecast is a small HDMI device that provides users with an easy way to stream online videos and music to the TV. The Chromecast out-of-box experience (OOBE) has been lauded by reviewers and consumers for its simplicity and ease of use. Even though setting up Chromecast is pretty simple, we found that without proper guidance there were several ways that users could fail. This case study will present the different challenges the team faced in designing the Chromecast OOBE and the different options the team explored. We will also describe our user research process and how the user experience team worked with engineers and product managers to implement a simple and easy OOBE.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Detecting Tapping Motion on the Side of Mobile Devices By Probabilistically Combining Hand Postures
UIST 2014: ACM Symposium on User Interface Software and Technology, ACM
[u'William McGrath', u'Yang Li']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43253.html
notfound
=========================
ESM Versus Logs: Filling in the Gaps
American Anthropological Association 2014 Annual Conference
[u'Kathy Baxter']
Human-ComputerInteractionandVisualization
Abstract: In the last few years weve all heard amazing stories of how big data can make uncanny predictions about users (e.g., Target knowing when someone is pregnant based on their purchases). However, there are just as many stories of when analytics gets it wrong (e.g., Google Flu Trends overestimating flu cases in 2013). It shouldnt be at all surprising when predictions based strictly on click analysis (sometimes with demographic data thrown in) gets it wrong because analytics tells us only the WHAT, not the WHY. In the case of Google Flu Trends, the massive media coverage influenced people to search on the keywords that previously indicated one was coming down with the flu but now simply meant people were curious about it. Our logs were missing the WHY behind the keywords. At Google, we conduct an annual Experience Sampling Methodology (ESM) study with a large sample of our users recording their needs, context, and experience to capture the WHY we cannot see in our query stream. Over a five day period, participants tell us about their experiences throughout their day and submit photos to explain things words alone cannot capture. Doing this over a several month period every year allows us to monitor changes in users subjective and objective behavior for a clearer picture than analytics alone.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43463.html
found
=========================
Easy Does It: More Usable CAPTCHAs
CHI '14 Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, ACM, 1600 Amphitheatre Pkwy (2014), pp. 2637-2646
[u'Elie Bursztein', u'Angelika Moscicki', u'Celine Fabry', u'Steven Bethard', u'John C. Mitchell', u'Dan Jurafasky']
Human-ComputerInteractionandVisualization
Abstract: Websites present users with puzzles called CAPTCHAs to curb abuse caused by computer algorithms masquerading as people. While CAPTCHAs are generally effective at stopping abuse, they might impair website usability if they are not properly designed. In this paper we describe how we designed two new CAPTCHA schemes for Google that focus on maximizing usability. We began by running an evaluation on Amazon Mechanical Turk with over 27,000 respondents to test the us- ability of different feature combinations. Then we studied user preferences using Googles consumer survey infrastructure. Finally, drawing on the insights gleaned during those studies, we tested our new captcha schemes first on Mechanical Turk and then on a fraction of production traffic. The resulting scheme is now an integral part of our production system and is served to millions of users. Our scheme achieved a 95.3% human accuracy, a 6.7% improvement.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41927.html
notfound
=========================
Experimenting At Scale With Google Chrome's SSL Warning
ACM CHI Conference on Human Factors in Computing Systems (2014)
[u'Adrienne Porter Felt', u'Robert W. Reeder', u'Hazim Almuhimedi', u'Sunny Consolvo']
Human-ComputerInteractionandVisualization
Abstract: Web browsers shown HTTPS authentication warnings (i.e., SSL warnings) when the integrity and confidentiality of users' interactions with websites are at risk. Our goal in this work is to decrease the number of users who click through the Google Chrome SSL warning. Prior research showed that the Mozilla Firefox SSL warning has a much lower click-through rate (CTR) than Chrome. We investigate several factors that could be responsible: the use of imagery, extra steps before the user can proceed, and style choices. To test these factors, we ran six experimental SSL warnings in Google Chrome 29 and measured 130,754 impressions.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Exploring Video Streaming in Public Settings: Shared Geocaching Over Distance with Mobile Video Chat
Proceedings of the 32nd annual ACM conference on Human factors in computing systems, ACM, New York, NY, USA (2014), pp. 2163-2172
[u'Jason Procyk', u'Carman Neustaedter', u'Carolyn Pang', u'Tejinder K Judge']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Exploring the Benets and Uses of Web Analytics Tools for Non-Transactional Websites
ACM Conference on Designing Interactive Systems: DIS '14 (2014)
[u'Manya Sleeper', u'Jessica Staddon', u'Sunny Consolvo']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Filter & Follow: Do Social Media Encourage Efficient News Curation?
SIGMETRICS 2014
[u'Nitish Korula', u'Augustin Chaintreau', u'Avner May', u'Silvio Lattanzi']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44181.html
notfound
=========================
Findings from Crisis Field Research in Four Countries
International Conference of Crisis Mappers (ICCM), New York, NY (2014)
[u'Chris Chapman']
Human-ComputerInteractionandVisualization
Abstract: Focus on the user and all else will follow - that's Google's #1 "Thing We Know to be True." In this talk, the Google Crisis Response user research team shares the key findings from field research in four countries. We went to Brazil, Indonesia, Mexico, and the Philippines to interview users in their homes about how they respond to crises that range from floods to landslides. We want to share those stories with you at ICCM so we can all focus on the user.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42232.html
notfound
=========================
From Interaction to Performance with Public Displays
Personal and Ubiquitous Computing (2014)
[u'Judy Chen', u'Paul Dourish', u'Gillian R. Hayes', u'Melissa Mazmanian']
Human-ComputerInteractionandVisualization
Abstract: Interacting with public displays involves more than what happens between individuals and the system; it also concerns how people experience others around and through those displays. In this paper, we use performance as an analytical lens for understanding experiences with a public display called rhythIMs and explore how displays shift social interaction through their mediation. By performance, we refer to a situation in which people are on display and orient themselves toward an audience that may be co-located, imagined, or virtual. To understand interaction with public displays, we use two related notions of collectivesaudiences and groupsto highlight the ways in which people orient to each other through public displays. Drawing examples from rhythIMs, a public display that shows patterns of instant messaging and physical presence, we demonstrate that there can be multiple, heterogeneous audiences and show how people experience these different types of collectives in various ways. By taking a performance perspective, we are able to understand how audiences that were not physically co-present with participants still influenced participants interpretations and interactions with rhythIMs. This extension of the traditional notion of audience illuminates the roles audiences can play in a performance.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
GestKeyboard: Enabling Gesture-Based Interaction on Ordinary Physical Keyboard
CHI 2014: ACM Conference on Human Factors in Computing Systems
[u'Haimo Zhang', u'Yang Li']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Gesture Script: Recognizing Gestures and their Structure using Rendering Scripts and Interactively Trained Parts
CHI 2014: ACM Conference on Human Factors in Computing Systems
[u'Hao Lu', u'James Fogarty', u'Yang Li']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Gesturemote: interacting with remote displays through touch gestures
AVI 2014: International Working Conference on Advanced Visual Interfaces
[u'Hao L', u'Matei Negulescu', u'Yang Li']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43221.html
notfound
=========================
HaTS: Large-scale In-product Measurement of User Attitudes & Experiences with Happiness Tracking Surveys
Proceedings of the 26th Australian Computer-Human Interaction Conference (OzCHI 2014), ACM, New York, NY, USA, pp. 308-315
[u'Hendrik Mller', u'Aaron Sedley']
Human-ComputerInteractionandVisualization
Abstract: With the rise of Web-based applications, it is both important and feasible for human-computer interaction practitioners to measure a products user experience. While quantifying user attitudes at a small scale has been heavily studied, in this industry case study, we detail best Happiness Tracking Surveys (HaTS) for collecting attitudinal data at a large scale directly in the product and over time. This method was developed at Google to track attitudes and open-ended feedback over time, and to characterize products user bases. This case study of HaTS goes beyond the design of the questionnaire to also suggest best practices for appropriate sampling, invitation techniques, and its data analysis. HaTS has been deployed successfully across dozens of Googles products to measure progress towards product goals and to inform product decisions; its sensitivity to product changes has been demonstrated widely. We are confident that teams in other organizations will be able to embrace HaTS as well, and, if necessary, adapt it for their unique needs.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43406.html
notfound
=========================
Helping You Protect You
IEEE (2014), pp. 39-42
[u'M. Angela Sasse', u'Charles C. Palmer', u'Markus Jakobsson', u'Sunny Consolvo', u'Rick Wash', u'L. Jean Camp']
Human-ComputerInteractionandVisualization
Abstract: Guest editors M. Angela Sasse and Charles C. Palmer speak with security practitioners (L. Jean Camp, Sunny Consolvo, Markus Jakobsson, and Rick Wash) about what companies are doing to keep customers secure, and what users can do to stay safe.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Hierarchical Route Maps for Efficient Navigation
IUI 2014: International Conference on Intelligent User Interfaces
[u'Noah Wang', u'Yang Li', u'Daisuke Sakamoto', u'Takeo Igarashi']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43217.html
notfound
=========================
How Developers Use Data Race Detection Tools
Evaluation and Usability of Programming Languages and Tools (PLATEAU), ACM (2014)
[u'Caitlin Sadowski', u'Jaeheon Yi']
Human-ComputerInteractionandVisualization
Abstract: Developers need help with multithreaded programming. We investigate how two program analysis tools are used by developers at Google: ThreadSafety, an annotation-based static data race analysis, and TSan, a dynamic data race detector. The data was collected by interviewing seven veteran industry developers at Google, and provides unique insight into how four different teams use tooling in different ways to help with multithreaded programming. The result is a collection of perceived pros and cons of using ThreadSafety and TSan, as well as general issues with multithreading.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
How Technology Supports Family Communication in Rural, Suburban, and Urban Kenya
Proceedings of the 32nd annual ACM conference on Human factors in computing systems, ACM, New York, NY, USA (2014), pp. 2705-2714
[u'Erick Oduor', u'Carman Neustaedter', u'Tejinder K. Judge', u'Kate Hennessy']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
InkAnchor: Enhancing Informal Ink-Based Note Taking on Touchscreen Mobile Phones
CHI 2014: ACM Conference on Human Factors in Computing Systems
[u'Yi Ren', u'Yang Li', u'Edward Lank']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42512.html
notfound
=========================
Is Once Enough? On the Extent and Content of Replications in Human-Computer Interaction
CHI '14 Proceedings of the 2014 annual conference on Human factors in computing systems, ACM, pp. 3523-3532
[u'Kasper Hornbk', u'Sren S. Sander', u'Javier Bargas-Avila', u'Jakob Grue Simonsen']
Human-ComputerInteractionandVisualization
Abstract: A replication is an attempt to confirm an earlier study's findings. It is often claimed that research in Human-Computer Interaction (HCI) contains too few replications. To investigate this claim we examined four publication outlets (891 papers) and found 3% attempting replication of an earlier result. The replications typically confirmed earlier findings, but treated replication as a confirm/not-confirm decision, rarely analyzing effect sizes or comparing in depth to the replicated paper. When asked, most authors agreed that their studies were replications, but rarely planned them as such. Many non-replication studies could have corroborated earlier work if they had analyzed data differently or used minimal effort to collect extra data. We discuss what these results mean to HCI, including how reporting of studies could be improved and how conferences/journals may change author instructions to get more replications.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41924.html
notfound
=========================
JustSpeak: Enabling Universal Voice Control on Android
W4A 2014
[u'Yu Zhong', u'T. V. Raman', u'Casey Burkhardt', u'Fadi Biadsy', u'Jeffrey P. Bigham']
Human-ComputerInteractionandVisualization
Abstract: In this paper we introduce JustSpeak, a universal voice control solution for non-visual access to the Android operating system. JustSpeak offers two contributions as compared to existing systems. First, it enables system wide voice control on Android that can accommodate any application. JustSpeak constructs the set of available voice commands based on application context; these commands are directly synthesized from on-screen labels and accessibility metadata, and require no further intervention from the application developer. Second, it provides more efficient and natural interaction with support of multiple voice commands in the same utterance. We present the system design of JustSpeak and describe its utility in various use cases. We then discuss the system level supports required by a service like JustSpeak on other platforms. By eliminating the target locating and pointing tasks, JustSpeak can significantly improve experience of graphic interface interaction for blind and motion-impaired users.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Mechanism Design for Crowdsourcing Markets with Heterogeneous Tasks
HCOMP (2014)
[u'Gagan Goel', u'Afshin Nikzad', u'Adish Singla']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Mechanism Design for Crowdsourcing: An Optimal 1-1/e Competitive Budget-Feasible Mechanism for Large Markets.
FOCS (2014)
[u'Nima Anari', u'Gagan Goel', u'Afshin Nikzad']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Necessary, Unpleasant, and Disempowering: Reputation Management in the Internet Age
CHI 2014
[u'Allison Woodruff']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
On Social Event Organization
KDD (2014), pp. 1206-1215
[u'Keqian Li', u'Wei Lu', u'Smriti Bhagat', u'Laks V. S. Lakshmanan', u'Cong Yu']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Online Microsurveys for User Experience Research
CHI '14 Extended Abstracts on Human Factors in Computing Systems (2014)
[u'Victoria Schwanda Sosik', u'Elie Bursztein', u'Sunny Consolvo', u'David Huffaker', u'Gueorgi Kossinets', u'Kerwell Liao', u'Paul McDonald', u'Aaron Sedley']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Optimistic Programming of Touch Interaction
TOCHI: ACM Transactions on Computer-Human Interaction (2014)
[u'Yang Li', u'Hao Lu', u'Haimo Zhang']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42485.html
notfound
=========================
Photographing information needs: the role of photos in experience sampling method-style research
CHI '14 Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, ACM, New York, NY, USA (2014), pp. 1545-1554
[u'Zhen Yue', u'Carrie Cai', u'Jeff Stern', u'Eden Litt', u'Kathy Baxter', u'George Zhang', u'Nikhil Sharma']
Human-ComputerInteractionandVisualization
Abstract: The Experience Sampling Method (ESM) enables researchers to capture information about participants' experiences in the moment. Adding an end-of-day retrospective survey also allows participants to elaborate on those experiences. Although the use of photos in retrospective interviews and surveys for memory elicitation is well known, little research has investigated the use of photos in ESM studies. As smartphone adoption increases facilitating ESM studies and making photo sharing easier, researchers need to continuously evaluate the method and investigate the role of photos in such studies. We conducted a large-scale ESM and retrospective survey study via Android smartphones with more than 1,000 US participants, and analyzed participants' photo submissions, including how photo use correlated with participants' data quality and what, if any, value photos added for researchers. Our study sheds light on the role of photos in ESM and retrospective studies that researchers can reference when constructing future study designs.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43153.html
notfound
=========================
Physical Telepresence: Shape Capture and Display for Embodied, Computer-mediated Remote Collaboration
ACM Symposium on User Interface Software and Technology, ACM (2014), pp. 461-470
[u'Daniel Leithinger', u'Sean Follmer', u'Alex Olwal', u'Hiroshi Ishii']
Human-ComputerInteractionandVisualization
Abstract: We propose a new approach to Physical Telepresence, based on shared workspaces with the ability to capture and remotely render the shapes of people and objects. In this paper, we describe the concept of shape transmission, and propose interaction techniques to manipulate remote physical objects and physical renderings of shared digital content. We investigate how the representation of user's body parts can be altered to amplify their capabilities for teleoperation. We also describe the details of building and testing prototype Physical Telepresence workspaces based on shape displays. A preliminary evaluation shows how users are able to manipulate remote objects, and we report on our observations of several different manipulation techniques that highlight the expressive nature of our system.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Reflection: Enabling Event Prediction As an On-Device Service for Mobile Interaction
UIST 2014: ACM Symposium on User Interface Software and Technology
[u'Yang Li']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Shared Geocaching Over Distance with Mobile Video Streaming
roceedings of the SIGCHI Conference on Human Factors in Computing Systems, ACM, New York, NY, USA (2014), pp. 2163-2172
[u'Jason Procyk', u'Carman Neustaedter', u'Carolyn Pang', u'Tejinder K. Judge']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42521.html
found
=========================
Social media in public opinion research
AAPOR, AAPOR (2014), pp. 57
[u'Michael Link', u'Joe Muphy', u'Michael F. Schober', u'Trent D. Buskirk', u'Jennifer Hunter Childs', u'Casey Langer Tesfaye', u'Mario Callegaro', u'Jon Cohen', u'Elizabeth Dean', u'Paul Harwood', u'Josh Pasek', u'Michael Stern']
Human-ComputerInteractionandVisualization
Abstract: AAPOR announces the release of an important report, Social Media in Public Opinion Research, authored by the Emerging Technologies Task Force. As social media platforms such as Facebook, Twitter, and LinkedIn to name a few expand and proliferate, so does access to users thoughts, feelings and actions expressed instantaneously, organically, and often publicly, across these platforms. At question is how researchers and others interested in public opinion derive reliable and valid insights from the data generated by social media users. The report, Social Media in Public Opinion Research, highlights the use of social media as a vehicle for facilitating the survey research process (i.e., questionnaire development, recruitment, locating, etc.) and as a way of potentially supplementing or replacing traditional survey methods (i.e., content analysis of existing data). It offers an initial set of guidelines and considerations for researchers and consumers of social media-based studies, noting the opportunities and challenges in this new area.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42497.html
notfound
=========================
Survey Research in HCI
Ways of Knowing in HCI, Springer, New York, NY, USA (2014), Survey Research in HCI
[u'Hendrik Mller', u'Aaron Sedley', u'Elizabeth Ferrall-Nunge']
Human-ComputerInteractionandVisualization
Abstract: Surveys, now commonplace on the Internet, allow researchers to make inferences about an entire population by gathering information from a small subset of the larger group. Surveys can gather insights about peoples attitudes, perceptions, intents, habits, awarenesses, experiences, and characteristics, at significant moments both in time and over time. Even though they are easy to administer, there is a wide gap between quick-and-dirty surveys and surveys that are properly planned, constructed, and analyzed.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43152.html
notfound
=========================
T(ether): Spatially-Aware Handhelds, Gestures and Proprioception for Multi-User 3D Modeling and Animation
ACM Symposium on Spatial User Interaction, ACM (2014), pp. 90-93
[u'Dvid Lakatos', u'Matthew Blackshaw', u'Alex Olwal', u'Zachary Barryte', u'Ken Perlin', u'Hiroshi Ishii']
Human-ComputerInteractionandVisualization
Abstract: T(ether) is a spatially-aware display system for multi-user, collaborative manipulation and animation of virtual 3D objects. The handheld display acts as a window into virtual reality, providing users with a perspective view of 3D data. T(ether) tracks users' heads, hands, fingers and pinching, in addition to a handheld touch screen, to enable rich interaction with the virtual scene. We introduce gestural interaction techniques that exploit proprioception to adapt the UI based on the hand's position above, behind or on the surface of the display. These spatial interactions use a tangible frame of reference to help users manipulate and animate the model in addition to controlling environment properties. We report on initial user observations from an experiment for 3D modeling, which indicate T(ether)'s potential for embodied viewport control and 3D modeling interactions.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Teaching Motion Gestures via Recognizer Feedback
IUI 2014: International Conference on Intelligent User Interfaces
[u'Ankit Kamal', u'Yang Li', u'Edward Lank']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43260.html
notfound
=========================
The Optical Mouse: Early Biomimetic Embedded Vision
Advnances in Embedded Computer Vision, Springer (2014), pp. 3-22
[u'Richard F. Lyon']
Human-ComputerInteractionandVisualization
Abstract: The 1980 Xerox optical mouse invention, and subsequent product, was a successful deployment of embedded vision, as well as of the MeadConway VLSI design methodology that we developed at Xerox PARC in the late 1970s. The design incorporated an interpretation of visual lateral inhibition, essentially mimicking biology to achieve a wide dynamic range, or light-level-independent operation. Conceived in the context of a research group developing VLSI design methodologies, the optical mouse chip represented an approach to self-timed semi-digital design, with the analog image-sensing nodes connecting directly to otherwise digital logic using a switch-network methodology. Using only a few hundred gates and pass transistors in 5-micron nMOS technology, the optical mouse chip tracked the motion of light dots in its field of view, and reported motion with a pair of 2-bit Gray codes for x and y relative positionjust like the mechanical mice of the time. Besides the chip, the only other electronic components in the mouse were the LED illuminators.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
The Reasons Behind Kenyan Family Communication Patterns
GRAND Conference Research Note (2014)
[u'Erick Oduor', u'Carman Neustaedter', u'Tejinder K. Judge']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43224.html
notfound
=========================
Towards better measurement of attention and satisfaction in mobile search
SIGIR '14 Proceedings of the 37th international ACM SIGIR conference on Research & development in information retrieval (2014), pp. 113-122
[u'Dmitry Lagun', u'Dale Webster', u'Chih-Hung Hsieh', u'Vidhya Navalpakkam']
Human-ComputerInteractionandVisualization
Abstract: Web Search has seen two big changes recently: rapid growth in mobile search traffic, and an increasing trend towards providing answer-like results for relatively simple information needs (e.g., [weather today]). Such results display the answer or relevant information on the search page itself without requiring a user to click. While clicks on organic search results have been used extensively to infer result relevance and search satisfaction, clicks on answer-like results are often rare (or meaningless), making it challenging to evaluate answer quality. Together, these call for better measurement and understanding of search satisfaction on mobile devices. In this paper, we studied whether tracking the browser viewport (visible portion of a web page) on mobile phones could enable accurate measurement of user attention at scale, and provide good measurement of search satisfaction in the absence of clicks. Focusing on answer-like results in web search, we designed a lab study to systematically vary answer presence and relevance (to the user's information need), obtained satisfaction ratings from users, and simultaneously recorded eye gaze and viewport data as users performed search tasks. Using this ground truth, we identified increased scrolling past answer and increased time below answer as clear, measurable signals of user dissatisfaction with answers. While the viewport may contain three to four results at any given time, we found strong correlations between gaze duration and viewport duration on a per result basis, and that the average user attention is focused on the top half of the phone screen, suggesting that we may be able to scalably and reliably identify which specific result the user is looking at, from viewport data alone.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42486.html
found
=========================
Trust, transparency & control in inferred user interest models
CHI '14 Extended Abstracts on Human Factors in Computing Systems, ACM, New York, NY, USA (2014), pp. 2449-2454
[u'Sebastian Schnorf', u'Martin Ortlieb', u'Nikhil Sharma']
Human-ComputerInteractionandVisualization
Abstract: This paper explores the importance of transparency and control to users in the context of inferred user interests. More specifically, we illustrate the association between various levels of control the users have on their inferred interests and users' trust in organizations that provide corresponding content. Our results indicate that users value transparency and control very differently. We segment users in two groups, one who states to not care about their personal interest model and another group that desires some level of control. We found substantial differences in trust impact between segments, depending on actual control option provided.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42901.html
found
=========================
Visualizing Statistical Mix Effects and Simpson's Paradox
Proceedings of IEEE InfoVis 2014, IEEE (to appear)
[u'Zan Armstrong', u'Martin Wattenberg']
Human-ComputerInteractionandVisualization
Abstract: We discuss how mix effects can surprise users of visualizations and potentially lead them to incorrect conclusions. This statistical issue (also known as omitted variable bias or, in extreme cases, as Simpsons paradox) is widespread and can affect any visualization in which the quantity of interest is an aggregated value such as a weighted sum or average. Our first contribution is to document how mix effects can be a serious issue for visualizations, and we analyze how mix effects can cause problems in a variety of popular visualization techniques, from bar charts to treemaps. Our second contribution is a new technique, the comet chart, that is meant to ameliorate some of these issues.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42847.html
notfound
=========================
Would a Privacy Fundamentalist Sell Their DNA for $1000...If Nothing Bad Happened as a Result? The Westin Categories, Behavioral Intentions, and Consequences
Proceedings of the Symposium On Usable Privacy and Security: SOUPS '14, USENIX (2014)
[u'Allison Woodruff', u'Vasyl Pihur', u'Sunny Consolvo', u'Lauren Schmidt', u'Laura Brandimarte', u'Alessandro Acquisti']
Human-ComputerInteractionandVisualization
Abstract: Westin's Privacy Segmentation Index has been widely used to measure privacy attitudes and categorize individuals into three privacy groups: fundamentalists, pragmatists, and unconcerned. Previous research has failed to establish a robust correlation between the Westin categories and actual or intended behaviors. Unexplored however is the connection between the Westin categories and individuals' responses to the consequences of privacy behaviors. We use a survey of 884 Amazon Mechanical Turk participants to investigate the relationship between the Westin Privacy Segmentation Index and attitudes and behavioral intentions for both privacy-sensitive scenarios and privacy-sensitive consequences. Our results indicate a lack of correlation between the Westin categories and consequences. We discuss potential implications of this attitude-consequence gap.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43254.html
notfound
=========================
You too can collect big data! How to combine quant and qual data to create a holistic picture of your users.
EPIC 2014 Proceedings
[u'Anna Avrekh', u'Kathy Baxter', u'Bob Evans']
Human-ComputerInteractionandVisualization
Abstract: Statements like data is the new oil abound. Companies have become obsessed with the ability to track what customers do and predict what they might do next. As we all know, quantitative data gives us the WHAT while qualitative data (e.g., ethnographic research) gives us the WHY. We need both to develop a holistic understanding of our target users. EPIC 2013 offered several papers and a salon focused on Big Data demonstrating a great interest in the topic; however, it was clear that many attendees were unsure how to combine their rich (or thick, as Tricia Wang noted) ethnographic data with large scale quantitative data. There are many ways to collect this type of data and in this workshop, we will offer one, which does not require a computer science degree: ESM via PACO. Experiential Sampling Methodology (ESM) is a type of longitudinal diary study that allows one to understand a persons experience in the moment. Using a free, open-source mobile app called the PACO (Personal Analytics COmpanion), we can conduct large scale ESM studies with users anywhere in the world. These studies can be conducted after ethnographic studies to ascertain how broadly your observations apply to your user population or they can be done in advance to identify insights you want to study in-person, in-depth. By combining these methodologies, you create a more holistic understanding of your users. In this three-hour workshop, we will introduce attendees to ESM, discuss ways we have used this methodology at Google, help attendees create their own ESM study, and discuss data analysis. The goal is for every attendee to leave the session equipped with the knowledge to design and create their own ESM study, analyze the data, and make actionable recommendations. Attendance will be capped at 25 attendees to ensure 1:1 attention and good group discussions.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42546.html
notfound
=========================
Your Reputation Precedes You: History, Reputation, and the Chrome Malware Warning
Proceedings of the Symposium On Usable Privacy and Security: SOUPS '14, USENIX (2014)
[u'Hazim Almuhimedi', u'Adrienne Porter Felt', u'Robert W. Reeder', u'Sunny Consolvo']
Human-ComputerInteractionandVisualization
Abstract: Several web browsers, including Google Chrome and Mozilla Firefox, use malware warnings to stop people from visiting infectious websites. However, users can choose to click through (i.e., ignore) these malware warnings. In Google Chrome, users click through a fifth of malware warnings on average. We investigate factors that may contribute to why people ignore such warnings. First, we examine field data to see how browsing history affects click-through rates. We find that users consistently heed warnings about websites that they have not visited before. However, users respond unpredictably to warnings about websites that they have previously visited. On some days, users ignore more than half of warnings about websites they've visited in the past. Next, we present results of an online, survey-based experiment that we ran to gain more insight into the effects of reputation on warning adherence. Participants said that they trusted high-reputation websites more than the warnings; however, their responses suggest that a notable minority of people could be swayed by providing more information. We provide recommendations for warning designers and pose open questions about the design of malware warnings.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41941.html
notfound
=========================
My religious aunt asked why I was trying to sell her viagra: Experiences with account hijacking
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems: CHI '14, ACM, New York, NY, USA (2014), pp. 2657-2666
[u'Richard Shay', u'Iulia Ion', u'Robert W. Reeder', u'Sunny Consolvo']
Human-ComputerInteractionandVisualization
Abstract: With so much of our lives digital, online, and not entirely under our control, we risk losing access to our communications, reputation, and data. Recent years have brought a rash of high-profile account compromises, but account hijacking is not limited to high-profile accounts. In this paper, we report results of a survey about peoples experiences with and attitudes toward account hijacking. The problem is widespread; 30% of our 294 participants had an email or social networking account accessed by an unauthorized party. Five themes emerged from our results: (1) compromised accounts are often valuable to victims, (2) attackers are mostly unknown, but sometimes known, to victims, (3) users acknowledge some responsibility for keeping their accounts secure, (4) users understanding of important security measures is incomplete, and (5) harm from account hijacking is concrete and emotional. We discuss implications for designing security mechanisms to improve chances for user adoption.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41461.html
notfound
=========================
2nd international workshop on user evaluations for software engineering researchers (USER)
International Conference on Software Engineering (ICSE) (2013)
[u'Andrew Begel', u'Caitlin Sadowski']
Human-ComputerInteractionandVisualization
Abstract: We have met many software engineering researchers who would like to evaluate a tool or system they developed with real users, but do not know how to begin. In this second iteration of the USER workshop, attendees will collaboratively design, develop, and pilot plans for conducting user evaluations of their own tools and/or software engineering research projects. Attendees will gain practical experience with various user evaluation methods through scaffolded group exercises, panel discussions, and mentoring by a panel of user-focused software engineering researchers. Together, we will establish a community of likeminded researchers and developers to help one another improve our research and practice through user evaluation.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A meteoroid on steroids: ranking media items stemming from multiple social networks
WWW (Companion Volume) (2013), pp. 31-34
[u'Thomas Steiner']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40678.html
notfound
=========================
A new approach to the semantics of model diagrams
18th International Workshop on Types for Proofs and Programs (TYPES 2011), LIPICS (2013), pp. 28-40
[u'Johan G. Granstrom']
Human-ComputerInteractionandVisualization
Abstract: Sometimes, a diagram can say more than a thousand lines of code. But, sadly, most of the time, software engineers give up on diagrams after the design phase, and all real work is done in code. The supremacy of code over diagrams would be leveled if diagrams were code. This paper suggests that model and instance diagrams, or, which amounts to the same, class and object diagrams, become first level entities in a suitably expressive programming language, viz., type theory. The proposed semantics of diagrams is compositional and self-describing, i.e., reflexive, or metacircular. Moreover, it is well suited for metamodelling and model driven engineering, as it is possible to prove model transformations correct in type theory. The encoding into type theory has the additional benefit of making diagrams immediately useful, given an implementation of type theory.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40667.html
notfound
=========================
Adolescent search roles
Journal of the American Society for Information Science and Technology, vol. 64(1) (2013), pp. 173-189
[u'Elizabeth Foss', u'Hilary Hutchinson', u'Allison Druin', u'Jason Yip', u'Whitney Ford', u'Evan Golub']
Human-ComputerInteractionandVisualization
Abstract: In this article, we present an in-home observation and in-context research study investigating how 38 adolescents aged 14-17 search on the Internet. We present the search trends adolescents display and develop a framework of search roles that these trends help define. We compare these trends and roles to similar trends and roles found in prior work with children ages 7, 9, and 11. We use these comparisons to make recommendations to adult stakeholders such as researchers, designers, and information literacy educators about the best ways to design search tools for children and adolescents, as well as how to use the framework of searching roles to find better methods of educating youth searchers. Major findings include the seven roles of adolescent searchers, and evidence that adolescents are social in their computer use, have a greater knowledge of sources than younger children, and that adolescents are less frustrated by searching tasks than younger children.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41323.html
notfound
=========================
Alice in Warningland: A Large-Scale Field Study of Browser Security Warning Effectiveness
USENIX Security Symposium, USENIX (2013)
[u'Devdatta Akhawe', u'Adrienne Porter Felt']
Human-ComputerInteractionandVisualization
Abstract: We empirically assess whether browser security warnings are as ineffective as suggested by popular opinion and previous literature. We used Mozilla Firefox and Google Chrome's in-browser telemetry to observe over 25 million warning impressions in situ. During our field study, users continued through a tenth of Mozilla Firefox's malware and phishing warnings, a quarter of Google Chrome's malware and phishing warnings, and a third of Mozilla Firefox's SSL warnings. This demonstrates that security warnings can be effective in practice; security experts and system architects should not dismiss the goal of communicating security information to end users. We also find that user behavior varies across warnings. In contrast to the other warnings, users continued through 70.2% of Google Chrome's SSL warnings. This indicates that the user experience of a warning can have a significant impact on user behavior. Based on our findings, we make recommendations for warning designers and researchers.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41200.html
notfound
=========================
All the news that's fit to read: a study of social annotations for news reading
In Proc. of CHI2013, ACM, pp. 2407-2416
[u'Chinmay Kulkarni', u'Ed H. Chi']
Human-ComputerInteractionandVisualization
Abstract: As news reading becomes more social, how do different types of annotations affect people's selection of news articles? This paper reports on results from two experiments looking at social annotations in two different news reading contexts. The first experiment simulates a logged-out experience with annotations from strangers, a computer agent, and a branded company. Results indicate that, perhaps unsurprisingly, annotations by strangers have no persuasive effects. However, surprisingly, unknown branded companies still had a persuasive effect. The second experiment simulates a logged-in experience with annotations from friends, finding that friend annotations are both persuasive and improve user satisfaction over their article selections. In post-experiment interviews, we found that this increased satisfaction is due partly because of the context that annotations add. That is, friend annotations both help people decide what to read, and provide social context that improves engagement. Interviews also suggest subtle expertise effects. We discuss implications for design of social annotation systems and suggestions for future research.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Arrival and departure in Social Networks
Sixth ACM International Conference on Web Search and Data Mining, WSDM 2013
[u'Shaomei Wu', u'Atish Das Sarma', u'Alex Fabrikant', u'Silvio Lattanzi', u'Andrew Tomkins']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40692.html
notfound
=========================
Authentication at Scale
IEEE Security and Privacy, vol. 11 (2013), pp. 15-22
[u'Eric Grosse', u'Mayank Upadhyay']
Human-ComputerInteractionandVisualization
Abstract: In working to keep cloud computing users' data safe, we observe many threats---malware on the client, attacks on ssl, vulnerabilities in web applications, rogue insiders, espionage---but authentication related issues stand out amongst the biggest. When trying to help hundreds of millions of people from an unbelievable variety of endpoints, attitudes, and skill levels, what can possibly displace plain old passwords? No single thing, nothing overnight, and nothing perfect. A combination of risk-based checks, second-factor options, privacy-enhanced client certificates, and different forms of delegation is starting to find adoption towards making a discernible difference.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41644.html
notfound
=========================
Bayesian Touch - A Statistic Criterion of Target Selection with Finger Touch
Proceedings of UIST 2013 The ACM Symposium on User Interface Software and Technology, ACM, New York, NY, USA, pp. 51-60
[u'Xiaojun Bi', u'Shumin Zhai']
Human-ComputerInteractionandVisualization
Abstract: To improve the accuracy of target selection for finger touch, we conceptualize finger touch input as an uncertain process, and derive a statistical target selection riterion, Bayesian Touch Criterion, from combining the basic Bayes rule of probability with the generalized dual Gaussian distribution hypothesis of finger touch. Bayesian Touch Criterion states that the selected target is the candidate with the shortest Bayesian Touch Distance to the touch point, which is computed from the touch point to target center distance and the size of the target. We give the derivation of the Bayesian touch criterion and its empirical evaluation with two experiments. The results show for 2D circular target selection, Bayesian Touch Criterion is significantly more accurate than the commonly used Visual Boundary Criterion (i.e., a target is selected if and only if the touch point falls within its boundary) and its two variants.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Bridging the Gap Between Industry and Academia
The 14th Annual Meeting of the Society for Personality and Social Psychology, New Orleans, Louisiana (2013)
[u'Joshua Tabak']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
C(ollab) RITE: How to run impactful iterative studies in a fast paced environment
UXPA 2013 (2013)
[u'Helena Roeber', u'Jhilmil Jain']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41878.html
notfound
=========================
Chale, How Much it Cost to Browse? Results from a Mobile Data Price Transparency Trial in Ghana
Proceedings of the Sixth International Conference on Information and Communication Technologies and Development: Full Papers - Volume 1 (ICTD '13), ACM, New York, NY, USA (2013), pp. 13-23
[u'Nithya Sambasivan', u'Paul Lee', u'Greg Hecht', u'Paul M. Aoki', u'Maria-Ines Carrera', u'Jenny Chen', u'David Pablo Cohn', u'Pete Kruskall', u'Everett Wetchler', u'Michael Youssefmir', u'Astrid Twenebowa Larssen']
Human-ComputerInteractionandVisualization
Abstract: Mobile data usage is on the rise globally. In emerging regions, mobile data is particularly expensive and suffers from the lack of price and data usage transparency needed to make informed decisions about Internet use. To measure and address this problem, we designed SmartBrowse, an Internet proxy system that shows mobile data usage information and provides controls to avoid overspending. In this paper, we discuss the results of a 10-week study with SmartBrowse, involving 299 participants in Ghana. Half the users were given SmartBrowse, and the other half was given a regular Internet experience. Our findings suggest that, compared with the control group, using SmartBrowse led to a significant reduction in Internet credit spend and increased online activity among SmartBrowse users, while providing the same or better mobile Internet user experience. Additionally, SmartBrowse users who were prior mobile data non-users increased their webpage views while spending less money than control users. Our discussion contributes to the understanding of how forward-looking ICTD research in the wild can empower mobile data users, in this case, through increased price transparency.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Creating scalable location-based games: lessons from Geocaching
Personal and Ubiquitous Computing, vol. 17 (2013), pp. 335-349
[u'Carman Neustaedter', u'Anthony Tang', u'Tejinder K. Judge']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
CrowdLearner: Rapidly Creating Mobile Recognizers Using Crowdsourcing
UIST'13: Proceedings of the 26th annual ACM symposium on User interface software and technology (2013), pp. 163-172
[u'Shahriyar Amini', u'Yang Li']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41338.html
notfound
=========================
Design of user interfaces for selective editing of digital photos on touchscreen devices
Proceedings SPIE 8667 (Multimedia Content and Mobile Devices), SPIE (2013)
[u'Thomas Binder', u'Meikel Steiding', u'Manuel Wille', u'Nils Kokemohr']
Human-ComputerInteractionandVisualization
Abstract: When editing images it is often desirable to apply a filter with a spatially varying strength. With the usual selection tools like gradient, lasso, brush, or quick selection tools, creating masks containing such spatially varying strength values is time-consuming and cumbersome. We present an interactive filtering approach which allows to process photos selectively without the intermediate step of creating a mask containing strength values. In using this approach, the user only needs to place reference points (called control points) on the image and to adjust the spatial influence and filter strength for each control point. The filter is then applied selectively to the image, with strength values interpolated for each pixel between control points. The interpolation is based on a mixture of distances in space, luminance, and color; it is therefore a low-level operation. Since the main goal of the approach is to make selective image editing intuitive, easy, and playful, emphasis is put on the user interface: We describe the process of developing an existing mouse-driven user interface into a touch-driven one. Many question needed to be answered anew, such as how to present a slider widget on a touchscreen. Several variants are discussed and compared.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Designing for What the World is Watching: Behind the scenes with the UX team at YouTube
Summer in the City, Alexandra Palace, London, UK (2013)
[u'Heather Traher', u'Joshua Tabak']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Differences in search engine evaluations between query owners and non-owners
WSDM 2013, ACM, pp. 103-112
[u'Alexandra Chouldechova', u'David Mease']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41438.html
notfound
=========================
Empirical evaluation of 20 web form optimization guidelines
CHI '13 Proceedings of the 2013 annual conference on Human factors in computing systems, ACM, pp. 1893-1898
[u'Mirjam Seckler', u'Silvia Heinz', u'Klaus Opwis', u'Alexandre N. Tuch', u'Javier A. Bargas-Avila']
Human-ComputerInteractionandVisualization
Abstract: Mostwebsitesuseinteractiveonlineformsasamain contact point to users. Recently, many publications aim at optimizing web forms. In contrast to former research that focused at the evaluation of single guidelines, the present study shows in a controlled lab experiment with n=23 participants the combined effectiveness of 20 guidelines on real company web forms. Results indicate that optimized web forms lead to faster completion times, less form submission trials, fewer eye fixations and higher user satisfaction in comparison to the original forms.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41420.html
notfound
=========================
Exploring and enhancing the user experience for TV
CHI 2013, pp. 3187-3190
[u'Jhilmil Jain', u'Michael Evans', u'Vinoba Vinayagamoorthy']
Human-ComputerInteractionandVisualization
Abstract: This workshop seeks to help increase the volume and quality of HCI research and innovative practice around user interfaces for television. Internet connectivity is driving a rapid increase in the range and scope of interactive experiences on the TV platform and it represents an exciting new opportunity for developing new HCI practice and methodology, as well as innovative forms of user experience.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41645.html
notfound
=========================
FFitts Law: Modeling Finger Touch with Fitts Law
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI 2013), ACM, New York, NY, USA, pp. 1363-1372
[u'Xiaojun Bi', u'Yang Li', u'Shumin Zhai']
Human-ComputerInteractionandVisualization
Abstract: Fitts law has proven to be a strong predictor of pointing performance under a wide range of conditions. However, it has been insufficient in modeling small-target acquisition with finger-touch based input on screens. We propose a dual-distribution hypothesis to interpret the distribution of the endpoints in finger touch input. We hypothesize the movement endpoint distribution as a sum of two independent normal distributions. One distribution reflects the relative precision governed by the speed-accuracy tradeoff rule in the human motor system, and the other captures the absolute precision of finger touch independent of the speed-accuracy tradeoff effect. Based on this hypothesis, we derived the FFitts modelan expansion of Fitts law for finger touch input. We present three experiments in 1D target acquisition, 2D target acquisition and touchscreen keyboard typing tasks respectively. The results showed that FFitts law is more accurate than Fitts law in modeling finger input on touchscreens. At 0.91 or a greater R2 value, FFitts index of difficulty is able to account for significantly more variance than conventional Fitts index of difficulty based on either a nominal target width or an effective target width in all the three experiments.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
From mixed-mode to multiple devices. Web surveys, smartphone surveys and apps.
International Journal of Market Research, vol. 55 (2013), pp. 317-320
[u'Mario Callegaro']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Gesture Studio: Authoring Multi-Touch Interactions through Demonstration and Composition
CHI 2013: ACM Conference on Human Factors in Computing Systems
[u'Hao Lu', u'Yang Li']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Global Design Teams: Best Practices for Maximizing Effectiveness
uxmag.com (2013)
[u'Jhilmil Jain', u'Catherine Courage']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Google+ Ripples: A Native Visualization of Information Flow
Proceedings of the 22nd International World Wide Web Conference (2013) (to appear)
[u'Fernanda Viegas', u'Martin Wattenberg', u'Jack Hebert', u'Geoffrey Borggaard', u'Alison Cichowlas', u'Jonathan Feinberg', u'Jon Orwant', u'Christopher Wren']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
How Visualization Layout Relates to Locus of Control and Other Personality Factors
IEEE Transactions on Visualization and Computer Graphics, vol. 19 (2013)
[u'Caroline Ziemkiewicz', u'Alvitta Ottley', u'R. Jordan Crouser', u'Ashely Rye Yauilla', u'Ashely Rye Yauilla', u'Sara L. Su', u'William Ribarsky', u'Remco Chang']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Inserting Micro-Breaks into Crowdsourcing Workflows
HCOMP 2013
[u'Jeffrey M. Rzeszotarski', u'Ed H. Chi', u'Praveen Paritosh', u'Peng Dai']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41382.html
found
=========================
Instant Foodie: Predicting Expert Ratings From Grassroots
CIKM13, Oct. 27Nov. 1, 2013, San Francisco, CA, USA, ACM
[u'Chenhao Tan', u'Ed H. Chi', u'David Huffaker', u'Gueorgi Kossinets', u'Alex J. Smola']
Human-ComputerInteractionandVisualization
Abstract: Consumer review sites and recommender systems typically rely on a large volume of user-contributed ratings, which makes rating acquisition an essential component in the design of such systems. User ratings are then summarized to provide an aggregate score representing a popular evaluation of an item. An inherent problem in such summarization is potential bias due to raters self-selection and heterogeneity in terms of experiences, tastes and rating scale interpretations. There are two major approaches to collecting ratings, which have different advantages and disadvantages. One is to allow a large number of volunteers to choose and rate items directly (a method employed by e.g. Yelp and Google Places). Alternatively, a panel of raters may be maintained and invited to rate a predened set of items at regular intervals (such as in Zagat Survey). The latter approach arguably results in more consistent reviews and reduced selection bias, however, at the expense of much smaller coverage (fewer rated items). In this paper, we examine the two different approaches to collecting user ratings of restaurants and explore the question of whether it is possible to reconcile them. Specically, we study the problem of inferring the more calibrated Zagat Survey ratings (which we dub expert ratings) from the user-contributed ratings (grassroots) in Google Places. To achieve this, we employ latent factor models and provide a probabilistic treatment of the ordinal ratings. We can predict Zagat Survey ratings accurately from ad hoc user-generated ratings by employing joint optimization. Furthermore, the resulting model show that users become more discerning as they submit more ratings. We also describe an approach towards cross-city recommendations, answering questions such as What is the equivalent of the Per Se restaurant in Chicago?
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Live topic generation from event streams
WWW (Companion Volume) (2013), pp. 285-288
[u'Vuk Milicic', u'Giuseppe Rizzo 0002', u'Jos Luis Redondo Garca', u'Raphal Troncy', u'Thomas Steiner']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
MJ no more: using concurrent wikipedia edit spikes with social network plausibility checks for breaking news detection
WWW (Companion Volume) (2013), pp. 791-794
[u'Thomas Steiner', u'Seth van Hooland', u'Ed Summers']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Making touchscreen keyboards adaptive to keys, hand postures, and individuals: a hierarchical spatial backoff model approach
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI 2013), ACM, New York, NY, pp. 2775-2784
[u'Ying Yin', u'Tom Ouyang', u'Kurt Partridge', u'Shumin Zhai']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Measurement and modeling of eye-mouse behavior
Proceedings of the 22nd International World Wide Web Conference (2013)
[u'Vidhya Navalpakkam', u'LaDawn Jentzsch', u'Rory Sayres', u'Sujith Ravi', u'Amr Ahmed', u'Alex J. Smola']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41221.html
notfound
=========================
Minimizing change aversion for the Google Drive launch
CHI'13 Extended Abstracts on Human Factors in Computing Systems, ACM, New York, NY, USA (2013), pp. 2351-2354
[u'Aaron Sedley', u'Hendrik Mller']
Human-ComputerInteractionandVisualization
Abstract: Change aversion is a natural response, which technology often exacerbates. Evolutionary changes can be subtle and occur over many generations. But Internet users must sometimes deal with sudden, significant product changes to applications they rely on and identify with. Despite the best intentions of designers and product managers, users often experience anxiety and confusion when faced with a new interface or changed functionality. While some change aversion is often inevitable, it can also be managed and minimized with the right steps. This case study describes how our understanding of change aversion helped minimize negative effects for the transition of the Google Docs List to Google Drive, a product for file storage in the cloud. We describe actions that allowed for a launch with no aversion.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41646.html
notfound
=========================
Octopus: Evaluating Touchscreen Keyboard Correction and Recognition Algorithms via Remulation
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI 2013), ACM, New York, NY, USA, pp. 543-552
[u'Xiaojun Bi', u'Shiri Azenkot', u'Kurt Partridge', u'Shumin Zhai']
Human-ComputerInteractionandVisualization
Abstract: The time and labor demanded by a typical laboratory-based keyboard evaluation are limiting resources for algorithmic adjustment and optimization. We propose Remulation, a complementary method for evaluating touchscreen keyboard correction and recognition algorithms. It replicates prior user study data through real-time, on-device simulation. To demonstrate remulation, we have developed Octopus, an evaluation tool that enables keyboard developers to efficiently measure and inspect the impact of algorithmic changes without conducting resource-intensive user studies. It can also be used to evaluate third-party keyboards in a black box fashion, without access to their algorithms or source code. Octopus can evaluate both touch keyboards and word-gesture keyboards. Two empirical examples show that Remulation can efficiently and effectively measure many aspects of touch screen keyboards at both macro and micro levels. Additionally, we contribute two new metrics to measure keyboard accuracy at the word level: the Ratio of Error Reduction (RER) and the Word Score.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40591.html
found
=========================
Online Python Tutor: Embeddable Web-Based Program Visualization for CS Education
Proceedings of the ACM Technical Symposium on Computer Science Education (SIGCSE), ACM (2013) (to appear)
[u'Philip Guo']
Human-ComputerInteractionandVisualization
Abstract: This paper presents Online Python Tutor, a web-based program visualization tool for Python, which is becoming a popular language for teaching introductory CS courses. Using this tool, teachers and students can write Python programs directly in the web browser (without installing any plugins), step forwards and backwards through execution to view the run-time state of data structures, and share their program visualizations on the web. In the past three years, over 200,000 people have used Online Python Tutor to visualize their programs. In addition, instructors in a dozen universities such as UC Berkeley, MIT, the University of Washington, and the University of Waterloo have used it in their CS1 courses. Finally, Online Python Tutor visualizations have been embedded within three web-based digital Python textbook projects, which collectively attract around 16,000 viewers per month and are being used in at least 25 universities. Online Python Tutor is free and open source software, available at pythontutor.com
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Open project: a lightweight framework for remote sharing of mobile applications
UIST '13: Proceedings of the 26th annual ACM symposium on User interface software and technology (2013), pp. 281-290
[u'Matei Negulescu', u'Yang Li']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41148.html
notfound
=========================
Paradata in Web Surveys
Improving Surveys with Paradata: Analytic Uses of Process Information, Wiley, Hoboken, NJ (2013), pp. 263-282
[u'Mario Callegaro']
Human-ComputerInteractionandVisualization
Abstract: An important technical distinction regarding the collection of paradata in web surveys is that they can be collected on the server side and/or the client side. In web surveys, paradata is categorized into device-type paradata and questionnaire navigation paradata. Device-type paradata provide information regarding the kind of device used to complete the survey. Questionnaire navigation paradata describe the entire process of filling out the questionnaire. This chapter provides examples of usage for device-type and questionnaire navigation paradata. Another use of paradata pioneered in the early 2000s by Jeavons is adaptive scripting. Adaptive scripting refers to using paradata in real time to change the survey experience for the respondent. The chapter also discusses two main classes of software to collect paradata such as specific paradata software and paradata collection tools embedded in commercial and non-commercial survey platforms. Ethical and communication issues are important considerations in using web survey paradata.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41199.html
notfound
=========================
Perception and Understanding of Social Annotations in Web Search
In Proc. of WWW2013, International World Wide Web Conferences Steering Committee, pp. 403-412
[u'Jennifer Fernquist', u'Ed H. Chi']
Human-ComputerInteractionandVisualization
Abstract: As web search increasingly becomes reliant on social signals, it is imperative for us to understand the effect of these signals on users' behavior. There are multiple ways in which social signals can be used in search: (a) to surface and rank important social content; (b) to signal to users which results are more trustworthy and important by placing annotations on search results. We focus on the latter problem of understanding how social annotations affect user behavior. In previous work, through eyetracking research we learned that users do not generally seem to fixate on social annotations when they are placed at the bottom of the search result block, with 11% probability of fixation [22]. A second eyetracking study showed that placing the annotation on top of the snippet block might mitigate this issue [22], but this study was conducted using mock-ups and with expert searchers. In this paper, we describe a study conducted with a new eyetracking mix-method using a live traffic search engine with the suggested design changes on real users using the same experimental procedures. The study comprised of 11 subjects with an average of 18 tasks per subject using an eyetrace-assisted retrospective think-aloud protocol. Using a funnel analysis, we found that users are indeed more likely to notice the annotations with a 60% probability of fixation (if the annotation was in view). Moreover, we found no learning effects across search sessions but found significant differences in query types, with subjects having a lower chance of fixating on annotations for queries in the news category. In the interview portion of the study, users reported interesting "wow" moments as well as usefulness in recalling or re-finding content previously shared by oneself or friends. The results not only shed light on how social annotations should be designed in search engines, but also how users make use of social annotations to make decisions about which pages are useful and potentially trustworthy.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43255.html
notfound
=========================
Pirates of the search results page
CHI'13 Proceedings, ACM (2013), pp. 3023-3026
[u'Kathy Baxter', u'Lori Wu Malahy', u'Jeremy Lubin']
Human-ComputerInteractionandVisualization
Abstract: Search malware redirects nearly 100% of infected users' clicks on web search results to unintended websites. Most published research details how web-based malware works and technological interventions to stop it before users ever see it; however, the constant evolution of obfuscation techniques makes it difficult to prevent infection altogether. User interventions in the form of toolbars, dialogs, and user education have seen limited success. Previous research has focused on a prototypical type of malware; a sophisticated program that conceals itself (e.g., surreptitious download onto a host computer) or tries to fool the user by mimicking known, trusted websites (e.g., phishing attacks). The goal of our research is to understand users' experience, understanding of and response to search malware. The present research shows that even when confronted with blatantly unusual search behavior, people are unlikely to attribute blame to malware or to engage in behavior that may remedy the situation.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Project Pokerface: Building a User-Centered Culture at Scale
Extended Abstracts of CHI 2013, ACM, New York, NY
[u'Asif Baki', u'Pat Bowen', u'Brianna Brekke', u'Elizabeth Ferrall-Nunge', u'Gueorgi Kossinets', u'Jens Riegelsberger', u'Nina Weber', u'Marissa Mayer']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41867.html
notfound
=========================
Response to the reviews on Bargas-Avila et al. (2009) Intranet Satisfaction Questionnaire: Development and Validation of a Questionnaire to Measure User Satisfaction with the Intranet
Interacting with Computers (2013), pp. 1-3
[u'Sebastien Orsini', u'Klaus Opwis', u'Javier A. Bargas-Avila']
Human-ComputerInteractionandVisualization
Abstract: This article contains the response to the reviews regarding the development and validation of the Intranet Satisfaction Questionnaire (ISQ), which measures user satisfaction with the Intranet. Where appropriate additional data analysis and interpretation is provided, the data show further evidence for the good validity, reliability and sensitivity of this tool. In addition, we provide a short preview of a follow-up publication and show that the ISQ can differentiate effectively between bad and good Intranets.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41201.html
notfound
=========================
Swipe vs. scroll: web page switching on mobile browsers
In Proc. of CHI2013, ACM, pp. 2171-2174
[u'Andrew Warr', u'Ed H. Chi']
Human-ComputerInteractionandVisualization
Abstract: Tabbed web browsing interfaces enable users to multi-task and easily switch between open web pages. However, tabbed browsing is difficult for mobile web browsers due to the limited screen space and the reduced precision of touch. We present an experiment comparing Safari's pages-based switching interface using horizontal swiping gestures with the stacked cards-based switching interface using vertical scrolling gestures, introduced by Chrome. The results of our experiment show that cards-based switching interface allows for faster switching and is less frustrating, with no significant effect on error rates. We generalize these findings, and provide design implications for mobile information spaces.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41609.html
notfound
=========================
Tablets use in emerging markets: an exploration.
Proceedings of the 15th international conference on Human-computer interaction with mobile devices and services (MobileHCI '13), ACM, New York, USA (2013), pp. 594-599
[u'Laura Garcia-Barrio', u'Lidia Oshlyansky']
Human-ComputerInteractionandVisualization
Abstract: Tablet sales are growing worldwide and changing the landscape of personal computing. This is true across mature markets as well as emerging ones. However, little research has been done on the influence of tablets in the emerging markets. This paper presents insights gained during an exploratory study on the use of tablets in four cities: Sao Paulo, Mexico City, Jakarta and Bangalore. The results uncover similarities and differences in the use of tablets in mature markets versus emerging markets and identify implications for design across markets.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41427.html
notfound
=========================
The Bigger Picture: The Use of Mobile Photos in Shopping
INTERACT 2013, Springer
[u'Maryam Tohidi', u'Andrew Warr']
Human-ComputerInteractionandVisualization
Abstract: Mobile phones are becoming, if not already, an integral part of our lives. They have a wide range of applications, such as communication, gaming and commerce. Shopping in particular is a rapidly growing domain. Today, shoppers use their phones to make more informed shopping decisions by researching products and merchants, save money using price comparison, mobile coupons and daily deal apps, even purchase products directly on a mobile device. While mobile commerce and shopping apps are in the spotlight, one area that has received little attention is the role of the native capabilities of a mobile phone, such as the mobile camera, in the shopping process. This paper demonstrates the key role mobile photos play in the shopping process, documenting use cases, practices and pain points, and informing opportunity areas for mobile shopping applications and services.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
The Map of the Future May Not Be a Map!
The Cartographic Journal, vol. 50 No.2 (2013), pp. 182-186
[u'Ed Parsons']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
The future of personal video communication: moving beyond talking heads to shared experiences
CHI Extended Abstracts (2013), pp. 3247-3250
[u'Erick Oduor', u'Carman Neustaedter', u'Gina Venolia', u'Tejinder K. Judge']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
To crop, or not to crop: compiling online media galleries
WWW (Companion Volume) (2013), pp. 201-202
[u'Thomas Steiner', u'Christopher Chedeau']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43256.html
notfound
=========================
UX management: current and future trends
CHI'13 Extended Abstracts on Human Factors in Computing Systems, ACM (2013), pp. 2413-2418
[u'Janice A. Rohn', u'Kathy Baxter', u'Catherine Courage', u'Janaki Kumar', u'Carola Fellenz Thompson', u'Steve Rogers']
Human-ComputerInteractionandVisualization
Abstract: User Experience (UX) leaders and managers are required to continually adapt to changes in: organizational strategies and re-structuring, resources, technology, economic pressures, and other factors. Simultaneously, more companies are realizing that they need UX expertise to ensure that they are competitive in today's marketplace. This panel is comprised of UX leaders who have created strategies and tactics to succeed both in spite of and with the aid of the past and current trends. The panel will focus on the current trends, what strategies and tactics have and have not worked in addressing these trends, and also discuss which future trends they think will impact UX departments, companies, and the field, and how they are preparing for these future trends. The panel will be of interest to managers, practitioners and those who work closely with these teams, including developers, project managers, market researchers, test managers, and executives.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42459.html
notfound
=========================
What is me online? Insights into how users manage digital identity.
UXPA 2013
[u'Sebastian Schnorf', u'Martin Ortlieb']
Human-ComputerInteractionandVisualization
Abstract: This talk provides comprehensive and up-to-date insights about how users manage identity-related aspects online. We gathered 100+ user stories from 4 countries as well as 1000+ survey responses in the US and UK. We will illustrate how people present themselves in profiles, manage devices, as well as set up and share accounts. Furthermore, we will show how users curate different audiences using social networking sites, if and how users selectively disclose information to others and how users perceive and deal with identity conflation situations. Finally, I will discuss some implications for the development of identity- and privacy-related features.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41653.html
notfound
=========================
Where Am I? A Meta-Analysis of Experiments on the Effects of Progress Indicators for Web Surveys
Social Science Computer Review, vol. 31 (2013), pp. 744 - 762
[u'Ana Villar', u'Mario Callegaro', u'Yongwei Yang']
Human-ComputerInteractionandVisualization
Abstract: The use of progress indicators seems to be standard in many online surveys. Researchers include them in surveys in the hope they will help reduce drop-off rates. However, there is no consensus in the literature regarding their effects. In this meta-analysis, we analyzed 32 randomized experiments comparing drop-off rates of an experimental group who completed an online survey in which a progress indicator was shown to drop-off rates of a control group to whom the progress indicator was not shown. In all the studies, a drop-off was defined as a discontinuance of the survey (at any point) after it has begun, resulting in failure to complete the survey. Three types of progress indicators were analyzed: constant, fast-to-slow, and slow-to-fast. Our results show that, overall, using a constant progress indicator does not significantly help reduce drop-offs and that effectiveness of the progress indicator varies depending on the speed of indicator: Fast-to-slow indicators reduced drop-offs, whereas slow-to-fast indicators increased drop-offs. We also found that among the studies in which a small incentive was promised, showing a constant progress indicator increased the drop-off rate. These findings question the common belief that progress indicators help reduce drop-off rates.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Will Massive Open Online Courses (MOOCs) Change Education?
Proc. CHI Conference 2013, ACM
[u'Daniel M Russell', u'Scott Klemmer', u'Armando Fox', u'Celine Latulipe']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41540.html
notfound
=========================
Write here, write now!: an experimental study of group maintenance in collaborative writing
CHI '13 Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, ACM, New York, NY, USA (2013), pp. 961-970
[u'Jeremy Birnholtz', u'Stephanie Steinhardt', u'Antonella Pavese']
Human-ComputerInteractionandVisualization
Abstract: Writing documents together using collaborative editing tools has become extremely common with the widespread availability of tools such as Google Docs. The design of such tools, rooted in early CSCW research, has historically been focused on providing awareness of the presence and activities of one's collaborators. Evidence from a recent qualitative study, however, suggests that people are also concerned about how their behaviors -- and they themselves -- will be perceived by others; and take steps to mitigate possible negative perceptions. We present an experimental study of dyads composing documents together, focusing in particular on group maintenance, impression management and relationship-focused behavior. Results suggest that communication is positively related to social relations, but only for synchronous writing in a shared space; the reverse can be true in asynchronous commenting and editing
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
2nd Workshop on context-awareness in retrieval and recommendation:(CaRR 2012)
Proceedings of the 2012 ACM international conference on Intelligent User Interfaces, pp. 409-412
[u'E.W. De Luca', u'M. Bhmer', u'A. Said', u'E. Chi']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38083.html
notfound
=========================
A Comparative Evaluation of Finger and Pen Stroke Gestures
ACM CHI 2012 Conference on Human Factors in Computing Systems, ACM, Austin, TX, pp. 1287-1296
[u'Huawei Tu', u'Xiangshi Ren', u'Shumin Zhai']
Human-ComputerInteractionandVisualization
Abstract: This paper reports an empirical investigation in which participants produced a set of stroke gestures with varying degrees of complexity and in different target sizes using both the finger and the pen. The recorded gestures were then analyzed according to multiple measures characterizing many aspects of stroke gestures. Our findings were as follows: (1) Finger drawn gestures were quite different to pen drawn gestures in basic measures including size ratio and average speed. Finger drawn gestures tended to be larger and faster than pen drawn gestures. They also differed in shape geometry as measured by, for example, aperture of closed gestures, corner shape distance and intersecting points deviation; (2) Pen drawn gestures and finger drawn gestures were similar in several measures including articulation time, indicative angle difference, axial symmetry and proportional shape distance; (3) There were interaction effects between gesture implement (finger vs. pen) and target gesture size and gesture complexity. Our findings show that half of the features we tested were performed well enough by the finger. This finding suggests that "finger friendly" systems should exploit these features when designing finger interfaces and avoid using the other features in which the finger does not perform as well as the pen.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37647.html
notfound
=========================
A Room with a View: Understanding Users' Stages in Picking a Hotel Online
Extended Abstracts of CHI 2012, ACM, New York, NY
[u'Jens Riegelsberger', u'Michelle Lee', u'Scott Lederer']
Human-ComputerInteractionandVisualization
Abstract: We describe how we built a model for user decision making during local search tasks, specifically hotels. We differentiate between affective and functional needs and identify the following stages and related information needs: 0: Lay of the land; 1: Generating options; 2: Scanning for attractors and detractors; 3: Due diligence. We contrast this framework with existing consumer decision-making models. We close by describing how this model influenced the development of the recently launched experiment, Google Hotel Finder
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
An examination of how households share and coordinate the completion of errands
Proceedings of the ACM 2012 conference on Computer Supported Cooperative Work, ACM, New York, NY, USA, pp. 729-738
[u'Timothy Sohn', u'Lorikeet Lee', u'Stephanie Zhang', u'David Dearman', u'Khai Truong']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38142.html
notfound
=========================
Are privacy concerns a turn-off? Engagement and privacy in social networks
Symposium on Usable Privacy and Security (SOUPS), ACM (2012) (to appear)
[u'Jessica Staddon', u'David Huffaker', u'Larkin Brown', u'Aaron Sedley']
Human-ComputerInteractionandVisualization
Abstract: We describe the survey results from a representative sample of 1,075 U.S. social network users who use Facebook as their primary network. Our results show a strong association between low engagement and privacy concern. Specifically, users who report concerns around sharing control, comprehension of sharing practices or general Facebook privacy concern, also report consistently less time spent as well as less (self-reported) posting, commenting and Likeing of content. The limited evidence of other significant differences between engaged users and others suggests that privacy-related concerns may be an important gate to engagement. Indeed, privacy concern and network size are the only malleable attributes that we find to have significant association with engagement. We manually categorize the privacy concerns finding that many are nonspecific and not associated with negative personal experiences. Finally, we identify some education and utility issues associated with low social network activity, suggesting avenues for increasing engagement amongst current users.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37826.html
notfound
=========================
Around the Water Cooler: Shared Discussion Topics and Contact Closeness in Social Search
Proceedings of the Sixth International AAAI Conference on Weblogs and Social Media (ICWSM-12), ACM (2012)
[u'Saranga Komanduri', u'Lujun Fang', u'David Huffaker', u'Jessica Staddon']
Human-ComputerInteractionandVisualization
Abstract: Search engines are now augmenting search results with social annotations, i.e., endorsements from users social network contacts. However, there is currently a dearth of published research on the effects of these annotations on user choice. This work investigates two research questions associated with annotations: 1) do some contacts affect user choice more than others, and 2) are annotations relevant across various information needs. We conduct a controlled experiment with 355 participants, using hypothetical searches and annotations, and elicit users choices. We find that domain contacts are preferred to close contacts, and this preference persists across a variety of information needs. Further, these contacts need not be experts and might be identified easily from conversation data.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40417.html
notfound
=========================
Backtracking Events as Indicators of Usability Problems in Creation-Oriented Applications
ACM Transactions on Computer-Human Interaction (TOCHI), vol. 19 Issue 2, July 2012 (2012)
[u'David Akers', u'Robin Jeffries', u'Matthew Simpson', u'Terry Winograd']
Human-ComputerInteractionandVisualization
Abstract: A diversity of user goals and strategies make creation-oriented applications such as word processors or photo-editors difficult to comprehensively test. Evaluating such applications requires testing a large pool of participants to capture the diversity of experience, but traditional usability testing can be prohibitively expensive. To address this problem, this article contributes a new usability evaluation method called backtracking analysis, designed to automate the process of detecting and characterizing usability problems in creation-oriented applications. The key insight is that interaction breakdowns in creation-oriented applications often manifest themselves in backtracking operations that can be automatically logged (e.g., undo and erase operations). Backtracking analysis synchronizes these events to contextual data such as screen capture video, helping the evaluator to characterize specific usability problems. The results from three experiments demonstrate that backtracking events can be effective indicators of usability problems in creation-oriented applications, and can yield a cost-effective alternative to traditional laboratory usability testing.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Big Data Storytelling Through Interactive Maps
IEEE Data Engineering Bulletin, vol. 35 (2012), pp. 46-54
[u'Jayant Madhavan', u'Sreeram Balakrishnan', u'Kathryn Hurley', u'Hector Gonzalez', u'Nitin Gupta', u'Alon Halevy', u'Karen Jacqmin-Adams', u'Heidi Lam', u'Anno Langen', u'Hongrae Lee', u'Rod McChesney', u'Rebecca Shapley', u'Warren Shen']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41647.html
notfound
=========================
Bimanual gesture keyboard
Proceeding of UIST 2012 The ACM Symposium on User Interface Software and Technology, ACM, New York, NY, USA, pp. 137-146
[u'Xiaojun Bi', u'Ciprian Chelba', u'Tom Ouyang', u'Kurt Partridge', u'Shumin Zhai']
Human-ComputerInteractionandVisualization
Abstract: Gesture keyboards represent an increasingly popular way to input text on mobile devices today. However, current gesture keyboards are exclusively unimanual. To take advantage of the capability of modern multi-touch screens, we created a novel bimanual gesture text entry system, extending the gesture keyboard paradigm from one finger to multiple fingers. To address the complexity of recognizing bimanual gesture, we designed and implemented two related interaction methods, finger-release and space-required, both based on a new multi-stroke gesture recognition algorithm. A formal experiment showed that bimanual gesture behaviors were easy to learn. They improved comfort and reduced the physical demand relative to unimanual gestures on tablets. The results indicated that these new gesture keyboards were valuable complements to unimanual gesture and regular typing keyboards.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Bootstrapping Personal Gesture Shortcuts with the Wisdom of the Crowd and Handwriting Recognition
CHI 2012: ACM Conference on Human Factors in Computing Systems, pp. 2895-2904
[u'Tom Ouyang', u'Yang Li']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub39967.html
notfound
=========================
Capturing Indoor Scenes with Smartphones
Proc. UIST, 651 N. 34th St. (2012) (to appear)
[u'Aditya Sankar', u'Steve Seitz']
Human-ComputerInteractionandVisualization
Abstract: In this paper, we present a novel smartphone application designed to easily capture, visualize and reconstruct homes, ofces and other indoor scenes. Our application leverages data from smartphone sensors such as the camera, accelerometer, gyroscope and magnetometer to help model the indoor scene. The output of the system is two-fold; rst, an interactive visual tour of the scene is generated in real time that allows the user to explore each room and transition between connected rooms. Second, with some basic interactive photogrammetric modeling the system generates a 2D oor plan and accompanying 3D model of the scene, under a Manhattan-world assumption. The approach does not require any specialized equipment or training and is able to produce accurate oor plans.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Case study: longitudinal comparative analysis for analyzing user behavior
Proceedings of the 2012 ACM annual conference extended abstracts on Human Factors in Computing Systems Extended Abstracts, ACM, New York, NY, USA, pp. 793-800
[u'Jhilmil Jain', u'Susan Boyce']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Comparing collaboration and individual personas for the design and evaluation of collaboration software
Proceedings of the 2012 ACM annual conference on Human Factors in Computing Systems, ACM, New York, NY, USA, pp. 1997-2000
[u'Tejinder Judge', u'Tara Matthews', u'Steve Whittaker']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42115.html
notfound
=========================
Foundational Issues in Touch-Surface Stroke Gesture Design An Integrative Review
Foundations and Trends in HumanComputer Interaction, NOW (2012), pp. 97-205
[u'Shumin Zhai', u'Per Ola Kristensson', u'Caroline Appert', u'Tue Haste Anderson', u'Xiang Cao']
Human-ComputerInteractionandVisualization
Abstract: The advent of modern touchscreen devices has unleashed many opportunities and calls for innovative use of stroke gestures as a richer interaction medium. A significant body of knowledge on stroke gesture design is scattered throughout the Human-Computer Interaction research literature. Primarily based on the authors' own decade-long gesture user interface (UI) research which launched the word-gesture keyboard paradigm, Foundational Issues in Touch-Surface Stroke Gesture Design - An Integrative Review synthesizes some of the foundational issues of human motor control complexity, visual and auditory feedback, and memory and learning capacity concerning gesture user interfaces. In the second half of the book a set of gesture UI design principles is derived from the research literature. The book also covers system implementation aspects of gesture UI such as gesture recognition algorithms and design toolkits. Foundational Issues in Touch-Surface Stroke Gesture Design - An Integrative Review is an ideal primer for researchers and graduate students embarking on research in gesture interfaces. It is also an excellent reference for designers and developers who want to leverage insights and lessons learned in the academic research community.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41690.html
notfound
=========================
Game Your Campaign
Think Quarterly, Google, Inc. (2012)
[u'Carolyn Wei', u'David Huffaker']
Human-ComputerInteractionandVisualization
Abstract: In this article Carolyn Wei and David Huffaker, Google User Experience researchers, explore how understanding gaming sociability could help marketers communicate with a growing audience in new ways. From heightening personalization with "virtual goods", to avoiding the pitfalls of "noisy" game notifications, today's marketers can create a gaming niche that is both relevant and meaningful to a highly engaged user base.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Gesture Search: Random Access to Smartphone Content
IEEE Computer: Pervasive Computing, vol. 11 (2012), pp. 10-13
[u'Yang Li']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Gesture coder: a tool for programming multi-touch gestures by demonstration
Proceedings of the 2012 ACM annual conference on Human Factors in Computing Systems, ACM, New York, NY, USA, pp. 2875-2884
[u'Hao Lu', u'Yang Li']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Gesture-based interaction: a new dimension for mobile user interfaces
Proceedings of the International Working Conference on Advanced Visual Interfaces, ACM, New York, NY, USA (2012), pp. 6-6
[u'Yang Li']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Google Image Swirl: A Large-Scale Content-Based Image Visualization System
WWW (2012), pp. 539-540
[u'Yushi Jing', u'Henry A. Rowley', u'Jingbin Wang', u'David Tsai', u'Chuck Rosenberg', u'Michele Covell']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
How do designers and user experience professionals actually perceive and use personas?
Proceedings of the 2012 ACM annual conference on Human Factors in Computing Systems, ACM, New York, NY, USA, pp. 1219-1228
[u'Tara Matthews', u'Tejinder Judge', u'Steve Whittaker']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Improving remote collaboration through side-by-side telepresence
Proceedings of the ACM 2012 conference on Computer Supported Cooperative Work Companion, ACM, New York, NY, USA, pp. 265-266
[u'Paul Tanner', u'Varnali Shah']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Interactive Digital Signage
Computer, vol. 45(5) (2012), pp. 21-24
[u'Roy Want', u'Bill Schilit']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Invited SIG: designing for the living room tv experience
Proceedings of the 2012 ACM annual conference extended abstracts on Human Factors in Computing Systems Extended Abstracts, ACM, New York, NY, USA, pp. 1169-1172
[u'Jhilmil Jain', u'Anne Aula']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37725.html
notfound
=========================
It's Our Research: Getting stakeholder buy-in for user experience research projects
Elsevier/Morgan Kaufmann, 225 Wyman St., Waltham, MA 02451 (2012)
[u'Tomer Sharon']
Human-ComputerInteractionandVisualization
Abstract: It's Our Research provides a strategic framework for people who practice UX research who wish to be heard by their stakeholders. It gives you the techniques needed to involve stakeholders throughout the process of planning, execution, analysis, and reporting UX research. Dramatically increase the chances that product managers, engineers, and management agree to do research and act upon its results. *Features a series of video interviews with UX practitioners and researchers *Provides dozens of case studies and visuals from international research practitioners *Provides a toolset that will help you justify your work to stakeholders, deal with office politics, and hone your client skills *Presents tried and tested techniques for working to reach positive, useful, and fruitful outcomes
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38169.html
found
=========================
Look Who I Found: Understanding the Effects of Sharing Curated Friend Groups
Proceedings of ACM Web Science 2012, ACM, pp. 137-146
[u'Lujun Fang', u'Alex Fabrikant', u'Kristen LeFevre']
Human-ComputerInteractionandVisualization
Abstract: Online social networks like Google+, Twitter, and Facebook allow users to build, organize, and manage their social connections for the purposes of information sharing and consumption. Nonetheless, most social network users still report that building and curating contact groups is a time-consuming burden. To help users overcome the burdens of contact discovery and grouping, Google+ recently launched a new feature known as "circle sharing". The feature makes it easy for users to share the benefits of their own contact curation by sharing entire "circles" (contact groups) with others. Recipients of a shared circle can adopt the circle as a whole, merge the circle into one of their own circles, or select specific members of the circle to add. In this paper, we investigate the impact that circle-sharing has had on the growth and structure of the Google+ social network. Using a cluster analysis, we identify two natural categories of shared circles, which represent two qualitatively different use cases: circles comprised primarily of celebrities (celebrity circles), and circles comprised of members of a community (community circles). We observe that exposure to circle-sharing accelerates the rate at which a user adds others to his or her circles. More specifically, we notice that circle-sharing has accelerated the "densification" rate of community circles, and also that it has disproportionately affected users with few connections, allowing them to find new contacts at a faster rate than would be expected based on accepted models of network growth. Finally, we identify features that can be used to predict which of a users circles (s)he is most likely to share, thus demonstrating that it is feasible to suggest to a user which circles to share with friends.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40393.html
notfound
=========================
Managing Global UX Teams
UPA 2012, UPA International 21st Annual Conference
[u'Jhilmil Jain', u'Catherine Courage']
Human-ComputerInteractionandVisualization
Abstract: In this interactive workshop, a group of experts from industry will discuss emerging issues and unique challenges related to managing global user experience teams, and how these differ from other disciplines such as marketing, sales, engineering etc.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Moving beyond talking heads to shared experiences: the future of personal video communication
GROUP (2012), pp. 327-330
[u'Carman Neustaedter', u'Erick Oduor', u'Gina Venolia', u'Tejinder K. Judge']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38134.html
notfound
=========================
Older adults perceptions of usefulness of personal health records
Universal Access in the Information Society (2012)
[u'Margaux M. Price', u'Richard Pak', u'Hendrik Mller', u'Aideen Stronge']
Human-ComputerInteractionandVisualization
Abstract: Electronic personal health records (PHRs) have the potential to both make health information more accessible to patients and function as a decision-support system for patients managing chronic conditions. Age-related changes in cognition may make traditional strategies of integrating and understanding existing (i.e., paper-based) health information more difficult for older adults. The centralized and integrated nature of health information, as well as the long-term tracking capabilities present in many PHRs, may be especially beneficial for older patients management of health. However, older adults tend to be late adopters of technology and may be hesitant to adopt a PHR if the benefits are not made clear (perceived usefulness). Toward the design of a useful PHR, a needs analysis was conducted to determine how people currently manage their health information, what they perceive as useful, and to identify any unmet needs. This paper describes two qualitative studies examining the health information needs of both younger and older adults. The first study used a 2-week diary methodology to examine everyday health questions or concerns, while the second study examined maintenance of health information and perceptions of PHRs through the use of a three-part interview. Users perceptions of the usefulness of PHRs are provided as recommendations for the design of e-health technology, especially those targeted for older adult healthcare consumers. The results suggest that both older and younger adults would deem a PHR useful if it provides memory support in the form of reminders, provides tools to aid in comprehension of ones health concerns, is interactive and provides automatic functions, and is highly accessible to authorized users, yet ones information is kept secure and private.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
On the Non-progressive Spread of Influence through Social Networks
LATIN (2012)
[u'MohammadAmin Fazli', u'Mohammad Ghodsi', u'Jafar Habibi', u'Pooya Jalaly Khalilabad', u'Vahab Mirrokni', u'Sina Sadeghian']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Participatory design of social search experiences
Proceedings of the 2012 ACM annual conference extended abstracts on Human Factors in Computing Systems Extended Abstracts, ACM, New York, NY, USA, pp. 1937-1942
[u'Nick Matterson', u'David Choi']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
People in books: using a FlashCam to become part of an interactive book for connected reading
Proceedings of the ACM 2012 conference on Computer Supported Cooperative Work, ACM, New York, NY, USA, pp. 685-694
[u'Sean Follmer', u'Rafael (Tico) Ballagas', u'Hayes Raffle', u'Mirjana Spasojevic', u'Hiroshi Ishii']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Perspective Probe Case Study by Marianne Berkovich (Google)
Human-Computer Interaction Handbook: Fundamentals, Evolving Technologies, and Emerging Applications, Third Edition (Human Factors and Ergonomics), CRC Press Taylor & Francis Group, New York, USA (2012), pp. 968-970
[u'Marianne Berkovich']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Privacy UX - Was ist datenschutzbezogene User Experience?
Usability Professionals 12, German UPA (2012), pp. 258-262
[u'Mitch Hatscher', u'Sebastian Schnorf', u'Martin Ortlieb', u'Kalle Kormann-Philipson']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Proceedings of the 2012 ACM Annual Conference on Human Factors in Computing Systems
ACM, New York, NY (2012)
[u'Joseph A. Konstan', u'Ed H. Chi', u'Kristina Hk']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Proceedings of the 2012 ACM Annual Conference on Human Factors in Computing Systems (Extended Abstracts).
ACM, New York, NY (2012)
[u'Joseph A. Konstan', u'Ed H. Chi', u'Kristina Hk']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Proceedings of the ACM 4th annual workshop on Evaluation and usability of programming languages and tools (PLATEAU)
Conference on Systems, Programming, and Applications: Software for Humanity (SPLASH) (2012)
[u'Emerson Murphy-Hill', u'Caitlin Sadowski', u'Shane Markstrum']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Productive Interrelationships between Collaborative Groups Ease the Challenges of Dynamic and Multi-Teaming
Computer Supported Cooperative Work, vol. 21 (2012), pp. 371-396
[u'Tara Matthews', u'Steve Whittaker', u'Thomas P. Moran', u'Sandra Y. Helsley', u'Tejinder K. Judge']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40568.html
notfound
=========================
Reading, Laughing, and Connecting with Young Children
Connecting Families, Springer, new york (2012), pp. 161-174
[u'Tico Ballagas', u'Joseph Kaye', u'Hayes Raffle']
Human-ComputerInteractionandVisualization
Abstract: In this chapter, we report on three projects that focus on storybook reading as a way to improve distance communication with very young children. Connected Reading builds on the insight that communication technologies for families with young children need to focus on play rather than conversations, and that having a shared activity can help structure this play. Our prototypes span a range of embodiments, from mobile video conferencing with physical books, to eBooks, and finally to video conferencing enhanced with depth camera technology. Our findings suggest guidelines to improve family communication with young children.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub39958.html
notfound
=========================
Real-Time Human Pose Tracking from Range Data
Proceedings of the European Conference on Computer Vision (ECCV) (2012)
[u'Varun Ganapathi', u'Christian Plagemann', u'Daphne Koller', u'Sebastian Thrun']
Human-ComputerInteractionandVisualization
Abstract: Tracking human pose in real-time is a difficult problem with many interesting applications. Existing solutions suffer from a variety of problems, especially when confronted with unusual human poses. In this paper, we derive an algorithm for tracking human pose in real-time from depth sequences based on MAP inference in a probabilistic temporal model. The key idea is to extend the iterative closest points (ICP) objective by modeling the constraint that the observed subject cannot enter free space, the area of space in front of the true range measurements. Our primary contribution is an extension to the articulated ICP algorithm that can efficiently enforce this constraint. Our experiments show that including this term improves tracking accuracy significantly. The resulting filter runs at 125 frames per second using a single desktop CPU core. We provide extensive experimental results on challenging real-world data, which show that the algorithm outperforms the previous state-of the-art trackers both in computational efficiency and accuracy.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
RepliCHI SIG: from a panel to a new submission venue for replication
Proceedings of the 2012 ACM annual conference extended abstracts on Human Factors in Computing Systems Extended Abstracts, ACM, New York, NY, USA, pp. 1185-1188
[u'Max Wilson', u'Wendy Mackay', u'Ed Chi', u'Michael Bernstein', u'Jeffrey Nichols']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
See it: a scalable location-based game for promoting physical activity
Proceedings of the ACM 2012 conference on Computer Supported Cooperative Work Companion, ACM, New York, NY, USA, pp. 235-238
[u'Carman Neustaedter', u'Tejinder K. Judge']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38116.html
notfound
=========================
Social Annotations in Web Search
Proceedings of the 2012 ACM annual conference on Human Factors in Computing Systems (CHI '12), ACM, New York, NY, pp. 1085-1094
[u'Aditi Muralidharan', u'Zoltan Gyongyi', u'Ed H. Chi']
Human-ComputerInteractionandVisualization
Abstract: We ask how to best present social annotations on search results, and attempt to find an answer through mixed-method eye-tracking and interview experiments. Current practice is anchored on the assumption that faces and names draw attention; the same presentation format is used independently of the social connection strength and the search query topic. The key findings of our experiments indicate room for improvement. First, only certain social contacts are useful sources of information, depending on the search topic. Second, faces lose their well-documented power to draw attention when rendered small as part of a social search result annotation. Third, and perhaps most surprisingly, social annotations go largely unnoticed by users in general due to selective, structured visual parsing behaviors specific to search result pages. We conclude by recommending improvements to the design and content of social annotations to make them more noticeable and useful.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38077.html
notfound
=========================
Social telepresence bakeoff: Skype group video calling, Google+ Hangouts, and Microsoft Avatar Kinect
Proceedings of the ACM 2012 conference on Computer Supported Cooperative Work Companion (CSCW '12), ACM, New York, pp. 37-40
[u'John C. Tang', u'Carolyn Wei', u'Reena Kawal']
Human-ComputerInteractionandVisualization
Abstract: This panel compares across recently released products that enable groups of people to socialize online using rich media (video, avatars). Each tool takes a different approach toward online socializing. The panelists will compare and contrast the design features and rationale of each system, review what has been learned from studying their usage so far, and elicit stories of how people in the audience have been using these tools. This discussion will help us learn how these tools are being used and identify design implications for future work in developing new ways to support socializing.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
StoryFaces: pretend-play with ebooks to support social-emotional storytelling
Proceedings of the 11th International Conference on Interaction Design and Children, ACM, New York, NY, USA (2012), pp. 125-133
[u'Kimiko Ryokai', u'Hayes Raffle', u'Robert Kowalski']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37843.html
notfound
=========================
Talking in Circles: Selective Sharing in Google+
Proceedings of the ACM Conference on Human Factors in Computing Systems (CHI 12), ACM, New York, NY (2012), pp. 1065-1074
[u'Sanjay Kairam', u'Michael J. Brzozowski', u'David Huffaker', u'Ed H. Chi']
Human-ComputerInteractionandVisualization
Abstract: Online social networks have become indispensable tools for information sharing, but existing all-or-nothing models for sharing have made it difficult for users to target information to specific parts of their networks. In this paper, we study Google+, which enables users to selectively share content with specific Circles of people. Through a combination of log analysis with surveys and interviews, we investigate how active users organize and select audiences for shared content. We find that these users frequently engaged in selective sharing, creating circles to manage content across particular life facets, ties of varying strength, and interest-based groups. Motivations to share spanned personal and informational reasons, and users frequently weighed limiting factors (e.g. privacy, relevance, and social norms) against the desire to reach a large audience. Our work identifies implications for the design of selective sharing mechanisms in social networks.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Tap, swipe, or move: attentional demands for distracted smartphone input
Proceedings of the International Working Conference on Advanced Visual Interfaces, ACM, New York, NY, USA (2012), pp. 173-180
[u'Matei Negulescu', u'Jaime Ruiz', u'Yang Li', u'Edward Lank']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Task Analysis
Human-Computer Interaction Handbook: Fundamentals, Evolving Technologies, and Emerging Applications, Third Edition, CRC Press; 3 edition (May 4, 2012) (2012), pp. 955-982
[u'Catherine Courage', u'Jhilmil Jain', u'Janice Redish', u'Dennis Wixon']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40349.html
notfound
=========================
The Shoebox and the Safe: When Once-Personal Information Changes Hands
Proceedings of the 5th International Workshop on Personal Information Management at CSCW 2012
[u'Manas Tungare']
Human-ComputerInteractionandVisualization
Abstract: This paper presents several examples where one users personal information is accessed by another, without the consent of the owner, or without the capability of the owner to consent to such sharing. While intentional sharing of information at home as well as at work has been studied in detail, there is extremely limited understanding about the practices, dimensions and models of unintentional sharing. Laws and policies that were developed with paper and other nondigital archives in mind are being found to be inadequate for addressing the challenges that digital personal information brings. Worse, those laws are being enforced in inconsistent ways, prompting lawsuits. Posthumously shared information brings up questions that have not been addressed before. This paper starts by noting examples of posthumous sharing and sharing without consent, proposes models and dimensions for understanding it, and concludes by proposing research questions that need to be addressed by the wider PIM community.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37738.html
found
=========================
The YouTube Social Network
ICWSM 2012, Sixth International AAAI Conference on Weblogs and Social Media (ICWSM 2012) (to appear)
[u'Mirjam Wattenhofer', u'Roger Wattenhofer', u'Zack Zhu']
Human-ComputerInteractionandVisualization
Abstract: Today, YouTube is the largest user-driven video content provider in the world; it has become a major platform for disseminating multimedia information. A major contribution to its success comes from the user-to-user social experience that differentiates it from traditional content broadcasters. This work examines the social network aspect of YouTube by measuring the fullscale YouTube subscription graph, comment graph, and video content corpus. We nd YouTube to deviate signicantly from network characteristics that mark traditional online social networks, such as homophily, reciprocative linking, and assortativity. However, comparing to reported characteristics of another content-driven online social network, Twitter, YouTube is remarkably similar. Examining the social and content facets of user popularity, we nd a stronger correlation between a users social popularity and his/her most popular content as opposed to typical content popularity. Finally, we demonstrate an application of our measurements for classifying YouTube Partners, who are selected users that share YouTubes advertisement revenue. Results are motivating despite the highly imbalanced nature of the classication proble
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44182.html
found
=========================
The landscape of digital media research: big data, big research, right impact
Digital Media Education Foundation Conference, Las Vegas, NV (2012)
[u'Chris Chapman']
Human-ComputerInteractionandVisualization
Abstract: Invited keynote
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38315.html
notfound
=========================
The role of visual complexity and prototypicality regarding first impression of websites: Working towards understanding aesthetic judgments
International Journal of Human-Computer Studies, vol. 70(11) (2012), pp. 794-811
[u'Alexandre N. Tuch', u'Eva Presslaber', u'Markus Stoecklin', u'Klaus Opwis', u'Javier Bargas-Avila']
Human-ComputerInteractionandVisualization
Abstract: This paper experimentally investigates the role of visual complexity (VC) and pro- totypicality (PT) as design factors of websites, shaping users first impressions by means of two studies. In the first study, 119 screenshots of real websites varying in VC (low vs. medium vs. high) and PT (low vs. high) were rated on perceived aes- thetics. Screenshot presentation time was varied as a between-subject factor (50 ms vs. 500 ms vs. 1000 ms). Results reveal that VC and PT affect participants aesthet- ics ratings within the first 50 ms of exposure. In the second study presentation times were shortened to 17, 33 and 50ms. Results suggest that VC and PT affect aesthetic perception even within 17ms, though the effect of PT is less pronounced than the one of VC. With increasing presentation time the effect of PT becomes as influential as the VC effect. This supports the reasoning of the information-processing stage model of aesthetic processing (Leder et al., 2004), where VC is processed at an earlier stage than PT. Overall, websites with low VC and high PT were perceived as highly appealing.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
The word-gesture keyboard: reimagining keyboard interaction (CACM Research Highlight)
Communications of the ACM, vol. 55, no. 9 (2012), pp. 91-101
[u'Shumin Zhai', u'Per Ola Kristensson']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Theories, methods and case studies of longitudinal HCI research
Proceedings of the 2012 ACM annual conference extended abstracts on Human Factors in Computing Systems Extended Abstracts, ACM, New York, NY, USA, pp. 2727-2730
[u'Evangelos Karapanos', u'Jhilmil Jain', u'Marc Hassenzahl']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub39989.html
notfound
=========================
Time, topic and trawl: stories about how we reach our past
DIS '12 Proceedings of the Designing Interactive Systems Conference, ACM New York, NY, USA (2012), pp. 234-243
[u'Joon-Suk Lee', u'Deborah Tatar', u'Elin Rnby Pedersen']
Human-ComputerInteractionandVisualization
Abstract: Legacy web tools attempt to build on information that uses have when they originally conduct web research. In contrast, we examine the information that they have at the time when they attempt to recreate their past. We interviewed 11 non-expert users twice a week for eight weeks in their own physical and computational environments. We used both Google web histories and the prototype Research Trails system as prompts to probe how the participants viewed their past web experiences and how they reconstructed them. The Research Trails system lets users utilize information about both time and topic to help themselves remember and resume everyday research tasks. Based on these observations, a model of users' perceived past web activities informed the iterative refinement of the Research Trails system. The user may see a past action as belonging to multiple categories at the same time or as in different categories at different time
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Touch behavior with different postures on soft smartphone keyboards
Proceedings of the 14th international conference on Human-computer interaction with mobile devices and services (MobileHCI '12), ACM (2012), pp. 251-260
[u'Shiri Azenkot', u'Shumin Zhai']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Ubiquitous search for smart workspaces
Universal Access in the Information Society, vol. 10 (2012), pp. 11-20
[u'Daniel M. Russell']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38135.html
notfound
=========================
Understanding Tablet Use: A Multi-Method Exploration
Proceedings of the 14th Conference on Human-Computer Interaction with Mobile Devices and Services (Mobile HCI 2012), ACM
[u'Hendrik Mller', u'Jennifer L. Gove', u'John S. Webb']
Human-ComputerInteractionandVisualization
Abstract: Tablet ownership has grown rapidly over the last year. While market research surveys have helped us understand the demographics of tablet ownership and provided early insights into usage, there is little comprehensive research available. This paper describes a multi-method research effort that employed written and video diaries, in-home interviews, and contextual inquiry observations to learn about tablet use across three locations in the US. Our research provides an in-depth picture of frequent tablet activities (e.g., checking emails, playing games, social networking), locations of use (e.g., couch, bed, table), and contextual factors (e.g., watching TV, eating, cooking). It also contributes an understanding of why and how people choose to use tablets. Popular activities for tablet use, such as media consumption, shopping, cooking, and productivity are also explored. The findings from our research provide design implications and opportunities for enriching the tablet experience, and agendas for future research.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Understanding Visualization by Understanding Individual Users
IEEE Computer Graphics and Applications (2012)
[u'Caroline Ziemkiewicz', u'Alvitta Ottley', u'R. Jordan Crouser', u'Krysta Chauncey', u'Sara L. Su', u'Remco Chang']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40416.html
notfound
=========================
Understanding Visualization: A Formal Approach using Category Theory and Semiotics
IEEE Transactions on Visualization and Computer Graphics (2012) (to appear)
[u'Joe Faith', u'Paul Vickers', u'Nick Rossiter']
Human-ComputerInteractionandVisualization
Abstract: This article combines the vocabulary of semiotics and category theory to provide a formal analysis of visualization. It shows how familiar processes of visualization fit the semiotic frameworks of both Saussure and Peirce, and extends these structures using the tools of category theory to provide a general framework for understanding visualization in practice, including: relationships between systems, data collected from those systems, renderings of those data in the form of representations, the reading of those representations to create visualizations, and the use of those visualizations to create knowledge and understanding of the system under inspection. The resulting framework is validated by demonstrating how familiar information visualization concepts (such as literalness, sensitivity, redundancy, ambiguity, generalizability, and chart junk) arise naturally from it and can be defined formally and precisely. This article generalizes previous work on the formal characterization of visualization by, inter alia, Ziemkiewicz and Kosara and allows us to formally distinguish properties of the visualization process that previous work does not.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37827.html
notfound
=========================
Understanding the Meta-Experience of Casual Games
Proceedings of the ACM Conference on Human Factors in Computing Systems (CHI 12). Workshop on Games User Research, ACM (2012)
[u'Carolyn Wei', u'David Huffaker']
Human-ComputerInteractionandVisualization
Abstract: In this position paper, we argue that casual gamers can be segmented by meta-experiences into a typology that could inform game platform design. These meta- experiences include out-of-game immersion, social layering, and game discovery. We discuss the interviews and video diaries that have helped shape the typology.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
User Demographics and Language in an Implicit Social Network
Proceedings of the 2012 Conference on Empirical Methods in Natural Language Processing (EMNLP'12), Jeju, Korea
[u'Katja Filippova']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37673.html
notfound
=========================
Vanity or Privacy? Social Media as a Facilitator of Privacy and Trust
CSCW Workshop: Reconciling Privacy with Social Media (2012)
[u'Jessica Staddon']
Human-ComputerInteractionandVisualization
Abstract: In this position paper, we argue that social media provides valuable support for the perception of ones self and others, and in doing so, supports privacy. In addition we suggest that engagement, which reflects a certain degree of trust, can be facilitated by social information. We support our arguments with results from a recent privacy survey and a study of social annotations in search.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Who knows?: searching for expertise on the social web: technical perspective.
Commun. ACM, vol. 55, 4 (2012), pp. 110-110
[u'Ed H. Chi']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Women in UX leadership in business
Proceedings of the 2012 ACM annual conference extended abstracts on Human Factors in Computing Systems Extended Abstracts, ACM, New York, NY, USA, pp. 1107-1110
[u'Janaki Kumar', u'Dan Rosenberg', u'Catherine Courage', u'Janice Rohn', u'Lisa Kamm', u'Lisa Anderson', u'Christine Holsberry', u'Apala Lahiri Chavan']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Four Group Cross-Over Design for Measuring Irreversible Treatments on Web Search Tasks
Proceedings of Hawaii International Conference on System Sciences (HICSS) (2011), pp. 1-9
[u'Li Ma', u'David Mease', u'Daniel M. Russell']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Apples to oranges?: comparing across studies of open collaboration/peer production
WikiSym '11: Proceedings of the 7th International Symposium on Wikis and Open Collaboration, ACM, New York, NY, USA (2011), pp. 227-228
[u'Judd Antin', u'Ed H. Chi', u'James Howison', u'Sharoda Paul', u'Aaron Shaw', u'Jude Yew']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub39980.html
notfound
=========================
CrowdForge: Crowdsourcing Complex Work
Proceedings of UIST 2011, Santa Barbara, CA
[u'Aniket Kittur', u'Boris Smus', u'Susheel Khamkar', u'Robert Kraut']
Human-ComputerInteractionandVisualization
Abstract: Micro-task markets such as Amazons Mechanical Turk represent a new paradigm for accomplishing work, in which employers can tap into a large population of workers around the globe to accomplish tasks in a fraction of the time and money of more traditional methods. However, such markets have been primarily used for simple, independent tasks, such as labeling an image or judging the relevance of a search result. Here we present a general purpose framework for accomplishing complex and interdependent tasks using micro-task markets. We describe our framework, a web-based prototype, and case studies on article writing, decision making, and science journalism that demonstrate the benefits and limitations of the approach.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37424.html
notfound
=========================
Crowdsourcing Event Detection in YouTube Videos
Detection, Representation, and Exploitation of Events in the Semantic Web (DeRiVE 2011), Bonn, Germany
[u'Thomas Steiner', u'Ruben Verborgh', u'Rik Van de Walle', u'Michael Hausenblas', u'Joaquim Gabarro']
Human-ComputerInteractionandVisualization
Abstract: Considerable efforts have been put into making video content on the Web more accessible, searchable, and navigable by research on both textual and visual analysis of the actual video content and the accompanying metadata. Nevertheless, most of the time, videos are opaque objects in websites. With Web browsers gaining more support for the HTML5 element, videos are becoming first class citizens on the Web. In this paper we show how events can be detected on-the-fly through crowdsourcing (i) textual, (ii) visual, and (iii) behavioral analysis in YouTube videos, at scale. The main contribution of this paper is a generic crowdsourcing framework for automatic and scalable semantic annotations of HTML5 videos. Eventually, we discuss our preliminary results using traditional server-based approaches to video event detection as a baseline.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Crowdsourcing the process of scientific publishing
Google, Inc. (2011)
[u'Atish Das Sarma', u'Luca de Alfaro']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37425.html
notfound
=========================
DC Proposal: Enriching Unstructured Media Content About Events to Enable Semi-Automated Summaries, Compilations, and Improved Search by Leveraging Social Networks
The 10th International Semantic Web Conference (ISWC 2011)
[u'Thomas Steiner']
Human-ComputerInteractionandVisualization
Abstract: Mobile devices like smartphones together with social networks enable people to generate, share, and consume enormous amounts of media content. Common search operations, for example searching for a music clip based on artist name and song title on video platforms such as YouTube, can be achieved both based on potentially shallow human-generated metadata, or based on more profound content analysis, driven by Optical Character Recognition (OCR) or Automatic Speech Recognition (ASR). However, more advanced use cases, such as summaries or compilations of several pieces of media content covering a certain event, are hard, if not impossible to fulfill at large scale. One example of such event can be a keynote speech held at a conference, where, given a stable network connection, media content is published on social networks while the event is still going on. In our thesis, we develop a framework for media content processing, leveraging social networks, utilizing the Web of Data and fine-grained media content addressing schemes like Media Fragments URIs to provide a scalable and sophisticated solution to realize the above use cases: media content summaries and compilations. We evaluate our approach on the entity level against social media platform APIs in conjunction with Linked (Open) Data sources, comparing the current manual approaches against our semi-automated approach. Our proposed framework can be used as an extension for existing video platforms.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Deep Shot: A Framework for Migrating Tasks Across Devices Using Mobile Phone Cameras
CHI 2011: ACM Conference on Human Factors in Computing Systems, pp. 2163-2172
[u'Sean Chang', u'Yang Li']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Design and Implementation of FAITH, an Experimental System to Intercept and Manipulate Online Social Informatics
International Conference on Advances in Social Networks Analysis and Mining, IEEE (2011), pp. 195-202
[u'Ruaylong Lee', u'Roozbeh Nia', u'Jason Hsu', u'Karl N. Levitt', u'Jeff Rowe', u'S. Felix Wu', u'Shaozhi Ye']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37660.html
notfound
=========================
Designing for user experience: academia & industry
CHI 2011, ACM, pp. 219-222
[u"Joseph 'Jofish' Kaye", u'Elizabeth Bule', u'Jettie Hoonhout', u'Kristina Hk', u'Virpi Roto', u'Scott Jenson', u'Peter Wright']
Human-ComputerInteractionandVisualization
Abstract: As the importance of user experience (UX) has grown, so too have attempts to define, delimit, categorize and theorize about it. In particular, there have been emerging lines of tension in User Experience that parallel the tensions in the larger field of HCI research, particularly between approaches that emphasize the need for representations and understandings of user experience that are precise, comparable, and generalizable, and third-wave approaches that emphasize the richness of situated actions, the inseparability of mind and body, and the contextual dependency of experiences. At the same time, there are tensions between the needs of industry for immediately useful and applicable techniques and methods, and academics' emphasis on verifiable, repeatable, and theoretically grounded work. In this panel, we bring together a number of these threads to discuss the necessity of designing for user experience. How can we connect the different threads of UX work, without erasing the differences between them? Is there any value in theory of UX, and if so, to whom? What actually works in designing for a user experience?
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
DoubleFlip: A Motion Gesture Delimiter for Mobile Interaction
CHI 2011: ACM Conference on Human Factors in Computing Systems, pp. 2717-2720
[u'Jaime Ruiz', u'Yang Li']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Electric Agents: Combining Television and Mobiles for an Educational Game.
ACM International Conference on Interaction Design and Children (IDC) 2011, ACM, 1600 Amphitheater Parkway
[u'Rafael Ballagas', u'Glenda Revelle', u'Hiroshi Horii', u'Koichi Mori', u'Hayes Raffle']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Estimating the size of online social networks
International Journal of Social Computing and Cyber-Physical Systems, vol. 1 (2011), pp. 160 - 179
[u'Shaozhi Ye', u'S. Felix Wu']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Experimental Analysis of Touch-Screen Gesture Designs in Mobile Environments
CHI 2011: ACM Conference on Human Factors in Computing Systems, pp. 403-412
[u'Andrew Bragdon', u'Eugene Nelson', u'Yang Li', u'Ken Hinckley']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37064.html
notfound
=========================
From Basecamp to Summit: Scaling Field Research Across 9 Locations
CHI 2011 Extended Abstracts, ACM, New York, NY
[u'Jens Riegelsberger', u'Audrey Yang', u'Konstantin Samoylov', u'Elizabeth Nunge', u'Molly Stevens', u'Patrick Larvie']
Human-ComputerInteractionandVisualization
Abstract: In this case study we discuss the mechanics of running a complex field research project within one week: 32 field visits, 4 countries, 9 locations, 10+ researchers, 30+ observers. We outline the goals that lead to this project plan, and the tools and processes we developed to succeed under the constraints given. We discuss in particular (1) the role of ongoing in-field analysis and data sharing, (2) the role of basecamp as a centralized mission control center and real-time analysis hub, and (3) the added value of running the study and initial analysis in such a compressed time frame. We close with a reflection on the strengths and weaknesses of this approach, as well as ideas for future improvements.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Gesture Avatar: A Technique for Operating Mobile User Interfaces Using Gestures
CHI 2011: ACM Conference on Human Factors in Computing Systems, pp. 207-216
[u'Hao L', u'Yang Li']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Globicomp - doing ubicomp differently: introduction to the special issue.
Personal and Ubiquitous Computing, vol. 15 (2011), pp. 551-552
[u'Gary Marsden', u'Lucia Terrenghi', u'Matt Jones']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37487.html
notfound
=========================
How Locus of Control Influences Compatibility with Visualization Style
Proceedings of IEEE Conference on Visual Analytics Science and Technology (VAST) (2011)
[u'Caroline Ziemkiewicz', u'R. Jordan Crouser', u'Sara L. Su', u'Ashley Rye Yauilla', u'William Ribarsky', u'Remco Chang']
Human-ComputerInteractionandVisualization
Abstract: Existing research suggests that individual personality differences are correlated with a users speed and accuracy in solving problems with different types of complex visualization systems. In this paper, we extend this research by isolating factors in personality traits as well as in the visualizations that could have contributed to the observed correlation. We focus on a personality trait known as locus of control, which represents a persons tendency to see themselves as controlled by or in control of external events. To isolate variables of the visualization design, we control extraneous factors such as color, interaction, and labeling, and specically focus on the overall layout style of the visualizations. We conduct a user study with four visualizations that gradually shift from an indentation metaphor to a containment metaphor and compare the participants speed, accuracy, and preference with their locus of control. Our ndings demonstrate that there is indeed a correlation between the two: participants with an internal locus of control perform more poorly with visualizations that employ a containment metaphor, while those with an external locus of control perform well with such visualizations. We discuss a possible explanation for this relationship based in cognitive psychology and propose that these results can be used to better understand how people use visualizations and how to adapt visual analytics design to an individual users needs.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41193.html
notfound
=========================
How the Order of Response Options in a Running Tally Can Affect Online Survey Estimates
Papers Presented at the 64th Annual Conference of the American Association for Public Opinion Research (AAPOR), AMSTAT (2011), pp. 5582-5585
[u'Tom Wells', u'Mario Callegaro', u'Charles DiSogra']
Human-ComputerInteractionandVisualization
Abstract: In the design of online surveys, running tallies or constant sums are used to help respondents sum up the allocation of amounts so that the total sums to 100%. We hypothesized that for time allocation, the order of the presentation of the time categories could make a difference in the distribution of reported time spent. We expected primacy effects, with the first-presented time category having a higher allocation of time than the later-presented options. An experiment was conducted with a general population adult sample from KnowledgePanel. In the experiment, respondents were asked to provide running tallies of the percentage of television they typically watch during the morning, afternoon, and evening (separately for weekdays and weekends). The order of the categories was rotated. Primacy effects were detected, however differences by position were small and not statistically significant. Because time spent watching TV is a regular activity, viewing patterns are more likely to be encoded or ingrained in memory, and more likely to be reported reliably, with responses less susceptible to order effects.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42216.html
notfound
=========================
IVR and web administration in structured interviews utilizing rating scales: Exploring the role of motivation as a moderator to mode effects
International Journal of Social Research Methodology, vol. 14 (2011), pp. 1-15
[u'Yongwei Yang', u'Mario Callegaro', u'Dennison S. Bhola', u'Don A. Dillman']
Human-ComputerInteractionandVisualization
Abstract: Survey researchers have reported differing results on frequency distributions when the same item is delivered via an interactive voice response (IVR) system versus the web. The current paper expands such research into the organizational research field and evaluated the hypothesis that respondent motivation affects the occurrence of mode differences. In this study, personnel selection instruments using fivepoint Likert scales were administered to job applicants and job incumbents. Data were collected via IVR or via the web. With job incumbents, the mode effect observed was similar in magnitude to that observed in the survey research literature. However, with job applicants the mode effect was smaller.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Influence Maximization in Social Networks When Negative Opinions May Emerge and Propagate
SIAM 2011 International Conference on Data Mining, SIAM, Society for Industrial and Applied Mathematics, 3600 Market Street, 6th Floor, Philadelphia, PA 19104-2688 USA., pp. 379-390
[u'Alex Collins']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36946.html
notfound
=========================
Managing Crowdsourced Human Computation
20th International World Wide Web Conference, WWW 2011
[u'Panagiotis G. Ipeirotis', u'Praveen K. Paritosh']
Human-ComputerInteractionandVisualization
Abstract: The tutorial covers an emerging topic of wide interest: Crowdsourcing. Specifically, we cover areas of crowdsourcing related to managing structured and unstructured data in a web-related content. Many researchers and practitioners today see the great opportunity that becomes available through easily-available crowdsourcing platforms. However, most newcomers face the same questions: How can we manage the (noisy) crowds to generate high quality output? How to estimate the quality of the contributors? How can we best structure the tasks? How can we get results in small amounts of time and minimizing the necessary resources? How to setup the incentives? How should such crowdsourcing markets be setup? Their presented material will cover topics from a variety of fields, including computer science, statistics, economics, and psychology. Furthermore, the material will include real-life examples and case studies from years of experience in running and managing crowdsourcing applications in business settings. The tutorial presenters have an extensive academic and systems building experience and will provide the audience with data sets that can be used for hands-on tasks.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Measuring improvement in user search performance resulting from optimal search tips
SIGIR 2011, ACM
[u'Daniel M. Russell', u'Neema Moraveji', u'Jacob Bien', u'David Mease']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37235.html
found
=========================
Milgram-routing in social networks.
Proceedings of the 20th International Conference on World Wide Web, WWW 2011, pp. 725-734
[u'Silvio Lattanzi', u'Alessandro Panconesi', u'D. Sivakumar']
Human-ComputerInteractionandVisualization
Abstract: We demonstrate how a recent model of social networks (Affiliation Networks) offers powerful cues in local routing within social networks, a theme made famous by sociologist Milgrams six degrees of separation experiments. This model posits the existence of an interest space that underlies a social network; we prove that in networks produced by this model, not only do short paths exist among all pairs of nodes but natural local routing algorithms can discover them effectively. Specifically, we show that local routing can discover paths of length O(log^2 n) to targets chosen uniformly at random, and paths of length O(1) to targets chosen with probability proportional to their degrees. Experiments on the co-authorship graph derived from DBLP data confirm our theoretical results, and shed light into the power of one step of lookahead in routing algorithms for social networks.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37663.html
notfound
=========================
Near to the brain: Functional near-infrared spectroscopy as a lightweight brain imaging technique for visualization
IEEE Conference on Information Visualization (2011)
[u'Evan M. Peck', u'Erin Treacy Solovey', u'Sara L. Su', u'Robert J. K. Jacob', u'Remco Chang']
Human-ComputerInteractionandVisualization
Abstract: In order to better understand the user and visual interface, it is crucial to also understand human cognitive processes. Unfortunately, these processes are traditionally difficult to monitor without the use of cumbersome or expensive brain imaging equipment. In recent years, functional near-infrared spectroscopy (fNIRS) has emerged as a brain imaging technique that is both lightweight and easy to set up. In this paper, we demonstrate the potential of fNIRS to examine current visualization techniques and influence the design of visual interfaces. To validate fNIRS as a tool for visualization research, we present two studies based on previous work in brightness contrast in visual search and angle vs. position comparisons in form. Our results indicate there are significant and unintuitive cognitive differences in the prefrontal cortex during visual search tasks of positive and negative contrast polarity. Furthermore, we are able to differentiate between angle and position comparisons under specific experimental conditions. Finally, we outline the potential of fNIRS to give objective, continuous, and near real-time feedback of brain activity in future visualization research.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Personalized Social Recommendations - Accurate or Private?
Very Large Data Bases (VLDB) (2011)
[u'Ashwin Machanavajjhala', u'Aleksandra Korolova', u'Atish Das Sarma']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Reputation Systems for Open Collaboration
Communications of the ACM, vol. 54 No. 8 (2011), pp. 81-87
[u'B.T. Adler', u'L. de Alfaro', u'A. Kulshrestra', u'I. Pye']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37670.html
notfound
=========================
Smart Phone Use by Non-Mobile Business Users
MobileHCI 2011, ACM, Stockholm, Sweden, pp. 445-454
[u'Patti Bao', u'Jeffrey Pierce', u'Stephen Whittaker', u'Shumin Zhai']
Human-ComputerInteractionandVisualization
Abstract: The rapid increase in smart phone capabilities has introduced new opportunities for mobile information access and computing. However, smart phone use may still be constrained by both device affordances and work environments. To understand how current business users employ smart phones and to identify opportunities for improving business smart phone use, we conducted two studies of actual and perceived performance of standard work tasks. Our studies involved 243 smart phone users from a large corporation. We intentionally chose users who primarily work with desktops and laptops, as these nonmobile users represent the largest population of business users. Our results go beyond the general intuition that smart phones are better for consuming than producing information: we provide concrete measurements that show how fast reading is on phones and how much slower and more effortful text entry is on phones than on computers. We also demonstrate that security mechanisms are a significant barrier to wider business smart phone use. We offer design suggestions to overcome these barriers.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37120.html
found
=========================
Suggesting (More) Friends Using the Implicit Social Graph
International Conference on Machine Learning (ICML) (2011)
[u'Maayan Roth', u'Tzvika Barenholz', u'Assaf Ben-David', u'David Deutscher', u'Guy Flysher', u'Avinatan Hassidim', u'Ilan Horn', u'Ari Leichtberg', u'Naty Leiser', u'Yossi Matias', u'Ron Merom']
Human-ComputerInteractionandVisualization
Abstract: Although users of online communication tools rarely categorize their contacts into groups such as "family", "co-workers", or "jogging buddies", they nonetheless implicitly cluster contacts, by virtue of their interactions with them, forming implicit groups. In this paper, we describe the implicit social graph which is formed by users' interactions with contacts and groups of contacts, and which is distinct from explicit social graphs in which users explicitly add other individuals as their "friends". We introduce an interaction-based metric for estimating a user's affinity to his contacts and groups. We then describe a novel friend suggestion algorithm that uses a user's implicit social graph to generate a friend group, given a small seed set of contacts which the user has already labeled as friends. We show experimental results that demonstrate the importance of both implicit group relationships and interaction-based affinity ranking in suggesting friends. Finally, we discuss two applications of the Friend Suggest algorithm that have been released as Gmail features.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37658.html
notfound
=========================
The future of child-computer interaction
CHI EA 2011: Proceedings of the 2011 annual conference extended abstracts on human factors in computing systems, ACM, New York, NY, pp. 693-696
[u'Allison Druin', u'Gary Knell', u'Elliot Soloway', u'Daniel M. Russell', u'Elizabeth Mynatt', u'Yvonne Rogers']
Human-ComputerInteractionandVisualization
Abstract: In this panel, academic, non-profit, and industry professionals will ask, what does the future hold for "child-computer interaction?" Panelists will explore such issues as how new mobile, social, and ubiquitous technologies change children's future patterns of searching, exploration, and expression of information; how learning environments will be ever-changing because of new technologies; and the challenges and opportunities of designing for child-computer interaction.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38084.html
notfound
=========================
Understanding information preview in mobile email processing
Mobile HCI, ACM (2011), pp. 303-312
[u'Kimberly A. Weaver', u'Huahai Yang', u'Shumin Zhai']
Human-ComputerInteractionandVisualization
Abstract: Browsing a collection of information on a mobile device is a common task, yet it can be difficult due to the small size of mobile displays. A common trade-off offered by many current mobile interfaces is to allow users to switch between an overview and detailed views of particular items. An open question is how much preview of each item to include in the overview. Using a mobile email processing task, we attempted to answer that question. We investigated participants' email processing behaviors under differing preview conditions in a semi-controlled, naturalistic study. We collected log data of participants' actual behaviors as well as their subjective impressions of different conditions. Our results suggest that a moderate level of two to three lines of preview should be the default. The overall benefit of a moderate amount of preview was supported by both positive subjective ratings and fewer transitions between the overview and individual items.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
User-Defined Motion Gestures for Mobile Interaction
CHI 2011: ACM Conference on Human Factors in Computing Systems, pp. 197-206
[u'Jaime Ruiz', u'Yang Li', u'Edward Lank']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37212.html
found
=========================
Web 2.0 and Performance: Using Social Media to Facilitate Learning at Google
Michael Allen's e-Learning Annual 2012, Pfeiffer, 989 Market St, San Francisco, CA 94103 (2011), pp. 171-179
[u'Julia Bulkowski']
Human-ComputerInteractionandVisualization
Abstract: Are you leveraging Web 2.0 technologies to solve performance problems? Google has tapped the power of online collaboration to solve business problems and engage learners. It is easier than you might think to leverage scalable and free technologies to address your organization's needs. In this hands-on session, explore case studies of how Google is using blogs, wikis, shared documents, RSS readers, and online video sharing to transform learning and performance.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37468.html
notfound
=========================
Working Smarter, Not Harder: Inter-Disciplinary Methods for the Age of Analytics
EPIC 2011
[u'Neal Patel', u'Andrew Warr', u'Kathy Baxter']
Human-ComputerInteractionandVisualization
Abstract: Increasingly large and complex data sets, fewer resources, and short timelines pose unique challenges to researchers. To over come obstacles of scale, complexity, and velocity, we propose two techniques data triangulation and process scaling. We will explain how weve used these techniques, discuss lessons learned, & through interactive exercises, participants will learn how to apply these techniques to their own work.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37469.html
notfound
=========================
YouPivot: Improving Recall with Contextual Search
CHI 2011, ACM Press, pp. 1521-1530
[u'Joshua Hailpern', u'Nicholas Jitkoff', u'Andrew Warr', u'Karrie Karahalios', u'Robert Sesek', u'Nik Shkrob']
Human-ComputerInteractionandVisualization
Abstract: According to cognitive science literature, human memory is predicated on contextual cues (e.g., room, music) in the environment. During recall tasks, we associate information/activities/objects with contextual cues. However, computer systems do not leverage our natural process of using contextual cues to facilitate recall. We present a new interaction technique, Pivoting, that allows users to search for contextually related activities and find a target piece of information (often not semantically related). A sample motivation for contextual search would be, 'what was that website I was looking at when Yesterday by The Beatles was last playing?' Our interaction technique is grounded in the cognitive science literature, and is demonstrated in our system YouPivot. In addition, we present a new personal annotation method, called TimeMarks, to further support contextual recall and the pivoting process. In a pilot study, participants were quicker to identify websites, and preferred using YouPivot, compared to current tools. YouPivot demonstrates how principles of human memory can be applied to enhance the search of digital information.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A comparison of visual and textual page previews in judging the helpfulness of web pages.
proceedings of WWW'2010
[u'Anne Aula', u'Rehan Khan', u'Peter Hong', u'Zhiwei Guan', u'Paul Fontes']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35610.html
notfound
=========================
Automatic Generation of Research Trails in Web History
Proc. IUI 2010, ACM Press
[u'Elin Rnby Pedersen', u'Shengyin Gu', u'Peter Jin Hong', u'Karl Gyllstrom']
Human-ComputerInteractionandVisualization
Abstract: The web is large and complex, and in the process of navigating it, we often lose our way. Research trailing is a method to organize web contents that we have spent some effort on into distinct research sessions. Research trails are automatically constructed by filtering and organizing users activity history, using a combination of semantic and temporal criteria for grouping similar web activity. The design of research trails was informed by an ethnographic study of ordinary people doing research on the web; it addresses the specific challenges of establishing and maintaining context when the research process is fragmented and the research question is still in formation. This paper motivates and describes our algorithms for generating high quality research trails. Research trails can be applied in several contexts: as the underlying mechanism for a research task browser, or as feed to an ambient display of history information while searching. A prototype was built to assess the utility of the first option, a research trail browser.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36329.html
notfound
=========================
Behind the Scenes of Google Maps Navigation: Enabling actionable user feedback at scale
CHI 2010 Extended Abstracts on Human Factors in Computing Systems, ACM, New York, NY, pp. 3763-3768
[u'Yelena Nakhimovsky', u'Andrew T. Miller', u'Tom Dimopoulos', u'Michael Siliski']
Human-ComputerInteractionandVisualization
Abstract: This case study describes an Android-based feedback mechanism, created to gain structured input on prototypes of Google Maps Navigation, a mobile GPS navigation system, during real-world usage. We note the challenges faced, common to many mobile projects, and how we addressed them. We describe the user flow for submitting feedback; the resulting feedback report from the team's perspective; our triaging process for the high volume of incoming data; and the results & benefits gleaned from using this system. Learnings and recommendations are provided, to aid mobile teams who may be interested in developing a similar system for their working prototype, particularly if real-world testing is required.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36334.html
notfound
=========================
Best of Both Worlds: Improving Gmail Labels with the Affordances of Folders
Extended Abstracts of ACM CHI 2010, ACM
[u'Kerry Rodden', u'Michael Leggett']
Human-ComputerInteractionandVisualization
Abstract: Gmails filing system for email conversations is based around labels, which are more flexible and powerful than folders. With its original user interface, many users did not discover labels, and wondered why Gmail had no folders. The Gmail team redesigned the user interface for labeling to make it more discoverable and understandable, and to add the most useful functionality of folders. The new design works for the simple use case (a conversation with only one label), while still making the more complex use case (multiple labels) easily available. It has been launched to millions of users worldwide and has resulted in much higher adoption of labels, especially by new users of Gmail.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Collaborative Human Computation as a Means of Information Management
Proceedings of the 2nd International Workshop on Collaborative Information Seeking at CSCW 2010
[u'Manas Tungare', u'Ben Hanrahan', u'Ricardo Quintana-Castillo', u'Michael Stewart', u'Manuel Prez-Quiones']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36900.html
found
=========================
Confucius and Its Intelligent Disciples: Integrating Social with Search
Proceedings of VLDB 2010, 36th International Conference on Very Large Data Bases, VLDB Endowment, pp. 1505-1516
[u'Xiance Si', u'Edward Y. Chang', u'Zoltan Gyongyi', u'Maosong Sun']
Human-ComputerInteractionandVisualization
Abstract: Q&A sites continue to flourish as a large number of users rely on them as useful substitutes for incomplete or missing search results. In this paper, we present our experience with developing Confucius, a Google Q&A service launched in 21 countries and four languages by the end of 2009. Confucius employs six data mining subroutines to harness synergy between web search and social networks. We present these subroutines design goals, algorithms, and their effects on service quality. We also describe techniques for and experience with scaling the subroutines to mine massive data sets.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37273.html
notfound
=========================
Designing for children's mobile storytelling
The International Journal of Mobile Human-Computer Interaction, vol. Special Issue: Mobile Interaction Design and Children (2010), pp. 19-36
[u'Sonia Franckel', u'Elizabeth Bonsignore', u'Allison Druin']
Human-ComputerInteractionandVisualization
Abstract: Mobile technologies offer novel opportunities for children to express themselves in-context, seamlessly, without disrupting the flow of their formal learning activities or informal play. Most contemporary mobile devices are equipped with multimedia support that can be used to create multimodal stories that represent the rich life narratives children experience, imagine, and want to share. The authors investigated these issues over a 9-month series of participatory design sessions in the Human Computer Interaction Lab (HCIL) at the University of Maryland. In this article, the authors describe their work with children in designing mobile tools for story creation and collaboration. Throughout this work, they asked the following questions: What stories do children want to tell, and how do they want to convey them in a mobile context? The findings suggest the need for mobile technology-based applications that support childrens unique storytelling habits, particularly interruptability and multimodality.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43257.html
notfound
=========================
Designing more Effective Workshops
Ethnographic Praxis in Industry Conference Proceedings, Blackwell Publishing Ltd (2010), pp. 311
[u'Jennifer Gove', u'Kathy Baxter']
Human-ComputerInteractionandVisualization
Abstract: Ethnographic researchers are often more at home in the field than in organizational settings and designers in the open studio. We often see competing internal goals trump insights from effective research-based design proposals, presentations and reports. The Strategic Dialogue workshop prepares participants with tools for organizing collaborative stakeholder workshops that help you establish joint ownership of the meaning of research.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40658.html
notfound
=========================
Do You Know Which Device Your Respondent Has Used to Take Your Online Survey?
Survey Practice, vol. December (2010)
[u'Mario Callegaro']
Human-ComputerInteractionandVisualization
Abstract: The type of devices that can be used to go online is becoming more varied. Users access the internet through traditional desktops and laptops, as well as netbooks, tablets, videogame consoles, mobile phones and ebook readers. Because many online surveys are designed to be taken on a standard desktop or laptop screen, it is important to monitor from which device your online sample is taking the survey, and to consider the consequences the device might have for visual design impact and survey estimates. A survey designed to be taken on a desktop does not necessarily or automatically look the same when taken from netbooks, smartphones and other devices. This article will present a description of some tools to collect paradata that allow us to understand from which device the online survey is accessed, along with an initial suggestion for best practices.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37451.html
notfound
=========================
From Research Hypotheses to Practical Guidelines: A Proposal to Facilitate Researcher-Practitioner Interaction
Proceedings of the CHI 2010 Workshop on Researcher-Practitioner Interaction
[u'Pardha S. Pyla', u'Catherine Grevet', u'Manas Tungare', u'Manuel Prez-Quiones']
Human-ComputerInteractionandVisualization
Abstract: In this paper, we describe the gulf that exists between research findings and their adoption in practice. We propose ideas that have the potential to increase the collaboration between researchers and practitioners to forge a symbiotic relationship between these two worlds. Our proposal includes highlighting industry constraints in academic HCI classes, encouraging researchers to present practical implications in papers, creating a collaborative platform between researchers and practitioners, and fostering strong relationships between HCI students and industry professionals.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36911.html
notfound
=========================
Gesture Search: A Tool for Fast Mobile Data Access
UIST'10: Symposium on User Interface Software and Technology, ACM (2010), pp. 87-96
[u'Yang Li']
Human-ComputerInteractionandVisualization
Abstract: Modern mobile phones can store a large amount of data, such as contacts, applications and music. However, it is difficult to access specific data items via existing mobile user interfaces. In this paper, we present Gesture Search, a tool that allows a user to quickly access various data items on a mobile phone by drawing gestures on its touch screen. Gesture Search contributes a unique way of combining gesture-based interaction and search for fast mobile data access. It also demonstrates a novel approach for coupling gestures with standard GUI interaction. A real world deployment with mobile phone users showed that Gesture Search enabled fast, easy access to mobile data in their day-to-day lives. Gesture Search has been released to public and is currently in use by hundreds of thousands of mobile users. It was rated positively by users, with a mean of 4.5 out of 5 for over 5000 ratings.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
How does search behavior change as search becomes more difficult?
Proceedings of the ACM Conference on Human Factors in Computing Systems - CHI 2010, ACM
[u'Anne Aula', u'Rehan Khan', u'Zhiwei Guan']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36461.html
notfound
=========================
Ignore These At Your Peril: Ten principles for trust design
Trust 2010. 3rd International Conference on Trust and Trustworthy Computing
[u'Jens Riegelsberger', u'M. Angela Sasse']
Human-ComputerInteractionandVisualization
Abstract: Online trust has been discussed for more than 10 years, yet little practical guidance has emerged that has proven to be applicable across contexts or useful in the long run. 'Trustworthy UI design guidelines' created in the late 90ies to address the then big question of online trust: how to get shoppers online, are now happily employed by people preparing phishing scams. In this paper we summarize, in practical terms, a conceptual framework for online trust we've established in 2005. Because of its abstract nature it is still useful as a lens through which to view the current big questions of the online trust debate - largely focused on usable security and phishing attacks. We then deduct practical 10 rules for providing effective trust support to help practitioners and researchers of usable security.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36299.html
notfound
=========================
Measuring the User Experience on a Large Scale: User-Centered Metrics for Web Applications
Proceedings of CHI 2010, ACM Press
[u'Kerry Rodden', u'Hilary Hutchinson', u'Xin Fu']
Human-ComputerInteractionandVisualization
Abstract: More and more products and services are being deployed on the web, and this presents new challenges and opportunities for measurement of user experience on a large scale. There is a strong need for user-centered metrics for web applications, which can be used to measure progress towards key goals, and drive product decisions. In this note, we describe the HEART framework for user-centered metrics, as well as a process for mapping product goals to metrics. We include practical examples of how HEART metrics have helped product teams make decisions that are both data-driven and user-centered. The framework and process have generalized to enough of our companys own products that we are confident that teams in other organizations will be able to reuse or adapt them. We also hope to encourage more research into metrics based on large-scale behavioral data.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36488.html
notfound
=========================
Not gone, but forgotten: Helping users re-find web pages by identifying those which are most likely to be lost
Proceedings of the SIGIR 2010 Workshop on Desktop Search (Understanding, Supporting and Evaluating Personal Data Search)., ACM, SIGIR, http://www.cdvp.dcu.ie/DS2010/DesktopSearchProceedings.pdf, pp. 7-8
[u'Karl Gyllstrom', u'Elin Rnby Pedersen']
Human-ComputerInteractionandVisualization
Abstract: We describe LostRank, a project in its formative stage which aims to produce a way to rank results in re-finding search engines according to the likelihood of their being lost to the user. To this end, we have explored a number of ideas, including applying users' temporal document access patterns to determine the documents that are both important and have not been recently accessed (indicating greater potential for loss), understanding users' topical access patterns to determine the topics that are more unfamiliar and hence more difficult to re-find documents within, and assessing users' difficulties in originally finding documents in order to predict future difficulties in re-finding them. As a position paper, we use this as an opportunity to describe early work, invite collaboration with others, and further the case for the use of temporal access patterns as a source for assisting users' re-finding of personal documents.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Optimal Iterative Pricing over Social Networks (Extended Abstract)
WINE (2010), pp. 415-423
[u'Hessameddin Akhlaghpour', u'Mohammad Ghodsi', u'Nima Haghpanah', u'Vahab Mirrokni', u'Hamid Mahini', u'Afshin Nikzad']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Optimal marketing and pricing over social networks
WWW (2010), pp. 1349-1350
[u'Nicole Immorlica', u'Vahab S. Mirrokni']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Protractor: A Fast and Accurate Gesture Recognizer
CHI 2010: ACM Conference on Human Factors in Computing Systems, ACM
[u'Yang Li']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36239.html
notfound
=========================
QuickSuggest: Character Prediction for Improved Text Entry on Web Appliances
International Conference on the World Wide Web (WWW) (2010)
[u'Ullas Gargi', u'Rich Gossweiler']
Human-ComputerInteractionandVisualization
Abstract: As traditional media and information devices integrate with the web, they must abruptly support a vastly larger database of relevant items. Many devices such as internet-capable televisions and set-top boxes support traditional remote controls with on-screen keyboards for text input. These input methods are not well suited for text entry but are difficult to displace. To make these devices work well in a rich information environment such as the WWW, we must develop ways to improve text entry through this input bottleneck. We introduce QuickSuggest which significantly improves text entry speed for on-screen keyboards, much like query suggestions in a search text box can improve query input. QuickSuggest uses the same simple Up/Down/Left/Right/Enter interface common to remote controls, gaming devices and car input controls used to enter text. The paper describes QuickSuggest's novel adaptive user interface to make text entry more efficient and demonstrates quantitative improvements from simulation results on millions of user queries. User experiments also show ease of use and efficiency with no learning curve. Our results suggest that very simple input devices can be used to enter text covering a large vocabulary with surprising ease.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36464.html
notfound
=========================
Reading Difculty in Adults with Intellectual Disabilities: Analysis with a Hierarchical Latent Trait Model
12th International ACM SIGACCESS Conference on Computers and Accessibility (ASSETS 2010)
[u'Martin Jansche', u'Lijun Feng', u'Matt Huenerfauth']
Human-ComputerInteractionandVisualization
Abstract: In prior work, adults with intellectual disabilities answered comprehension questions after reading texts. We apply a latent trait model to this data to infer the intrinsic difficulty of texts for the participant group. We then analyze the correlation between grade levels predicted by an automatic readability assessment tool and the inferred text difficulty.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36332.html
notfound
=========================
Rhythms and plasticity: television temporality at home
Personal and Ubiquitous Computing (2010)
[u'Lilly Irani', u'Robin Jeffries', u'Andrea Knight']
Human-ComputerInteractionandVisualization
Abstract: Digital technologies have enabled new temporalities of media consumption in the home. Through a field study of home television viewing practices, we investigated temporal orderings of television watching. In contrast to traditional pictures of television use, our evidence suggests that rhythms across households play an important role in shaping television watching. Further, we found a flexibility and openness within the patterns of television viewing that we refer to as plasticity. Our data suggest that plasticity and rhythms co-exist and together compose the qualitative experience of domestic television time; an understanding of both aspects of temporality suggests an approach for the design of future television technologies.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36577.html
notfound
=========================
Say What? Why users choose to speak their web queries
Interspeech (2010)
[u'Maryam Kamvar', u'Doug Beeferman']
Human-ComputerInteractionandVisualization
Abstract: The context in which a speech-driven application is used (or conversely not used) can be an important signal for recognition engines, and for spoken interface design. Using large-scale logs from a widely deployed spoken system, we analyze on an aggregate level factors that are correlated with a decision to speak a web search query rather than type it. We find the factors most predictive of spoken queries are whether a query is made from an unconventional keyboard, for a search topic relating to a users' location, or for a search topic that can be answered in a hands-free fashion. We also find, contrary to our intuition, that longer queries have a higher probability of being typed than shorter queries.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36371.html
notfound
=========================
Suggesting Friends Using the Implicit Social Graph
Proceedings of the 16th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (2010)
[u'Maayan Roth', u'Assaf Ben-David', u'David Deutscher', u'Guy Flysher', u'Ilan Horn', u'Ari Leichtberg', u'Naty Leiser', u'Yossi Matias', u'Ron Merom']
Human-ComputerInteractionandVisualization
Abstract: Although users of online communication tools rarely categorize their contacts into groups such as "family", "co-workers", or "jogging buddies", they nonetheless implicitly cluster contacts, by virtue of their interactions with them, forming implicit groups. In this paper, we describe the implicit social graph which is formed by users' interactions with contacts and groups of contacts, and which is distinct from explicit social graphs in which users explicitly add other individuals as their "friends". We introduce an interaction-based metric for estimating a user's affinity to his contacts and groups. We then describe a novel friend suggestion algorithm that uses a user's implicit social graph to generate a friend group, given a small seed set of contacts which the user has already labeled as friends. We show experimental results that demonstrate the importance of both implicit group relationships and interaction-based affinity ranking in suggesting friends. Finally, we discuss two applications of the Friend Suggest algorithm that have been released as Gmail Labs features.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37452.html
notfound
=========================
Sustainability of Bits, not just Atoms
Proceedings of the CHI 2010 Workshop: Examining Appropriation, Re-use, and Maintenance for Sustainability
[u'Manas Tungare', u'Manuel Prez-Quiones', u'Pardha S. Pyla', u'Ben Hanrahan', u'Uma Murthy', u'Ricardo Quintana-Castillo']
Human-ComputerInteractionandVisualization
Abstract: In this paper, we discuss sustainability as it applies to digital artifacts and personal information. We continually create and/or receive new information items in the form of emails, files, photos, media, etc., but once these artifacts enter our information ecosystems, they stay permanently and are rarely deleted even if their intrinsic value is no longer the same as earlier. This impacts information seeking tasks negatively, as users must now learn to navigate a larger corpus of information, and leads to information overload. We describe the technological causes of information overload in the context of existing finding, filing, and refiling practices and information heirlooms. We conclude with an example of a solution that can address this challenge.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40647.html
notfound
=========================
N the Network? Using Internet Resources for Predicting Cell Phone Number Status
Social Science Computer Review, vol. 28 (2010), pp. 271-286
[u'Trent D. Buskirk', u'Mario Callegaro', u'Kumar Rao']
Human-ComputerInteractionandVisualization
Abstract: Despite higher hit rates for cell phone samples, inefficiencies in processing calls to these numbers relative to landline numbers continue to be documented in the U.S. literature. In this study, we propose one method for using cell phone provider information and Internet resources for validating number status. Specifically, we describe how we used in network options available from three major providers web sites to determine the validity of cell phone numbers. We tested differences in working number rates (WNRs) among valid and nonvalid numbers against a normal processing control group and determined that the WNR among valid numbers was approximately 14 percentage points higher than the WNR of the comparison group. This process also shows promise in reducing the effort required to determine working status and may provide a basis for developing screening tools for cell phones that capitalize on resources that are unique to this technology.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
'You've Got IMs!' How People Manage Concurrent Instant Messages
Proceedings of the 13th International Conference on Human-Computer Interaction. Part I, Springer-Verlag, Berlin, Heidelberg (2009), pp. 500-509
[u'Shailendra Rao', u'Judy Chen', u'Robin Jeffries', u'Richard Boardman']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
An incentive-based architecture for social recommendations
RecSys '09: Proceedings of the third ACM conference on Recommender systems, ACM, New York, NY, USA (2009), pp. 229-232
[u'Rajat Bhattacharjee', u'Ashish Goel', u'Konstantinos Kollias']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Beyond Pinch and Flick: Enriching Mobile Gesture Interaction
IEEE Comuter, vol. 42 (2009), pp. 87-89
[u'Yang Li']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35176.html
notfound
=========================
DTorial: An interactive tutorial framework for blind users in a Web 2.0 world
Proceedings of the 12th IFIP TC13 Conference in Human-Computer Interaction INTERACT 2009, Springer-Verlag, Uppsala, Sweden, pp. 5-18
[u'Joshua Hailpern', u'Loretta Guarino Reid', u'Richard Boardman']
Human-ComputerInteractionandVisualization
Abstract: Effective tutorial systems can help promote products by reducing barriers of learning new applications. With dynamic web applications becoming as complex as desktop programs, there is a growing need for online tutorial/help systems. For visually impaired users the key limitations of traditional help systems are 1) poor access to help content with assistive technology, and 2) frequent reliance on videos/images to identify parts of web applications and demonstrate functionality. In this paper, we present a new interaction model, targeted towards screen-reader users, that describes how to embed an interactive tutorial within a web application. The interaction model is demonstrated within a system called DTorial, a fully functional dynamic audio-based tutorial with embedded content. While remaining within the web application, users can rapidly access any tutorial content, injected inline near relevant application controls, allowing them to quickly apply what they just heard to the application itself, without ever losing their position or having to shift windows. The model and implementation are grounded in sighted user help-systems literature and an analysis of screen-reader and Web-Application interactions. Lessons learned from the incremental design and evaluations indicate that providing visually impaired users with dynamic, embedded, interactive audio-based tutorial systems can reduce the barriers to new Web-Applications.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Discriminating the relevance of web search results with measures of pupil size
Proceedings of the 27th international conference on Human factors in computing systems, CHI 2009, pp. 2209-2212
[u'Flavio Oliveira', u'Anne Aula', u'Dan Russell']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35214.html
notfound
=========================
Gmail Accessibility: A Case Study of Accessibility for AJAX Applications
24th Annual International Technology & Persons with Disabilities Conference, California State University Northridge (2009)
[u'Srinivas Annam', u'Loretta Guarino Reid', u'Jyotsna Kaki']
Human-ComputerInteractionandVisualization
Abstract: Discuss recent changes to Gmail to make it more accessible to AT users. Also, talk about challenges for screen reader users while using AJAX applications.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Google Internationalization Quality Control Framework
33rd Internationalization & Unicode Conference (2009)
[u'Andrew Swerdlow', u'Manish Bhargava', u'Jens Riegelsberger', u'Laura Cuozzo']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
How Children Search the Internet with Keyword Interfaces
Interaction Design and Children, ACM, Como, Italy (2009), pp. 89-96
[u'Allison Druin', u'Elizabeth Foss', u'Leshell Hatley', u'Evan Golub', u'Mona Leigh Guha', u'Jerry Fails', u'Hilary Hutchinson']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35388.html
notfound
=========================
How opinions are received by online communities: A case study on Amazon.com helpfulness votes
Proceedings of the 18th International Conference on World Wide Web, WWW 2009, Madrid, Spain, April 20-24, 2009, pp. 141-150
[u'Cristian Danescu-Niculescu-Mizil', u'Gueorgi Kossinets', u'Jon Kleinberg', u'Lillian Lee']
Human-ComputerInteractionandVisualization
Abstract: There are many on-line settings in which users publicly express opinions. A number of these offer mechanisms for other users to evaluate these opinions; a canonical example is Amazon.com, where reviews come with annotations like ``26 of 32 people found the following review helpful.'' Opinion evaluation appears in many off-line settings as well, including market research and political campaigns. Reasoning about the evaluation of an opinion is fundamentally different from reasoning about the opinion itself: rather than asking, ``What did Y think of X?'', we are asking, ``What did Z think of Y's opinion of X?'' Here we develop a framework for analyzing and modeling opinion evaluation, using a large-scale collection of Amazon book reviews as a dataset. We find that the perceived helpfulness of a review depends not just on its content but also but also in subtle ways on how the expressed evaluation relates to other evaluations of the same product. As part of our approach, we develop novel methods that take advantage of the phenomenon of review ``plagiarism'' to control for the effects of text in opinion evaluation, and we provide a simple and natural mathematical model consistent with our findings. Our analysis also allows us to distinguish among the predictions of competing theories from sociology and social psychology, and to discover unexpected differences in the collective opinion-evaluation behavior of user populations from different countries.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Mechanisms for making crowds truthful
J. Artif. Int. Res., vol. 34 (2009), pp. 209-253
[u'Radu Jurca', u'Boi Faltings']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35067.html
notfound
=========================
Mobile User Experience Research: Challenges, Methods & Tools
CHI 2009 Extended Abstracts, ACM, New York, pp. 4795-4798
[u'Yelena Nakhimovsky', u'Dean Eckles', u'Jens Riegelsberger']
Human-ComputerInteractionandVisualization
Abstract: The main goal of this CHI 2009 workshop was to bring together researchers from industry and academia, designers, and creators of mobile research tools to discuss methods, tools and infrastructure for mobile UX and HCI research. To achieve this goal, we: Provided a forum for participants to share past experiences, success stories, failures and associated learnings, as well as recurring problems; Jointly prioritized these; Mapped out the dimensions required of mobile research tools, and translate some of these into draft requirements and low-fidelity prototypes for novel research tools. Details and videos can be found at http://sites.google.com/site/chi09mobileworkshop
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Multilingual search strategies
Proceedings of the 27th international conference extended abstracts on Human factors in computing systems, CHI 2009, pp. 3854-3870
[u'Anne Aula', u'Melanie Kellar']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35626.html
notfound
=========================
Origins of Homophily in an Evolving Social Network
American Journal of Sociology, vol. 115 (2009), pp. 405-450
[u'Gueorgi Kossinets', u'Duncan J. Watts']
Human-ComputerInteractionandVisualization
Abstract: The authors investigate the origins of homophily in a large university community, using network data in which interactions, attributes, and affiliations are all recorded over time. The analysis indicates that highly similar pairs do show greater than average propensity to form new ties; however, it also finds that tie formation is heavily biased by triadic closure and focal closure, which effectively constrain the opportunities among which individuals may select. In the case of triadic closure, moreover, selection to "friend of a friend" status is determined by an analogous combination of individual preference and structural proximity. The authors conclude that the dynamic interplay of choice homophily and induced homophily, compounded over many "generations" of biased selection of similar individuals to structurally proximate positions, can amplify even a modest preference for similar others, via a cumulative advantage-like process, to produce striking patterns of observed homophily.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Overcoming challenges in mobile UX research methods and tools
CHI 2009 Extended Abstracts, ACM, New York, pp. 2747-2750
[u'Yelena Nakhimovsky', u'Dean Eckles', u'Jens Riegelsberger']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40573.html
notfound
=========================
Perspective Probe
CHI EA '09 CHI '09 Extended Abstracts on Human Factors in Computing Systems, ACM, New York, USA (2009), pp. 2945-2954
[u'Marianne Berkovich']
Human-ComputerInteractionandVisualization
Abstract: This case study describes a variation of cultural, technology, and other probes, called a perspective probe. The perspective probe consisted of multiple activities that participants completed on their own and then discussed with the researcher. The participants responses to the individual activities added up to their whole perspective. The probes activities helped guide the conversation around a sensitive topic instead of asking directly about it. This paper illustrates how the perspective probe methodology was used to gather information for Google Finance. The focus is on the method rather than the particular findings from the study. The perspective probe methodology was useful in getting rich data from participants and building a holistic understanding of the participants perspective on a difficult topic, in this case money and investing.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Perspective Probe: Many Parts add up to a Whole Perspective
Proceedings CHI (2009)
[u'Marianne Berkovich']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Sensemaking workshop CHI 2009
ACM Press (2009), pp. 3891-3984
[u'Daniel M Russell', u'George Furnas', u'Mark Stefik', u'Stuart Card', u'Peter Pirolli']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
The application of forgiveness in social system design
Proceedings of CHI 2009, ACM, New York, pp. 225-228
[u'Asimina Vasalou', u'Jens Riegelsberger', u'Adam Joinson']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
The mobile revolution: using technology to transform fieldwork
Proceedings of EPIC (Ethnographic Practice in Industry Conference) (2009), pp. 295-297
[u'Patrick Larvie', u'Jens Riegelsberger', u'Olga Khroustaleva', u'Yelena Nakhimovsky']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34630.html
notfound
=========================
Undo and Erase Events as Indicators of Usability Problems
Proceedings of SIGCHI 2009, ACM, N/A
[u'David Akers', u'Matthew Simpson', u'Robin Jeffries', u'Terry Winograd']
Human-ComputerInteractionandVisualization
Abstract: One approach to reduce the costs of usability testing is to facilitate the automatic detection of critical incidents: serious breakdowns in interaction that stand out during software use. This research evaluates the use of undo and erase events as indicators of critical incidents in Google SketchUp (a 3D-modeling application), measuring an indicators usefulness by the numbers and types of usability problems discovered. Our evaluation also compares problems identified using undo and erase events to problems identified using the user-reported critical incident technique [CITE]. In a within-subjects experiment with 37 participants, undo and erase episodes together revealed over 80% of the problems rated as severe, one third of which would not have been discovered by self-report alone. Moreover, problems found by all three techniques were rated as significantly more severe than those identified by only a subset of techniques. These results suggest that undo and erase events will serve as a useful complement to user reported critical incidents for low cost usability evaluation of design-oriented applications like Google SketchUp.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35169.html
notfound
=========================
WCAG 2.0 for Designers: Beyond Screen Readers and Captions
Proceedings of the 13th International Conference on Human-Computer Interaction HCII 2009, Springer-Verlag, pp. 674-682
[u'Loretta Guarino Reid', u'Andi Snow-Weaver']
Human-ComputerInteractionandVisualization
Abstract: The W3C Web Content Accessibility Guidelines (WCAG) provide guidance on making websites accessible to people with disabilities. WCAG 1.0 focused largely on coding requirements that enable websites to interoperate with assistive technologies used by people with disabilities. WCAG 2.0 addresses an environment where website complexity has increased significantly due to higher network bandwidth and the introduction of new interactive technologies. It places more constraints on the default look and feel of a website. Of the 38 Level A and AA provisions, about 50%, impact the website design. This paper reviews those requirements, examining the user needs that they are intended to support and highlighting example strategies for addressing those needs.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34911.html
notfound
=========================
WEB 2.0: BLIND TO A BRAVE NEW WORLD
World Wide Web Conference 2009, Madrid, Spain, pp. 821-830
[u'Joshua Hailpern', u'Loretta Guarino Reid', u'Richard Boardman', u'Srinivas Annam']
Human-ComputerInteractionandVisualization
Abstract: With the advent of Web 2.0 technologies, websites have evolved from static pages to dynamic, interactive Web-based applications with the ability to replicate common desktop functionality. However, for blind and visually impaired individuals who rely upon screen readers, Web 2.0 applications force them to adapt to an inaccessible use model. Many technologies, including WAI-ARIA, AJAX, and improved screen reader support, are rapidly evolving to improve this situation. However, simply combining them does not solve the problems of screen reader users. The main contributions of this paper are two models of interaction for screen reader users, for both traditional websites and Web 2.0 applications. Further contributions are a discussion of accessibility difficulties screen reader users encounter when interacting with Web 2.0 applications, a user workflow design model for improving Web 2.0 accessibility, and a set of design requirements for developers to ease the user's burden and increase accessibility. These models, accessibility difficulties, and design implications are based directly on responses and lessons learned from usability research focusing on Web 2.0 usage and screen reader users. Without the conscious effort of Web engineers and designers, most blind and visually impaired users will shy away from using new Web 2.0 technology in favor of desktop based applications.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35157.html
notfound
=========================
What's Up CAPTCHA? A CAPTCHA Based On Image Orientation
WWW 2009
[u'Rich Gossweiler', u'Maryam Kamvar', u'Shumeet Baluja']
Human-ComputerInteractionandVisualization
Abstract: We present a new CAPTCHA which is based on identifying an image's upright orientation. This task requires analysis of the often complex contents of an image, a task which humans usually perform well and machines generally do not. Given a large repository of images, such as those from a web search result, we use a suite of automated orientation detectors to prune those images that can be automatically set upright easily. We then apply a social feedback mechanism to verify that the remaining images have a human-recognizable upright orientation. The main advantages of our CAPTCHA technique over the traditional text recognition techniques are that it is language-independent, does not require text-entry (e.g. for a mobile device), and employs another domain for CAPTCHA generation beyond character obfuscation. This CAPTCHA lends itself to rapid implementation and has an almost limitless supply of images. We conducted extensive experiments to measure the viability of this technique.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35767.html
notfound
=========================
sos: Searching Help Pages of R Packages
The R Journal, vol. 1/2 (2009), pp. 56-59
[u'Spencer Graves', u'Sundar Dorai-Raj', u'Romain Francois']
Human-ComputerInteractionandVisualization
Abstract: The sos package provides a means to quickly and flexibly search the help pages of contributed packages, finding functions and datasets in seconds or minutes that could not be found in hours or days by any other means we know. Its findFn function accesses Jonathan Baron's R Site Search database and returns the matches in a data frame of class "findFn", which can be further manipulated by other sos functions to produce, for example, an Excel file that starts with a summary sheet that makes it relatively easy to prioritize alternative packages for further study. As such, it provides a very powerful way to do a literature search for functions and packages relevant to a particular topic of interest and could become virtually mandatory for authors of new packages or papers in publications such as The R Journal and the Journal of Statistical Software.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
xBook: Redesigning Privacy Control in Social Networking Platforms
18th Usenix Security Symposium, Usenix (2009)
[u'Kapil Singh', u'Sumeer Bhola', u'Wenke Lee']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub33381.html
notfound
=========================
A Case for Usage Tracking to Relate Digital Objects
ReColl 2008 proceedings (section of IUI 2008 proceedings), ACM
[u'Elin Rnby Pedersen', u'Jeanine Spence']
Human-ComputerInteractionandVisualization
Abstract: This paper covers the evolution of the concept of Usage Tracking to automatically link digital objects such as documents. Extensive ethnographic studies of information work have revealed that establishing and maintaining relationships between documents, between artifacts and between people is at the core of information work. Focusing on just one aspect of this challenge, we looked for practical ways of relating digital documents. Leveraging the fieldwork, we designed a mechanism captures the users activity across documents and reinterprets it as links between these documents. We implemented the mechanism as a running prototype to assess the feasibility of the concept, and in general gauge the opportunities to make better use of usage data which are mostly gets ignored in todays computing platforms. Object to object relation building through usage data has three important advantages over most existing methods for automatically establishing relations: first, it is behaviorist, not relying on guesswork about the users intentions; second, it is media agnostic: text, images and sounds are all just objects and treated alike; it is the users handling of the objects that matter, and third, it is application agnostic: it does not rely on privileged access to specific applications.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Social Query Model for Decentralized Search
Second ACM Workshop on Social Network Mining and Analysis at the KDD Conference (SNAKDD-08) (2008)
[u'Arindam Banerjee', u'Sugato Basu']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
AxsJAX: A Talking Translation Bot using Google IM: Bringing Web-2.0 Applications to Life
Proceedings of the 2008 International Cross-Disciplinary Conference on Web Accessibility (W4A), ACM, Beijing, pp. 54-56
[u'Charles L. Chen', u'T. V. Raman']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Blocked sites and offensive videos: the challenges of teen computer use
CHI '08: CHI '08 extended abstracts on Human factors in computing systems, ACM, New York, NY, USA (2008), pp. 2757-2762
[u'Anne Aula', u'Sasha Lubomirsky']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Controlling the Complexity in Comparing Search User Interfaces via User Studies
Information Processing and Management: an International Journal, vol. 44 (2008), pp. 82-91
[u'Mika Kki', u'Anne Aula']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43252.html
notfound
=========================
Extreme usability: adapting research approaches for agile development
CHI'08 extended abstracts on Human factors in computing systems, ACM (2008), pp. 2269-2272
[u'Melissa Federoff', u'Craig Villamor', u'Lynn Miller', u'Jeff Patton', u'Aviva Rosenstein', u'Kathy Baxter', u'Kuldeep Kelkar']
Human-ComputerInteractionandVisualization
Abstract: Abstract Agile development is being adopted by many leading software companies, such as those represented by this panel. Though many instructional resources exist to guide companies through a change to Agile Development, there are few resources available on the subject of Agile development and User Centered Design (UCD). As a result, user experience practitioners have had to develop their own tactics and strategies for maintaining sound UCD practices within their organizations when moving to Agile.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Eye-Mouse Coordination Patterns on Web Search Results Pages
Extended Abstracts of ACM CHI 2008, ACM Press
[u'Kerry Rodden', u'Xin Fu', u'Anne Aula', u'Ian Spiro']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Formulargestaltung fr Dummies: Die hufigsten Fehler erkennen, beheben und zuknftig vermeiden
Usability Professionals 2008, H. Brau, S. Diefenbach, M. Hassenzahl, F. Koller, M. Peissner, K. Rse, pp. 49-52
[u'Iris Niedermann', u'Michael Hatscher']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
From Logs to People: Field Research at Google
Being Seen: Paradoxes and Practices of (in)Visibility - Conference Proceedings of EPIC 2009, American Antrhopological Association, 2200 Wilson Blvd, Suite 600 Arlington, VA 22201 (2008), pp. 329-330
[u'Jens Riegelsberger', u'Olga Khroustaleva']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Generating Summary Keywords for Emails Using Topics
Proceedings of the 2008 International Conference on Intelligent User Interfaces
[u'Mark Dredze', u'Hanna Wallach', u'Danny Puller', u'Fernando Pereira']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34437.html
notfound
=========================
Google TV Search: Dual-Wielding Search and Discovery in a Large-Scale Product
UXTV 2008
[u'Manish Patel', u'Rich Gossweiler', u'Mehran Sahami', u'John Blackburn', u'David Brown', u'Andrea Knight']
Human-ComputerInteractionandVisualization
Abstract: In 2006 Google designed and implemented a TV Show search system which featured a dual-navigation control combining a powerful search system with an interactive, personalize-able TV listings grid. The dual-control system allowed users to move fluidly between explicit search and general discovery, obtain detailed information without leaving the global context and construct a personal channel for easy access and recommendations. As a complete system, TV Search integrated with Google's general search page through a mini-listings onebox and also exported information out to Google calendar, Gmail and TiVo. Building this TV Search system as a large-scale product meant addressing many technological, business and fine-grained user experience details. This paper describes the design process including the early designs, the user studies and the details of the final system including the mini-guide, main page dual-control and the integrated services on the detail pages.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35215.html
notfound
=========================
Improving Access to Web Content at Google
Google (2008)
[u'Loretta Guarino Reid', u'Srinivas Annam']
Human-ComputerInteractionandVisualization
Abstract: We review our work in enhancing the accessibility of Web content at Google, including improvements to GMail, Google Books and the Mobile Google Calendar.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Mass Personalization: Social and Interactive Applications using Sound-Track Identification
Journal of Multimedia Tools and Applications, vol. 36 (2008), pp. 115-132
[u'Michael Fink', u'Michele Covell', u'Shumeet Baluja']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Now You See It, Now You Dont: Ethnography and Selective Visibility in the Technology Sector
Being Seen: Paradoxes and Practices of (in)Visibility - Conference Proceedings of EPIC 2009, American Antrhopological Association, 2200 Wilson Blvd, Suite 600 Arlington, VA 22201 (2008), pp. 253-266
[u'Laura Granka', u'Patrick Larvie', u'Jens Riegelsberger']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub33379.html
notfound
=========================
Paper interface to electronic medical records: a case of usage-driven technology appropriation
Proceedings of the 7th ACM conference on Designing interactive systems, ACM, The Association for Computing Machinery, Inc. 1515 Broadway New York, New York 10036 (2008), pp. 40-49
[u'Elin Rnby Pedersen', u'Greg Wolff']
Human-ComputerInteractionandVisualization
Abstract: We conducted a 6-month project with a physical therapy clinic, involving equal parts ethnographic fieldwork and rapid prototyping. It differed from most reported user-informed design by having an explicit dual purpose. On the one hand, the prototype should provide significant, measurable improvements for the field site. On the other hand, the project sponsor did not intend to develop the prototype into a product but rather identify future opportunities and needs in the small-to-medium health care sector, requirements for next generation multifunction peripherals (MFPs), and business applications of existing technology. Thus, the project simultaneously investigated specific solutions for a specific work practice while looking for key technologies to address future needs. This paper provides a detailed account of the process and results, highlighting particular contingencies that come with a dual-purpose exploration, as well as the benefits of a small, focused team that oscillates between research and deployment.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Query Suggestions for Mobile Search: Understanding Usage Patterns
Proceedings of the SIGCHI conference on Human Factors in computing systems (CHI) (2008)
[u'Maryam Kamvar', u'Shumeet Baluja']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Recovering trust and avoiding escalation: an overlooked design goal of social systems
Proc. of Conference on Human Factors in Computing Systems - CHI 2008, ACM Press, New York, NY, US, pp. 3333-3338
[u'Asimina Vasalou', u'Jens Riegelsberger']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub33380.html
notfound
=========================
Relating Documents via User Activity: The Missing Link
International Conference on Intelligent User Interfaces. Proceedings of the 13th international conference on Intelligent user interfaces, ACM (2008), pp. 389-392
[u'Elin Rnby Pedersen', u'David W McDonald']
Human-ComputerInteractionandVisualization
Abstract: In this paper we describe a system for creating and exposing relationships between documents: a users interaction with digital objects (like documents) is interpreted as links to be discovered and maintained by the system. Such relationships are created automatically, requiring no priming by the user. Using a very simple set of heuristics we demonstrate the uniquely useful relationships that can be established between documents that have been touched by the user. Furthermore, this mechanism for relationship building is media agnostic, thus discovering relationships that would not be found by conventional content based approaches. We describe a proof-of-concept implementation of this basic idea and discuss a couple of natural expansions of the scope of user activity monitoring
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Review of Beyond the Desktop Metaphor: Designing Integrated Digital Work Environments, edited by Victor Kaptelinin and Mary Czerwinski
Technical Communication, vol. 55 (2008), pp. 434-435
[u'Carolyn Wei']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Seeing the bigger picture: A multi-method field trial of Google Maps for Mobile
Extended Abstracts CHI'08, ACM, New York, NY (2008)
[u'Jens Riegelsberger', u'Yelena Nakhimovsky']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Sensemaking
CHI extended abstracts on Human Factors in Computing Systems, ACM, Florence (2008), pp. 3981-3984
[u'Daniel M Russell', u'George Furnas', u'Mark Stefik', u'Stuart K. Card', u'Peter Pirolli']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Truthful opinions from the crowds
SIGecom Exch., vol. 7 (2008), pp. 1-4
[u'Radu Jurca', u'Boi Faltings']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Usability Professionals - ein Rollenspiel
Usability Professionals 2008, H. Brau, S. Diefenbach, M. Hassenzahl, F. Koller, M. Peissner, K. Rse, pp. 135-138
[u'Michael Hatscher', u'Iris Niedermann']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34439.html
notfound
=========================
User Preference and Search Engine Latency
JSM Proceedings, Qualtiy and Productivity Research Section., American Statistical Association, Alexandria, VA (2008)
[u'Jake D. Brutlag', u'Hilary Hutchinson', u'Maria Stone']
Human-ComputerInteractionandVisualization
Abstract: Presented at the 2008 Quality and Productivity Research Conference in Madison, WI.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
User experience at Google: focus on the user and all else will follow
Conference on Human Factors in Computing Systems - CHI, ACM Press, New York, NY, US (2008), pp. 3681-3686
[u'Irene Au', u'Richard Boardman', u'Robin Jeffries', u'Patrick Larvie', u'Antonella Pavese', u'Jens Riegelsberger', u'Kerry Rodden', u'Molly Stevens']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Word Usage and Posting Behaviors: Modeling Bloggers with Unobtrusive Data Collection Methods
Proceedings of ACM CHI 2008
[u'Adam Kramer', u'Kerry Rodden']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Zebra: Exploring users engagement in fieldwork
DIS 2008: Designing Interactive Systems
[u'Yann Riche', u'Matthew Simpson', u'Stephen Viller']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Express yourself / Stay together: The middle-class Indian family
Handbook of Mobile Communication Studies, MIT Press (2008), pp. 325-38
[u'Jonathan Donner', u'Nimmi Rangaswamy', u'Molly Wright Steenson', u'Carolyn Wei']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Its our only connection: Mobile phones and romantic relationships in India
Proceedings of Design and Emotion 2008
[u'Carolyn Wei']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Applying a User-Centered Metric to Identify Active Blogs
Extended Abstracts of ACM CHI 2007, ACM
[u'Adam Kramer', u'Kerry Rodden']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Assigned tasks are not the same as self-chosen Web search tasks.
HICSS (2007)
[u'Daniel M. Russell', u'Carrie Grimes']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Capturing mobile phone usage: Research methods for mobile studies
Proceedings of the 2007 International Professional Communication Conference
[u'Carolyn Y. Wei']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34303.html
notfound
=========================
Communication mapping: Understanding anyones social network in 60 minutes
DUX 2007
[u'Paul Adams']
Human-ComputerInteractionandVisualization
Abstract: To design successful user experiences for Googles communication products, it is important for us to understand their users communication behaviours beyond what they do with the product itself. To make informed design decisions, product development teams often require us to build this understanding in a matter of weeks. This paper describes a research technique for building an understanding of peoples social networks and communication tools by only spending 60 minutes each with a small number of research participants. It also describes examples of the type of insights this technique can yield.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Conducting remote, internet-based experiments on Web design
Connecting People with Technology: Issues in Professional Communication, Baywood (2007), pp. 31-41
[u'Elisabeth Cuddihy', u'Carolyn Wei', u'Alexandra L. Bartell', u'Jennifer Barrick', u'Brandon Maust', u'Seth S. Leopold', u'Jan H. Spyridakis']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Designing Searching and Browsing Software for Elementary-Age Children
Universal Usability: Designing Computer Interfaces for Diverse User Populations, Wiley, West Sussex, UK (2007), pp. 13-42
[u'Hilary Hutchinson', u'Allison Druin', u'Benjamin Bederson']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub33003.html
notfound
=========================
Emacspeak -- The Complete Audio Desktop
Beautiful Code, O'Reilly Media (2007), pp. 503 - 526
[u'Raman, T. V.']
Human-ComputerInteractionandVisualization
Abstract: A desktop is a workspace that one uses to organize the tools of one's trade. Graphical desktops provide rich visual interaction for performing day-to-day computing tasks; the goal of the audio desktop is to enable similar efficiencies in an eyes-free environment. Thus, the primary goal of an audio desktop is to use the expressiveness of auditory output (both verbal and nonverbal) to enable the end user to perform a full range of computing tasks: Communication through the full range of electronic messaging services Ready access to local documents on the client and global documents on the Web Ability to develop software effectively in an eyes-free environment
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Evaluating the accuracy of implicit feedback from clicks and query reformulations in web search
ACM Transactions on Information Systems, vol. 25, no 2 (2007), pp. 7
[u'Thorsten Joachims', u'Laura A. Granka', u'Bing Pan', u'Helene Hembrooke', u'Filip Radlinski', u'Geri Gay']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Exploring How Mouse Movements Relate to Eye Movements on Web Search Results Pages
Proceedings of ACM SIGIR 2007 Workshop on Web Information Seeking and Interaction, pp. 29-32
[u'Kerry Rodden', u'Xin Fu']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Interpreting and Acting on Mobile Awareness Cues
Human-Computer Interaction, vol. 22 (2007), pp. 97-135
[u'Antti Oulasvirta', u'Renaud Petit', u'Mika Raento', u'Sauli Tiitta']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Organizing and Searching the World Wide Web of Facts - Step Two: Harnessing the Wisdom of the Crowds
Proceedings of the 16th International World Wide Web Conference (WWW-07) (2007), pp. 101-110
[u'Marius Pasca']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Review of The Body and the Screen: Theories of Internet Spectatorship, by Michele White
Technical Communication, vol. 54 (2007), pp. 384-385
[u'Carolyn Wei']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34510.html
notfound
=========================
Session Viewer: Visual Exploratory Analysis of Web Session Logs
Symposium on Visual Analytics Science and Technology (VAST), IEEE (2007), pp. 147-154
[u'Heidi Lam', u'Daniel M. Russell', u'Diane Tang', u'Tamara Munzner']
Human-ComputerInteractionandVisualization
Abstract: Large-scale session log analysis typically includes statistical methods and detailed log examinations. While both methods have merits, statistical methods can miss previously unknown subpopulations in the data and detailed analyses may have selection biases. We therefore built Session Viewer, a visualization tool to facilitate and bridge between statistical and detailed analyses. Taking a multiple-coordinated view approach, Session Viewer shows multiple session populations at the Aggregate, Multiple, and Detail data levels to support different analysis styles. To bridge between the statistical and the detailed analysis levels, Session Viewer provides fluid traversal between data levels and side-by-side comparison at all data levels. We describe an analysis of a large-scale web usage study to demonstrate the use of Session Viewer, where we quantified the importance of grouping sessions based on task type.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Social Dynamics of Early Stage Co-design in Developing Regions
CHI '07, ACM, San Jose (2007), pp. 1087-1096
[u'Divya Ramachandran', u'Matthew Kam', u'Jane Chiu']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Thinking but not seeing: think-aloud for non-sighted users
CHI '07, ACM, San Jose (2007), pp. 1851-1856
[u'Philip Strain', u'A. Dawn Shaikh', u'Richard Boardman']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub32578.html
notfound
=========================
Towards the Perfect Infrastructure for Usability Testing on Mobile Devices
CHI '07 extended abstracts on Human factors in computing systems, ACM Press, New York, NY, USA (2007), pp. 1839-1844
[u'Rudy Schusteritsch', u'Carolyn Wei', u'Mark LaRosa']
Human-ComputerInteractionandVisualization
Abstract: In this paper, we describe various setups that allow usability professionals to conduct effective user studies on mobile devices. We describe the factors relevant when building a solution for mobile device observation and the various designs we worked with in the Google user experience research environment as we iterated to meet changing study needs. We highlight a novel setup that is fully portable, can be used in a usability lab as well as in the field, accommodates a large variety of different mobile devices, and allows for live observation by product teams around the world.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Trust 2.1: advancing the trust debate
CHI '07, ACM, San Jose (2007)
[u'Jens Riegelsberger', u'Asimina Vasalou']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Using structural cues to guide readers on the internet
Information Design Journal, vol. 15 (2007), pp. 242-259
[u'Jan H. Spyridakis', u'Kathryn A. Mobrand', u'Elisabeth Cuddihy', u'Carolyn Y. Wei']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
When two methods are better than one: Combining user study with cognitive modeling
CHI '07, ACM, San Jose (2007), pp. 1783-1788
[u'Andrea Knight', u'Guy Pyrzak', u'Collin Green']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
"It's about the information stupid!": why we need a separate field of human-information interaction
Conference on Human Factors in Computing Systems, ACM, Montral, Qubec (2006), pp. 65-68
[u'William Jones', u'Peter Pirolli', u'Stuart K. Card', u'Raya Fidel', u'Nahum Gershon', u'Peter Morville', u'Bonnie Nardi', u'Daniel M. Russell']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Incorporating Eyetracking into User Studies at Google
Proceedings of ACM CHI 2006 workshop on Getting a Measure of Satisfaction from Eyetracking in Practice
[u'Laura A. Granka', u'Kerry Rodden']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Location location location: viewing patterns on WWW pages
ETRA (2006), pp. 43
[u'Laura A. Granka', u'Helene Hembrooke', u'Geri Gay']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
No IM please, We're Testing
Conference on Human Factors in Computing Systems, ACM, Montral, Qubec (2006), pp. 81-86
[u'Richard Boardman']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Panels: Design Communication
CHI '06 Extended Abstracts on Human Factors in Computing Systems, ACM, Montral, Qubec (2006), pp. 49-52
[u'Scott Jenson', u'Harry Sadler', u'Charlie Hill', u'Carlo DiSalvo']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Scaling the card sort method to over 500 items: restructuring the Google AdWords Help Center
Proceedings of ACM CHI 2006, pp. 183 - 188
[u'Yelena Nakhimovsky', u'Rudy Schusteritsch', u'Kerry Rodden']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Shared Family Calendars: Promoting Symmetry and Accessibility
ACM Transactions on Computer-Human Interaction, vol. 13 (3) (2006), pp. 313-346
[u'Catherine Plaisant', u'Aaron Clamage', u'Hilary Hutchinson', u'Benjamin Bederson', u'Allison Druin']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
The Evolution of the International Children's Digital Library Searching and Browsing Interface
Proceedings of Interaction Design and Children, ACM Press (2006), pp. 105-112
[u'Hilary Hutchinson', u'Benjamin Bederson', u'Allison Druin']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Virtual Information Piles for Small Screen Devices
CHI '06 Extended Abstracts on Human Factors in Computing Systems, ACM, Montral, Qubec (2006), pp. 345-350
[u'QianYing Wang', u'Tony Hsieh', u'Meredith Ringel Morris', u'Andreas Paepcke']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Mobile search with text messages: designing the user experience for Google SMS
Proceedings of ACM CHI 2005
[u'Rudy Schusteritsch', u'Shailendra Rao', u'Kerry Rodden']
Human-ComputerInteractionandVisualization
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/InformationRetrievalandtheWeb.html
found
http://research.google.com/pubs/pub44012.html
notfound
=========================
AdAlyze Redux: Post-Click and Post-Conversion Text Feature Attribution for Sponsored Search Ads
WWW '15 Companion Proceedings of the 24th International Conference on World Wide Web, ACM (2015)
[u'Thomas Steiner']
InformationRetrievalandtheWeb
Abstract: In this paper, we present our ongoing research on an ads quality testing tool that we call AdAlyze Redux. This tool allows advertisers to get individual best practice recommendations based on an expandable set of textual ads features, tailored to exactly the ads in an advertiser's set of accounts. This lets them optimize their ad copies against the common online advertising key performance indicators clickthrough rate and, if available, conversion rate. We choose the Web as the tool's platform and automatically generate the analyses as platform-independent HTML5 slides and full reports.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43796.html
notfound
=========================
Learning to Extract Local Events from the Web
SIGIR 2015 (to appear)
[u'John Foley', u'Michael Bendersky', u'Vanja Josifovski']
InformationRetrievalandtheWeb
Abstract: The goal of this work is extraction and retrieval of local events from web pages. Examples of local events include small venue concerts, theater performances, garage sales, movie screenings, etc. We collect these events in the form of retrievable calendar entries that include structured information about event name, date, time and location. Between existing information extraction techniques and the availability of information on social media and semantic web technologies, there are numerous ways to collect commercial, high-profile events. However, most extraction techniques require domain-level supervision, which is not attainable at web scale. Similarly, while the adoption of the semantic web has grown, there will always be organizations without the resources or the expertise to add machine-readable annotations to their pages. Therefore, our approach bootstraps these explicit annotations to massively scale up local event extraction. We propose a novel event extraction model that uses distant supervision to assign scores to individual event fields (event name, date, time and location) and a structural algorithm to optimally group these fields into event records. Our model integrates information from both the entire source document and its relevant sub-regions, and is highly scalable. We evaluate our extraction model on all 700 million documents in a large publicly available web corpus, ClueWeb12. Using the 217,000 unique explicitly annotated events as distant supervision, we are able to double recall with 85% precision and quadruple it with 65% precision, with no additional human supervision. We also show that our model can be bootstrapped for a fully supervised approach, which can further improve the precision by 30%. In addition, we evaluate the geographic coverage of the extracted events. We find that there is a significant increase in the geo-diversity of extracted events compared to existing explicit annotations, while maintaining high precision levels
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42453.html
notfound
=========================
A Scalable Gibbs Sampler for Probabilistic Entity Linking
Advances in Information Retrieval (ECIR 2014), Springer International Publishing, pp. 335-346
[u'Neil Houlsby', u'Massimiliano Ciaramita']
InformationRetrievalandtheWeb
Abstract: Entity linking involves labeling phrases in text with their referent entities, such as Wikipedia or Freebase entries. This task is challenging due to the large number of possible entities, in the millions, and heavy-tailed mention ambiguity. We formulate the problem in terms of probabilistic inference within a topic model, where each topic is associated with a Wikipedia article. To deal with the large number of topics we propose a novel efficient Gibbs sampling scheme which can also incorporate side information, such as the Wikipedia graph. This conceptually simple probabilistic approach achieves state-of-the-art performance in entity-linking on the Aida-CoNLL dataset.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Circumlocution in Diagnostic Medical Queries
The 37th Annual ACM SIGIR Conference (2014)
[u'Isabelle Stanton', u'Samuel Ieong', u'Nina Mishra']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43145.html
notfound
=========================
Discrete Graph Hashing
Neural Information Processing Systems (2014)
[u'Wei Liu', u'Cun Mu', u'Sanjiv Kumar', u'Shih-Fu Chang']
InformationRetrievalandtheWeb
Abstract: Hashing has emerged as a popular technique for fast nearest neighbor search in gigantic databases. In particular, learning based hashing has received considerable attention due to its appealing storage and search efficiency. However, the performance of most unsupervised learning based hashing methods deteriorates rapidly as the hash code length increases. We argue that the degraded performance is due to inferior optimization procedures used to achieve discrete binary codes. This paper presents a graph-based unsupervised hashing model to preserve the neighborhood structure of massive data in a discrete code space. We cast the graph hashing problem into a discrete optimization framework which directly learns the binary codes. A tractable alternating maximization algorithm is then proposed to explicitly deal with the discrete constraints, yielding high-quality codes to well capture the local neighborhoods. Extensive experiments performed on four large datasets with up to one million samples show that our discrete optimization based graph hashing method obtains superior search accuracy over state-of-the-art unsupervised hashing methods, especially for longer codes.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Near Neighbor Join
ICDE (2014)
[u'Herald Kllapi', u'Boulos Harb', u'Cong Yu']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
On Reconstructing a Hidden Permutation
RANDOM (2014)
[u'Flavio Chierichetti', u'Anirban Dasgupta', u'Ravi Kumar', u'Silvio Lattanzi']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42853.html
notfound
=========================
Scalable K-Means by ranked retrieval
Proceedings of the 7th ACM international conference on Web search and data mining, ACM, New York, NY, USA (2014), pp. 233-242
[u'Andrei Broder', u'Lluis Garcia-Pueyo', u'Vanja Josifovski', u'Sergei Vassilvitskii', u'Srihari Venkatesan']
InformationRetrievalandtheWeb
Abstract: The k-means clustering algorithm has a long history and a proven practical performance, however it does not scale to clustering millions of data points into thousands of clusters in high dimensional spaces. The main computational bottleneck is the need to recompute the nearest centroid for every data point at every iteration, aprohibitive cost when the number of clusters is large. In this paper we show how to reduce the cost of the k-means algorithm by large factors by adapting ranked retrieval techniques. Using a combination of heuristics, on two real life data sets the wall clock time per iteration is reduced from 445 minutes to less than 4, and from 705 minutes to 1.4, while the clustering quality remains within 0.5% of the k-means quality. The key insight is to invert the process of point-to-centroid assignment by creating an inverted index over all the points and then using the current centroids as queries to this index to decide on cluster membership. In other words, rather than each iteration consisting of "points picking centroids", each iteration now consists of "centroids picking points". This is much more efficient, but comes at the cost of leaving some points unassigned to any centroid. We show experimentally that the number of such points is low and thus they can be separately assigned once the final centroids are decided. To speed up the computation we sparsify the centroids by pruning low weight features. Finally, to further reduce the running time and the number of unassigned points, we propose a variant of the WAND algorithm that uses the results of the intermediate results of nearest neighbor computations to improve performance.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43119.html
found
=========================
Storing and Querying Tree-Structured Records in Dremel
Proceedings of the VLDB Endowment, vol. 7 (2014), pp. 1131-1142
[u'Foto N Afrati', u'Dan Delorey', u'Mosha Pasumansky', u'Jeffrey D. Ullman']
InformationRetrievalandtheWeb
Abstract: In Dremel, data is stored as nested relations. The schema for a relation is a tree, all of whose nodes are attributes, and whose leaf attributes hold values. We explore filter and aggregate queries that are given in the Dremel dialect of SQL. Complications arise because of repeated attributes, i.e., attributes that are allowed to have more than one value. We focus on the common class of Dremel queries that are processed on column-stored data in a way that results in query processing time that is linear on the size of the relevant data, i.e., data in the columns that participate in the query. We formally define the data model, the query language and the algorithms for query processing in column-stored data. The concepts of repetition context and semi-flattening are introduced here and play a central role in understanding this class of queries and their algorithms.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42720.html
notfound
=========================
The SMAPH System for Query Entity Recognition and Disambiguation
ERD 2014: Entity Recognition and Disambiguation Challenge. SIGIR Forum., ACM
[u'Marco Cornolti', u'Paolo Ferragina', u'Massimiliano Ciaramita', u'Stefan Rued', u'Hinrich Schuetze']
InformationRetrievalandtheWeb
Abstract: The SMAPH system implements a pipeline of four main steps: (1) Fetching it fetches the search results returned by a search engine given the query to be annotated; (2) Spotting search result snippets are parsed to identify candidate mentions for the entities to be annotated. This is done in a novel way by detecting the keywords-in-context by looking at the bold parts of the search snippets; (3) Candidate generation candidate entities are generated in two ways: from the Wikipedia pages occurring in the search results, and from an existing annotator, using the mentions identified in the spotting step as input; (4) Pruning a binary SVM classifier is used to decide which entities to keep/discard in order to generate the final annotation set for the query. The SMAPH system ranked third on the development set and first on the final blind test of the 2014 ERD Challenge short text track.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43224.html
found
=========================
Towards better measurement of attention and satisfaction in mobile search
SIGIR '14 Proceedings of the 37th international ACM SIGIR conference on Research & development in information retrieval (2014), pp. 113-122
[u'Dmitry Lagun', u'Dale Webster', u'Chih-Hung Hsieh', u'Vidhya Navalpakkam']
InformationRetrievalandtheWeb
Abstract: Web Search has seen two big changes recently: rapid growth in mobile search traffic, and an increasing trend towards providing answer-like results for relatively simple information needs (e.g., [weather today]). Such results display the answer or relevant information on the search page itself without requiring a user to click. While clicks on organic search results have been used extensively to infer result relevance and search satisfaction, clicks on answer-like results are often rare (or meaningless), making it challenging to evaluate answer quality. Together, these call for better measurement and understanding of search satisfaction on mobile devices. In this paper, we studied whether tracking the browser viewport (visible portion of a web page) on mobile phones could enable accurate measurement of user attention at scale, and provide good measurement of search satisfaction in the absence of clicks. Focusing on answer-like results in web search, we designed a lab study to systematically vary answer presence and relevance (to the user's information need), obtained satisfaction ratings from users, and simultaneously recorded eye gaze and viewport data as users performed search tasks. Using this ground truth, we identified increased scrolling past answer and increased time below answer as clear, measurable signals of user dissatisfaction with answers. While the viewport may contain three to four results at any given time, we found strong correlations between gaze duration and viewport duration on a per result basis, and that the average user attention is focused on the top half of the phone screen, suggesting that we may be able to scalably and reliably identify which specific result the user is looking at, from viewport data alone.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42623.html
notfound
=========================
Up Next: Retrieval Methods for Large Scale Related Video Suggestion
Proceedings of KDD 2014, New York, NY, USA, pp. 1769-1778
[u'Michael Bendersky', u'Lluis Garcia Pueyo', u'Vanja Josifovski', u'Jeremiah J. Harmsen', u'Dima Lepikhin']
InformationRetrievalandtheWeb
Abstract: The explosive growth in sharing and consumption of the video content on the web creates a unique opportunity for scientific advances in video retrieval, recommendation and discovery. In this paper, we focus on the task of video suggestion, commonly found in many online applications. The current state-of-the-art video suggestion techniques are based on the collaborative filtering analysis, and suggest videos that are likely to be co-viewed with the watched video. In this paper, we propose augmenting the collaborative filtering analysis with the topical representation of the video content to suggest related videos. We propose two novel methods for topical video representation. The first method uses information retrieval heuristics such as tf-idf, while the second method learns the optimal topical representations based on the implicit user feedback available in the online scenario. We conduct a large scale live experiment on YouTube traffic, and demonstrate that augmenting collaborative filtering with topical representations significantly improves the quality of the related video suggestions in a live setting, especially for categories with fresh and topically-rich video content such as news videos. In addition, we show that employing user feedback for learning the optimal topical video representations can increase the user engagement by more than 80% over the standard information retrieval representation, when compared to the collaborative filtering baseline.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40749.html
found
=========================
A Framework for Benchmarking Entity-Annotation Systems
Proceedings of the International World Wide Web Conference (WWW) (Practice & Experience Track), ACM (2013) (to appear)
[u'Marco Cornolti', u'Paolo Ferragina', u'Massimiliano Ciaramita']
InformationRetrievalandtheWeb
Abstract: In this paper we design and implement a benchmarking framework for fair and exhaustive comparison of entity-annotation systems. The framework is based upon the definition of a set of problems related to the entity-annotation task, a set of measures to evaluate systems performance, and a systematic comparative evaluation involving all publicly available datasets, containing texts of various types such as news, tweets and Web pages. Our framework is easily-extensible with novel entity annotators, datasets and evaluation measures for comparing systems, and it has been released to the public as open source. We use this framework to perform the first extensive comparison among all available entity annotators over all available datasets, and draw many interesting conclusions upon their efficiency and effectiveness. We also draw conclusions between academic versus commercial annotators.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40667.html
found
=========================
Adolescent search roles
Journal of the American Society for Information Science and Technology, vol. 64(1) (2013), pp. 173-189
[u'Elizabeth Foss', u'Hilary Hutchinson', u'Allison Druin', u'Jason Yip', u'Whitney Ford', u'Evan Golub']
InformationRetrievalandtheWeb
Abstract: In this article, we present an in-home observation and in-context research study investigating how 38 adolescents aged 14-17 search on the Internet. We present the search trends adolescents display and develop a framework of search roles that these trends help define. We compare these trends and roles to similar trends and roles found in prior work with children ages 7, 9, and 11. We use these comparisons to make recommendations to adult stakeholders such as researchers, designers, and information literacy educators about the best ways to design search tools for children and adolescents, as well as how to use the framework of searching roles to find better methods of educating youth searchers. Major findings include the seven roles of adolescent searchers, and evidence that adolescents are social in their computer use, have a greater knowledge of sources than younger children, and that adolescents are less frustrated by searching tasks than younger children.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41445.html
notfound
=========================
AngularJS
O'Reilly (2013), pp. 196
[u'Brad Green', u'Shyam Seshadri']
InformationRetrievalandtheWeb
Abstract: Develop smaller, lighter web apps that are simple to create and easy to test, extend, and maintain as they grow. This hands-on guide introduces you to AngularJS, the open source JavaScript framework that uses Modelviewcontroller (MVC) architecture, data binding, client-side templates, and dependency injection to create a much-needed structure for building web apps. Guided by two engineers who worked on AngularJS at Google, youll walk through the frameworks key features, and then build a working AngularJS appfrom layout to testing, compiling, and debugging. Youll learn how AngularJS helps reduce the complexity of your web app. Dive deep into Angulars building blocks and learn how they work together Gain maximum flexibility by separating logic, data, and presentation responsibilities with MVC Assemble your full app in the browser, using client-side templates Use AngularJS directives to extend HTML with declarative syntax Communicate with the server and implement simple caching with the $http service Use dependency injection to improve refactoring, testability, and multiple environment design Get code samples for common problems you face in most web apps
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Capturing the functionality of Web services with functional descriptions
Multimedia Tools Appl., vol. 64 (2013), pp. 365-387
[u'Ruben Verborgh', u'Thomas Steiner', u'Davy Van Deursen', u'Jos De Roo', u'Rik Van de Walle', u'Joaquim Gabarr Valls']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Crawling deep web entity pages
WSDM (2013), pp. 355-364
[u'Yeye He', u'Dong Xin', u'Venkatesh Ganti', u'Sriram Rajaraman', u'Nirav Shah']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Distributed affordance: an open-world assumption for hypermedia
WWW (Companion Volume) (2013), pp. 1399-1406
[u'Ruben Verborgh', u'Michael Hausenblas', u'Thomas Steiner', u'Erik Mannens', u'Rik Van de Walle']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42181.html
notfound
=========================
Instant Google Drive Starter
Packt Publishing, Packt Publishing Limited, 2nd Floor, Livery Place, 35 Livery Street, Birmingham, B3 2PB (2013)
[u'Michael J. Procopio']
InformationRetrievalandtheWeb
Abstract: This book is a Starter which teaches you how to use Google Drive practically. This book is perfect for people of all skill levels who want to enjoy the benefits of using Google Drive to safely store their files online and in the cloud. It's also great for anyone looking to learn more about cloud computing in general. Readers are expected to have an Internet connection and basic knowledge of using the internet.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41534.html
notfound
=========================
Learning to Rank Recommendations with the k-Order Statistic Loss
ACM International Conference on Recommender Systems (RecSys) (2013)
[u'Jason Weston', u'Hector Yee', u'Ron Weiss']
InformationRetrievalandtheWeb
Abstract: Making recommendations by learning to rank is becoming an increasingly studied area. Approaches that use stochastic gradient descent scale well to large collaborative ltering datasets, and it has been shown how to approximately optimize the mean rank, or more recently the top of the ranked list. In this work we present a family of loss functions, the korder statistic loss, that includes these previous approaches as special cases, and also derives new ones that we show to be useful. In particular, we present (i) a new variant that more accurately optimizes precision at k, and (ii) a novel procedure of optimizing the mean maximum rank, which we hypothesize is useful to more accurately cover all of the users tastes. The general approach works by sampling N positive items, ordering them by the score assigned by the model, and then weighting the example as a function of this ordered set. Our approach is studied in two real-world systems, Google Music and YouTube video recommendations, where we obtain improvements for computable metrics, and in the YouTube case, increased user click through and watch duration when deployed live on www.youtube.com.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42036.html
notfound
=========================
Modelling Score Distributions Without Actual Scores
Proceedings of the 2013 Conference on the Theory of Information Retrieval, ACM, New York, NY, USA, pp. 85-92
[u'Stephen Robertson', u'Evangelos Kanoulas', u'Emine Yilmaz']
InformationRetrievalandtheWeb
Abstract: Score-distribution models are used for various practical purposes in search, for example for results merging and threshold setting. In this paper, the basic ideas of the score-distributional approach to viewing and analyzing the effectiveness of search systems are re-examined. All recent score-distribution modelling work depends on the availability of actual scores generated by systems, and makes assumptions about these scores. Such work is therefore not applicable to systems which do not generate or reveal such scores, or whose scoring/ranking approach violates the assumptions. We demonstrate that it is possible to apply at least some score-distributional ideas without access to real scores, knowing only the rankings produced (together with a single effectiveness metric based on relevance judgments). This new basic insight is illustrated by means of simulation experiments, on a range of TREC runs, some of whose reported scores are clearly unsuitable for existing methods.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41694.html
notfound
=========================
Nearest Neighbor Search in Google Correlate
Google (2013)
[u'Dan Vanderkam', u'Rob Schonberger', u'Henry Rowley', u'Sanjiv Kumar']
InformationRetrievalandtheWeb
Abstract: This paper presents the algorithms which power Google Correlate, a tool which finds web search terms whose popularity over time best matches a user-provided time series. Correlate was developed to generalize the query-based modeling techniques pioneered by Google Flu Trends and make them available to end users. Correlate searches across millions of candidate query time series to find the best matches, returning results in less than 200 milliseconds. Its feature set and requirements present unique challenges for Approximate Nearest Neighbor (ANN) search techniques. In this paper, we present Asymmetric Hashing (AH), the technique used by Correlate, and show how it can be adapted to the specific needs of the product. We then develop experiments to test the throughput and recall of Asymmetric Hashing as compared to a brute-force search. For "full" search vectors, we achieve a 10x speedup over brute force search while maintaining 97% recall. For search vectors which contain holdout periods, we achieve a 4x speedup over brute force search, also with 97% recall.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41860.html
notfound
=========================
Proceedings of the 2013 Conference on the Theory of Information Retrieval
ACM (2013)
[u'Oren Kurland', u'Donald Metzler', u'Christina Lioma', u'Birger Larsen', u'Peter Ingwersen']
InformationRetrievalandtheWeb
Abstract: These proceedings contain the refereed papers, posters and abstracts of keynotes, tutorials and panel discussion presented at the Fourth International Conference on the Theory of Information Retrieval (ICTIR13), held in Copenhagen, Denmark, during September 29-October 2, 2013.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
R-Score: Reputation-based Scoring of Research Groups
CoRR, vol. abs/1308.5286 (2013)
[u'Sabir Ribas', u'Berthier A. Ribeiro-Neto', u'Edmundo de Souza e Silva', u'Nivio Ziviani']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41388.html
notfound
=========================
Random Grids: Fast Approximate Nearest Neighbors and Range Searching for Image Search
ICCV 2013
[u'Dror Aiger', u'Efi Kokiopoulou', u'Ehud Rivlin']
InformationRetrievalandtheWeb
Abstract: We propose two solutions for both nearest neigh- bors and range search problems. For the nearest neighbors problem, we propose a c-approximate so- lution for the restricted version of the decision prob- lem with bounded radius which is then reduced to the nearest neighbors by a known reduction. For range searching we propose a scheme that learns the parameters in a learning stage adopting them to the case of a set of points with low intrinsic dimension that are embedded in high dimensional space (common scenario for image point descrip- tors). We compare our algorithms to the best known methods for these problems, i.e. LSH, ANN and FLANN. We show analytically and experimentally that we can do better for moderate approximation factor. In contrast to tree structures, our algorithms are trivial to parallelize. In the experiments con- ducted, running on couple of million images, our algorithms show meaningful speed-ups when com- pared with the above mentioned methods.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41400.html
notfound
=========================
Real-time communications for the web
Communications Magazine, IEEE, vol. 51 (2013), pp. 20-26
[u'Cullen Jenngins', u'Ted Hardie', u'Magnus Westerlund']
InformationRetrievalandtheWeb
Abstract: This article provides an overview of the work that W3C and IETF are doing toward defining a framework, protocols, and application programming interfaces that will provide real-time interactive voice, video, and data in web browsers and other applications. The article explains how media and data will flow in a peer-to-peer style directly between two web browsers. This explains the protocols used to transport and secure the encrypted media, traverse NATs and firewalls, negotiate media capabilities, and provide identity for the media.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40815.html
found
=========================
Top-k Publish-Subscribe for Social Annotation of News
Proceedings of the 39th International Conference on Very Large Data Bases, VLDB Endowment (2013)
[u'Alexander Shraer', u'Maxim Gurevich', u'Marcus Fontoura', u'Vanja Josifovski']
InformationRetrievalandtheWeb
Abstract: Social content, such as Twitter updates, often have the quickest first-hand reports of news events, as well as numerous commentaries that are indicative of public view of such events. As such, social updates provide a good complement to professionally written news articles. In this paper we consider the problem of automatically annotating news stories with social updates (tweets), at a news website serving high volume of pageviews. The high rate of both the pageviews (millions to billions a day) and of the incoming tweets (more than 100 millions a day) make real-time indexing of tweets ineffective, as this requires an index that is both queried and updated extremely frequently. The rate of tweet updates makes caching techniques almost unusable since the cache would become stale very quickly. We propose a novel architecture where each story is treated as a subscription for tweets relevant to the story's content, and new algorithms that efficiently match tweets to stories, proactively maintaining the top-k tweets for each story. Such {\em top-k pub-sub} consumes only a small fraction of the resource cost of alternative solutions, and can be applicable to other large scale content-based publish-subscribe problems. We demonstrate the effectiveness of our approach on real-world data: a corpus of news stories from Yahoo! News and a log of Twitter updates.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41530.html
notfound
=========================
Transfer Learning In MIR: Sharing Learned Latent Representations For Music Audio Classification And Similarity
14th International Conference on Music Information Retrieval (ISMIR '13) (2013)
[u'Philippe Hamel', u'Matthew E. P. Davies', u'Kazuyoshi Yoshii', u'Masataka Goto']
InformationRetrievalandtheWeb
Abstract: This paper discusses the concept of transfer learning and its potential applications to MIR tasks such as music audio classification and similarity. In a traditional supervised machine learning setting, a system can only use labeled data from a single dataset to solve a given task. The labels associated with the dataset define the nature of the task to solve. A key advantage of transfer learning is in leveraging knowledge from related tasks to improve performance on a given target task. One way to transfer knowledge is to learn a shared latent representation across related tasks. This method has shown to be beneficial in many domains of machine learning, but has yet to be explored in MIR. Many MIR datasets for audio classification present a semantic overlap in their labels. Furthermore, these datasets often contain relatively few songs. Thus, there is a strong case for exploring methods to share knowledge between these datasets towards a more general and robust understanding of high level musical concepts such as genre and similarity. Our results show that shared representations can improve classification accuracy. We also show how transfer learning can improve performance for music similarity.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41524.html
notfound
=========================
Web Workers Multithreaded Programs in JavaScript
O'Reilly, 1005 Gravenstein Hwy N Sebastopol, CA 95472 (2013), pp. 62
[u'Ido Green']
InformationRetrievalandtheWeb
Abstract: Web apps would run much better if heavy calculations could be performed in the background, rather than compete with the user interface. With this book, youll learn how to use Web Workers to run computationally intensive JavaScript code in a thread parallel to the UI. Yes, multi-threaded programing is complicated, but Web Workers provide a simple API that helps you be productive without the complex algorithms. If you have an intermediate to advanced understanding of JavaScript especially event handling and callbacksyoure ready to tackle Web Workers with the tools in this example-driven guide.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Cross-Lingual Dictionary for English Wikipedia Concepts
Eighth International Conference on Language Resources and Evaluation (LREC 2012)
[u'Valentin I. Spitkovsky', u'Angel X. Chang']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Social Description Revolution - Describing Web APIs' Social Parameters with RESTdesc
AAAI Spring Symposium: Intelligent Web Services Meet Social Computing (2012)
[u'Ruben Verborgh', u'Thomas Steiner', u'Joaquim Gabarr', u'Erik Mannens', u'Rik Van de Walle']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40571.html
found
=========================
An Integrated Framework for Spatio-Temporal-Textual Search and Mining
20th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems (ACM SIGSPATIAL GIS 2012), ACM, 2 Penn Plaza, Suite 701, New York, NY 10121, pp. 570-573
[u'Bingsheng Wang', u'Haili Dong', u'Arnold Boedihardjo', u'Chang-Tien Lu', u'Harland Yu', u'Ing-Ray Chen', u'Jing Dai']
InformationRetrievalandtheWeb
Abstract: This paper presents an integrated framework for Spatio-Temporal-Textual (STT) information retrieval and knowledge discovery system. The proposed ensemble framework contains an efficient STT search engine with multiple indexing, ranking and scoring schemes, an effective STT pattern miner with Spatio-Temporal (ST) analytics, and novel STT topic modeling. Specifically, we design an effective prediction prototype with a third-order linear regression model, and present an innovative STT topic modeling relevance ranker to score documents based on inherent STT features under topical space. We demonstrate the framework with a crime dataset from the Washington, DC area from 2006 to 2010 and a global terrorism dataset from 2004 to 2010.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Angular Quantization-based Binary Codes for Fast Similarity Search
Neural Information Processing Systems (NIPS) (2012)
[u'Yunchao Gong', u'Sanjiv Kumar', u'Vishal Verma', u'Svetlana Lazebnik']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Beyond Web Developer Tools: Strace
Web Performance Daybook Volume Two, O'Reilly Media, Inc., 1005 Gravenstein Highway North, Sebastopol, CA 95472 (2012), pp. 119-121
[u'Tony Gentilcore']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38141.html
notfound
=========================
Compact Hyperplane Hashing with Bilinear Functions
International Conference on Machine Learning (ICML) (2012)
[u'Wei Liu', u'Jun Wang', u'Yadong Mu', u'Sanjiv Kumar', u'Shih-Fu Chang']
InformationRetrievalandtheWeb
Abstract: Hyperplane hashing aims at rapidly searching nearest points to a hyperplane, and has shown practical impact in scaling up active learning with SVMs. Unfortunately, the existing randomized methods need long hash codes to achieve reasonable search accuracy and thus suffer from reduced search speed and large memory overhead. To this end, this paper proposes a novel hyperplane hashing technique which yields compact hash codes. The key idea is the bilinear form of the proposed hash functions, which leads to higher collision probability than the existing hyperplane hash functions when using random projections. To further increase the performance, we propose a learning based framework in which the bilinear functions are directly learned from the data. This results in short yet discriminative codes, and also boosts the search performance over the random projection based solutions. Large-scale active learning experiments carried out on two datasets with up to one million samples demonstrate the overall superiority of the proposed approach.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Context-aware querying for multimodal search engines
Proceedings of the 18th international conference on Advances in Multimedia Modeling, Springer-Verlag, Berlin, Heidelberg (2012), pp. 728-739
[u'Jonas Etzold', u'Arnaud Brousseau', u'Paul Grimm', u'Thomas Steiner']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
DOHA: scalable real-time web applications through adaptive concurrent execution
Proceedings of the 21st international conference on World Wide Web, ACM, New York, NY, USA (2012), pp. 161-170
[u'Aiman Erbad', u'Norman C. Hutchinson', u'Charles Krasic']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Dart: Up and Running
O'Reilly Media, 1005 Gravenstein Highway North Sebastopol, CA 95472 USA (2012)
[u'Kathleen Walrath', u'Seth Ladd']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Experimental methods for information retrieval
SIGIR (2012), pp. 1185-1186
[u'Donald Metzler', u'Oren Kurland']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38346.html
notfound
=========================
Hokusai | Sketching Streams in Real Time
Proceedings of the 28th International Conference on Conference on Uncertainty in Artificial Intelligence (UAI) (2012)
[u'Sergiy Matusevych', u'Alex Smola', u'Amr Ahmed']
InformationRetrievalandtheWeb
Abstract: We describe Hokusai, a real time system which is able to capture frequency information for streams of arbitrary sequences of symbols. The algorithm uses the Count-Min sketch as its basis and exploits the fact that sketching is linear. It provides real time statistics of arbitrary events, e.g. streams of queries as a function of time. We use a factorizing approximation to provide point estimates at arbitrary (time, item) combinations.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
I-SEARCH: a multimodal search engine based on rich unified content description (RUCoD)
Proceedings of the 21st international conference companion on World Wide Web, ACM, New York, NY, USA (2012), pp. 291-294
[u'Thomas Steiner', u'Lorenzo Sutton', u'Sabine Spiller', u'Marilena Lazzaro', u'Francesco Nucci', u'Vincenzo Croce', u'Alberto Massari', u'Antonio Camurri', u'Anne Verroust-Blondet', u'Laurent Joyeux', u'Jonas Etzold', u'Paul Grimm', u'Athanasios Mademlis', u'Sotiris Malassiotis', u'Petros Daras', u'Apostolos Axenopoulos', u'Dimitrios Tzovaras']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
IR paradigms in computational advertising
SIGIR (2012), pp. 1019
[u'Andrei Z. Broder']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37043.html
notfound
=========================
Indexing the World Wide Web: The Journey So Far
Next Generation Search Engines: Advanced Models for Information Retrieval, IGI-Global (2012), pp. 1-28
[u'Abhishek Das', u'Ankit Jain']
InformationRetrievalandtheWeb
Abstract: In this chapter, we describe the key indexing components of todays web search engines. As the World Wide Web has grown, the systems and methods for indexing have changed significantly. We present the data structures used, the features extracted, the infrastructure needed, and the options available for designing a brand new search engine. We highlight techniques that improve relevance of results, discuss trade-offs to best utilize machine resources, and cover distributed processing concepts in this context. In particular, we delve into the topics of indexing phrases instead of terms, storage in memory vs. on disk, and data partitioning. We will finish with some thoughts on information organization for the newly emerging data-forms.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40569.html
notfound
=========================
Latent Collaborative Retrieval
International Conference on Machine Learning (2012)
[u'Jason Weston', u'Chong Wang', u'Ron Weiss', u'Adam Berenzweig']
InformationRetrievalandtheWeb
Abstract: Retrieval tasks typically require a ranking of items given a query. Collaborative filtering tasks, on the other hand, learn models comparing users with items. In this paper we study the joint problem of recommending items to a user with respect to a given query, which is a surprisingly common task. This setup differs from the standard collaborative filtering one in that we are given a query user item tensor for training instead of the more traditional user item matrix. Compared to document retrieval we do have a query, but we may or may not have content features (we will consider both cases) and we can also take account of the users profile. We introduce a factorized model for this new task that optimizes the top ranked items returned for the given query and user. We report empirical results where it outperforms several baselines.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40574.html
notfound
=========================
Latent Structured Ranking
UAI (2012)
[u'Jason Weston', u'John Blitzer']
InformationRetrievalandtheWeb
Abstract: Many latent (factorized) models have been proposed for recommendation tasks like collaborative ltering and for ranking tasks like document or image retrieval and annotation. Common to all those methods is that during inference the items are scored independently by their similarity to the query in the latent embedding space. The structure of the ranked list (i.e. considering the set of items returned as a whole) is not taken into account. This can be a problem because the set of top predictions can be either too diverse (contain results that contradict each other) or are not diverse enough. In this paper we introduce a method for learning latent structured rankings that improves over existing methods by providing the right blend of predictions at the top of the ranked list. Particular emphasis is put on making this method scalable. Empirical results on large scale image annotation and music recommendation tasks show improvements over existing approaches.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Nowcasting the macroeconomy with search engine data
Proceedings of the fifth ACM international conference on Web search and data mining, ACM, New York, NY, USA (2012), pp. 1-2
[u'Hal R. Varian']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38140.html
notfound
=========================
On the Difficulty of Nearest Neighbor Search
International Conference on Machine Learning (ICML) (2012)
[u'Junfeng He', u'Sanjiv Kumar', u'Shih-Fu Chang']
InformationRetrievalandtheWeb
Abstract: Fast approximate nearest neighbor (NN) search in large databases is becoming popular and several powerful learning-based formulations have been proposed recently. However, not much attention has been paid to a more fundamental question: how difficult is (approximate) nearest neighbor search in a given data set? And which data properties affect the difficulty of nearest neighbor search and how? This paper introduces the first concrete measure called Relative Contrast that can be used to evaluate the influence of several crucial data characteristics such as dimensionality, sparsity, and database size simultaneously in arbitrary normed metric spaces. Moreover, we present a theoretical analysis to show how relative contrast affects the complexity of Local Sensitive Hashing, a popular approximate NN search method. Relative contrast also provides an explanation for a family of heuristic hashing algorithms with good practical performance based on PCA. Finally, we show that most of the previous works measuring meaningfulness or difficulty of NN search can be derived as special asymptotic cases for dense vectors of the proposed measure.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Online Selection of Diverse Results
Proceedings of the 5th ACM international Conference on Web Search and Data Mining (2012), pp. 263-272
[u'Debmalya Panigrahi', u'Atish Das Sarma', u'Gagan Aggarwal', u'Andrew Tomkins']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Participatory design of social search experiences
Proceedings of the 2012 ACM annual conference extended abstracts on Human Factors in Computing Systems Extended Abstracts, ACM, New York, NY, USA, pp. 1937-1942
[u'Nick Matterson', u'David Choi']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Spotting fake reviewer groups in consumer reviews
Proceedings of the 21st international conference on World Wide Web, ACM, New York, NY, USA (2012), pp. 191-200
[u'Arjun Mukherjee', u'Bing Liu', u'Natalie Glance']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40349.html
found
=========================
The Shoebox and the Safe: When Once-Personal Information Changes Hands
Proceedings of the 5th International Workshop on Personal Information Management at CSCW 2012
[u'Manas Tungare']
InformationRetrievalandtheWeb
Abstract: This paper presents several examples where one users personal information is accessed by another, without the consent of the owner, or without the capability of the owner to consent to such sharing. While intentional sharing of information at home as well as at work has been studied in detail, there is extremely limited understanding about the practices, dimensions and models of unintentional sharing. Laws and policies that were developed with paper and other nondigital archives in mind are being found to be inadequate for addressing the challenges that digital personal information brings. Worse, those laws are being enforced in inconsistent ways, prompting lawsuits. Posthumously shared information brings up questions that have not been addressed before. This paper starts by noting examples of posthumous sharing and sharing without consent, proposes models and dimensions for understanding it, and concludes by proposing research questions that need to be addressed by the wider PIM community.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37745.html
notfound
=========================
Topical clustering of search results
Proceedings of the fifth ACM international conference on Web search and data mining, ACM, New York, NY, USA (2012), pp. 223-232
[u'Ugo Scaiella', u'Paolo Ferragina', u'Andrea Marino', u'Massimiliano Ciaramita']
InformationRetrievalandtheWeb
Abstract: Search results clustering (SRC) is a challenging algorithmic problem that requires grouping together the results returned by one or more search engines in topically coherent clusters, and labeling the clusters with meaningful phrases describing the topics of the results included in them. In this paper we propose to solve SRC via an innovative approach that consists of modeling the problem as the labeled clustering of the nodes of a newly introduced graph of topics. The topics are Wikipedia-pages identified by means of recently proposed topic annotators [9, 11, 16, 20] applied to the search results, and the edges denote the relatedness among these topics computed by taking into account the linkage of the Wikipedia-graph. We tackle this problem by designing a novel algorithm that exploits the spectral properties and the labels of that graph of topics. We show the superiority of our approach with respect to academic state-of-the-art work [6] and well-known commercial systems (CLUSTY and LINGO3G) by performing an extensive set of experiments on standard datasets and user studies via Amazon Mechanical Turk. We test several standard measures for evaluating the performance of all systems and show a relative improvement of up to 20%.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Towards a High Quality and Web-Scalable Table Search Engine
Proceedings of the Third International Workshop on Keyword Search on Structured Data (2012), pp. 1-1
[u'Cong Yu']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Web Search - Challenges and Opportunities
AMW (2012), pp. 16-17
[u'Berthier A. Ribeiro-Neto']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Who knows?: searching for expertise on the social web: technical perspective.
Commun. ACM, vol. 55, 4 (2012), pp. 110-110
[u'Ed H. Chi']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
YouTube around the world: geographic popularity of videos
Proceedings of the 21st international conference on World Wide Web, ACM, New York, NY, USA (2012), pp. 241-250
[u'Anders Brodersen', u'Salvatore Scellato', u'Mirjam Wattenhofer']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Four Group Cross-Over Design for Measuring Irreversible Treatments on Web Search Tasks
Proceedings of Hawaii International Conference on System Sciences (HICSS) (2011), pp. 1-9
[u'Li Ma', u'David Mease', u'Daniel M. Russell']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A generic Web-based entity resolution framework
JASIST, vol. 62 (2011), pp. 919-932
[u'Denilson Alves Pereira', u'Berthier A. Ribeiro-Neto', u'Nivio Ziviani', u'Alberto H. F. Laender', u'Marcos Andr Gonalves']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Analysis of an Expert Search Query Log
SIGIR (2011)
[u'Yi Fang', u'Naveen Somasundaram', u'Luo Si', u'Jeongwoo Ko', u'Aditya P. Mathur']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Context-sensitive query auto-completion
Proceedings of the 20th International Conference on World Wide Web (WWW) (2011), pp. 107-116
[u'Ziv Bar-Yossef', u'Naama Kraus']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub39980.html
found
=========================
CrowdForge: Crowdsourcing Complex Work
Proceedings of UIST 2011, Santa Barbara, CA
[u'Aniket Kittur', u'Boris Smus', u'Susheel Khamkar', u'Robert Kraut']
InformationRetrievalandtheWeb
Abstract: Micro-task markets such as Amazons Mechanical Turk represent a new paradigm for accomplishing work, in which employers can tap into a large population of workers around the globe to accomplish tasks in a fraction of the time and money of more traditional methods. However, such markets have been primarily used for simple, independent tasks, such as labeling an image or judging the relevance of a search result. Here we present a general purpose framework for accomplishing complex and interdependent tasks using micro-task markets. We describe our framework, a web-based prototype, and case studies on article writing, decision making, and science journalism that demonstrate the benefits and limitations of the approach.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37427.html
notfound
=========================
Efficient Runtime Service Discovery and Consumption with Hyperlinked RESTdesc
The 7th International Conference on Next Generation Web Services Practices (NWeSP 2011), Salamanca, Spain
[u'Ruben Verborgh', u'Thomas Steiner', u'Davy Van Deursen', u'Rik Van de Walle', u'Joaquim Gabarro']
InformationRetrievalandtheWeb
Abstract: Hyperlinks and forms let humans navigate with ease through websites they have never seen before. In contrast, automated agents can only perform preprogrammed actions on Web services, reducing their generality and restricting their usefulness to a specialized domain. Many of the employed services call themselves RESTful, although they neglect the hypermedia constraint as defined by Roy T. Fielding, stating that the application state should be driven by hypertext. This lack of link usage on the Web of services severely limits agents in what they can do, while connectedness forms a primary feature of the human Web. An urgent need for more intelligent agents becomes apparent, and in this paper, we demonstrate how the conjunction of functional service descriptions and hypermedia links leads to advanced, interactive agent behavior. We propose a new mode for our previously introduced semantic service description format RESTdesc, providing the mechanisms for agents to consume Web services based on links, similar to human browsing strategies. We illustrate the potential of these descriptions by a use case that shows the enhanced capabilities they offer to automated agents, and explain how this is vital for the future Web.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Estimating the size of online social networks
International Journal of Social Computing and Cyber-Physical Systems, vol. 1 (2011), pp. 160 - 179
[u'Shaozhi Ye', u'S. Felix Wu']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37429.html
notfound
=========================
Fulfilling the Hypermedia Constraint Via HTTP OPTIONS, the HTTP Vocabulary In RDF, and Link Headers
Proceedings of the Second International Workshop on RESTful Design, ACM, New York, NY, USA (2011), pp. 11-14
[u'Thomas Steiner', u'Jan Algermissen']
InformationRetrievalandtheWeb
Abstract: One of the main REST design principles is the focus on media types as the core of contracts on the Web. However, not always is the service designer free to select the most appropriate media type for a task, sometimes a generic media type like application/rdf+xml (or in the worst case a binary format like image/png) with no defined or possible hypermedia controls at all has to be chosen. With this position paper we present a way how the hypermedia constraint of REST can still be fulfilled using a combination of Link headers, the OPTIONS method, and the HTTP Vocabulary in RDF.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41695.html
notfound
=========================
Google Correlate Whitepaper
Google (2011)
[u'Matt Mohebbi', u'Dan Vanderkam', u'Julia Kodysh', u'Rob Schonberger', u'Hyunyoung Choi', u'Sanjiv Kumar']
InformationRetrievalandtheWeb
Abstract: Trends in online web search query data have been shown useful in providing models of real world phenomena. However, many of these results rely on the careful choice of queries that prior knowledge suggests should correspond with the phenomenon. Here, we present an online, automated method for query selection that does not require such prior knowledge. Instead, given a temporal or spatial pattern of interest, we determine which queries best mimic the data. These search queries can then serve to build an estimate of the true value of the phenomenon. We present the application of this method to produce accurate models of influenza activity and home refinance rate in the United States. We additionally show that spatial patterns in real world activity and temporal patterns in web search query activity can both surface interesting and useful correlations.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37686.html
notfound
=========================
Learning to Search Efficiently in High Dimensions
Neural Information Processing Systems (2011)
[u'Zhen Li', u'Huazhong Ning', u'Liangliang Cao', u'Tong Zhan', u'Yihong Gong', u'Thomas S. Huang']
InformationRetrievalandtheWeb
Abstract: High dimensional similarity search in large scale databases becomes an important challenge due to the advent of Internet. For such applications, specialized data structures are required to achieve computational efciency. Traditional approaches relied on algorithmic constructions that are often data independent (such as Locality Sensitive Hashing) or weakly dependent (such as kd-trees, k-means trees). While supervised learning algorithms have been applied to related problems, those proposed in the literature mainly focused on learning hash codes optimized for compact embedding of the data rather than search efciency. Consequently such an embedding has to be used with linear scan or another search algorithm. Hence learning to hash does not directly address the search efciency issue. This paper considers a new framework that applies supervised learning to directly optimize a data structure that supports efcient large scale search. Our approach takes both search quality and computational cost into consideration. Specically, we learn a boosted search forest that is optimized using pair-wise similarity labeled examples. The output of this search forest can be efciently converted into an inverted indexing data structure, which can leverage modern text search infrastructure to achieve both scalability and efciency. Experimental results show that our approach signicantly outperforms the start-of-the-art learning to hash methods (such as spectral hashing), as well as state-of-the-art high dimensional search algorithms (such as LSH and k-means trees).
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Modern Information Retrieval - the concepts and technology behind search, Second edition
Pearson Education Ltd., Harlow, England (2011)
[u'Ricardo A. Baeza-Yates', u'Berthier A. Ribeiro-Neto']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Recovering Semantics of Tables on the Web
Proceedings of the VLDB Endowment, vol. 4 (2011), pp. 528-538
[u'Petros Venetis', u'Alon Y. Halevy', u'Jayant Madhavan', u'Marius Pasca', u'Warren Shen', u'Fei Wu', u'Gengxin Miao']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Reputation Systems for Open Collaboration
Communications of the ACM, vol. 54 No. 8 (2011), pp. 81-87
[u'B.T. Adler', u'L. de Alfaro', u'A. Kulshrestra', u'I. Pye']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
The Future of Browsers - A Primer for HTML5 and Other Modern Browser Game Technologies
Game Developer Magazine, vol. 18 #5 (2011), pp. 35-41
[u'Vincent Scheib']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37669.html
notfound
=========================
The Need for Music Information Retrieval with User-Centered and Multimodal Strategies
MIRUM '11, ACM, Scottsdale, Arizona (2011), pp. 1-6
[u'Cynthia C.S. Liem', u'Meinard Mller', u'Douglas Eck', u'George Tzanetakis', u'Alan Hanjalic']
InformationRetrievalandtheWeb
Abstract: Music is a widely enjoyed content type, existing in many multifaceted representations. With the digital information age, a lot of digitized music information has theoretically become available at the users fingertips. However, the abundance of information is too large-scaled and too diverse to annotate, oversee and present in a consistent and human manner, motivating the development of automated Music Information Retrieval (Music-IR) techniques. In this paper, we encourage to consider music content beyond a monomodal audio signal and argue that Music-IR approaches with multimodal and user-centered strategies are necessary to serve reallife usage patterns and maintain and improve accessibility of digital music data. After discussing relevant existing work in these directions, we show that the eld of Music-IR faces similar challenges as neighboring elds, and thus suggest opportunities for joint collaboration and mutual inspiration.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37267.html
notfound
=========================
The Snap Framework: A Web Toolkit for Haskell
IEEE Internet Computing, vol. 15 (2011), pp. 84-87
[u'Gregory Collins', u'Doug Beardsley']
InformationRetrievalandtheWeb
Abstract: The authors discuss Web development in the Haskell programming language. They look at Snap, a simple, expressive Web development framework with an integrated, high-performance HTTP server.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Capacity Planning for Vertical Search Engines
CoRR, vol. abs/1006.5059 (2010)
[u'Claudine Santos Badue', u'Jussara M. Almeida', u'Virgilio Almeida', u'Ricardo A. Baeza-Yates', u'Berthier A. Ribeiro-Neto', u'Artur Ziviani', u'Nivio Ziviani']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36300.html
notfound
=========================
Children's Roles Using Keyword Search Interfaces in the Home
Proceedings of CHI 2010, ACM Press
[u'Allison Druin', u'Elizabeth Foss', u'Hilary Hutchinson', u'Evan Golub', u'Leshell Hatley']
InformationRetrievalandtheWeb
Abstract: Children want to find information about their world, but there are barriers to finding what they seek. Young people have varying abilities to formulate multi-step queries and comprehend search results. Challenges in understanding where to type, confusion about what tools are available, and frustration with how to parse the results page all have led to a lack of perceived search success for children 7-11 years old. In this paper, we describe seven search roles children display as information seekers using Internet keyword interfaces, based on a home study of 83 children ages 7, 9, and 11. These roles are defined not only by the childrens search actions, but also by who influences their searching, their perceived success, and trends in age and gender. These roles suggest a need for new interfaces that expand the notion of keywords, scaffold results, and develop a search culture among children.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36242.html
notfound
=========================
Clustering Query Refinements by User Intent
Proceedings of the International World Wide Web Conference (WWW) (2010)
[u'Eldar Sadikov', u'Jayant Madhavan', u'Lu Wang', u'Alon Halevy']
InformationRetrievalandtheWeb
Abstract: We address the problem of clustering the renements of a user search query. The clusters computed by our proposed algorithm can be used to improve the selection and placement of the query suggestions proposed by a search engine, and can also serve to summarize the different aspects of information relevant to the original user query. Our algorithm clusters renements based on their likely underlying user intents by combining document click and session co-occurrence information. At its core, our algorithm operates by performing multiple random walks on a Markov graph that approximates user search behavior. A user study performed on top search engine queries shows that our clusters are rated better than corresponding clusters computed using approaches that use only document click or only sessions co-occurrence information.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Combining Evidence with a Probabilistic Framework for Answer Ranking and Answer Merging in Question Answering
Information Processing and Management, vol. 46 (2010), pp. 541-554
[u'Jeongwoo Ko', u'Luo Si', u'Eric Nyberg']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Generalized Syntactic and Semantic Models of Query Reformulation
Proceedings of SIGIR-2010
[u'Amac Herdagdelen', u'Massimiliano Ciaramita', u'Daniel Mahler', u'Maria Holmqvist', u'Keith Hall', u'Stefan Riezler', u'Enrique Alfonseca']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36641.html
notfound
=========================
Google Squared: web scale, open domain information extraction and presentation
European Conference on Information Retrieval, Industry Day (2010)
[u'Dan Crow']
InformationRetrievalandtheWeb
Abstract: Google Squared performs open domain information extraction at massive scale. This paper gives an overview of the techniques used and the user interface developed to help users navigate complex information about multiple comparable entities.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37430.html
notfound
=========================
How Google is using Linked Data Today and Vision For Tomorrow
Proceedings of Linked Data in the Future Internet at the Future Internet Assembly (FIA 2010), Ghent, December 2010
[u'Thomas Steiner', u'Raphael Troncy', u'Michael Hausenblas']
InformationRetrievalandtheWeb
Abstract: In this position paper, we first discuss how modern search engines, such as Google, make use of Linked Data spread in Web pages for displaying Rich Snippets. We present an example of the technology and we analyze its current uptake. We then sketch some ideas on how Rich Snippets could be extended in the future, in particular for multimedia documents. We outline bottlenecks in the current Internet architecture that require fixing in order to enable our vision to work at Web scale.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Information Retrieval: Implementing and Evaluating Search Engines
MIT Press, Cambridge, MA (2010)
[u'Stefan Buettcher', u'Charles L. A. Clarke', u'Gordon V. Cormack']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35599.html
notfound
=========================
Personalized News Recommendation Based on Click Behavior
2010 International Conference on Intelligent User Interfaces
[u'Jiahui Liu', u'Elin Pedersen', u'Peter Dolan']
InformationRetrievalandtheWeb
Abstract: Online news reading has become very popular as the web provides access to news articles from millions of sources around the world. A key challenge of news service website is help users to find news articles that are interesting to read. In this paper, we present our research on developing personalized news recommendation system in Google News. The recommendation system builds profiles of users news interests based on users click behavior on the website. To understand the news interest change over time, we first conducted a large-scale log analysis of the click behavior of Google News users. Based on the log analysis, we developed a Bayesian framework for predict users current news interests, which considers both the activities of that particular user and the news trend demonstrated in activities of a group of users. We combine the information filtering mechanism using learned user profile with an existing collaborative filtering mechanism to generate personalized news recommendation. The combined method was deployed in Google News. Experiments on the live traffic of Google News website demonstrated that the combined method improves the quality of news recommendation and attracts more frequent visit to the website.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Probabilistic Models for Answer Ranking in Multilingual Question Answering
Transactions on Information Systems (2010)
[u'Jeongwoo Ko', u'Luo Si', u'Eric Nyberg', u'Teruko Mitamura']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37388.html
notfound
=========================
Quantitative Analysis of Culture Using Millions of Digitized Books
Science (2010)
[u'Jean-Baptiste Michel', u'Yuan Kui Shen', u'Aviva Presser Aiden', u'Adrian Veres', u'Matthew K. Gray', u'The Google Books Team', u'Joseph P. Pickett', u'Dale Holberg', u'Dan Clancy', u'Peter Norvig', u'Jon Orwant', u'Steven Pinker', u'Martin A. Nowak', u'Erez Lieberman Aiden']
InformationRetrievalandtheWeb
Abstract: We constructed a corpus of digitized texts containing about 4% of all books ever printed. Analysis of this corpus enables us to investigate cultural trends quantitatively. We survey the vast terrain of culturomics, focusing on linguistic and cultural phenomena that were reflected in the English language between 1800 and 2000. We show how this approach can provide insights about fields as diverse as lexicography, the evolution of grammar, collective memory, the adoption of technology, the pursuit of fame, censorship, and historical epidemiology. Culturomics extends the boundaries of rigorous quantitative inquiry to a wide array of new phenomena spanning the social sciences and the humanities.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Query Difficulty Prediction for Contextual Image Retrieval
32nd European Conference on Information Retrieval (ECIR'10) (2010)
[u'Xing Xing', u'Yi Zhang', u'Mei Han']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Query Rewriting using Monolingual Statistical Machine Translation
Computational Linguistics, vol. 36 (2010)
[u'Stefan Riezler', u'Yi Liu']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36583.html
notfound
=========================
Research trails: getting back where you left off
Proceedings of the 19th international conference on World Wide Web, ACM, Raleigh, North Carolina (2010), pp. 1151-1152
[u'Jiahui Liu', u'Peter Jin Hong', u'Elin Rnby Pedersen']
InformationRetrievalandtheWeb
Abstract: In this paper, we present a prototype system that helps users in early-stage web research to create and reestablish context across fragmented work process, without requiring them to explicitly collect and organize the material they visit. The system clusters a user's web history and shows it as research trails. We present two user interaction models with the research trails. The first interaction model is implemented as a standalone application, which presents a hierarchical view of research trails. The second interaction model is integrated with the web browser. It shows the user's research trails as selectable and manipulable visual streams when they open a new tab. Thereby, the NewTab page serves as a springboard in the browser for a user resuming an ongoing task.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Search flavours - recent updates and trends
SIGIR (2010)
[u'Yossi Matias']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36551.html
notfound
=========================
Shopping for Top Forums: Discovering Online Discussion for Product Research
KDD SOMA 2010 Workshop on Social Media Analytics
[u'Jonathan Elsas', u'Natalie Glance']
InformationRetrievalandtheWeb
Abstract: Community generated content, or social media, has become increasingly important over the past several years. Social media sites such as blogs, twitter and online discussion boards have been recognized as valuable sources of market intelligence for companies wishing to keep abreast of their customers' attitudes expressed online. There has been little focus, however, on providing a similar service to potential customers. In this paper we present a system for aiding consumers with their product research by providing access to community generated content. We focus specifically on online forums or message boards, which are particularly useful for product research. These web sites often host discussion among users with rst-hand product experiences, expert users and enthusiasts. The system presented here is designed to integrate with a shopping search portal, providing access to online forums that are likely to have a significant amount of discussion relating to a user's expressed interest in product brands and categories. We describe this system and present experiments showing that in the context of a shopping search engine, the proposed system is preferred or equivalent to results from a web search engine 80% of the time and achieves accuracy at the top ranked result of 85%.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Stochastic Models for Tabbed Browsing
Proceedings of the 19th international conference on World Wide Web, ACM, Raleigh, North Carolina (2010), pp. 241-250
[u'Flavio Chierichetti', u'Ravi Kumar', u'Andrew Tomkins']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36588.html
notfound
=========================
User browsing models: relevance versus examination
Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining, ACM, Washington, DC (2010), pp. 223-232
[u'Ramakrishnan Srikant', u'Sugato Basu', u'Ni Wang', u'Daryl Pregibon']
InformationRetrievalandtheWeb
Abstract: There has been considerable work on user browsing models for search engine results, both organic and sponsored. The click-through rate (CTR) of a result is the product of the probability of examination (will the user look at the result) times the perceived relevance of the result (probability of a click given examination). Past papers have assumed that when the CTR of a result varies based on the pattern of clicks in prior positions, this variation is solely due to changes in the probability of examination. We show that, for sponsored search results, a substantial portion of the change in CTR when conditioned on prior clicks is in fact due to a change in the relevance of results for that query instance, not just due to a change in the probability of examination. We then propose three new user browsing models, which attribute CTR changes solely to changes in relevance, solely to changes in examination (with an enhanced model of user behavior), or to both changes in relevance and examination. The model that attributes all the CTR change to relevance yields substantially better predictors of CTR than models that attribute all the change to examination, and does only slightly worse than the model that attributes CTR change to both relevance and examination. For predicting relevance, the model that attributes all the CTR change to relevance again does better than the model that attributes the change to examination. Surprisingly, we also find that one model might do better than another in predicting CTR, but worse in predicting relevance. Thus it is essential to evaluate user browsing models with respect to accuracy in predicting relevance, not just CTR.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Using structural information to improve search in Web collections
JASIST, vol. 61 (2010), pp. 2503-2513
[u'Edleno Silva de Moura', u'David Fernandes', u'Berthier A. Ribeiro-Neto', u'Altigran Soares da Silva', u'Marcos Andr Gonalves']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
What the web can't do
Proceedings of the 19th international conference on World Wide Web, ACM, Raleigh, North Carolina (2010), pp. 1341-1342
[u'David A. Shamma', u'Seth Fitzsimmonds', u'Joe Gregorio', u'Adam Hupp', u'Ramesh Jain', u'Kevin Marks']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
7th workshop on large-scale distributed systems for information retrieval (LSDS-IR'09)
SIGIR forum, vol. 43 (2009), pp. 34-40
[u'Claudio Lucchese', u'Gleb Skobeltsyn', u'Wai Gen Yee']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Simple Linear Ranking Algorithm Using Query Dependent Intercept Variables
ECIR 2009 (to appear)
[u'Nir Ailon']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35613.html
notfound
=========================
An Audio Indexing System for Election Video Material
Proceedings of ICASSP (2009), pp. 4873-4876
[u'Christopher Alberti', u'Michiel Bacchiani', u'Ari Bezman', u'Ciprian Chelba', u'Anastassia Drofa', u'Hank Liao', u'Pedro Moreno', u'Ted Power', u'Arnaud Sahuguet', u'Maria Shugrina', u'Olivier Siohan']
InformationRetrievalandtheWeb
Abstract: In the 2008 presidential election race in the United States, the prospective candidates made extensive use of YouTube to post video material. We developed a scalable system that transcribes this material and makes the content searchable (by indexing the meta-data and transcripts of the videos) and allows the user to navigate through the video material based on content. The system is available as an iGoogle gadget as well as a Labs product. Given the large exposure, special emphasis was put on the scalability and reliability of the system. This paper describes the design and implementation of this system.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36029.html
notfound
=========================
Answer typing for information retrieval
Proceeding of the 18th ACM conference on Information and knowledge management (CIKM), ACM, Hong Kong (2009), pp. 1955-1958
[u'Christopher Pinchak', u'Davood Rafiei', u'Dekang Lin']
InformationRetrievalandtheWeb
Abstract: Answer typing is commonly thought of as finding appropriate responses to given questions. We extend the notion of answer typing to information retrieval to ensure results contain plausible answers to queries. Identification of a large class of applicable queries is performed using a discriminative classifier, and discriminative preference ranking methods are employed for the selection of type-appropriate terms. Experimental results show that type-appropriate terms identified by the model are superior to terms most commonly associated with the query, providing strong evidence that answer typing techniques can find meaningful and appropriate terms. Further experiments show that snippets containing correct answers are ranked higher by our model than by the baseline Google search engine in those instances in which a query does indeed seek a short answer.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Challenges in building large-scale information retrieval systems: invited talk
WSDM '09: Proceedings of the Second ACM International Conference on Web Search and Data Mining, ACM, New York, NY, USA (2009), pp. 1-1
[u'Jeffrey Dean']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Do not crawl in the DUST: Different URLs with similar text
ACM Transactions on the Web, vol. 3 (2009), pp. 3
[u'Ziv Bar-Yossef', u'Idit Keidar', u'Uri Schonfeld']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Estimating the ImpressionRank of Web Pages
Proceedings of the 18th International Conference on World Wide Web (WWW) (2009), pp. 41-50
[u'Ziv Bar-Yossef', u'Maxim Gurevich']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Evaluating web search using task completion time
SIGIR '09: Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval, ACM, New York, NY, USA (2009), pp. 676-677
[u'Ya Xu', u'David Mease']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Expected reciprocal rank for graded relevance
CIKM '09: Proceeding of the 18th ACM conference on Information and knowledge management, ACM, New York, NY, USA (2009), pp. 621-630
[u'Olivier Chapelle', u'Donald Metlzer', u'Ya Zhang', u'Pierre Grinspan']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Fancy a Drink in Canary Wharf?: A User Study on Location-Based Mobile Search
INTERACT '09: Proceedings of the 12th IFIP TC 13 International Conference on Human-Computer Interaction, Springer-Verlag, Berlin, Heidelberg (2009), pp. 736-749
[u'Alia Amin', u'Sian Townsend', u'Jacco Ossenbruggen', u'Lynda Hardman']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Going Beyond Gzipping
Even Faster Web Sites, O'Reilly Media, Inc., 1005 Gravenstein Highway North, Sebastopol, CA 95472 (2009), pp. 121-132
[u'Tony Gentilcore']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35486.html
notfound
=========================
Good Abandonment in Mobile and PC Internet Search
32nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, ACM (Association for Computing Machinery), 2 Penn Plaza, Suite 701, New York 10121-0701 (2009), pp. 43-50
[u'Jane Li', u'Scott Huffman', u'Akihito Tokuda']
InformationRetrievalandtheWeb
Abstract: Query abandonment by search engine users is generally considered to be a negative signal. In this paper, we explore the concept of good abandonment. We define a good abandonment as an abandoned query for which the user's information need was successfully addressed by the search results page, with no need to click on a result or refine the query. We present an analysis of abandoned internet search queries across two modalities (PC and mobile) in three locales. The goal is to approximate the prevalence of good abandonment, and to identify types of information needs that may lead to good abandonment, across different locales and modalities. Our study has three key findings: First, queries potentially indicating good abandonment make up a significant portion of all abandoned queries. Second, the good abandonment rate from mobile search is significantly higher than that from PC search, across all locales tested. Third, classified by type of information need, the major classes of good abandonment vary dramatically by both locale and modality. Our findings imply that it is a mistake to uniformly consider query abandonment as a negative signal. Further, there is a potential opportunity for search engines to drive additional good abandonment, especially for mobile search users, by improving search features and result snippets.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Harnessing the Deep Web: Present and Future
Proceedings of the Conference on Innovative Data system Research (CIDR) (2009)
[u'Jayant Madhavan', u'Loredana Afanasiev', u'Lyublena Antova', u'Alon Halevy']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Harvesting Relational Tables from Lists on the Web
Proceedings of the VLDB Endowment (PVLDB) (2009), pp. 1078-1089
[u'Hazem Elmeleegy', u'Jayant Madhavan', u'Alon Halevy']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
High precision retrieval using relevance-flow graph
SIGIR '09: Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval, ACM, New York, NY, USA (2009), pp. 694-695
[u'Jangwon Seo', u'Jiwoon Jeon']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35388.html
found
=========================
How opinions are received by online communities: A case study on Amazon.com helpfulness votes
Proceedings of the 18th International Conference on World Wide Web, WWW 2009, Madrid, Spain, April 20-24, 2009, pp. 141-150
[u'Cristian Danescu-Niculescu-Mizil', u'Gueorgi Kossinets', u'Jon Kleinberg', u'Lillian Lee']
InformationRetrievalandtheWeb
Abstract: There are many on-line settings in which users publicly express opinions. A number of these offer mechanisms for other users to evaluate these opinions; a canonical example is Amazon.com, where reviews come with annotations like ``26 of 32 people found the following review helpful.'' Opinion evaluation appears in many off-line settings as well, including market research and political campaigns. Reasoning about the evaluation of an opinion is fundamentally different from reasoning about the opinion itself: rather than asking, ``What did Y think of X?'', we are asking, ``What did Z think of Y's opinion of X?'' Here we develop a framework for analyzing and modeling opinion evaluation, using a large-scale collection of Amazon book reviews as a dataset. We find that the perceived helpfulness of a review depends not just on its content but also but also in subtle ways on how the expressed evaluation relates to other evaluations of the same product. As part of our approach, we develop novel methods that take advantage of the phenomenon of review ``plagiarism'' to control for the effects of text in opinion evaluation, and we provide a simple and natural mathematical model consistent with our findings. Our analysis also allows us to distinguish among the predictions of competing theories from sociology and social psychology, and to discover unexpected differences in the collective opinion-evaluation behavior of user populations from different countries.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Incremental Crawling
Encyclopedia of Database Systems, Springer, New York (2009), pp. 1417-1421
[u'Kevin S. McCurley']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Information arbitrage across multi-lingual Wikipedia
WSDM '09: Proceedings of the Second ACM International Conference on Web Search and Data Mining, ACM, New York, NY, USA (2009), pp. 94-103
[u'Eytan Adar', u'Michael Skinner', u'Daniel S. Weld']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Information extraction meets relation databases
CIKM '09: Proceeding of the 18th ACM conference on Information and knowledge management, ACM, New York, NY, USA (2009), pp. 897-897
[u'Davood Rafiei', u'Andrei Broder', u'Edward Chang', u'Patrick Pantel']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36728.html
notfound
=========================
Modeling similarity in the age of data
MAA (2009)
[u'Kevin S. McCurley']
InformationRetrievalandtheWeb
Abstract: The process of applying mathematics to the real world is undergoing a radical change through our ability to gather data at a massive scale. This is particularly true at Google, where we routinely process petabytes of human language, and interact with many millions of users. In this talk I describe some surprising realizations that arose from this data while trying to improve part of our search quality. It turns out that everything I thought I knew about similarity was wrong, and I should have been talking to psychologists.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Reciprocal rank fusion outperforms condorcet and individual rank learning methods
SIGIR '09: Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval, ACM, New York, NY, USA (2009), pp. 758-759
[u'Gordon V. Cormack', u'Charles L A Clarke', u'Stefan Buettcher']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Search Engines: Information Retrieval in Practice
Addison Wesley (2009)
[u'W. Bruce Croft', u'Donald Metzler', u'Trevor Strohman']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
The impact of result abstracts on task completion time.
WWW 2009 Proceedings
[u'Rehan Khan', u'David Mease', u'Rajan Patel']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Topic and Trend Detection in Text Collections Using Latent Dirichlet Allocation
ECIR '09: Proceedings of the 31th European Conference on IR Research on Advances in Information Retrieval, Springer-Verlag, Berlin, Heidelberg (2009), pp. 776-780
[u'Levent Bolelli', u'eyda Ertekin', u'C. Lee Giles']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Using web information for author name disambiguation
JCDL (2009), pp. 49-58
[u'Denilson Alves Pereira', u'Berthier A. Ribeiro-Neto', u'Nivio Ziviani', u'Alberto H. F. Laender', u'Marcos Andr Gonalves', u'Anderson A. Ferreira']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35097.html
notfound
=========================
Web Derived Pronunciations for Spoken Term Detection
32nd Annual International ACM SIGIR Conference (2009), pp. 83-90
[u'Doan Can', u'Erica Cooper', u'Arnab Ghoshal', u'Martin Jansche', u'Sanjeev Khudanpur', u'Bhuvana Ramabhadran', u'Michael Riley', u'Murat Saralar', u'Abhinav Sethy', u'Morgan Ulinski', u'Christopher White']
InformationRetrievalandtheWeb
Abstract: Indexing and retrieval of speech content in various forms such as broadcast news, customer care data and on-line media has gained a lot of interest for a wide range of applications, from customer analytics to on-line media search. For most retrieval applications, the speech content is typically first converted to a lexical or phonetic representation using automatic speech recognition (ASR). The first step in searching through indexes built on these representations is the generation of pronunciations for named entities and foreign language query terms. This paper summarizes the results of the work conducted during the 2008 JHU Summer Workshop by the Multilingual Spoken Term Detection team, on mining the web for pronunciations and analyzing their impact on spoken term detection. We will first present methods to use the vast amount of pronunciation information available on the Web, in the form of IPA and ad-hoc transcriptions. We describe techniques for extracting candidate pronunciations from Web pages and associating them with orthographic words, filtering out poorly extracted pronunciations, normalizing IPA pronunciations to better conform to a common transcription standard, and generating phonemic representations from ad-hoc transcriptions. We then present an analysis of the effectiveness of using these pronunciations to represent Out-Of-Vocabulary (OOV) query terms on the performance of a spoken term detection (STD) system. We will provide comparisons of Web pronunciations against automated techniques for pronunciation generation as well as pronunciations generated by human experts. Our results cover a range of speech indexes based on lattices, confusion networks and one-best transcriptions at both word and word fragments levels.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36735.html
notfound
=========================
YouTube's Collaborative Annotations
Webcentives (2009), pp. 18-19
[u'Michael Fink', u'Sigalit Bar', u'Aviad Bazilai', u'Nir Kerem', u'Isaac Elias', u'Julian Frumar', u'Herb Ho', u'Ryan Junee', u'Simon Ratner', u'Jasson Schrock', u'Ran Tavory']
InformationRetrievalandtheWeb
Abstract: More and more YouTube videos no longer provide a passive viewing experience, but rather entice the viewer to interact with the video by clicking on objects with embedded links. These links are part of YouTubes Annotations system, which enables content owners to add active overlays on top of their videos. YouTube Annotation overlays also enable adding dynamic speech bubbles and pop-ups which can function as an ever-changing layer of supplementary information and entertainment, augmenting the video experience. This paper addresses the question of whether the ability to add annotation overlays on a given video should be opened to the YouTube public. The basic dilemma in opening a video to collaborative annotations is derived from the tension between the benefits of collaboration and the risks of visual clutter and spam. We term the degree to which a video is open to external contributions as the collaboration spectrum, and describe several models that let content owners to explore this spectrum in order to find the optimal way to harness the power of the masses.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Eye Monitoring in Online Search
Passive Eye Monitoring, Springer Verlag, 69121 Heidelberg, Germany (2008), pp. 283-304
[u'Laura A. Granka', u'Matthew Feusner', u'Lori Lorigo']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Generating Diverse Katakana Variants Based on Phenomic Mapping
Proc. 31st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, ACM, Singapore (2008), pp. 793-794
[u'Kazuhiro Seki', u'Hiroyuki Hattori', u'Kuniaki Uehara']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Generating Links by Mining Quotations
Hypertext, Pittsburgh, Pennsylvania, USA (2008), pp. 117-126
[u'Okan Kolak', u'Bill N. Schilit']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Google's Deep-Web Crawl
Proceedings of the International Conference on Very Large Databases (VLDB) (2008)
[u'Jayant Madhavan', u'David Ko', u'Lucja Kot', u'Vignesh Ganapathy', u'Alex Rasmussen', u'Alon Halevy']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
How evaluator domain expertise affects search result relevance
Conference on Information and Knowledge Management (2008), pp. 591-598
[u'Kenneth A. Kinney', u'Scott B. Huffman', u'Juting Zhai']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Income Inequality in the Attention Economy
Google, Inc. (2008)
[u'Kevin S. McCurley']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Learning From Labeled Features Using Generalized Expectation Criteria
Proc. 31st International ACM SIGIR Conference on Research and Development in Information Retrieval, ACM, Singapore (2008), pp. 595-602
[u'Gregory Druck', u'Gideon Mann', u'Andrew McCallum']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Local Approximation of PageRank and Reverse PageRank
Proceedings of the 17th ACM Conference on Information and Knowledge Management (CIKM) (2008), pp. 279-288
[u'Ziv Bar-Yossef', u'Li-Tal Mashiach']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Microscale Evolution of Web Pages
WWW 2008
[u"Sean O'Brien", u'Carrie Grimes']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Mining Search Engine Query Logs via Suggestion Sampling
Proceedings of the VLDB Endowment (2008), pp. 54-65
[u'Ziv Bar-Yossef', u'Maxim Gurevich']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Next-generation Digital Earth. A position paper from the Vespucci Initiative for the Advancement of Geographic Information Science
International Journal of Spatial Data Infrastructure Research, vol. 3 (2008), pp. 146-167
[u'M. Craglia', u'M.F. Goodchild', u'A. Annoni', u'G. Camara', u'M. Gould', u'W. Kuhn', u'D.M. Mark', u'I. Masser', u'D.J. Maguire', u'S. Liang', u'E. Parsons']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Random sampling from a search engine's index
Journal of the ACM, vol. 55 (2008)
[u'Ziv Bar-Yossef', u'Maxim Gurevich']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Retrieval models for question and answer archives
SIGIR (2008), pp. 475-482
[u'Xiaobing Xue', u'Jiwoon Jeon', u'W. Bruce Croft']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Rich Media and Web 2.0
Proc. 17th International Conference on World Wide Web, ACM, Beijing (2008), pp. 1259-1259
[u'Edward Chang', u'Ken Ong', u'Susanne Boll', u'Wei-Ying Ma']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
The Mobile Web is Structurally Different
11th IEEE Global Internet Symposium (2008)
[u'Apoorva Jindal', u'Chris Crutchfied', u'Samir Goel', u'Ravi Jain', u'Ravi Kolluri']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34382.html
notfound
=========================
Translating Queries into Snippets for Improved Query Expansion
Proceedings of the 22nd International Conference on Computational Linguistics (COLING'08), Manchester, England (2008)
[u'Stefan Riezler', u'Yi Liu', u'Alexander Vasserman']
InformationRetrievalandtheWeb
Abstract: User logs of search engines have recently been applied successfully to improve various aspects of web search quality. In this paper, we will apply pairs of user queries and snippets of clicked results to train a machine translation model to bridge the ``lexical gap'' between query and document space. We show that the combination of a query-to-snippet translation model with a large n-gram language model trained on queries achieves improved contextual query expansion compared to a system based on term correlations.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Using Web Information for Creating Publication Venue Authority Files
Proc. ACM/IEEE Joint Conference on Digital Libraries, ACM, Pittsburgh (2008), pp. 295-304
[u'Denilson Alves Pereira', u'Berthier Ribeiro-Neto', u'Nivio Ziviani', u'Alberto H. F. Laender']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
WCAG 2.0: A Web Accessibility Standard for the Evolving Web
Proceedings of the 2008 Internationl Cross-disciplinary Conference on Web Accessibility (W4A)
[u'Loretta Guarino Reid', u'Andi Snow-Weaver']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Web-scale extraction of structured data.
SIGMOD Record, vol. 37(4) (2008), pp. 55-61
[u'Michael Cafarella', u'Jayant Madhavan', u'Alon Halevy']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Fact/Opinion Classifier for News Articles
Proc. 30th SIGIR, ACM, Amsterdam (2007), pp. 807-808
[u'Adam Stepinksi', u'Vibhu Mittal']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
ASAP: An Advertisement-based Search Algorithm for Unstructured Peer-to-peer Systems
Proc. International Conference on Parallel Processing (ICPP), IEEE Computer Society (2007), pp. 8
[u'Peng Gu', u'Jun Wang', u'Hailong Cai']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Analyzing imbalance among homogeneous index servers in a web search system
Inf. Process. Manage., vol. 43 (2007), pp. 592-608
[u'Claudine Santos Badue', u'Ricardo A. Baeza-Yates', u'Berthier A. Ribeiro-Neto', u'Artur Ziviani', u'Nivio Ziviani']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Automatic and Versatile Publications Ranking for Research Institutions and Scholars
Communications of the ACM, vol. 50, no. 6 (2007), pp. 81-85
[u'Jie Ren', u'Richard N. Taylor']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Corroborate and learn facts from the web
Proceedings of the 13th ACM SIGKDD international conference on Knowledge discovery and data mining, ACM, San Jose (2007), pp. 995-1003
[u'Shubin Zhao', u'Jonathan Betz']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Detecting near-duplicates for web crawling
WWW 2007 (16th International Conference on the World Wide Web), ACM, Banff, pp. 141-150
[u'Gurmeet Singh Manku', u'Arvind Jain', u'Anish Das Sarma']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Do Not Crawl in the DUST: Different URLs with Similar Text
WWW (2007), pp. 111-120
[u'Ziv Bar-Yossef', u'Idit Keidar', u'Uri Schonfeld']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Efficient Search Engine Measurements
WWW (2007), pp. 401-410
[u'Ziv Bar-Yossef', u'Maxim Gurevich']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Efficient Search Ranking in Social Networks
Proc. CIKM, ACM, Lisboa, Portugal (2007)
[u'Monique V. Vieira', u'Bruno M. Fonseca', u'Rodrigo Damazio', u'Paulo B. Golgher', u'Davi de Castro Reis', u'Berthier Ribeiro-Neto']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Google News Personalization: Scalable Online Collaborative Filtering
Proceedings of WWW 2007, pp. 271-280
[u'Abhinandan Das', u'Mayur Datar', u'Ashutosh Garg', u'Shyam Rajaram']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
How well does result relevance predict session satisfaction?
Proceedings of the 30th annual international ACM SIGIR, ACM, Amsterdam (2007), pp. 567-574
[u'Scott B. Huffman', u'Michael Hochster']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Learning people annotation from the web via consistency learning
Proc. international Workshop on Multimedia Information Retrieval, ACM, Augsberg, Germany (2007), pp. 285-290
[u'Jay Yagnik', u'Atig Islam']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Multiple-Signal Duplicate Detection for Search Evaluation
Proceedings of 30th Annual International ACM SIGIR Conference, ACM (2007), pp. 223-230
[u'Scott Huffman', u'April Lehman', u'Alexei Stolboushkin', u'Howard Wong-Toi', u'Fan Yang', u'Hein Roehrig']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Query logs alone are not enough
WWW 2007 Workshop on Query Log Analysis: Social and Technological Changes
[u'Carrie Grimes', u'Diane Tang', u'Daniel Russell']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub32707.html
notfound
=========================
Statistical Machine Translation for Query Expansion in Answer Retrieval
Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics (ACL'07), Prague, Czech Republic (2007)
[u'Stefan Riezler', u'Alexander Vasserman', u'Ioannis Tsochantaridis', u'Vibhu Mittal', u'Yi Liu']
InformationRetrievalandtheWeb
Abstract: This paper presents a novel approach to query expansion in answer retrieval that uses Statistical Machine Translation (SMT) techniques to bridge the lexical gap between questions and answers. SMT-based query expansion is performed on the one hand by using a SMT-based full-sentence paraphraser to introduce synonyms in the context the full query, and on the other hand by training an SMT model on question-answer pairs and expanding queries by answer terms taken from translations of full queries. We compare these global, context-aware query expansion techniques with a baseline tfidf model and local query expansion on a database of 10 million question-answer pairs extracted from FAQ pages. Experimental results show a significant improvement of SMT-based query expansion over both baselines.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Web-based Kernel Function for Measuring the Similarity of Short Text Snippets
Proceedings of the Fifteenth International World Wide Web Conference, Edinburgh, Scotland (2006), pp. 377-386
[u'Mehran Sahami', u'Tim Heilman']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A comparative study of citations and links in document classification
JCDL (2006), pp. 75-84
[u'Thierson Couto', u'Marco Cristo', u'Marcos Andr', u'P', u'Nivio Ziviani', u'Edleno Silva de Moura', u'Berthier A. Ribeiro-Neto']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Browsing on Small Screens: Recasting Web-Page Segmentation into an Efficient Machine Learning Framework
Proceedings of the Fifteenth International World Wide Web Conference, Edinburgh, Scotland (2006)
[u'Shumeet Baluja']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Finding Near-Duplicate Web Pages: A Large-Scale Evaluation of Algorithms
Proc. SIGIR, ACM (2006)
[u'Monika Henzinger']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Identity management on converged networks: a reality check
WWW (2006), pp. 747
[u'Arnaud Sahuguet', u'Stefan Brands', u'Kim Cameron', u'Cahill Conor', u'Aude Pichelin', u'Fulup Ar Foll', u'Mike Neuenschwander']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Indexing Shared Content in Information Retrieval Systems
EDBT (2006), pp. 313-330
[u'Andrei Z. Broder', u'Nadav Eiron', u'Marcus Fontoura', u'Michael Herscovici', u'Ronny Lempel', u'John McPherson', u'Runping Qi', u'Eugene J. Shekita']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Introduction to the special issue on XML retrieval
ACM Transactions on Information Systems, vol. 24 (2006), pp. 405-406
[u'Ricardo Baeza-Yates', u'Norbert Fuhr', u'Yoelle Maarek']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Learning to Advertise
Proc. SIGIR, ACM Press, Seattle (2006), pp. 549-556
[u'Ansio Lacerda', u'Marco Cristo', u'Marcos Andr Gonalves', u'Weiguo Fan', u'Nivio Ziviani', u'Berthier Ribeiro-Neto']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Retroactive Answering of Search Queries
Proc. International World Wide Web Conference, ACM, Edinburgh, Scotland (2006), pp. 457-466
[u'Beverly Yang', u'Glen Jeh']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Semantic Search via XML Fragments: A High Precision Approach to IR
Proc. 29th ACM SIGIR Conference on Research and Development in Information Retrieval, ACM, Seattle, WA (2006), pp. 445-452
[u'Jennifer Chu-Carroll', u'John Prager', u'Krzysztof Czuba', u'David Ferrucci', u'Pablo Duboue']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34631.html
notfound
=========================
The Mobile Web in Developing Countries
W3C Workshop on the Mobile Web in Developing Countries, W3C, W3C (2006)
[u'Ravi Jain']
InformationRetrievalandtheWeb
Abstract: The mobile web in developing countries has received increasing attention within the last few years, both as a potential means of bridging the digital divide as well as a lucrative market opportunity. However, while the realized gains so far as well as the potential are indeed tremendous, significant challenges remain to be overcome. Mobile data usage, particularly for advanced data applications, faces difficulties that are different from those posed by the initial expansion of voice services. The needs and environments of developing countries are very diverse, with as many significant differences perhaps as similarities, making it difficult to replicate country-specific solutions. In addition, while one traditional migration route of functionality from the desktop to the handheld may be viable in the industrialized world, it is not clear that this is the likely best approach in developing countries. What does seem clear is that there is a definite and significant need for further research examining the characteristics and challenges of the mobile web in developing countries at all layers, ranging from applications to networking. We sketch examples of such research issues, and mention specific roles the W3C could potentially play. This brief position paper presents these hypotheses with the goal of stimulating discussion at the workshop.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Using annotations in enterprise search
WWW (2006), pp. 811-817
[u'Pavel A. Dmitriev', u'Nadav Eiron', u'Marcus Fontoura', u'Eugene Shekita']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Web mining with search engines: A web-based kernel function for measuring the similarity of short text snippets
Proc. 15th International World Wide Web Conference, ACM, Edinburgh, Scotland (2006), pp. 377-386
[u'Mehran Sahami', u'Timothy D. Heilman']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Challenges in running a commercial search engine
SIGIR (2005), pp. 432
[u'Amit Singhal']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Concept-based interactive query expansion
CIKM (2005), pp. 696-703
[u'Bruno M. Fonseca', u'Paulo Braz Golgher', u'Bruno Possas', u'Berthier A. Ribeiro-Neto', u'Nivio Ziviani']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Current trends in the integration of searching and browsing
WWW (Special interest tracks and posters) (2005), pp. 793
[u'Andrei Z. Broder', u'Yoelle S. Maarek', u'Krishna Bharat', u'Susan T. Dumais', u'Steve Papa', u'Jan O. Pedersen', u'Prabhakar Raghavan']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Hyperlink analysis on the world wide web
Hypertext (2005), pp. 1-3
[u'Monika Rauch Henzinger']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Information Discovery-Needles and Haystacks
IEEE Internet Computing, vol. 9 (2005), pp. 16-18
[u'Carl Lagoze', u'Amit Singhal']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Thresher: automating the unwrapping of semantic content from the World Wide Web
WWW '05: Proceedings of the 14th international conference on World Wide Web, ACM Press, New York, NY, USA (2005), pp. 86-95
[u'Andrew Hogue', u'David Karger']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Algorithmic Aspects of Web Search Engines
ESA (2004), pp. 3
[u'Monika Rauch Henzinger']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Internet Searching
Computer Science: Reflections on the Field, Reflections from the Field, Computer Science and Telecommunications Board of the National Academies (2004)
[u'Peter Norvig']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
The Happy Searcher: Challenges in Web Information Retrieval
The Eighth Pacific Rim International Conference on Artificial Intelligence (PRICAI-2004)
[u'Mehran Sahami', u'Vibhu Mittal', u'Shumeet Baluja', u'Henry A. Rowley']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
The Past, Present and Future of Web Information Retrieval
PODS (2004), pp. 46
[u'Monika Rauch Henzinger']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
The Past, Present, and Future of Web Search Engines
ICALP (2004), pp. 3
[u'Monika Rauch Henzinger']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Extracting knowledge from the World Wide Web
Mapping Knowledge Domains, National Academy of Sciences, USA, Irvine, CA (2003)
[u'Monika Henzinger', u'Steve Lawrence']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Patterns on the Web
SPIRE (2003), pp. 1-15
[u'Krishna Bharat']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Query-Free News Search
Proceedings of the 12th International World Wide Web Conference (WWW-2003), Budapest, Hungary
[u'Monika Henzinger', u'Bay-Wei Chang', u'Brian Milch', u'Sergey Brin']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
eBizSearch: An OAI-Compliant Digital Library for eBusiness
JCDL (2003), pp. 199-209
[u'Yves Petinot', u'Pradeep B. Teregowda', u'Hui Han', u'C. Lee Giles', u'Steve Lawrence', u'Arvind Rangaswamy', u'Nirmal Pal']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
eBizSearch: a niche search engine for e-business
SIGIR (2003), pp. 413-414
[u'C. Lee Giles', u'Yves Petinot', u'Pradeep B. Teregowda', u'Hui Han', u'Steve Lawrence', u'Arvind Rangaswamy', u'Nirmal Pal']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Modern Information Retrieval: A Brief Overview
IEEE Data Eng. Bull., vol. 24 (2001), pp. 35-43
[u'Amit Singhal']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Who Links to Whom: Mining Linkage between Web Sites
IEEE International Conference on Data Mining (ICDM '01), San Jose, CA (2001)
[u'Krishna Bharat', u'Bay-Wei Chang', u'Monika Henzinger', u'Matthias Ruhl']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Comparison of Techniques to Find Mirrored Hosts on the WWW
JASIS, vol. 51 (2000), pp. 1114-1122
[u'Krishna Bharat', u'Andrei Z. Broder', u'Jeffrey Dean', u'Monika Rauch Henzinger']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
The Anatomy of a Large-Scale Hypertextual Web Search Engine
Computer Networks, vol. 30 (1998), pp. 107-117
[u'Sergey Brin', u'Lawrence Page']
InformationRetrievalandtheWeb
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/MachineIntelligence.html
found
=========================
Hierarchical Label Propagation and Discovery for Machine Generated Email
Proceedings of the International Conference on Web Search and Data Mining (WSDM) (2016) (to appear)
[u'James B. Wendt', u'Michael Bendersky', u'Lluis Garcia-Pueyo', u'Vanja Josifovski', u'Balint Miklos', u'Ivo Krka', u'Amitabh Saikia', u'Jie Yang', u'Marc-Allen Cartright', u'Sujith Ravi']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43912.html
notfound
=========================
A Gaussian Mixture Model Layer Jointly Optimized with Discriminative Features within A Deep Neural Network Architecture
ICASSP, IEEE (2015)
[u'Ehsan Variani', u'Erik McDermott', u'Georg Heigold']
MachineIntelligence
Abstract: This article proposes and evaluates a Gaussian Mixture Model (GMM) represented as the last layer of a Deep Neural Network (DNN) architecture and jointly optimized with all previous layers using Asynchronous Stochastic Gradient Descent (ASGD). The resulting Deep GMM architecture was investigated with special attention to the following issues: (1) The extent to which joint optimization improves over separate optimization of the DNN-based feature extraction layers and the GMM layer; (2) The extent to which depth (measured in number of layers, for a matched total number of parameters) helps a deep generative model based on the GMM layer, compared to a vanilla DNN model; (3) Head-to-head performance of Deep GMM architectures vs. equivalent DNN architectures of comparable depth, using the same optimization criterion (frame-level Cross Entropy (CE)) and optimization method (ASGD); (4) Expanded possibilities for modeling offered by the Deep GMM generative model. The proposed Deep GMMs were found to yield Word Error Rates (WERs) competitive with state-of-the-art DNN systems, at the cost of pre-training using standard DNNs to initialize the Deep GMM feature extraction layers. An extension to Deep Subspace GMMs is described, resulting in additional gains.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Adaptation algorithm and theory based on generalized discrepancy
Proceedings of the 21st ACM Conference on Knowledge Discovery and Data Mining (KDD 2015)
[u'Corinna Cortes', u'Mehryar Mohri', u'Andrs Muoz Medina']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43424.html
found
=========================
Adding Third-Party Authentication to Open edX: A Case Study
Proceedings of the Second (2015) ACM Conference on Learning @ Scale, ACM, New York, NY, USA, pp. 277-280
[u'John Cox', u'Pavel Simakov']
MachineIntelligence
Abstract: In this document, we describe the third-party authentication system we added to Open edX. With this system, Open edX administrators can allow their users to sign in with a large array of external authentication providers. We outline the features and advantages of the system, describe how it can be extended and customized, and highlight reusable design principles that can be applied to other authentication implementations in online education.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43993.html
notfound
=========================
An Exploration of Parameter Redundancy in Deep Networks with Circulant Projections
International Conference on Computer Vision (ICCV) (2015)
[u'Yu Cheng', u'Felix X. Yu', u'Rogerio Feris', u'Sanjiv Kumar', u'Shih-Fu Chang']
MachineIntelligence
Abstract: We explore the redundancy of parameters in deep neural networks by replacing the conventional linear projection in fully-connected layers with the circulant projection. The circulant structure substantially reduces memory footprint and enables the use of the Fast Fourier Transform to speed up the computation. Considering a fully-connected neural network layer with d input nodes, and d output nodes, this method improves the time complexity from O(d^2) to O(dlogd) and space complexity from O(d^2) to O(d). The space savings are particularly important for modern deep convolutional neural network architectures, where fully-connected layers typically contain more than 90% of the network parameters. We further show that the gradient computation and optimization of the circulant projections can be performed very efficiently. Our experiments on three standard datasets show that the proposed approach achieves this significant gain in storage and efficiency with minimal increase in error rate compared to neural networks with unstructured projections.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43988.html
notfound
=========================
Approximating the Effects of Installed Traffic Lights: A Behaviorist Approach Based on Travel Tracks
International Conference on Intelligent Transportation Systems (2015)
[u'Shumeet Baluja', u'Michele Covell', u'Rahul Sukthankar']
MachineIntelligence
Abstract: Decades of research have been directed towards improving the timing of existing traffic lights. In many parts of the world where this research has been conducted, detailed maps of the streets and the precise locations of the traffic lights are publicly available. Continued timing research has recently been further spurred by the increasing ubiquity of personal cell-phone based GPS systems. Through their use, an enormous amount of travel tracks have been amassed thus providing an easy source of real traffic data. Nonetheless, one fundamental piece of information remains absent that limits the quantification of the benefits of new approaches: the existing traffic light schedules and traffic light response behaviors. Unfortunately, deployed traffic light schedules are often not known. Rarely are they kept in a central database, and even when they are, they are often not easily obtainable. The alternative, manual inspection of a system of multiple traffic lights may be prohibitively expensive and time-consuming for many experimenters. Without the existing light schedules, it is difficult to ascertain the real-improvements that new traffic light algorithms and approaches will have especially on traffic patterns that have not yet been encountered in the collected data. To alleviate this problem, we present an approach to estimating existing traffic light schedules based on collected GPS-travel tracks. We present numerous ways to test the results and comprehensively demonstrate them on both synthetic and real data. One of the many uses, beyond studying the effects of existing lights in previously unencountered traffic flow environments, is to serve as a realistic baseline for light timing and schedule optimization studies.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43793.html
notfound
=========================
Beyond Short Snippets: Deep Networks for Video Classification
Computer Vision and Pattern Recognition (2015)
[u'Joe Yue-Hei Ng', u'Matthew Hausknecht', u'Sudheendra Vijayanarasimhan', u'Oriol Vinyals', u'Rajat Monga', u'George Toderici']
MachineIntelligence
Abstract: Convolutional neural networks (CNNs) have been extensively applied for image recognition problems giving state-of-the-art results on recognition, detection, segmentation and retrieval. In this work we propose and evaluate several deep neural network architectures to combine image information across a video over longer time periods than previously attempted. We propose two methods capable of handling full length videos. The first method explores various convolutional temporal feature pooling architectures, examining the various design choices which need to be made when adapting a CNN for this task. The second proposed method explicitly models the video as an ordered sequence of frames. For this purpose we employ a recurrent neural network that uses Long Short-Term Memory (LSTM) cells which are connected to the output of the underlying CNN. Our best networks exhibit significant performance improvements over previously published results on the Sports 1 million dataset (73.1% vs. 60.9%) and the UCF-101 datasets with (88.6% vs. 88.0%) and without additional optical flow information (82.6% vs. 72.8%).
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Context dependent phone models for LSTM RNN acoustic modelling
ICASSP (2015), pp. 4585-4589
[u'Andrew W. Senior', u'Hasim Sak', u'Izhak Shafran']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Convolutional, Long Short-Term Memory, Fully Connected Deep Neural Networks
ICASSP (2015)
[u'Tara Sainath', u'Oriol Vinyals', u'Andrew Senior', u'Hasim Sak']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43812.html
notfound
=========================
Diagnosing Automatic Whitelisting for Dynamic Remarketing Ads Using Hybrid ASP
Francesco Calimeri, Giovambattista Ianni, Miroslaw Truszczynski. Logic Programming and Nonmonotonic Reasoning, 13th International Conference, LPNMR 2015, Lexington, September 27-30, 2015. Proceedings., Springer International Publishing AG, Gewerbestrasse 11, CH-6330 Cham (ZG), Switzerland, t.b.d. (to appear)
[u'Alex Brik', u'Jeffrey Remmel']
MachineIntelligence
Abstract: Hybrid ASP (H-ASP) is an extension of ASP that allows users to combine ASP type rules and numerical algorithms. Dynamic Remarketing Ads is Googles platform for serving customized ads based on past interactions with a user. In this paper we will describe the use of H-ASP to diagnose failures of the automatic whitelisting system for Dynamic Remarketing Ads. We will show that the diagnosing task is an instance of a computational pattern that we call the Branching Computational Pattern (BCP). We will then describe a Python H-ASP library (H-ASP PL) that allows to perform computations using a BCP, and we will describe a H-ASP PL program that solves the diagnosing problem.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43251.html
notfound
=========================
Efficient Inference and Structured Learning for Semantic Role Labeling
Transactions of the Association for Computational Linguistics, vol. 3 (2015), pp. 29-41
[u'Oscar Tckstrm', u'Kuzman Ganchev', u'Dipanjan Das']
MachineIntelligence
Abstract: We present a dynamic programming algorithm for efficient constrained inference in semantic role labeling. The algorithm tractably captures a majority of the structural constraints examined by prior work in this area, which has resorted to either approximate methods or off-the-shelf integer linear programming solvers. In addition, it allows training a globally-normalized log-linear model with respect to constrained conditional likelihood. We show that the dynamic program is several times faster than an off-the-shelf integer linear programming solver, while reaching the same solution. Furthermore, we show that our structured model results in significant improvements over its local counterpart, achieving state-of-the-art results on both PropBank- and FrameNet-annotated corpora.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Embedding Inference for Structured Multilabel Prediction
Advances in Neural Information Processing Systems (2015) (to appear)
[u'Farzaneh Mirzazadeh', u'Siamak Ravanbakhsh', u'Bing Xu', u'Nan Ding', u'Dale Schuurmans']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Explaining and Harnessing Adversarial Examples
International Conference on Learning Representations (2015)
[u'Ian Goodfellow', u'Jonathon Shlens', u'Christian Szegedy']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43992.html
notfound
=========================
Fast Orthogonal Projection Based on Kronecker Product
International Conference on Computer Vision (ICCV) (2015)
[u'Xu Zhang', u'Felix X. Yu', u'Ruiqi Guo', u'Sanjiv Kumar', u'Shengjin Wang', u'Shih-Fu Chang']
MachineIntelligence
Abstract: We propose a family of structured matrices to speed up orthogonal projections for high-dimensional data commonly seen in computer vision applications. In this, a structured matrix is formed by the Kronecker product of a series of smaller orthogonal matrices. This achieves O(dlogd) computational complexity and O(logd) space complexity for d-dimensional data, a drastic improvement over the standard unstructured projections whose computational and space complexities are both O(d^2). We also introduce an efficient learning procedure for optimizing such matrices in a data dependent fashion. We demonstrate the significant advantages of the proposed approach in solving the approximate nearest neighbor (ANN) image search problem with both binary embedding and quantization. Comprehensive experiments show that the proposed approach can achieve similar or better accuracy as the existing state-of-the-art but with significantly less time and memory.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Fast and Accurate Recurrent Neural Network Acoustic Models for Speech Recognition
CoRR, vol. abs/1507.06947 (2015)
[u'Hasim Sak', u'Andrew W. Senior', u'Kanishka Rao', u'Franoise Beaufays']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44310.html
found
=========================
Federated Optimization: Distributed Optimization Beyond the Datacenter
NIPS Optimization for Machine Learning Workshop (2015), pp. 5
[u'Jakub Konen', u'H. Brendan McMahan', u'Daniel Ramage']
MachineIntelligence
Abstract: We introduce a new and increasingly relevant setting for distributed optimization in machine learning, where the data defining the optimization are distributed (unevenly) over an extremely large number of nodes, but the goal remains to train a high-quality centralized model. We refer to this setting as Federated Optimization. In this setting, communication efficiency is of utmost importance. A motivating example for federated optimization arises when we keep the training data locally on users' mobile devices rather than logging it to a data center for training. Instead, the mobile devices are used as nodes performing computation on their local data in order to update a global model. We suppose that we have an extremely large number of devices in our network, each of which has only a tiny fraction of data available totally; in particular, we expect the number of data points available locally to be much smaller than the number of devices. Additionally, since different users generate data with different patterns, we assume that no device has a representative sample of the overall distribution. We show that existing algorithms are not suitable for this setting, and propose a new algorithm which shows encouraging experimental results. This work also sets a path for future research needed in the context of federated optimization.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43022.html
notfound
=========================
Going Deeper with Convolutions
CVPR 2015
[u'Christian Szegedy', u'Wei Liu', u'Yangqing Jia', u'Pierre Sermanet', u'Scott Reed', u'Dragomir Anguelov', u'Dumitru Erhan', u'Vincent Vanhoucke', u'Andrew Rabinovich']
MachineIntelligence
Abstract: We propose a deep convolutional neural network architecture codenamed Inception that achieves the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC2014). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. By a carefully crafted design, we increased the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation of this architecture, GoogLeNet, a 22 layers deep network, was used to assess its quality in the context of object detection and classification.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Grapheme-to-Phoneme Conversion Using Long Short-Term Memory Recurrent Neural Networks
ICASSP (2015)
[u'Kanishka Rao', u'Fuchun Peng', u'Hasim Sak', u'Franoise Beaufays']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43807.html
found
=========================
Improving User Topic Interest Profiles by Behavior Factorization
Proceedings of the 24th International Conference on World Wide Web, International World Wide Web Conferences Steering Committee, Republic and Canton of Geneva, Switzerland (2015), pp. 1406-1416
[u'Zhe Zhao', u'Zhiyuan Cheng', u'Lichan Hong', u'Ed H. Chi']
MachineIntelligence
Abstract: Many recommenders aim to provide relevant recommendations to users by building personal topic interest profiles and then using these profiles to find interesting contents for the user. In social media, recommender systems build user profiles by directly combining users' topic interest signals from a wide variety of consumption and publishing behaviors, such as social media posts they authored, commented on, +1'd or liked. Here we propose to separately model users' topical interests that come from these various behavioral signals in order to construct better user profiles. Intuitively, since publishing a post requires more effort, the topic interests coming from publishing signals should be more accurate of a user's central interest than, say, a simple gesture such as a +1. By separating a single user's interest profile into several behavioral profiles, we obtain better and cleaner topic interest signals, as well as enabling topic prediction for different types of behavior, such as topics that the user might +1 or comment on, but might never write a post on that topic. To do this at large scales in Google+, we employed matrix factorization techniques to model each user's behaviors as a separate example entry in the input user-by-topic matrix. Using this technique, which we call "behavioral factorization", we implemented and built a topic recommender predicting user's topical interests using their actions within Google+. We experimentally showed that we obtained better and cleaner signals than baseline methods, and are able to more accurately predict topic interests as well as achieve better coverage.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44019.html
notfound
=========================
Large-scale, sequence-discriminative, joint adaptive training for masking-based robust ASR
INTERSPEECH-2015, ISCA, pp. 3571-3575
[u'Arun Narayanan', u'Ananya Misra', u'Kean Chin']
MachineIntelligence
Abstract: Recently, it was shown that the performance of supervised time-frequency masking based robust automatic speech recognition techniques can be improved by training them jointly with the acoustic model [1]. The system in [1], termed deep neural network based joint adaptive training, used fully-connected feed-forward deep neural networks for estimating time-frequency masks and for acoustic modeling; stacked log mel spectra was used as features and training minimized cross entropy loss. In this work, we extend such jointly trained systems in several ways. First, we use recurrent neural networks based on long short-term memory (LSTM) units this allows the use of unstacked features, simplifying joint optimization. Next, we use a sequence discriminative training criterion for optimizing parameters. Finally, we conduct experiments on large scale data and show that joint adaptive training can provide gains over a strong baseline. Systematic evaluations on noisy voice-search data show relative improvements ranging from 2% at 15 dB to 5.4% at -5 dB over a sequence discriminative, multi-condition trained LSTM acoustic model.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Learning acoustic frame labeling for speech recognition with recurrent neural networks
ICASSP (2015), pp. 4280-4284
[u'Hasim Sak', u'Andrew W. Senior', u'Kanishka Rao', u'Ozan Irsoy', u'Alex Graves', u'Franoise Beaufays', u'Johan Schalkwyk']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Learning semantic relationships for better action retrieval in images
CVPR (2015)
[u'Vignesh Ramanathan', u'Congcong Li', u'Jia Deng', u'Wei Han', u'Zhen Li', u'Kunlong Gu', u'Yang Song', u'Samy Bengio', u'Chuck Rosenberg', u'Li Fei-Fei']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43977.html
notfound
=========================
Learning with Deep Cascades
Proceedings of the Twenty-Sixth International Conference on Algorithmic Learning Theory (ALT 2015) (to appear)
[u'Giulia DeSalvo', u'Mehryar Mohri', u'Umar Syed']
MachineIntelligence
Abstract: We introduce a broad learning model formed by cascades of predictors, Deep Cascades, that is structured as general decision trees in which leaf predictors or node questions may be members of rich function families. We present new detailed data-dependent theoretical guarantees for learning with Deep Cascades with complex leaf predictors or node question in terms of the Rademacher complexities of the sub-families composing these sets of predictors and the fraction of sample points correctly classified at each leaf. These general guarantees can guide the design of a variety of different algorithms for deep cascade models and we give a detailed description of two such algorithms. Our second algorithm uses as node and leaf classifiers SVM predictors and we report the results of experiments comparing its performance with that of SVM combined with polynomial kernels.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Long-Short Term Memory Neural Network for Keyboard Gesture Recognition
International Conference on Acoustics, Speech and Signal Processing (ICASSP) (2015)
[u'Ouais Alsharif', u'Tom Ouyang', u'Franoise Beaufays', u'Shumin Zhai', u'Thomas Breuel', u'Johan Schalkwyk']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Massively Multitask Networks for Drug Discovery
arXiv:1502.02072 [stat.ML] (2015)
[u'Bharath Ramsundar', u'Steven Kearnes', u'Patrick Riley', u'Dale Webster', u'David Konerding', u'Vijay Pande']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43987.html
notfound
=========================
Micro-Auction-Based Traffic-Light Control: Responsive, Local Decision Making
International Conference on Intelligent Transportation Systems (2015)
[u'Michele Covell', u'Shumeet Baluja', u'Rahul Sukthankar']
MachineIntelligence
Abstract: Real-time, responsive optimization of traffic flow serves to address important practical problems: reducing drivers wasted time and improving city-wide efficiency, as well as reducing gas emissions and improving air quality. Much of the current research in traffic-light optimization relies on extending the capabilities of basic traffic lights to either communicate with each other or communicate with vehicles. However, before such capabilities become ubiquitous, opportunities exist to improve traffic lights by being more responsive to current traffic situations within the existing, deployed, infrastructure. In this paper, we use micro-auctions as the organizing principle with which to incorporate local induction loop information; no other outside sources of information are assumed. At every time step in which a phase change is permitted, each light conducts a decentralized, weighted, micro-auction to determine which phase to instantiate next. We test the lights on real-world data collected over a period of several weeks around the Mountain View, California area. In our simulations, the auction mechanisms based only on local sensor data surpass longer-term planning approaches that rely on widely placed sensors and communications.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43407.html
notfound
=========================
Modeling the Lifespan of Discourse Entities with Application to Coreference Resolution
Journal of Artificial Intelligence Research, vol. 52 (2015), pp. 445-475
[u'Marie-Catherine de Marneffe', u'Marta Recasens', u'Christopher Potts']
MachineIntelligence
Abstract: A discourse typically involves numerous entities, but few are mentioned more than once. Distinguishing those that die out after just one mention (singleton) from those that lead longer lives (coreferent) would dramatically simplify the hypothesis space for coreference resolution models, leading to increased performance. To realize these gains, we build a classifier for predicting the singleton/coreferent distinction. The models feature representations synthesize linguistic insights about the factors affecting discourse entity lifespans (especially negation, modality, and attitude predication) with existing results about the benefits of surface (part-of-speech and n-gram-based) features for coreference resolution. The model is effective in its own right, and the feature representations help to identify the anchor phrases in bridging anaphora as well. Furthermore, incorporating the model into two very different state-of-the-art coreference resolution systems, one rule-based and the other learning-based, yields significant performance improvements.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42550.html
found
=========================
Multi-armed bandit experiments in the online service economy
Applied Stochastic Models in Business and Industry, vol. 31 (2015), pp. 37-49
[u'Steven L. Scott']
MachineIntelligence
Abstract: The modern service economy is substantively different from the agricultural and manufacturing economies that preceded it. In particular, the cost of experimenting is dominated by opportunity cost rather than the cost of obtaining experimental units. The different economics require a new class of experiments, in which stochastic models play an important role. This article briefly summarizes mulit-armed bandit experiments, where the experimental design is modified as the experiment progresses to make the experiment as inexpensive as possible.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44280.html
notfound
=========================
Multinomial Loss on Held-out Data for the Sparse Non-negative Matrix Language Model
ArXiv, Google (2015)
[u'Ciprian Chelba', u'Fernando Pereira']
MachineIntelligence
Abstract: We describe Sparse Non-negative Matrix (SNM) language model estimation using multinomial loss on held-out data. Being able to train on held-out data is important in practical situations where the training data is usually mismatched from the held-out/test data. It is also less constrained than the previous training algorithm using leave-one-out on training data: it allows the use of richer meta-features in the adjustment model, e.g. the diversity counts used by Kneser-Ney smoothing which would be difficult to deal with correctly in leave-one-out training. In experiments on the one billion words language modeling benchmark, we are able to slightly improve on our previous results which use a different loss function, and employ leave-one-out training on a subset of the main training set. Surprisingly, an adjustment model with meta-features that discard all lexical information can perform as well as lexicalized meta-features. We find that fairly small amounts of held-out data (on the order of 30-70 thousand words) are sufficient for training the adjustment model. In a real-life scenario where the training data is a mix of data sources that are imbalanced in size, and of different degrees of relevance to the held-out and test data, taking into account the data source for a given skip-/n-gram feature and combining them for best performance on held-out/test data improves over skip-/n-gram SNM models trained on pooled data by about 8%. The ability to mix various data sources based on how relevant they are to a mismatched held-out set is probably the most attractive feature of the new estimation method for SNM LM.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
On the Convergence of Stochastic Gradient MCMC Algorithms with High-Order Integrators
Advances in Neural Information Processing Systems (2015) (to appear)
[u'Changyou Chen', u'Nan Ding', u'Lawrence Carin']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
On-line learning algorithms for path experts with non-additive losses
Proceedings of The 28th Annual Conference on Learning Theory (COLT 2015)
[u'Corinna Cortes', u'Vitaly Kuznetsov', u'Mehryar Mohri', u'Manfred K. Warmuth']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Probabilistic Label Relation Graphs with Ising Models
International Conference on Computer Vision (2015) (to appear)
[u'Nan Ding', u'Jia Deng', u'Kevin Murphy', u'Hartmut Neven']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43932.html
notfound
=========================
Product Echo State Networks: Time-Series Computation with Multiplicative Neurons
The 2015 International Joint Conference on Neural Networks (IJCNN) (to appear)
[u'Alireza Goudarzi', u'Alireza Shabani', u'Darko Stefanovic']
MachineIntelligence
Abstract: Echo state networks (ESN), a type of reservoir computing (RC) architecture, are efficient and accurate artificial neural systems for time series processing and learning. An ESN consists of a core of recurrent neural networks, called a reservoir, with a small number of tunable parameters to generate a high-dimensional representation of an input, and a readout layer which is easily trained using regression to produce a desired output from the reservoir states. Certain computational tasks involve real-time calculation of high-order time correlations, which requires nonlinear transformation either in the reservoir or the readout layer. Traditional ESN employs a reservoir with sigmoid or tanh function neurons. In contrast, some types of biological neurons obey response curves that can be described as a product unit rather than a sum and threshold. Inspired by this class of neurons, we introduce a RC architecture with a reservoir of product nodes for time series computation. We find that the product RC shows many properties of standard ESN such as short-term memory and nonlinear capacity. On standard benchmarks for chaotic prediction tasks, the product RC maintains the performance of a standard nonlinear ESN while being more amenable to mathematical analysis. Our study provides evidence that such networks are powerful in highly nonlinear tasks owing to high-order statistics generated by the recurrent product node reservoir
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Qualitatively Characterizing Neural Network Optimization Problems
International Conference on Learning Representations (2015)
[u'Ian Goodfellow', u'Oriol Vinyals', u'Andrew Saxe']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43433.html
notfound
=========================
Resolving Discourse-Deictic Pronouns: A Two-Stage Approach to Do It
Proceedings of the 4th Joint Conference on Lexical and Computational Semantics (*SEM 2015), pp. 299-308
[u'Sujay Kumar Jauhar', u'Raul D. Guerra', u'Edgar Gonzlez Pellicer', u'Marta Recasens']
MachineIntelligence
Abstract: Discourse deixis is a linguistic phenomenon in which pronouns have verbal or clausal, rather than nominal, antecedents. Studies have estimated that between 5% and 10% of pronouns in non-conversational data are discourse deictic. However, current coreference resolution systems ignore this phenomenon. This paper presents an automatic system for the detection and resolution of discourse-deictic pronouns. We introduce a two-step approach that first recognizes instances of discourse-deictic pronouns, and then resolves them to their verbal antecedent. Both components rely on linguistically motivated features. We evaluate the components in isolation and in combination with two state-of-the-art coreference resolvers. Results show that our system outperforms several baselines, including the only comparable discourse deixis system, and leads to small but statistically significant improvements over the full coreference resolution systems. An error analysis lays bare the need for a less strict evaluation of this task.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Scalable and interpretable data representation for high-dimensional complex data
AAAI Conference on Artificial Intelligence (2015)
[u'Been Kim', u'Kayur Patel', u'Afshin Rostamizadeh', u'Julie Shah']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43984.html
notfound
=========================
Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks
Advances in Neural Information Processing Systems, NIPS (2015) (to appear)
[u'Samy Bengio', u'Oriol Vinyals', u'Navdeep Jaitly', u'Noam M. Shazeer']
MachineIntelligence
Abstract: Recurrent Neural Networks can be trained to produce sequences of tokens given some input, as exemplified by recent results in machine translation and image captioning. The current approach to training them consists of maximizing the likelihood of each token in the sequence given the current (recurrent) state and the previous token. At inference, the unknown previous token is then replaced by a token generated by the model itself. This discrepancy between training and inference can yield errors that can accumulate quickly along the generated sequence. We propose a curriculum learning strategy to gently change the training process from a fully guided scheme using the true previous token, towards a less guided scheme which mostly uses the generated token instead. Experiments on several sequence prediction tasks show that this approach yields significant improvements. Moreover, it was used successfully in our winning entry to the MSCOCO image captioning challenge, 2015.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43274.html
notfound
=========================
Show and tell: A neural image caption generator
Computer Vision and Pattern Recognition (2015)
[u'Oriol Vinyals', u'Alexander Toshev', u'Samy Bengio', u'Dumitru Erhan']
MachineIntelligence
Abstract: Automatically describing the content of an image is a fundamental problem in artificial intelligence that connects computer vision and natural language processing. In this paper, we present a generative model based on a deep recurrent architecture that combines recent advances in computer vision and machine translation and that can be used to generate natural sentences describing an image. The model is trained to maximize the likelihood of the target description sentence given the training image. Experiments on several datasets show the accuracy of the model and the fluency of the language it learns solely from image descriptions. Our model is often quite accurate, which we verify both qualitatively and quantitatively. For instance, while the current state-of-the-art BLEU score (the higher the better) on the Pascal dataset is 25, our approach yields 59, to be compared to human performance around 69. We also show BLEU-1 score improvements on Flickr30k, from 56 to 66, and on SBU, from 19 to 28. Lastly, on the newly released COCO dataset, we achieve a BLEU-4 of 27.7, which is the current state-of-the-art.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43829.html
notfound
=========================
Sparse Non-negative Matrix Language Modeling For Skip-grams
Proceedings of Interspeech 2015, ISCA, pp. 1428-1432
[u'Noam M. Shazeer', u'Joris Pelemans', u'Ciprian Chelba']
MachineIntelligence
Abstract: We present a novel family of language model (LM) estimation techniques named Sparse Non-negative Matrix (SNM) estimation. A first set of experiments empirically evaluating these techniques on the One Billion Word Benchmark [3] shows that with skip-gram features SNMLMs are able to match the state-of-the art recurrent neural network (RNN) LMs; combining the two modeling techniques yields the best known result on the benchmark. The computational advantages of SNM over both maximum entropy and RNNLM estimation are probably its main strength, promising an approach that has the same flexibility in combining arbitrary features effectively and yet should scale to very large amounts of data as gracefully as n-gram LMs do.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43964.html
notfound
=========================
Sparse Non-negative Matrix Language Modeling for Geo-annotated Query Session Data
Automatic Speech Recognition and Understanding Workshop (ASRU 2015) Proceedings, IEEE, to appear (to appear)
[u'Ciprian Chelba', u'Noam M. Shazeer']
MachineIntelligence
Abstract: The paper investigates the impact on query language modeling when using skip-grams within query as well as across queries in a given search session, in conjunction with the geo-annotation available for the query stream data. As modeling tool we use the recently proposed sparse non-negative matrix estimation technique, since it offers the same expressive power as the well-established maximum entropy approach in combining arbitrary context features. Experiments on the google.com query stream show that using session-level and geo-location context we can expect reductions in perplexity of 34% relative over the Kneser Ney N-gram baseline; when evaluating on the `''local'' subset of the query stream, the relative reduction in PPL is 51%---more than a bit. Both sources of context information (geo-location, and previous queries in session) are about equally valuable in building a language model for the query stream.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44290.html
notfound
=========================
Spherical Random Features for Polynomial Kernels
Neural Information Processing Systems (NIPS) (2015)
[u'Jeffrey Pennington', u'Felix X. Yu', u'Sanjiv Kumar']
MachineIntelligence
Abstract: Compact explicit feature maps provide a practical framework to scale kernel methods to large-scale learning, but deriving such maps for many types of kernels remains a challenging open problem. Among the commonly used kernels for nonlinear classification are polynomial kernels, for which low approximation error has thus far necessitated explicit feature maps of large dimensionality, especially for higher-order polynomials. Meanwhile, because polynomial kernels are unbounded, they are frequently applied to data that has been normalized to unit l2 norm. The question we address in this work is: if we know a priori that data is normalized, can we devise a more compact map? We show that a putative affirmative answer to this question based on Random Fourier Features is impossible in this setting, and introduce a new approximation paradigm, Spherical Random Fourier (SRF) features, which circumvents these issues and delivers a compact approximation to polynomial kernels for data on the unit sphere. Compared to prior work, SRF features are less rank-deficient, more compact, and achieve better kernel approximation, especially for higher-order polynomials. The resulting predictions have lower variance and typically yield better classification accuracy.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44312.html
notfound
=========================
Statistical parametric speech synthesis: from HMM to LSTM-RNN
N/A (2015)
[u'Heiga Zen']
MachineIntelligence
Abstract: This talk will present progress of acoustic modeling in statistical parametric speech synthesis from the conventional hidden Markov model HMM to the state-of-the-art long short-term memory recurrent neural network. The details of implementation and applications of statistical parametric speech synthesis are also included.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43976.html
notfound
=========================
Structural maxent models
Proceedings of the Thirty-Second International Conference on Machine Learning (ICML 2015)
[u'Corinna Cortes', u'Vitaly Kuznetsov', u'Mehryar Mohri', u'Umar Syed']
MachineIntelligence
Abstract: We present a new class of density estimation models, Structural Maxent models, with feature functions selected from a union of possibly very complex sub-families and yet benefiting from strong learning guarantees. The design of our models is based on a new principle supported by uniform convergence bounds and taking into consideration the complexity of the different sub-families composing the full set of features. We prove new data-dependent learning bounds for our models, expressed in terms of the Rademacher complexities of these sub-families. We also prove a duality theorem, which we use to derive our Structural Maxent algorithm. We give a full description of our algorithm, including the details of its derivation, and report the results of several experiments demonstrating that its performance improves on that of existing L1-norm regularized Maxent algorithms. We further similarly define conditional Structural Maxent models for multi-class classification problems. These are conditional probability models also making use of a union of possibly complex feature subfamilies. We prove a duality theorem for these models as well, which reveals their connection with existing binary and multi-class deep boosting algorithms.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43986.html
notfound
=========================
The Virtues of Peer Pressure: A Simple Method for Discovering High-Value Mistakes
International Conference on Computer Analysis of Images and Patterns (2015)
[u'Shumeet Baluja', u'Michele Covell', u'Rahul Sukthankar']
MachineIntelligence
Abstract: Much of the recent success of neural networks can be attributed to the deeper architectures that have become prevalent. However, the deeper architectures often yield unintelligible solutions, require enormous amounts of labeled data, and still remain brittle and easily broken. In this paper, we present a method to efficiently and intuitively discover input instances that are misclassified by well-trained neural networks. As in previous studies, we can identify instances that are so similar to previously seen examples such that the transformation is visually imperceptible. Additionally, unlike in previous studies, we can also generate mistakes that are significantly different from any training sample, while, importantly, still remaining in the space of samples that the network should be able to classify correctly. This is achieved by training a basket of N peer networks rather than a single network. These are similarly trained networks that serve to provide consistency pressure on each other. When an example is found for which a single network, S, disagrees with all of the other N 1 networks, which are consistent in their prediction, that example is a potential mistake for S. We present a simple method to find such examples and demonstrate it on two visual tasks. The examples discovered yield realistic images that clearly illuminate the weaknesses of the trained models, as well as provide a source of numerous, diverse, labeled-training samples.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
To Have a Tiger by the Tail: Improving Music Recommendation for International Users
Machine Learning for Music Discovery Workshop, ICML 2015
[u'Philippe Hamel']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43273.html
notfound
=========================
Training Deep Neural Networks on Noisy Labels with Bootstrapping
ICLR 2015
[u'Scott E. Reed', u'Honglak Lee', u'Dragomir Anguelov', u'Christian Szegedy', u'Dumitru Erhan', u'Andrew Rabinovich']
MachineIntelligence
Abstract: Current state-of-the-art deep learning systems for visual object recognition and detection use purely supervised training with regularization such as dropout to avoid overfitting. The performance depends critically on the amount of labeled examples, and in current practice the labels are assumed to be unambiguous and accurate. However, this assumption often does not hold; e.g. in recognition, class labels may be missing; in detection, objects in the image may not be localized; and in general, the labeling may be subjective. In this work we propose a generic way to handle noisy and incomplete labeling by augmenting the prediction objective with a notion of consistency. We consider a prediction consistent if the same prediction is made given similar percepts, where the notion of similarity is between deep network features computed from the input data. In experiments we demonstrate that our approach yields substantial robustness to label noise on several datasets. On MNIST handwritten digits, we show that our model is robust to label corruption. On the Toronto Face Database, we show that our model handles well the case of subjective labels in emotion recognition, achieving state-of-theart results, and can also benefit from unlabeled face images with no modification to our method. On the ILSVRC2014 detection challenge data, we show that our approach extends to very deep networks, high resolution images and structured outputs, and results in improved scalable detection.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43266.html
notfound
=========================
Unidirectional Long Short-Term Memory Recurrent Neural Network with Recurrent Output Layer for Low-Latency Speech Synthesis
Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), IEEE (2015), pp. 4470-4474
[u'Heiga Zen', u'Hasim Sak']
MachineIntelligence
Abstract: Long short-term memory recurrent neural networks (LSTM-RNNs) have been applied to various speech applications including acoustic modeling for statistical parametric speech synthesis. One of the concerns for applying them to text-to-speech applications is its effect on latency. To address this concern, this paper proposes a low-latency, streaming speech synthesis architecture using unidirectional LSTM-RNNs with a recurrent output layer. The use of unidirectional RNN architecture allows frame-synchronous streaming inference of output acoustic features given input linguistic features. The recurrent output layer further encourages smooth transition between acoustic features at consecutive frames. Experimental results in subjective listening tests show that the proposed architecture can synthesize natural sounding speech without requiring utterance-level batch processing.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Weakly Supervised Clustering: Learning Fine-Grained Signals from Coarse Labels
Annals of Applied Statistics (2015) (to appear)
[u'Stefan Wager', u'Alexander W Blocker', u'Niall Cardin']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42183.html
notfound
=========================
A Discriminative Latent Variable Model for Online Clustering
International Conference on Machine Learning (2014) (to appear)
[u'Rajhans Samdani', u'Kai-Wei Chang', u'Dan Roth']
MachineIntelligence
Abstract: This paper presents a latent variable structured prediction model for discriminative supervised clustering of items called the Latent Left-linking Model (L3M). We present an online clustering algorithm for L3M based on a feature-based item similarity function. We provide a learning framework for estimating the similarity function and present a fast stochastic gradient-based learning technique. In our experiments on coreference resolution and document clustering, L3M outperforms several existing online as well as batch supervised clustering techniques.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43105.html
notfound
=========================
A Survey of Algorithms and Analysis for Adaptive Online Learning
Preprint (2014)
[u'H. Brendan McMahan']
MachineIntelligence
Abstract: We present tools for the analysis of Follow-The-Regularized-Leader (FTRL), Dual Averaging, and Mirror Descent algorithms when the regularizer (equivalently, prox-function or learning rate schedule) is chosen adaptively based on the data. Adaptivity can be used to prove regret bounds that hold on every round, and also allows for data-dependent regret bounds as in AdaGrad-style algorithms (e.g., Online Gradient Descent with adaptive per-coordinate learning rates). We present results from a large number of prior works in a unified manner, using a modular and tight analysis that isolates the key arguments in easily re-usable lemmas. This approach strengthens previously known FTRL analysis techniques to produce bounds as tight as those achieved by potential functions or primal-dual analysis. Further, we prove a general and exact equivalence between an arbitrary adaptive Mirror Descent algorithm and a correspond- ing FTRL update, which allows us to analyze any Mirror Descent algorithm in the same framework. The key to bridging the gap between Dual Averaging and Mirror Descent algorithms lies in an analysis of the FTRL-Proximal algorithm family. Our regret bounds are proved in the most general form, holding for arbitrary norms and non-smooth regularizers with time-varying weight.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42557.html
notfound
=========================
Affinity Weighted Embedding
International Conference on Machine Learning (2014)
[u'Jason Weston', u'Ron Weiss', u'Hector Yee']
MachineIntelligence
Abstract: Supervised linear embedding models like Wsabie (Weston et al., 2011) and supervised semantic indexing (Bai et al., 2010) have proven successful at ranking, recommendation and annotation tasks. However, despite being scalable to large datasets they do not take full advantage of the extra data due to their linear nature, and we believe they typically underfit. We propose a new class of models which aim to provide improved performance while retaining many of the benefits of the existing class of embedding models. Our approach works by reweighting each component of the embedding of features and labels with a potentially nonlinear affinity function. We describe several variants of the family, and show its usefulness on several datasets.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42533.html
notfound
=========================
Applications of Maximum Entropy Rankers to Problems in Spoken Language Processing
Interspeech 2014, International Speech Communications Association
[u'Richard Sproat', u'Keith Hall']
MachineIntelligence
Abstract: We report on two applications of Maximum Entropy-based ranking models to problems of relevance to automatic speech recognition and text-to-speech synthesis. The first is stress prediction in Russian, a language with notoriously complex morphology and stress rules. The second is the classification of alphabetic non-standard words, which may be read as words (NATO), as letter sequences (USA), or as a mixed (mymsn). For this second task we report results on English, and five other European languages.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42248.html
notfound
=========================
Asynchronous Stochastic Optimization for Sequence Training of Deep Neural Networks
Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), IEEE, Firenze, Italy (2014)
[u'Georg Heigold', u'Erik McDermott', u'Vincent Vanhoucke', u'Andrew Senior', u'Michiel Bacchiani']
MachineIntelligence
Abstract: This paper explores asynchronous stochastic optimization for sequence training of deep neural networks. Sequence training requires more computation than frame-level training using pre-computed frame data. This leads to several complications for stochastic optimization, arising from signicant asynchrony in model updates under massive parallelization, and limited data shufing due to utterance-chunked processing. We analyze the impact of these two issues on the efciency and performance of sequence training. In particular, we suggest a framework to formalize the reasoning about the asynchrony and present experimental results on both small and large scale Voice Search tasks to validate the effectiveness and efciency of asynchronous stochastic optimization.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Asynchronous Stochastic Optimization for Sequence Training of Deep Neural Networks: Towards Big Data
Interspeeech, ISCA (2014)
[u'Erik McDermott', u'Georg Heigold', u'Pedro Moreno', u'Andrew Senior', u'Michiel Bacchiani']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Automatic Language Identification using Long Short-Term Memory Recurrent Neural Networks
Interspeech (2014)
[u'Javier Gonzalez-Dominguez', u'Ignacio Lopez-Moreno', u'Hasim Sak']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42947.html
notfound
=========================
Autoregressive Product of Multi-frame Predictions Can Improve the Accuracy of Hybrid Models
Proceedings of Interspeech 2014
[u'Navdeep Jaitly', u'Vincent Vanhoucke', u'Geoffrey Hinton']
MachineIntelligence
Abstract: We describe a simple but effective way of using multi-frame targets to improve the accuracy of Artificial Neural Network- Hidden Markov Model (ANN-HMM) hybrid systems. In this approach a Deep Neural Network (DNN) is trained to predict the forced-alignment state of multiple frames using a separate softmax unit for each of the frames. This is in contrast to the usual method of training a DNN to predict only the state of the central frame. By itself this is not sufficient to improve accuracy of the system significantly. However, if we average the predic- tions for each frame - from the different contexts it is associated with - we achieve state of the art results on TIMIT using a fully connected Deep Neural Network without convolutional archi- tectures or dropout training. On a 14 hour subset of Wall Street Journal (WSJ) using a context dependent DNN-HMM system it leads to a relative improvement of 6.4% on the dev set (test- dev93) and 9.3% on test set (test-eval92).
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43934.html
found
=========================
Bayesian Sampling using Stochastic Gradient Thermostats
Advances in Neural Information Processing Systems (2014), pp. 3203-3211
[u'Nan Ding', u'Youhan Fang', u'Ryan Babbush', u'Changyou Chen', u'Robert Skeel', u'Hartmut Neven']
MachineIntelligence
Abstract: Dynamics-based sampling methods, such as Hybrid Monte Carlo (HMC) and Langevin dynamics (LD), are commonly used to sample target distributions. Recently, such approaches have been combined with stochastic gradient techniques to increase sampling efficiency when dealing with large datasets. An outstanding problem with this approach is that the stochastic gradient introduces an unknown amount of noise which can prevent proper sampling after discretization. To remedy this problem, we show that one can leverage a small number of additional variables to stabilize momentum fluctuations induced by the unknown noise. Our method is inspired by the idea of a thermostat in statistical physics and is justified by a general theory.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43016.html
notfound
=========================
Bridging Text and Knowledge with Frames
ACL Workshop on Frame Semantics (in honor of Charles FIllmore) (2014)
[u'Srini Narayanan']
MachineIntelligence
Abstract: FrameNet is the current best operational version of Chuck Fillmores Frame Semantics. As FrameNet has evolved over the years, we have been building a series of increasingly ambitious prototype applications that exploit the ideas of frame semantics and FrameNet as a resource. Results from this work suggest that frames are a natural semantic representation linking issue of textual meaning and world knowledge.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42462.html
notfound
=========================
Cicada: Predictive Guarantees for Cloud Network Bandwidth
MIT (2014), MIT-CSAIL-TR-2014-004
[u'Katrina LaCurts', u'Jeffrey C Mogul', u'Hari Balakrishnan', u'Yoshio Turner']
MachineIntelligence
Abstract: In cloud-computing systems, network-bandwidth guarantees have been shown to improve predictability of application performance and cost. Most previous work on cloud-bandwidth guarantees has assumed that cloud tenants know what bandwidth guarantees they want. However, application bandwidth demands can be complex and time-varying, and many tenants might lack sufficient information to request a bandwidth guarantee that is well-matched to their needs. A tenant's lack of accurate knowledge about its future bandwidth demands can lead to over-provisioning (and thus reduced cost-efficiency) or under-provisioning (and thus poor user experience in latency-sensitive user-facing applications). We analyze traffic traces gathered over six months from an HP Cloud Services datacenter, finding that application bandwidth consumption is both time-varying and spatially inhomogeneous. This variability makes it hard to predict requirements. To solve this problem, we develop a prediction algorithm usable by a cloud provider to suggest an appropriate bandwidth guarantee to a tenant. The key idea in the prediction algorithm is to treat a set of previously observed traffic matrices as "experts" and learn online the best weighted linear combination of these experts to make its prediction. With tenant VM placement using these predictive guarantees, we find that the inter-rack network utilization in certain datacenter topologies can be more than doubled.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43144.html
found
=========================
Circulant Binary Embedding
International Conference on Machine Learning (ICML) (2014)
[u'Felix X. Yu', u'Sanjiv Kumar', u'Yunchao Gong', u'Shih-Fu Chang']
MachineIntelligence
Abstract: Binary embedding of high-dimensional data requires long codes to preserve the discriminative power of the input space. Traditional binary coding methods often suffer from very high computation and storage costs in such a scenario. To address this problem, we propose Circulant Binary Embedding (CBE) which generates binary codes by projecting the data with a circulant matrix. The circulant structure enables the use of Fast Fourier Transformation to speed up the computation. Compared to methods that use unstructured matrices, the proposed method improves the time complexity from O(d^2) to O(dlogd), and the space complexity from O(d^2) to O(d) where d is the input dimensionality. We also propose a novel time-frequency alternating optimization to learn data-dependent circulant projections, which alternatively minimizes the objective in original and Fourier domains. We show by extensive experiments that the proposed approach gives much better performance than the state-of-the-art approaches for fixed time, and provides much faster computation with no performance degradation for fixed number of bits.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43944.html
found
=========================
Construction of non-convex polynomial loss functions for training a binary classifier with quantum annealing
arXiv preprint 1406.4203 (2014)
[u'Ryan Babbush', u'Vasil Denchev', u'Nan Ding', u'Sergei Isakov', u'Hartmut Neven']
MachineIntelligence
Abstract: Quantum annealing is a heuristic quantum algorithm which exploits quantum resources to minimize an objective function embedded as the energy levels of a programmable physical system. To take advantage of a potential quantum advantage, one needs to be able to map the problem of interest to the native hardware with reasonably low overhead. Because experimental considerations constrain our objective function to take the form of a low degree PUBO (polynomial unconstrained binary optimization), we employ non-convex loss functions which are polynomial functions of the margin. We show that these loss functions are robust to label noise and provide a clear advantage over convex methods. These loss functions may also be useful for classical approaches as they compile to regularized risk expressions which can be evaluated in constant time with respect to the number of training examples.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42855.html
found
=========================
Corporate learning at scale: Lessons from a large online course at Google
Learning at Scale (2014)
[u'Arthur Asuncion', u'Jac de Haan', u'Mehryar Mohri', u'Kayur Patel', u'Afshin Rostamizadeh', u'Umar Syed', u'Lauren Wong']
MachineIntelligence
Abstract: Google Research recently tested a massive online class model for an internal engineering education program, with machine learning as the topic, that blended theoretical concepts and Google-specific software tool tutorials. The goal of this training was to foster engineering capacity to leverage machine learning tools in future products. The course was delivered both synchronously and asynchronously, and students had the choice between studying independently or participating with a group. Since all students are company employees, unlike most publicly offered MOOCs we can continue to measure the students behavioral change long after the course is complete. This paper describes the course, outlines the available data set and presents directions for analysis.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42960.html
notfound
=========================
DaMN Discriminative and Mutually Nearest: Exploiting Pairwise Category Proximity for Video Action Recognition
Proceedings of European Conference on Computer Vision (2014)
[u'Rui Hou', u'Amir Roshan Zamir', u'Rahul Sukthankar', u'Mubarak Shah']
MachineIntelligence
Abstract: We propose a method for learning discriminative category-level features and demonstrate state-of-the-art results on large-scale action recognition in video. The key observation is that one-vs-rest classifiers, which are ubiquitously employed for this task, face challenges in separating very similar categories (such as running vs. jogging). Our proposed method automatically identifies such pairs of categories using a criterion of mutual pairwise proximity in the (kernelized) feature space, using a category-level similarity matrix where each entry corresponds to the one-vs-one SVM margin for pairs of categories. We then exploit the observation that while splitting such "Siamese Twin" categories may be difficult, separating them from the remaining categories in a two-vs-rest framework is not. This enables us to augment one-vs-rest classifiers with a judicious selection of "two-vs-rest" classifier outputs, formed from such discriminative and mutually nearest (DaMN) pairs. By combining one-vs-rest and two-vs-rest features in a principled probabilistic manner, we achieve state-of-the-art results on the UCF101 and HMDB51 datasets. More importantly, the same DaMN features, when treated as a mid-level representation also outperform existing methods in knowledge transfer experiments, both cross-dataset from UCF101 to HMDB51 and to new categories with limited training data (one-shot and few-shot learning). Finally, we study the generality of the proposed approach by applying DaMN to other classification tasks; our experiments show that DaMN outperforms related approaches in direct comparisons, not only on video action recognition but also on their original image dataset tasks.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Deep Convolutional Ranking for Multilabel Image Annotation
International Conference on Learning Representations (2014) (to appear)
[u'Yunchao Gong', u'Yangqing Jia', u'Alexander Toshev', u'Thomas Leung', u'Sergey Ioffe']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Deep Neural Networks for Small Footprint Text-dependent Speaker Verification
Proc. ICASSP, IEEE (2014)
[u'Ehsan Variani', u'Xin Lei', u'Erik McDermott', u'Ignacio Lopez Moreno', u'Javier Gonzalez-Dominguez']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42856.html
notfound
=========================
Deep boosting
Proceedings of the Thirty-First International Conference on Machine Learning (ICML 2014)
[u'Corinna Cortes', u'Mehryar Mohri', u'Umar Syed']
MachineIntelligence
Abstract: We present a new ensemble learning algorithm, DeepBoost, which can use as base classifiers a hypothesis set containing deep decision trees, or members of other rich or complex families, and succeed in achieving high accuracy without overfitting the data. The key to the success of the algorithm is a capacity-conscious criterion for the selection of the hypotheses. We give new data- dependent learning bounds for convex ensembles expressed in terms of the Rademacher complexities of the sub-families composing the base classifier set, and the mixture weight assigned to each sub-family. Our algorithm directly benefits from these guarantees since it seeks to minimize the corresponding learning bound. We give a full description of our algorithm, including the details of its derivation, and report the results of several experiments showing that its performance compares favorably to that of AdaBoost and Logistic Regression and their L1-regularized variants.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43138.html
notfound
=========================
Delay-Tolerant Algorithms for Asynchronous Distributed Online Learning
Advances in Neural Information Processing Systems (NIPS) (2014)
[u'H. Brendan McMahan', u'Matthew Streeter']
MachineIntelligence
Abstract: We analyze new online gradient descent algorithms for distributed systems with large delays between gradient computations and the corresponding updates. Using insights from adaptive gradient methods, we develop algorithms that adapt not only to the sequence of gradients, but also to the precise update delays that occur. We first give an impractical algorithm that achieves a regret bound that precisely quantifies the impact of the delays. We then analyze AdaptiveRevision, an algorithm that is efficiently implementable and achieves comparable guarantees. The key algorithmic technique is appropriately and efficiently revising the learning rate used for previous gradient steps. Experimental results show when the delays grow large (1000 updates or more), our new algorithms perform significantly better than standard adaptive gradient methods.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43145.html
found
=========================
Discrete Graph Hashing
Neural Information Processing Systems (2014)
[u'Wei Liu', u'Cun Mu', u'Sanjiv Kumar', u'Shih-Fu Chang']
MachineIntelligence
Abstract: Hashing has emerged as a popular technique for fast nearest neighbor search in gigantic databases. In particular, learning based hashing has received considerable attention due to its appealing storage and search efficiency. However, the performance of most unsupervised learning based hashing methods deteriorates rapidly as the hash code length increases. We argue that the degraded performance is due to inferior optimization procedures used to achieve discrete binary codes. This paper presents a graph-based unsupervised hashing model to preserve the neighborhood structure of massive data in a discrete code space. We cast the graph hashing problem into a discrete optimization framework which directly learns the binary codes. A tractable alternating maximization algorithm is then proposed to explicitly deal with the discrete constraints, yielding high-quality codes to well capture the local neighborhoods. Extensive experiments performed on four large datasets with up to one million samples show that our discrete optimization based graph hashing method obtains superior search accuracy over state-of-the-art unsupervised hashing methods, especially for longer codes.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Domain adaptation and sample bias correction theory and algorithm for regression
Theoretical Computer Science, vol. 519 (2014)
[u'Corinna Cortes', u'Mehryar Mohri']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Enhanced Search with Wildcards and Morphological Inections in the Google Books Ngram Viewer
Proceedings of the 52th Annual Meeting of the Association for Computational Linguistics (Demonstrations), Association for Computational Linguistics (2014)
[u'Jason Mann', u'David Zhang', u'Lu Yang', u'Dipanjan Das', u'Slav Petrov']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Ensemble methods for structured prediction
Proceedings of the 31st International Conference on Machine Learning (ICML 2014)
[u'Corinna Cortes', u'Vitaly Kuznetsov', u'Mehryar Mohri']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42902.html
notfound
=========================
Evolving QWOP gaits
GECCO '14 Proceedings of the 2014 conference on Genetic and evolutionary computation, ACM, Vancouver, pp. 823-830
[u'Steven Ray', u'Vahl Scott Gordon', u'Laurent Vaucher']
MachineIntelligence
Abstract: QWOP is a popular Flash game in which a human player controls a sprinter in a simulated 100-meter dash. The game is notoriously difficult owing to its ragdoll physics engine, and the simultaneous movements that must be carefully coordinated to achieve forward progress. While previous researchers have evolved gaits using simulations similar to QWOP, we describe a software interface that connects directly to QWOP itself, incorporating a genetic algorithm to evolve actual QWOP gaits. Since QWOP has no API, ours detects graphical screen elements and uses them to build a fitness function. Two variable-length encoding schemes, that codify sequences of QWOP control commands that loop to form gaits, are tested. We then compare the performance of SGA, Genitor, and a Cellular Genetic Algorithm on this task. Using only the end score as the basis for fitness, the cellular algorithm is consistently able to evolve a successful scooting strategy similar to one most humans employ. The results confirm that steady-state GAs are preferred when the task is sensitive to small input variations. Although the limited feedback does not yet produce performance competitive with QWOP champions, it is the first autonomous software evolution of successful QWOP gaits.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41227.html
notfound
=========================
Frame-Semantic Parsing
Computational Linguistics, vol. 40:1 (2014), pp. 9-56
[u'Dipanjan Das', u'Desai Chen', u'Andr F. T. Martins', u'Nathan Schneider', u'Noah A. Smith']
MachineIntelligence
Abstract: Frame semantics (Fillmore 1982) is a linguistic theory that has been instantiated for English in the FrameNet lexicon (Fillmore, Johnson, and Petruck 2003). We solve the problem of frame-semantic parsing using a two-stage statistical model that takes lexical targets (i.e., content words and phrases) in their sentential contexts and predicts frame-semantic structures. Given a target in context, the first stage disambiguates it to a semantic frame. This model employs latent variables and semi-supervised learning to improve frame disambiguation for targets unseen at training time. The second stage finds the target's locally expressed semantic arguments. At inference time, a fast exact dual decomposition algorithm collectively predicts all the arguments of a frame at once in order to respect declaratively stated linguistic constraints, resulting in qualitatively better structures than nave local predictors. Both components are feature-based and discriminatively trained on a small set of annotated frame-semantic parses. On the SemEval 2007 benchmark dataset, the approach, along with a heuristic identifier of frame-evoking targets, outperforms the prior state of the art by significant margins. Additionally, we present experiments on the much larger FrameNet 1.5 dataset. We have released our frame-semantic parser as open-source software.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42531.html
found
=========================
Insulin Resistance: Regression and Clustering
PLoS ONE, vol. 9(6) (2014)
[u'Sangho Yoon']
MachineIntelligence
Abstract: In this paper we try to define insulin resistance (IR) precisely for a group of Chinese women. Our definition deliberately does not depend upon body mass index (BMI) or age, although in other studies, with particular random effects models quite different from models used here, BMI accounts for a large part of the variability in IR. We accomplish our goal through application of Gauss mixture vector quantization (GMVQ), a technique for clustering that was developed for application to lossy data compression. Defining data come from measurements that play major roles in medical practice. A precise statement of what the data are is in Section 1. Their family structures are described in detail. They concern levels of lipids and the results of an oral glucose tolerance test (OGTT). We apply GMVQ to residuals obtained from regressions of outcomes of an OGTT and lipids on functions of age and BMI that are inferred from the data. A bootstrap procedure developed for our family data supplemented by insights from other approaches leads us to believe that two clusters are appropriate for defining IR precisely. One cluster consists of women who are IR, and the other of women who seem not to be. Genes and other features are used to predict cluster membership. We argue that prediction with main effects is not satisfactory, but prediction that includes interactions may be.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42503.html
notfound
=========================
Intriguing properties of neural networks
International Conference on Learning Representations (2014)
[u'Christian Szegedy', u'Wojciech Zaremba', u'Ilya Sutskever', u'Joan Bruna', u'Dumitru Erhan', u'Ian Goodfellow', u'Rob Fergus']
MachineIntelligence
Abstract: Deep neural networks are highly expressive models that have recently achieved state of the art performance on speech and visual recognition tasks. While their expressiveness is the reason they succeed, it also causes them to learn uninterpretable solutions that could have counter-intuitive properties. In this paper we report two such properties. First, we find that there is no distinction between individual high level units and random linear combinations of high level units, according to various methods of unit analysis. It suggests that it is the space, rather than the individual units, that contains of the semantic information in the high layers of neural networks. Second, we find that deep neural networks learn input-output mappings that are fairly discontinuous to a significant extend. We can cause the network to misclassify an image by applying a certain imperceptible perturbation, which is found by maximizing the network's prediction error. In addition, the specific nature of these perturbations is not a random artifact of learning: the same perturbation can cause a different network, that was trained on a different subset of the dataset, to misclassify the same input.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43150.html
notfound
=========================
Large Scale Deep Learning
Tsinghua University (2014)
[u'Jeffrey Dean']
MachineIntelligence
Abstract: Keynote at CIKM 2014 conference, Shanghai, China, November, 2014. Talk also given at Tsinghua University.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42455.html
notfound
=========================
Large-scale Video Classication with Convolutional Neural Networks
Proceedings of International Computer Vision and Pattern Recognition (CVPR 2014), IEEE
[u'Andrej Karpathy', u'George Toderici', u'Sanketh Shetty', u'Thomas Leung', u'Rahul Sukthankar', u'Li Fei-Fei']
MachineIntelligence
Abstract: Convolutional Neural Networks (CNNs) have been established as a powerful class of models for image recognition problems. Encouraged by these results, we provide an extensive empirical evaluation of CNNs on large-scale video classification using a dataset of 1 million YouTube videos belonging to 487 classes. We study multiple approaches for extending the connectivity of a CNN in time domain to take advantage of local spatio-temporal information and suggest a multi-resolution, foveated architecture as a promising way of regularizing the learning problem and speeding up training. Our best spatio-temporal networks display significant performance improvements compared to strong feature-based baselines (55.3% to 63.9%), but only a surprisingly modest improvement compared to single-frame models (59.3% to 60.9%). We further study the generalization performance of our best model by retraining the top layers on the UCF-101 action Recognition dataset and observe significant performance improvements compared to the UCF-101 baseline model (63.3% up from 43.9%).
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42945.html
notfound
=========================
Learning Fine-grained Image Similarity with Deep Ranking
CVPR'2014, IEEE
[u'Jiang Wang', u'Yang Song', u'Thomas Leung', u'Chuck Rosenberg', u'Jingbin Wang', u'James Philbin', u'Bo Chen', u'Ying Wu']
MachineIntelligence
Abstract: Learning fine-grained image similarity is a challenging task. It needs to capture between-class and within-class image differences. This paper proposes a deep ranking model that employs deep learning techniques to learn similarity metric directly from images. It has higher learning capability than models based on hand-crafted features. A novel multiscale network structure has been developed to describe the images effectively. An efficient triplet sampling algorithm is proposed to learn the model with distributed asynchronized stochastic gradient. Extensive experiments show that the proposed algorithm outperforms models based on hand-crafted visual features and deep classification models.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Learning ensembles of structured prediction rules
Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics (ACL 2014)
[u'Corinna Cortes', u'Vitaly Kuznetsov', u'Mehryar Mohri']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Long Short-Term Memory Based Recurrent Neural Network Architectures for Large Vocabulary Speech Recognition
CoRR, vol. abs/1402.1128 (2014)
[u'Hasim Sak', u'Andrew W. Senior', u'Franoise Beaufays']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Long short-term memory recurrent neural network architectures for large scale acoustic modeling
INTERSPEECH (2014), pp. 338-342
[u'Hasim Sak', u'Andrew W. Senior', u'Franoise Beaufays']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42542.html
notfound
=========================
Machine Learning Applications for Data Center Optimization
Google (2014)
[u'Jim Gao']
MachineIntelligence
Abstract: The modern data center (DC) is a complex interaction of multiple mechanical, electrical and controls systems. The sheer number of possible operating configurations and nonlinear interdependencies make it difficult to understand and optimize energy efficiency. We develop a neural network framework that learns from actual operations data to model plant performance and predict PUE within a range of 0.004 +/0.005 (mean absolute error +/- 1 standard deviation), or 0.4% error for a PUE of 1.1. The model has been extensively tested and validated at Google DCs. The results demonstrate that machine learning is an effective way of leveraging existing sensor data to model DC performance and improve energy efficiency.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42434.html
found
=========================
Machine Learning in an Auction Environment
Proceedings of the 23rd International Conference on the World Wide Web (WWW) (2014), pp. 7-18
[u'Patrick Hummel', u'Preston McAfee']
MachineIntelligence
Abstract: We consider a model of repeated online auctions in which an ad with an uncertain click-through rate faces a random distribution of competing bids in each auction and there is discounting of payoffs. We formulate the optimal solution to this explore/exploit problem as a dynamic programming problem and show that efficiency is maximized by making a bid for each advertiser equal to the advertiser's expected value for the advertising opportunity plus a term proportional to the variance in this value divided by the number of impressions the advertiser has received thus far. We then use this result to illustrate that the value of incorporating active exploration into a machine learning system in an auction environment is exceedingly small.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43146.html
notfound
=========================
Machine Learning: The High Interest Credit Card of Technical Debt
SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop)
[u'D. Sculley', u'Gary Holt', u'Daniel Golovin', u'Eugene Davydov', u'Todd Phillips', u'Dietmar Ebner', u'Vinay Chaudhary', u'Michael Young']
MachineIntelligence
Abstract: Machine learning offers a fantastically powerful toolkit for building complex systems quickly. This paper argues that it is dangerous to think of these quick wins as coming for free. Using the framework of technical debt, we note that it is remarkably easy to incur massive ongoing maintenance costs at the system level when applying machine learning. The goal of this paper is highlight several machine learning specific risk factors and design patterns to be avoided or refactored where possible. These include boundary erosion, entanglement, hidden feedback loops, undeclared consumers, data dependencies, changes in the external world, and a variety of system-level anti-patterns.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43247.html
notfound
=========================
Multi-Class Deep Boosting
Advances in Neural Information Processing Systems (2014)
[u'Vitaly Kuznetsov', u'Mehryar Mohri', u'Umar Syed']
MachineIntelligence
Abstract: We present new ensemble learning algorithms for multi-class classification. Our algorithms can use as a base classifier set a family of deep decision trees or other rich or complex families and yet benefit from strong generalization guarantees. We give new data-dependent learning bounds for convex ensembles in the multiclass classification setting expressed in terms of the Rademacher complexities of the sub-families composing the base classifier set, and the mixture weight assigned to each sub-family. These bounds are finer than existing ones both thanks to an improved dependency on the number of classes and, more crucially, by virtue of a more favorable complexity term expressed as an average of the Rademacher complexities based on the ensembles mixture weights. We introduce and discuss several new multi-class ensemble algorithms benefiting from these guarantees, prove positive results for the H-consistency of several of them, and report the results of experiments showing that their performance compares favorably with that of multi-class versions of AdaBoost and Logistic Regression and their L1-regularized counterparts.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Projecting the Knowledge Graph to Syntactic Parsing
EACL 2014: 15th Conference of the European Chapter of the Association for Computational Linguistics
[u'Andrea Gesmundo', u'Keith Hall']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42500.html
found
=========================
Reducing the Sampling Complexity of Topic Models
ACM Conference on Knowledge Discovery and Data Mining (KDD) (2014)
[u'Aaron Li', u'Amr Ahmed', u'Sujith Ravi', u'Alexander J Smola']
MachineIntelligence
Abstract: Inference in topic models typically involves a sampling step to associate latent variables with observations. Unfortunately, the generative model loses sparsity with the increase in data, requiring O(k) operations per word for k latent states, such as topics. In this paper we propose an algorithm which requires only O(kd) operations per word, where kd is the number of actually instantiated topics in the document. For large document collections and structured hierarchical models kd k, thus yielding an order of magnitude speedup. Our method is general and it applies to a wide variety of statistical models. At its core is the idea that dense, rapidly changing distributions can be approximated efficiently by the combination of a Metropolis-Hastings step, judicious use of sparsity, and amortized preprocessing via the alias method.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Repeated Contextual Auctions with Strategic Buyers
Advances in Neural Information Processing Systems (2014)
[u'Kareem Amin', u'Afshin Rostamizadeh', u'Umar Syed']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42935.html
found
=========================
Revisiting Stein's Paradox: Multi-Task Averaging
Journal Machine Learning Research, vol. 15 (2014)
[u'Sergey Feldman', u'Maya R. Gupta', u'Bela A. Frigyik']
MachineIntelligence
Abstract: We present a multi-task learning approach to jointly estimate the means of multiple independent distributions from samples. The proposed multi-task averaging (MTA) algorithm results in a convex combination of the individual task's sample averages We derive the optimal amount of regularization for the two task case for the minimum risk estimator and a minimax estimator, and show that the optimal amount of regularization can be practically estimated without cross-validation. We extend the practical estimators to an arbitrary number of tasks. Simulations and real data experiments demonstrate the advantage of the proposed MTA estimators over standard averaging and James-Stein estimation.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42498.html
found
=========================
Scalable Hierarchical Multitask Learning Algorithms for Conversion Optimization in Display Advertising
ACM International Conference on Web Search And Data Mining (WSDM) (2014)
[u'Amr Ahmed', u'Abhimanyu Das', u'Alexander J. Smola']
MachineIntelligence
Abstract: Many estimation tasks come in groups and hierarchies of related problems. In this paper we propose a hierarchical model and a scalable algorithm to perform inference for multitask learning. It infers task correlation and subtask structure in a joint sparse setting. Implementation is achieved by a distributed subgradient oracle and the successive application of prox-operators pertaining to groups and sub-groups of variables. We apply this algorithm to conversion optimization in display advertising. Experimental results on over 1TB data for up to 1 billion observations and 1 million attributes show that the algorithm provides significantly better prediction accuracy while simultaneously being efficiently scalable by distributed parameter synchronization.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42245.html
notfound
=========================
Semantic Frame Identification with Distributed Word Representations
Proceedings of the 52th Annual Meeting of the Association for Computational Linguistics (2014)
[u'Karl Moritz Hermann', u'Dipanjan Das', u'Jason Weston', u'Kuzman Ganchev']
MachineIntelligence
Abstract: We present a novel technique for semantic frame identification using distributed representations of predicates and their syntactic context; this technique leverages automatic syntactic parses and a generic set of word embeddings. Given labeled data annotated with frame-semantic parses, we learn a model that projects the set of word representations for the syntactic context around a predicate to a low dimensional representation. The latter is used for semantic frame identification; with a standard argument identification method inspired by prior work, we achieve state-of-the-art results on FrameNet-style frame-semantic analysis. Additionally, we report strong results on PropBank-style semantic role labeling in comparison to prior work.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42547.html
notfound
=========================
Sequence Discriminative Distributed Training of Long Short-Term Memory Recurrent Neural Networks
Interspeech (2014)
[u'Hasim Sak', u'Oriol Vinyals', u'Georg Heigold', u'Andrew Senior', u'Erik McDermott', u'Rajat Monga', u'Mark Mao']
MachineIntelligence
Abstract: We recently showed that Long Short-Term Memory (LSTM) recurrent neural networks (RNNs) outperform state-of-the-art deep neural networks (DNNs) for large scale acoustic modeling where the models were trained with the cross-entropy (CE) criterion. It has also been shown that sequence discriminative training of DNNs initially trained with the CE criterion gives significant improvements. In this paper, we investigate sequence discriminative training of LSTM RNNs in a large scale acoustic modeling task. We train the models in a distributed manner using asynchronous stochastic gradient descent optimization technique. We compare two sequence discriminative criteria -- maximum mutual information and state-level minimum Bayes risk, and we investigate a number of variations of the basic training strategy to better understand issues raised by both the sequential model, and the objective function. We obtain significant gains over the CE trained LSTM RNN model using sequence discriminative training techniques.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43155.html
notfound
=========================
Sequence to Sequence Learning with Neural Networks
Proc. NIPS, Montreal, CA (2014)
[u'Ilya Sutskever', u'Oriol Vinyals', u'Quoc V. Le']
MachineIntelligence
Abstract: Deep Neural Networks (DNNs) are powerful models that have achieved excellent performance on difficult learning tasks. Although DNNs work well whenever large labeled training sets are available, they cannot be used to map sequences to sequences. In this paper, we present a general end-to-end approach to sequence learning that makes minimal assumptions on the sequence structure. Our method uses a multilayered Long Short-Term Memory (LSTM) to map the input sequence to a vector of a fixed dimensionality, and then another deep LSTM to decode the target sequence from the vector. Our main result is that on an English to French translation task from the WMT-14 dataset, the translations produced by the LSTM achieve a BLEU score of 34.8 on the entire test set, where the LSTM's BLEU score was penalized on out-of-vocabulary words. Additionally, the LSTM did not have difficulty on long sentences. For comparison, a phrase-based SMT system achieves a BLEU score of 33.3 on the same dataset. When we used the LSTM to rerank the 1000 hypotheses produced by the aforementioned SMT system, its BLEU score increases to 36.5, which is close to the previous state of the art. The LSTM also learned sensible phrase and sentence representations that are sensitive to word order and are relatively invariant to the active and the passive voice. Finally, we found that reversing the order of the words in all source sentences (but not target sentences) improved the LSTM's performance markedly, because doing so introduced many short term dependencies between the source and the target sentence which made the optimization problem easier.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43222.html
notfound
=========================
Skip-gram Language Modeling Using Sparse Non-negative Matrix Probability Estimation
Google (2014)
[u'Noam M. Shazeer', u'Joris Pelemans', u'Ciprian Chelba']
MachineIntelligence
Abstract: We present a novel family of language model (LM) estimation techniques named Sparse Non-negative Matrix (SNM) estimation. A first set of experiments empirically evaluating it on the One Billion Word Benchmark shows that SNM n-gram LMs perform almost as well as the well-established Kneser-Ney (KN) models. When using skip-gram features the models are able to match the state-of-the-art recurrent neural network (RNN) LMs; combining the two modeling techniques yields the best known result on the benchmark. The computational advantages of SNM over both maximum entropy and RNN LM estimation are probably its main strength, promising an approach that has the same flexibility in combining arbitrary features effectively and yet should scale to very large amounts of data as gracefully as n-gram LMs do.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Small-Footprint Keyword Spotting using Deep Neural Networks
ICASSP, IEEE (2014)
[u'Guoguo Chen', u'Carolina Parada', u'Georg Heigold']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42624.html
notfound
=========================
Statistical Parametric Speech Synthesis
UKSpeech Conference, Edinburgh, UK (2014)
[u'Heiga Zen']
MachineIntelligence
Abstract: Statistical parametric speech synthesis has grown in popularity over the last years. In this tutorial, its system architecture is outlined, and then basic techniques used in the system, including algorithms for speech parameter generation, are described with simple examples.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42499.html
found
=========================
Taxonomy Discovery for Personalized Recommendation
ACM International Conference on Web Search And Data Mining (WSDM) (2014)
[u'Yuchen Zhang', u'Amr Ahmed', u'Vanja Josifovski', u'Alexander J Smola']
MachineIntelligence
Abstract: Personalized recommender systems based on latent factor models are widely used to increase sales in e-commerce. Such systems use the past behavior of users to recommend new items that are likely to be of interest to them. However, latent factor model suffer from sparse user-item interaction in online shopping data: for a large portion of items that do not have sufficient purchase records, their latent factors cannot be estimated accurately. In this paper, we propose a novel approach that automatically discovers the taxonomies from online shopping data and jointly learns a taxonomy-based recommendation system. Out model is non-parametric and can learn the taxonomy structure automatically from the data. Since the taxonomy allows purchase data to be shared between item- s, it effectively improves the accuracy of recommending tail items by sharing strength with the more frequent items. Ex- periments on a large-scale online shopping dataset confirm that our proposed model improves significantly over state-of- the-art latent factor models. Moreover, our model generates high-quality and human readable taxonomies. Finally, us- ing the algorithm-generated taxonomy, our model even out- performs latent factor models based on the human-induced taxonomy, thus alleviating the need for costly manual taxonomy generation.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43464.html
notfound
=========================
The End is Nigh: Generic Solving of Text-based CAPTCHAs
WOOT'14 Proceedings of the 8th USENIX conference on Offensive Technologies, Usenix (2014)
[u'Elie Bursztein', u'Jonathan Aigrain', u'Angelika Moscicki', u'John C. Mitchell']
MachineIntelligence
Abstract: Over the last decade, it has become well-established that a captchas ability to withstand automated solving lies in the difficulty of segmenting the image into individual characters. The standard approach to solving captchas automatically has been a sequential process wherein a segmentation algorithm splits the image into segments that contain individual characters, followed by a character recognition step that uses machine learning. While this approach has been effective against particular captcha schemes, its generality is limited by the segmentation step, which is hand-crafted to defeat the distortion at hand. No general algorithm is known for the character collapsing anti-segmentation technique used by most prominent real world captcha schemes. This paper introduces a novel approach to solving captchas in a single step that uses machine learning to attack the segmentation and the recognition problems simultaneously. Performing both operations jointly allows our algorithm to exploit information and context that is not available when they are done sequentially. At the same time, it removes the need for any hand-crafted component, making our approach generalize to new captcha schemes where the previous approach can not. We were able to solve all the real world captcha schemes we evaluated ac- curately enough to consider the scheme insecure in practice, including Yahoo (5.33%) and ReCaptcha (33.34%), without any adjustments to the algorithm or its parameters. Our success against the Baidu (38.68%) and CNN (51.09%) schemes that use occluding lines as well as character collapsing leads us to believe that our approach is able to defeat occluding lines in an equally general manner. The effectiveness and universality of our results suggests that combining segmentation and recognition is the next evolution of captcha solving, and that it supersedes the sequential approach used in earlier works. More generally, our approach raises questions about how to develop sufficiently secure captchas in the future.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43968.html
found
=========================
Theoretical Foundations for Learning Kernels in Supervised Kernel PCA
Modern Nonparametrics 3: Automating the Learning Pipeline, Neural Information Processing Systems, Workshop (2014)
[u'Mehryar Mohri', u'Afshin Rostamizadeh', u'Dmitry Storcheus']
MachineIntelligence
Abstract: This paper presents a novel learning scenario which combines dimensionality reduction, supervised learning as well as kernel selection. We carefully define the hypothesis class that addresses this setting and provide an analysis of its Rademacher complexity and thereby provide generalization guarantees. The proposed algorithm uses KPCA to reduce the dimensionality of the feature space, i.e. by projecting data onto top eigenvectors of covariance operator in a kernel reproducing space. Moreover, it simultaneously learns a linear combination of base kernel functions, which defines a reproducing space, as well as the parameters of a supervised learning algorithm in order to minimize a regularized empirical loss. The bound on Rademacher complexity of our hypothesis is shown to be logarithmic in the number of base kernels, which encourages practitioners to combine as many base kernels as possible.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41872.html
notfound
=========================
Training Highly Multi-class Linear Classifiers
Journal Machine Learning Research (JMLR) (2014), 1461-1492
[u'Maya R. Gupta', u'Samy Bengio', u'Jason Weston']
MachineIntelligence
Abstract: Classification problems with thousands or more classes often have a large variance in the confusability between classes, and we show that the more-confusable classes add more noise to the empirical loss that is minimized during training. We propose an online solution that reduces the effect of highly confusable classes in training the classifier parameters, and focuses the training on pairs of classes that are easier to differentiate at any given time in the training. We also show that the adagrad method, recently proposed for automatically decreasing step sizes for convex stochastic gradient descent optimization, can also be profitably applied to the nonconvex optimization stochastic gradient descent training of a joint supervised dimensionality reduction and linear classifier. Experiments on ImageNet benchmark datasets and proprietary image recognition problems with 15,000 to 97,000 classes show substantial gains in classification accuracy compared to one-vs-all linear SVMs and Wsabie.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42504.html
notfound
=========================
Unconstrained Online Linear Learning in Hilbert Spaces: Minimax Algorithms and Normal Approximations
Proceedings of the 27th Annual Conference on Learning Theory (COLT) (2014)
[u'H. Brendan McMahan', u'Francesco Orabona']
MachineIntelligence
Abstract: We study algorithms for online linear optimization in Hilbert spaces, focusing on the case where the player is unconstrained. We develop a novel characterization of a large class of minimax algorithms, recovering, and even improving, several previous results as immediate corollaries. Moreover, using our tools, we develop an algorithm that provides a regret bound of $O(U \sqrt{T \log( U \sqrt{T} \log^2 T +1)})$, where $U$ is the $L_2$ norm of an arbitrary comparator and both $T$ and $U$ are unknown to the player. This bound is optimal up to $\sqrt{\log \log T}$ terms. When $T$ is known, we derive an algorithm with an optimal regret bound (up to constant factors). For both the known and unknown $T$ case, a Normal approximation to the conditional value of the game proves to be the key analysis tool.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42623.html
found
=========================
Up Next: Retrieval Methods for Large Scale Related Video Suggestion
Proceedings of KDD 2014, New York, NY, USA, pp. 1769-1778
[u'Michael Bendersky', u'Lluis Garcia Pueyo', u'Vanja Josifovski', u'Jeremiah J. Harmsen', u'Dima Lepikhin']
MachineIntelligence
Abstract: The explosive growth in sharing and consumption of the video content on the web creates a unique opportunity for scientific advances in video retrieval, recommendation and discovery. In this paper, we focus on the task of video suggestion, commonly found in many online applications. The current state-of-the-art video suggestion techniques are based on the collaborative filtering analysis, and suggest videos that are likely to be co-viewed with the watched video. In this paper, we propose augmenting the collaborative filtering analysis with the topical representation of the video content to suggest related videos. We propose two novel methods for topical video representation. The first method uses information retrieval heuristics such as tf-idf, while the second method learns the optimal topical representations based on the implicit user feedback available in the online scenario. We conduct a large scale live experiment on YouTube traffic, and demonstrate that augmenting collaborative filtering with topical representations significantly improves the quality of the related video suggestions in a live setting, especially for categories with fresh and topically-rich video content such as news videos. In addition, we show that employing user feedback for learning the optimal topical video representations can increase the user engagement by more than 80% over the standard information retrieval representation, when compared to the collaborative filtering baseline.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42961.html
notfound
=========================
Video Object Discovery and Co-segmentation with Extremely Weak Supervision
Proceedings of European Conference on Computer Vision (2014)
[u'Le Wang', u'Gang Hua', u'Rahul Sukthankar', u'Jianru Xue', u'Nanning Zheng']
MachineIntelligence
Abstract: Video object co-segmentation refers to the problem of simultaneously segmenting a common category of objects from multiple videos. Most existing video co-segmentation methods assume that all frames from all videos contain the target objects. Unfortunately, this assumption is rarely true in practice, particularly for large video sets, and existing methods perform poorly when the assumption is violated. Hence, any practical video object co-segmentation algorithm needs to identify the relevant frames containing the target object from all videos, and then co-segment the object only from these relevant frames. We present a spatiotemporal energy minimization formulation for simultaneous video object discovery and co-segmentation across multiple videos. Our formulation incorporates a spatiotemporal auto-context model, which is combined with appearance modeling for superpixel labeling. The superpixel-level labels are propagated to the frame level through a multiple instance boosting algorithm with spatial reasoning (Spatial-MILBoosting), based on which frames containing the video object are identified. Our method only needs to be bootstrapped with the frame-level labels for a few video frames (e.g., usually 1 to 3) to indicate if they contain the target objects or not. Experiments on three datasets validate the efficacy of our proposed method, which compares favorably with the state-of-the-art.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42543.html
notfound
=========================
Word Embeddings for Speech Recognition
Proceedings of the 15th Conference of the International Speech Communication Association, Interspeech (2014)
[u'Samy Bengio', u'Georg Heigold']
MachineIntelligence
Abstract: Speech recognition systems have used the concept of states as a way to decompose words into sub-word units for decades. As the number of such states now reaches the number of words used to train acoustic models, it is interesting to consider approaches that relax the assumption that words are made of states. We present here an alternative construction, where words are projected into a continuous embedding space where words that sound alike are nearby in the Euclidean sense. We show how embeddings can still allow to score words that were not in the training dictionary. Initial experiments using a lattice rescoring approach and model combination on a large realistic dataset show improvements in word error rate.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42371.html
notfound
=========================
Zero-Shot Learning by Convex Combination of Semantic Embeddings
International Conference on Learning Representations (2014)
[u'Mohammad Norouzi', u'Tomas Mikolov', u'Samy Bengio', u'Yoram Singer', u'Jonathon Shlens', u'Andrea Frome', u'Greg Corrado', u'Jeffrey Dean']
MachineIntelligence
Abstract: Several recent publications have proposed methods for mapping images into continuous semantic embedding spaces. In some cases the embedding space is trained jointly with the image transformation. In other cases the semantic embedding space is established by an independent natural language processing task, and then the image transformation into that space is learned in a second stage. Proponents of these image embedding systems have stressed their advantages over the traditional \nway{} classification framing of image understanding, particularly in terms of the promise for zero-shot learning -- the ability to correctly annotate images of previously unseen object categories. In this paper, we propose a simple method for constructing an image embedding system from any existing \nway{} image classifier and a semantic word embedding model, which contains the $\n$ class labels in its vocabulary. Our method maps images into the semantic embedding space via convex combination of the class label embedding vectors, and requires no additional training. We show that this simple and direct method confers many of and indeed outperforms state of the art methods on the ImageNet zero-shot learning task.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42242.html
notfound
=========================
Local Collaborative Ranking
International World Wide Web Conference, WWW (2014)
[u'Joonseok Lee', u'Samy Bengio', u'Seungyeon Kim', u'Guy Lebanon', u'Yoram Singer']
MachineIntelligence
Abstract: Personalized recommendation systems are used in a wide variety of applications such as electronic commerce, social networks, web search, and more. Collaborative filtering approaches to recommendation systems typically assume that the rating matrix (e.g., movie ratings by viewers) is low-rank. In this paper, we examine an alternative approach in which the rating matrix is \emph{locally low-rank}. Concretely, we assume that the rating matrix is low-rank within certain neighborhoods of the metric space defined by (user, item) pairs. We combine a recent approach for local low-rank approximation based on the Frobenius norm with a general empirical risk minimization for ranking losses. Our experiments indicate that the combination of a mixture of local low-rank matrices each of which was trained to minimize a ranking loss outperforms many of the currently used state-of-the-art recommendation systems. Moreover, our method is easy to parallelize, making it a viable approach for large scale real-world rank-based recommendation systems.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41643.html
notfound
=========================
3DNN: Viewpoint Invariant 3D Geometry Matching for Scene Understanding
Proceedings of the International Conference on Computer Vision (ICCV) (2013) (to appear)
[u'Scott Satkin', u'Martial Hebert']
MachineIntelligence
Abstract: We present a new algorithm 3DNN (3D Nearest-Neighbor), which is capable of matching an image with 3D data, independently of the viewpoint from which the image was captured. By leveraging rich annotations associated with each image, our algorithm can automatically produce precise and detailed 3D models of a scene from a single image. Moreover, we can transfer information across images to accurately label and segment objects in a scene. The true benefit of 3DNN compared to a traditional 2D nearest-neighbor approach is that by generalizing across viewpoints, we free ourselves from the need to have training examples captured from all possible viewpoints. Thus, we are able to achieve comparable results using orders of magnitude less data, and recognize objects from never-before-seen viewpoints. In this work, we describe the 3DNN algorithm and rigorously evaluate its performance for the tasks of geometry estimation and object detection/segmentation. By decoupling the viewpoint and the geometry of an image, we develop a scene matching approach which is truly 100% viewpoint invariant, yielding state-of-the-art performance on challenging data.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41401.html
notfound
=========================
A Generic Technique for Synthesizing Bounded Finite-State Controllers
Proceedings of the International Conference on Automated Planning and Scaduling, Association for the Advancement of Articial Intelligence (2013), pp. 109-116
[u'Yuxiao Hu', u'Giuseppe De Giacomo']
MachineIntelligence
Abstract: Finite-state controllers are a compact and effective plan representation for agent widely used in AI. In this paper, we proposea generic framework and related solver for synthesizing bounded finite-state controllers, and show its instantiations to three different applications, including generalized planning, planning programs and service composition under partial observability and controllability. We show that our generic solver is sound and complete, and amenable to heuristics that take into account the structure of the specific target instantiation. Experiments show that instantiations of our solver to the problems above often outperform tailored approaches in the literature. This suggests that our proposal is a promising base point for future research on finite-state controller synthesis.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41089.html
found
=========================
A Method for Measuring Online Audiences
Google Inc (2013), pp. 1-24 (to appear)
[u'Jim Koehler', u'Evgeny Skvortsov', u'Wiesner Vos']
MachineIntelligence
Abstract: We present a method for measuring the reach and frequency of online ad campaigns by audience attributes. This method uses a combination of data sources, including ad server logs, publisher provided user data (PPD), census data, and a representative online panel. It adjusts for known problems with cookie data and potential non-representative and inaccurate PPD. It generalizes for multiple publishers and for targeting based on the PPD. The method includes the conversion of adjusted cookie counts to unique audience counts. The benefit of our method is that we get both reduced variance from server logs and reduced bias from the panel. Simulation results and a case study are presented.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Semantic Matching Energy Function for Learning with Multi-relational Data
International Conference on Learning Representations (2013)
[u'Xavier Glorot', u'Antoine Bordes', u'Jason Weston', u'Yoshua Bengio']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41159.html
found
=========================
Ad Click Prediction: a View from the Trenches
Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD) (2013)
[u'H. Brendan McMahan', u'Gary Holt', u'D. Sculley', u'Michael Young', u'Dietmar Ebner', u'Julian Grady', u'Lan Nie', u'Todd Phillips', u'Eugene Davydov', u'Daniel Golovin', u'Sharat Chikkerur', u'Dan Liu', u'Martin Wattenberg', u'Arnar Mar Hrafnkelsson', u'Tom Boulos', u'Jeremy Kubica']
MachineIntelligence
Abstract: Predicting ad click--through rates (CTR) is a massive-scale learning problem that is central to the multi-billion dollar online advertising industry. We present a selection of case studies and topics drawn from recent experiments in the setting of a deployed CTR prediction system. These include improvements in the context of traditional supervised learning based on an FTRL-Proximal online learning algorithm (which has excellent sparsity and convergence properties) and the use of per-coordinate learning rates. We also explore some of the challenges that arise in a real-world system that may appear at first to be outside the domain of traditional machine learning research. These include useful tricks for memory savings, methods for assessing and visualizing performance, practical methods for providing confidence estimates for predicted probabilities, calibration methods, and methods for automated management of features. Finally, we also detail several directions that did not turn out to be beneficial for us, despite promising results elsewhere in the literature. The goal of this paper is to highlight the close relationship between theoretical advances and practical engineering in this industrial setting, and to show the depth of challenges that appear when applying traditional machine learning methods in a complex dynamic system.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Affinity Weighted Embedding
International Conference on Learning Representations (2013)
[u'Jason Weston', u'Ron Weiss', u'Hector Yee']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
An Empirical study of learning rates in deep neural networks for speech recognition
Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), IEEE, Vancouver, CA (2013) (to appear)
[u'Andrew Senior', u'Georg Heigold', u"Marc'aurelio Ranzato", u'Ke Yang']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41849.html
found
=========================
Bayes and Big Data: The Consensus Monte Carlo Algorithm
Bayes 250 (2013) (to appear)
[u'Steven L. Scott', u'Alexander W. Blocker', u'Fernando V. Bonassi']
MachineIntelligence
Abstract: A useful definition of ``big data'' is data that is too big to comfortably process on a single machine, either because of processor, memory, or disk bottlenecks. Graphics processing units can alleviate the processor bottleneck, but memory or disk bottlenecks can only be eliminated by splitting data across multiple machines. Communication between large numbers of machines is expensive (regardless of the amount of data being communicated), so there is a need for algorithms that perform distributed approximate Bayesian analyses with minimal communication. Consensus Monte Carlo operates by running a separate Monte Carlo algorithm on each machine, and then averaging individual Monte Carlo draws across machines. Depending on the model, the resulting draws can be nearly indistinguishable from the draws that would have been obtained by running a single machine algorithm for a very long time. Examples of consensus Monte Carlo are shown for simple models where single-machine solutions are available, for large single-layer hierarchical models, and for Bayesian additive regression trees (BART).
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Breaking Out of Local Optima with Count Transforms and Model Recombination: A Study in Grammar Induction
2013 Conference on Empirical Methods in Natural Language Processing (EMNLP 2013; Best Paper Award)
[u'Valentin I. Spitkovsky', u'Daniel Jurafsky', u'Hiyan Alshawi']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41699.html
found
=========================
Classifying with Confidence From Incomplete Test Data
Journal Machine Learning Research (JMLR), vol. 14 (2013)
[u'Nathan Parris', u'Hyrum S. Anderson', u'Maya R. Gupta', u'Dun Yu Hsaio']
MachineIntelligence
Abstract: We consider the classification problem given incomplete information about a test sample. This problem arises naturally when data about the test sample is collected over time, or when costs must be incurred to collect the data. For example, in a distributed sensor network only a fraction of the sensors may have reported measurements at a certain time, and either additional time, power, bandwidth or some other cost must be incurred to collect the complete data to classify. A practical goal is to assign a class label as soon as enough data is available to make a good decision. We formalize this goal through the notion of reliability --- the probability that a label assigned to the incomplete data matches the label that would be assigned to the complete data, and we propose a method to classify incomplete data only if some reliability threshold is met. Our approach models the complete data as a random variable whose distribution is dependent on the current incomplete data and the (complete) training data. The method differs from standard imputation strategies in that our focus is on determining the reliability of the classification decision, rather than just the class label. We show that the method provides useful reliability estimates of the correctness of the imputed class labels on a set of experiments on time-series datasets, where the goal is to classify the time-series as early as possible while still guaranteeing that the reliability threshold is met.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41339.html
found
=========================
Cluster forest
Computational Statistics and Data Analysis, vol. 66 (2013), pp. 178-192
[u'Donghui Yan', u'Aiyou Chen', u'Michael I Jordan']
MachineIntelligence
Abstract: With inspiration from Random Forests (RF) in the context of classification, a new clustering ensemble method---Cluster Forests (CF) is proposed. Geometrically, CF randomly probes a high-dimensional data cloud to obtain "good local clusterings" and then aggregates via spectral clustering to obtain cluster assignments for the whole dataset. The search for good local clusterings is guided by a cluster quality measure kappa. CF progressively improves each local clustering in a fashion that resembles the tree growth in RF. Empirical studies on several real-world datasets under two different performance metrics show that CF compares favorably to its competitors. Theoretical analysis reveals that the kappa measure makes it possible to grow the local clustering in a desirable way---it is "noise-resistant". A closed-form expression is obtained for the mis-clustering rate of spectral clustering under a perturbation model, which yields new insights into some aspects of spectral clustering.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Comparative study of classifiers to mitigate intersymbol interference in diffuse indoor optical wireless communication links
Optik - International Journal for Light and Electron Optics (2013)
[u'Sujan Rajbhandari', u'Joe Faith', u'Zabih Ghassemlooy']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Connecting Language and Knowledge Bases with Embedding Models for Relation Extraction
Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing.
[u'Jason Weston', u'Antoine Bordes', u'Oksana Yakhnenko', u'Nicolas Usunier']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41533.html
notfound
=========================
Cross-Lingual Discriminative Learning of Sequence Models with Posterior Regularization
Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing
[u'Kuzman Ganchev', u'Dipanjan Das']
MachineIntelligence
Abstract: We present a framework for cross-lingual transfer of sequence information from a resource-rich source language to a resource-impoverished target language that incorporates soft constraints via posterior regularization. To this end, we use automatically word aligned bitext between the source and target language pair, and learn a discriminative conditional random field model on the target side. Our posterior regularization constraints are derived from simple intuitions about the task at hand and from cross-lingual alignment information. We show improvements over strong baselines for two tasks: part-of-speech tagging and named-entity segmentation.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41657.html
found
=========================
Data Fusion: Resolving Conflicts from Multiple Sources
WAIM (2013), pp. 64-76 (to appear)
[u'Xin Luna Dong', u'Laure Berti-Equille', u'Divesh Srivastava']
MachineIntelligence
Abstract: Many data management applications, such as setting up Web portals, managing enterprise data, managing community data, and sharing scientific data, require integrating data from multiple sources. Each of these sources provides a set of values and different sources can often provide conflicting values. To present quality data to users, it is critical to resolve conflicts and discover values that reflect the real world; this task is called data fusion. This paper describes a novel approach that finds true values from conflicting information when there are a large number of sources, among which some may copy from others. We present a case study on real-world data showing that the described algorithm can significantly improve accuracy of truth discovery and is scalable when there are a large number of data sources.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41869.html
notfound
=========================
DeViSE: A Deep Visual-Semantic Embedding Model
Neural Information Processing Systems (NIPS) (2013)
[u'Andrea Frome', u'Greg Corrado', u'Jonathon Shlens', u'Samy Bengio', u'Jeffrey Dean', u'MarcAurelio Ranzato', u'Tomas Mikolov']
MachineIntelligence
Abstract: Modern visual recognition systems are often limited in their ability to scale to large numbers of object categories. This limitation is in part due to the increasing difficulty of acquiring sufficient training data in the form of labeled images as the number of object categories grows. One remedy is to leverage data from other sources such as text data both to train visual models and to constrain their predictions. In this paper we present a new deep visual-semantic embedding model trained to identify visual objects using both labeled image data as well as semantic information gleaned from unannotated text. We demonstrate that this model matches state-of-the-art performance on the 1000-class ImageNet object recognition challenge while making more semantically reasonable errors, and also show that the semantic information can be exploited to make predictions about tens of thousands of image labels not observed during training. Semantic knowledge improves such zero-shot predictions achieving hit rates of up to 18% across thousands of novel labels never seen by the visual model.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41539.html
notfound
=========================
Deep Learning in Speech Synthesis
8th ISCA Speech Synthesis Workshop, Barcelona, Spain (2013)
[u'Heiga Zen']
MachineIntelligence
Abstract: Deep learning has been a hot research topic in various machine learning related areas including general object recognition and automatic speech recognition. This talk will present recent applications of deep learning to statistical parametric speech synthesis and contrast the deep learning-based approaches to the existing hidden Markov model-based one.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Deep Learning via Semi-Supervised Embedding
Neural Networks Tricks of the Trade, Reloaded, Springer (2013)
[u'Jason Weston', u'Frederic Ratle', u'Hossein Mobahi', u'Ronan Collobert']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Deep Neural Networks for Object Detection
Advances in Neural Information Processing Systems (2013)
[u'Christian Szegedy', u'Alexander Toshev', u'Dumitru Erhan']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40751.html
notfound
=========================
Discriminative Segment Annotation in Weakly Labeled Video
Proceedings of International Conference on Computer Vision and Pattern Recognition (CVPR 2013)
[u'Kevin Tang', u'Rahul Sukthankar', u'Jay Yagnik', u'Li Fei-Fei']
MachineIntelligence
Abstract: paper tackles the problem of segment annotation in complex Internet videos. Given a weakly labeled video, we automatically generate spatiotemporal masks for each of the concepts with which it is labeled. This is a particularly relevant problem in the video domain, as large numbers of YouTube videos are now available, tagged with the visual concepts that they contain. Given such weakly labeled videos, we focus on the problem of spatiotemporal segment classification. We propose a straightforward algorithm, CRANE, that utilizes large amounts of weakly labeled video to rank spatiotemporal segments by the likelihood that they correspond to a given visual concept. We make publicly available segment-level annotations for a subset of the Prest et al. dataset and show convincing results. We also show state-of-the-art results on Hartmann et al.'s more difficult, large-scale object segmentation dataset.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Distributed Large-scale Natural Graph Factorization
Proceedings of the 22nd International World Wide Web Conference (WWW 2013) (to appear)
[u'Amr Ahmed', u'Nino Shervashidze', u'Shravan Narayanamurthy', u'Vanja Josifovski', u'Alexander J Smola']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41224.html
notfound
=========================
Efficient Estimation of Word Representations in Vector Space
International Conference on Learning Representations (2013)
[u'Tomas Mikolov', u'Kai Chen', u'Greg S. Corrado', u'Jeffrey Dean']
MachineIntelligence
Abstract: We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41474.html
notfound
=========================
Efficient Learning of Sparse Ranking Functions
Empirical Inference, Springer (2013)
[u'Mark Stevens', u'Samy Bengio', u'Yoram Singer']
MachineIntelligence
Abstract: Algorithms for learning to rank can be inefficient when they employ risk functions that use structural information. We describe and analyze a learning algorithm that efficiently learns a ranking function using a domination loss. This loss is designed for problems in which we need to rank a small number of positive examples over a vast number of negative examples. In that context, we propose an efficient coordinate descent approach that scales linearly with the number of examples. We then present an extension that incorporates regularization thus extending Vapniks notion of regularized empirical risk minimization to ranking learning. We also discuss an extension to the case of multi-values feedback. Experiments performed on several benchmark datasets and large scale Google internal dataset demonstrate the effectiveness of learning algorithm in constructing compact models while retaining the empirical performance accuracy.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41858.html
notfound
=========================
Estimation, Optimization, and Parallelism when Data is Sparse
Advances in Neural Information Processing Systems (NIPS) (2013)
[u'John C. Duchi', u'Michael I. Jordan', u'H. Brendan McMahan']
MachineIntelligence
Abstract: We study stochastic optimization problems when the \emph{data} is sparse, which is in a sense dual to current perspectives on high-dimensional statistical learning and optimization. We highlight both the difficulties---in terms of increased sample complexity that sparse data necessitates---and the potential benefits, in terms of allowing parallelism and asynchrony in the design of algorithms. Concretely, we derive matching upper and lower bounds on the minimax rate for optimization and learning with sparse data, and we exhibit algorithms achieving these rates. We also show how leveraging sparsity leads to (still minimax optimal) parallel and asynchronous algorithms, providing experimental evidence complementing our theoretical results on several medium to large-scale learning tasks.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40814.html
notfound
=========================
Fast, Accurate Detection of 100,000 Object Classes on a Single Machine
Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, IEEE Computer Society, Washington, DC, USA (2013)
[u'Thomas Dean', u'Mark Ruzon', u'Mark Segal', u'Jonathon Shlens', u'Sudheendra Vijayanarasimhan', u'Jay Yagnik']
MachineIntelligence
Abstract: Many object detection systems are constrained by the time required to convolve a target image with a bank of filters that code for different aspects of an object's appearance, such as the presence of component parts. We exploit locality-sensitive hashing to replace the dot-product kernel operator in the convolution with a fixed number of hash-table probes that effectively sample all of the filter responses in time independent of the size of the filter bank. To show the effectiveness of the technique, we apply it to evaluate 100,000 deformable-part models requiring over a million (part) filters on multiple scales of a target image in less than 20 seconds using a single multi-core processor with 20GB of RAM. This represents a speed-up of approximately 20,000 times - four orders of magnitude - when compared with performing the convolutions explicitly on the same hardware. While mean average precision over the full set of 100,000 object classes is around 0.16 due in large part to the challenges in gathering training data and collecting ground truth for so many classes, we achieve a mAP of at least 0.20 on a third of the classes and 0.30 or better on about 20% of the classes.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41466.html
found
=========================
Fastfood - Approximating Kernel Expansions in Loglinear Time
30th International Conference on Machine Learning (ICML), Omnipress (2013)
[u'Quoc Le', u'Tamas Sarlos', u'Alex Smola']
MachineIntelligence
Abstract: Fast nonlinear function classes are crucial for nonparametric estimation, such as in kernel methods. This paper proposes an improvement to random kitchen sinks that offers significantly faster computation in log-linear time without sacrificing accuracy. Furthermore, we show how one may adjust the regularization properties of the kernel simply by changing the spectral distribution of the projection matrix. We provide experimental results which show that even for for moderately small problems we already achieve two orders of magnitude faster computation and three orders of magnitude lower memory footprint.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Focused Marix Factorization for Audience Selection in Display Advertising
Proceedings of the 29th International Conference on Data Engineering (ICDE) (2013) (to appear)
[u'Bhargav Kanagal', u'Amr Ahmed', u'Sandeep Pandey', u'Vanja Josifovski', u'Lluis Garcia-Pueyo', u'Jeff Yuan']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Guest editors' introduction: Special section on learning deep architectures
IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI), vol. 35 (2013), pp. 1795-1797
[u'Samy Bengio', u'Li Deng', u'Hugo Larochelle', u'Honglak Lee', u'Ruslan Salakhutdinov']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43996.html
notfound
=========================
HMM-based script identification for OCR
Proceedings of the 4th International Workshop on Multilingual OCR, ACM, New York, NY, US (2013), 2:1-2:5
[u'Dmitriy Genzel', u'Ashok Popat', u'Remco Teunen', u'Yasuhisa Fujii']
MachineIntelligence
Abstract: While current OCR systems are able to recognize text in an increasing number of scripts and languages, typically they still need to be told in advance what those scripts and languages are. We propose an approach that repurposes the same HMM-based system used for OCR to the task of script/language ID, by replacing character labels with script class labels. We apply it in a multi-pass overall OCR process which achieves universal OCR over 54 tested languages in 18 distinct scripts, over a wide variety of typefaces in each. For comparison we also consider a brute-force approach, wherein a singe HMM-based OCR system is trained to recognize all considered scripts. Results are presented on a large and diverse evaluation set extracted from book images, both for script identification accuracy and for overall OCR accuracy. On this evaluation data, the script ID system provided a script ID error rate of 1.73% for 18 distinct scripts. The end-to-end OCR system with the script ID system achieved a character error rate of 4.05%, an increase of 0.77% over the case where the languages are known a priori.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Handbook of Human Computation
Springer (2013)
[u'Pietro Michelucci', u'Peng Dai']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Hierarchical Geographical Modeling of User locations from Social Media Posts
Proceedings of the 22nd International World Wide Web Conference (WWW 2013) (to appear)
[u'Amr Ahmed', u'Liangjie Hong', u'Alexander J Smola']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41435.html
notfound
=========================
Image Annotation in Presence of Noisy Labels
International Conference on Pattern Recognition and Machine Intelligence (2013) (to appear)
[u'Chandrashekhar V.', u'Shailesh Kumar', u'C. V. Jawahar']
MachineIntelligence
Abstract: Labels associated with social images are valuable source of information for tasks of image annotation, understanding and retrieval. These labels are often found to be noisy, mainly due to the collaborative tagging activities of users. Existing methods on annotation have been developed and verified on noise free labels of images. In this paper, we propose a novel and generic framework that exploits the collective knowledge embedded in noisy label co-occurrence pairs to derive robust annotations. We compare our method with a well-known image annotation algorithm and show its superiority in terms of annotation accuracy on benchmark Corel5K and ESP datasets in presence of noisy labels.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
KDD tutorial: The Dataminer Guide to Scalable Mixed-Membership and Nonparametric Bayesian Models
ACM conference on Knowledge Discovery and Data Mining (KDD) (2013) (to appear)
[u'Amr Ahmed', u'Alexander J Smola']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Label Partitioning for Sublinear Ranking
International Conference on Machine Learning (2013)
[u'Jason Weston', u'Ameesh Makadia', u'Hector Yee']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41188.html
notfound
=========================
Language-Independent Discriminative Parsing of Temporal Expressions
The 51st Annual Meeting of the Association for Computational Linguistics (ACL 2013) (to appear)
[u'Gabor Angeli', u'Jakob Uszkoreit']
MachineIntelligence
Abstract: Temporal resolution systems are traditionally tuned to a particular language, requiring significant human effort to translate them to new languages. We present a language independent semantic parser for learning the interpretation of temporal phrases given only a corpus of utterances and the times they reference. We make use of a latent parse that encodes a language-flexible representation of time, and extract rich features over both the parse and associated temporal semantics. The parameters of the model are learned using a weakly supervised bootstrapping approach, without lexical cues or language-specific tuning. We achieve state-of-the-art accuracy on all languages in the TempEval-2 temporal normalization task, reporting a 4% improvement in both English and Spanish accuracy, and to our knowledge the first results for four other languages.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41133.html
notfound
=========================
Large Scale Distributed Acoustic Modeling With Back-off N-grams
ICSI, Berkeley, California (2013)
[u'Ciprian Chelba', u'Peng Xu', u'Fernando Pereira', u'Thomas Richardson']
MachineIntelligence
Abstract: Google Voice Search is an application that provides a data-rich setup for both language and acoustic modeling research. The approach we take revives an older approach to acoustic modeling that borrows from n-gram language modeling in an attempt to scale up both the amount of training data, and the model size (as measured by the number of parameters in the model), to approximately 100 times larger than current sizes used in automatic speech recognition. Speech recognition experiments are carried out in an N-best list rescoring framework for Google Voice Search. We use 87,000 hours of training data (speech along with transcription) obtained by filtering utterances in Voice Search logs on automatic speech recognition confidence. Models ranging in size between 20--40 million Gaussians are estimated using maximum likelihood training. They achieve relative reductions in word-error-rate of 11% and 6% when combined with first-pass models trained using maximum likelihood, and boosted maximum mutual information, respectively. Increasing the context size beyond five phones (quinphones) does not help.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Large Scale SVD and Manifold Learning
Journal of Machine Learning Research (JMLR) (2013)
[u'Ameet Talwalkar', u'Sanjiv Kumar', u'Mehryar Morhri', u'Henry A. Rowley']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40813.html
notfound
=========================
Large-Scale Learning with Less RAM via Randomization
Proceedings of the 30 International Conference on Machine Learning (ICML) (2013), pp. 10
[u'Daniel Golovin', u'D. Sculley', u'H. Brendan McMahan', u'Michael Young']
MachineIntelligence
Abstract: We reduce the memory footprint of popular large-scale online learning methods by projecting our weight vector onto a coarse discrete set using randomized rounding. Compared to standard 32-bit float encodings, this reduces RAM usage by more than 50% during training and by up to 95% when making predictions from a fixed model, with almost no loss in accuracy. We also show that randomized counting can be used to implement per-coordinate learning rates, improving model quality with little additional RAM. We prove these memory-saving methods achieve regret guarantees similar to their exact variants. Empirical evaluation confirms excellent performance, dominating standard approaches across memory versus accuracy tradeoffs.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Latent Factor Models with Additive Hierarchically-smoothed User Preferences
Proceedings of The 6th ACM International Conference on Web Search and Data Mining (WSDM) (2013) (to appear)
[u'Amr Ahmed', u'Bhargav Kanagal', u'Sandeep Pandey', u'Vanja Josifovski', u'Lluis Garcia-Pueyo']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40753.html
notfound
=========================
Learning Binary Codes for High Dimensional Data Using Bilinear Projections
IEEE Computer Vision and Pattern Recognition (2013)
[u'Yunchao Gong', u'Sanjiv Kumar', u'Henry Rowley', u'Svetlana Lazebnik']
MachineIntelligence
Abstract: Recent advances in visual recognition indicate that to achieve good retrieval and classication accuracy on large scale datasets like ImageNet, extremely high-dimensional visual descriptors, e.g., Fisher Vectors, are needed. We present a novel method for converting such descriptors to compact similarity-preserving binary codes that exploits their natural matrix structure to reduce their dimensionality using compact bilinear projections instead of a single large projection matrix. This method achieves comparable retrieval and classication accuracy to the original descriptors and to the state-of-the-art Product Quantization approach while having orders of magnitude faster code generation time and smaller memory footprint.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41320.html
notfound
=========================
Learning Multiple Non-Linear Sub-Spaces using K-RBMs
Computer Vision and Pattern Recognition (2013)
[u'Siddhartha Chandra', u'Shailesh Kumar', u'C. V. Jawahar']
MachineIntelligence
Abstract: Understanding the nature of data is the key to building good representations. In domains such as natural images, the data comes from very complex distributions which are hard to capture. Feature learning intends to discover or best approximate these underlying distributions and use their knowledge to weed out irrelevant information, preserving most of the relevant information. Feature learning can thus be seen as a form of dimensionality reduction. In this paper, we describe a feature learning scheme for natural images. We hypothesize that image patches do not all come from the same distribution, they lie in multiple nonlinear subspaces. We propose a framework that uses K-Restricted Boltzmann Machines (K-RBMS) to learn multiple non-linear subspaces in the raw image space. Projections of the image patches into these subspaces gives us features, which we use to build image representations. Our algorithm solves the coupled problem of nding the right non-linear subspaces in the input space and associating image patches with those subspaces in an iterative EM like algorithm to minimize the overall reconstruction error. Extensive empirical results over several popular image classication datasets show that representations based on our framework outperform the traditional feature representations such as the SIFT based Bag-of-Words (BoW) and convolutional deep belief networks.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41394.html
notfound
=========================
Learning Prices for Repeated Auctions with Strategic Buyers
Neural Information Processing Systems (2013)
[u'Kareem Amin', u'Afshin Rostamizadeh', u'Umar Syed']
MachineIntelligence
Abstract: Inspired by real-time ad exchanges for online display advertising, we consider the problem of inferring a buyers value for a good when the buyer is repeatedly interacting with the seller through a posted-price mechanism. We model the buyer as a strategic agent, interested in maximizing her long-term surplus, and are interested in optimizing seller revenue. We show conditions under which the seller cannot hope to gain an advantage by learning the buyers value i.e. the buyer can always manipulate the exchange to hide her value. This result is accompanied by a seller algorithm that is able to achieve no-regret when the buyer is unable to incur the short-term costs of such manipulation.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Learning Semantic Representations Of Objects And Their Parts.
Special Issue on Learning Semantics in Machine Learning Journal (2013) (to appear)
[u'G Mesnil', u'Antoine Bordes', u'Jason Weston', u'Gal Chechik', u'Yoshua Bengio']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42029.html
notfound
=========================
Learning kernels using local rademacher complexity
Advances in Neural Information Processing Systems (NIPS 2013), MIT Press.
[u'Corinna Cortes', u'Marius Kloft', u'Mehryar Mohri']
MachineIntelligence
Abstract: We use the notion of local Rademacher complexity to design new algorithms for learning kernels. Our algorithms thereby benefit from the sharper learning bounds based on that notion which, under certain general conditions, guarantee a faster convergence rate. We devise two new learning kernel algorithms: one based on a convex optimization problem for which we give an efficient solution using existing learning kernel techniques, and another one that can be formulated as a DC-programming problem for which we describe a solution in detail. We also re- port the results of experiments with both algorithms in both binary and multi-class classification tasks.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41534.html
found
=========================
Learning to Rank Recommendations with the k-Order Statistic Loss
ACM International Conference on Recommender Systems (RecSys) (2013)
[u'Jason Weston', u'Hector Yee', u'Ron Weiss']
MachineIntelligence
Abstract: Making recommendations by learning to rank is becoming an increasingly studied area. Approaches that use stochastic gradient descent scale well to large collaborative ltering datasets, and it has been shown how to approximately optimize the mean rank, or more recently the top of the ranked list. In this work we present a family of loss functions, the korder statistic loss, that includes these previous approaches as special cases, and also derives new ones that we show to be useful. In particular, we present (i) a new variant that more accurately optimizes precision at k, and (ii) a novel procedure of optimizing the mean maximum rank, which we hypothesize is useful to more accurately cover all of the users tastes. The general approach works by sampling N positive items, ordering them by the score assigned by the model, and then weighting the example as a function of this ordered set. Our approach is studied in two real-world systems, Google Music and YouTube video recommendations, where we obtain improvements for computable metrics, and in the YouTube case, increased user click through and watch duration when deployed live on www.youtube.com.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Making touchscreen keyboards adaptive to keys, hand postures, and individuals: a hierarchical spatial backoff model approach
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI 2013), ACM, New York, NY, pp. 2775-2784
[u'Ying Yin', u'Tom Ouyang', u'Kurt Partridge', u'Shumin Zhai']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Measurement and modeling of eye-mouse behavior
Proceedings of the 22nd International World Wide Web Conference (2013)
[u'Vidhya Navalpakkam', u'LaDawn Jentzsch', u'Rory Sayres', u'Sujith Ravi', u'Amr Ahmed', u'Alex J. Smola']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41859.html
found
=========================
Minimax Optimal Algorithms for Unconstrained Linear Optimization
Advances in Neural Information Processing Systems (NIPS) (2013)
[u'H. Brendan McMahan', u'Jacob Abernethy']
MachineIntelligence
Abstract: We design and analyze minimax-optimal algorithms for online linear optimization games where the player's choice is unconstrained. The player strives to minimize regret, the difference between his loss and the loss of a post-hoc benchmark strategy. While the standard benchmark is the loss of the best strategy chosen from a bounded comparator set, we consider a very broad range of benchmark functions. The problem is cast as a sequential multi-stage zero-sum game, and we give a thorough analysis of the minimax behavior of the game, providing characterizations for the value of the game, as well as both the player's and the adversary's optimal strategy. We show how these objects can be computed efficiently under certain circumstances, and by selecting an appropriate benchmark, we construct a novel hedging strategy for an unconstrained betting game.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40750.html
notfound
=========================
Multi-Armed Recommendation Bandits for Selecting State Machine Policies for Robotic Systems
Proceedings of International Conference on Robotics and Automation (ICRA 2013)
[u'Pyry Matikainen', u'P. Michael Furlong', u'Rahul Sukthankar', u'Martial Hebert']
MachineIntelligence
Abstract: We investigate the problem of selecting a state-machine from a library to control a robot. We are particularly interested in this problem when evaluating such state machines on a particular robotics task is expensive. As a motivating example, we consider a problem where a simulated vacuuming robot must select a driving state machine well-suited for a particular (unknown) room layout. By borrowing concepts from collaborative filtering (recommender systems such as Netflix and Amazon.com), we present a multi-armed bandit formulation that incorporates recommendation techniques to efficiently select state machines for individual room layouts. We show that this formulation outperforms the individual approaches (recommendation, multi-armed bandits) as well as the baseline of selecting the `average best' state machine across all rooms.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Multi-class classification with maximum margin multiple kernel
Proceedings of the Thirtieth International Conference on Machine Learning (ICML 2013)
[u'Corinna Cortes', u'Mehryar Mohri', u'Afshin Rostamizadeh']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Multiframe Deep Neural Networks for Acoustic Modeling
Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), IEEE, Vancouver, CA (2013)
[u'Vincent Vanhoucke', u'Matthieu Devin', u'Georg Heigold']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Multilingual acoustic models using distributed deep neural networks
Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), IEEE, Vancouver, CA (2013)
[u'Georg Heigold', u'Vincent Vanhoucke', u'Andrew Senior', u'Patrick Nguyen', u"Marc'aurelio Ranzato", u'Matthieu Devin', u'Jeff Dean']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41333.html
found
=========================
Neighborhood Preserving Codes for Assigning Point Labels: Applications to Stochastic Search
Procedia Computer Science: 2013 International Conference on Computational Science, Elsevier, pp. 956-965
[u'Shumeet Baluja', u'Michele Covell']
MachineIntelligence
Abstract: Selecting a good representation of a solution-space is vital to solving any search and optimization problem. In particular, once regions of high performance are found, having the property that small changes in the candidate solution correspond to searching nearby neighborhoods provides the ability to perform effective local optimization. To achieve this, it is common for stochastic search algorithms, such as stochastic hillclimbing, evolutionary algorithms (including genetic algorithms), and simulated annealing, to employ Gray Codes for encoding ordinal points or discretized real numbers. In this paper, we present a novel method to label similar and/or close points within arbitrary graphs with small Hamming distances. The resultant point labels can be seen as an approximate high-dimensional variant of Gray Codes with standard Gray Codes as a subset of the labels found here. The labeling procedure is applicable to any task in which the solution requires the search algorithm to select a small subset of items out of many. Such tasks include vertex selection in graphs, knapsack-constrained item selection, bin packing, prototype selection for machine learning, and numerous scheduling problems, to name a few.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41535.html
notfound
=========================
Nonlinear Latent Factorization by Embedding Multiple User Interests
ACM International Conference on Recommender Systems (RecSys) (2013)
[u'Jason Weston', u'Ron Weiss', u'Hector Yee']
MachineIntelligence
Abstract: Classical matrix factorization approaches to collaborative filtering learn a latent vector for each user and each item, and recommendations are scored via the similarity between two such vectors, which are of the same dimension. In this work, we are motivated by the intuition that a user is a much more complicated entity than any single item, and cannot be well described by the same representation. Hence, the variety of a users interests could be better captured by a more complex representation. We propose to model the user with a richer set of functions, specically via a set of latent vectors, where each vector captures one of the users latent interests or tastes. The overall recommendation model is then nonlinear where the matching score between a user and a given item is the maximum matching score over each of the users latent interests with respect to the items latent representation. We describe a simple, general and efficient algorithm for learning such a model, and apply it to large scale, real world datasets from YouTube and Google Music, where our approach outperforms existing techniques.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40811.html
notfound
=========================
On Rectified Linear Units For Speech Processing
38th International Conference on Acoustics, Speech and Signal Processing (ICASSP), Vancouver (2013)
[u'M.D. Zeiler', u'M. Ranzato', u'R. Monga', u'M. Mao', u'K. Yang', u'Q.V. Le', u'P. Nguyen', u'A. Senior', u'V. Vanhoucke', u'J. Dean', u'G.E. Hinton']
MachineIntelligence
Abstract: Deep neural networks have recently become the gold standard for acoustic modeling in speech recognition systems. The key computational unit of a deep network is a linear projection followed by a point-wise non-linearity, which is typically a logistic function. In this work, we show that we can improve generalization and make training of deep networks faster and simpler by substituting the logistic units with rectified linear units. These units are linear when their input is positive and zero otherwise. In a supervised setting, we can successfully train very deep nets from random initialization on a large vocabulary speech recognition task achieving lower word error rates than using a logistic network with the same topology. Similarly in an unsupervised setting, we show how we can learn sparse features that can be useful for discriminative tasks. All our experiments are executed in a distributed environment using several hundred machines and several hundred hours of speech data.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41880.html
notfound
=========================
One Billion Word Benchmark for Measuring Progress in Statistical Language Modeling
ArXiv, Google (2013)
[u'Ciprian Chelba', u'Tomas Mikolov', u'Mike Schuster', u'Qi Ge', u'Thorsten Brants', u'Phillipp Koehn', u'Tony Robinson']
MachineIntelligence
Abstract: We propose a new benchmark corpus to be used for measuring progress in statistical language modeling. With almost one billion words of training data, we hope this benchmark will be useful to quickly evaluate novel language modeling techniques, and to compare their contribution when combined with other advanced techniques. We show performance of several well-known types of language models, with the best results achieved with a recurrent neural network based language model. The baseline unpruned Kneser-Ney 5-gram model achieves perplexity 67.6; a combination of techniques leads to 35% reduction in perplexity, or 10% reduction in cross-entropy (bits), over that baseline. The benchmark is available as a code.google.com project at https://code.google.com/p/1-billion-word-language-modeling-benchmark/; besides the scripts needed to rebuild the training/held-out data, it also makes available log-probability values for each word in each of ten held-out data sets, for each of the baseline n-gram models.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
POMDP-Based Control of Workflows for Crowdsourcing
Artificial Intelligence, vol. 202 (2013), pp. 52-85
[u'Peng Dai', u'Christopher H. Lin', u'Mausam', u'Daniel S. Weld']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41343.html
found
=========================
PRIME: Probabilistic Initial 3D Model Generation for Single-Particle Cryo-Electron Microscopy
Structure, vol. 21 (2013), pp. 1299-1306
[u'Hans Elmlund', u'Dominika Elmlund', u'Samy Bengio']
MachineIntelligence
Abstract: Low-dose electron microscopy of cryo-preserved individual biomolecules (single-particle cryo-EM) is a powerful tool for obtaining information about the structure and dynamics of large macromolecular assemblies. Acquiring images with low dose reduces radiation damage, preserves atomic structural details, but results in low signal-to-noise ratio of the individual images. The projection directions of the two-dimensional images are random and unknown. The grand challenge is to achieve the precise three-dimensional (3D) alignment of many (tens of thousands to millions) noisy projection images, which may then be combined to obtain a faithful 3D map. An accurate initial 3D model is critical for obtaining the precise 3D alignment required for high-resolution (<10 ) map reconstruction. We report a method (PRIME) that, in a single step and without prior structural knowledge, can generate an accurate initial 3D map directly from the noisy images.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41341.html
notfound
=========================
Parallel Boosting with Momentum
ECML PKDD 2013, Part III, LNAI 8190, Springer, Heidelberg, pp. 17-32 (to appear)
[u'Indraneel Mukherjee', u'Kevin Canini', u'Rafael Frongillo', u'Yoram Singer']
MachineIntelligence
Abstract: We describe a new, simplied, and general analysis of a fusion of Nesterovs accelerated gradient with parallel coordinate descent. The resulting algorithm, which we call BOOM, for boosting with momentum, enjoys the merits of both techniques. Namely, BOOM retains the momentum and convergence properties of the accelerated gradient method while taking into account the curvature of the objective function. We describe a distributed implementation of BOOM which is suitable for massive high dimensional datasets. We show experimentally that BOOM is especially eective in large scale learning problems with rare yet informative features.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41332.html
found
=========================
Point Representation for Local Optimization: Towards Multi-Dimensional Gray Codes
Proceedings IEEE Congress on Evolutionary Computation, IEEE (2013)
[u'Shumeet Baluja', u'Michele Covell']
MachineIntelligence
Abstract: In the context of stochastic search, once regions of high performance are found, having the property that small changes in the candidate solution correspond to searching nearby neighborhoods provides the ability to perform effective local optimization. To achieve this, Gray Codes are often employed for encoding ordinal points or discretized real numbers. In this paper, we present a method to label similar and/or close points within arbitrary graphs with small Hamming distances. The resultant point labels can be viewed as an approximate high-dimensional variant of Gray Codes. The labeling procedure is useful for any task in which the solution requires the search algorithm to select a small subset of items out of many. A large number of empirical results using these encodings with a combination of genetic algorithms and hill-climbing are presented.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41531.html
notfound
=========================
ReFr: An Open-Source Reranker Framework
Interspeech 2013, pp. 756-758
[u'Daniel M. Bikel', u'Keith B. Hall']
MachineIntelligence
Abstract: ReFr (http://refr.googlecode.com) is a software architecture for specifying, training and using reranking models, which take the n-best output of some existing system and produce new scores for each of the n hypotheses that potentially induce a different ranking, ideally yielding better results than the original system. The Reranker Framework has some special support for building discriminative language models, but can be applied to any reranking problem. The framework is designed with parallelism and scalability in mind, being able to run on any Hadoop cluster out of the box. While extremely efcient, ReFr is also quite exible, allowing researchers to explore a wide variety of features and learning methods. ReFr has been used for building state-of-the-art discriminative LMs for both speech recognition and machine translation systems.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41186.html
notfound
=========================
Recurrent Neural Networks for Voice Activity Detection
ICASSP, IEEE (2013), pp. 7378-7382
[u'Thad Hughes', u'Keir Mierle']
MachineIntelligence
Abstract: We present a novel recurrent neural network (RNN) model for voice activity detection. Our multi-layer RNN model, in which nodes compute quadratic polynomials, outperforms a much larger baseline system composed of Gaussian mixture models (GMMs) and a hand-tuned state machine (SM) for temporal smoothing. All parameters of our RNN model are optimized together, so that it properly weights its preference for temporal continuity against the acoustic features in each frame. Our RNN uses one tenth the parameters and outperforms the GMM+SM baseline system by 26% reduction in false alarms, reducing overall speech recognition computation time by 17% while reducing word error rate by 1% relative.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41871.html
notfound
=========================
Restricted Transfer learning for Text Categorization
NIPS Workshop (2013) (to appear)
[u'Rajhans Samdani', u'Gideon Mann']
MachineIntelligence
Abstract: In practice, machine learning systems deal with multiple datasets over time. When the feature spaces between these datasets overlap, it is possible to transfer information from one task to another. Typically in transfer learning, all labeled data from a source task is saved to be applied to a new target task thereby raising concerns of privacy, memory and scaling. To ameliorate such concerns, we present a semi-supervised algorithm for text categorization that transfers information across tasks without storing the data of the source task. In particular, our technique learns a sparse low-dimensional projection from unlabeled and the source task data. In particular, our technique learns low-dimensional sparse word clusters-based features from the source task data and a massive amount of additional unlabeled data. Our algorithm is efcient, highly parallelizable, and outperforms competitive baselines by up to 9% on several difcult benchmark text categorization tasks.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Russian Stress Prediction using Maximum Entropy Ranking
EMNLP, ACL (2013)
[u'Keith Hall', u'Richard Sproat']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Scalable Decipherment for Machine Translation via Hash Sampling
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL) (2013)
[u'Sujith Ravi']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Scalable Dynamic Nonparametric Bayesian Models of Content and Users
International Joint Conference on Artificial Intelligence (IJCAI - Best paper track) (2013) (to appear)
[u'Amr Ahmed', u'Eric P. Xing']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Search Results Based N-Best Hypothesis Rescoring With Maximum Entropy Classification
Proceedings of ASRU (2013)
[u'Fuchun Peng', u'Scott Roy', u'Ben Shahshahani', u'Franoise Beaufays']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41697.html
found
=========================
Similarity-based Clustering by Left-Stochastic Matrix Factorization
Journal Machine Learning Research (JMLR), vol. 14 (2013), pp. 1715-1746
[u'Raman Arora', u'Maya R. Gupta', u'Amol Kapila', u'Maryam Fazel']
MachineIntelligence
Abstract: For similarity-based clustering, we propose modeling the entries of a given similarity matrix as the inner products of the unknown cluster probabilities. To estimate the cluster probabilities from the given similarity matrix, we introduce a left-stochastic non-negative matrix factorization problem. A rotation-based algorithm is proposed for the matrix factorization. Conditions for unique matrix factorizations and clusterings are given, and an error bound is provided. The algorithm is particularly efficient for the case of two clusters, which motivates a hierarchical variant for cases where the number of desired clusters is large. Experiments show that the proposed left-stochastic decomposition clustering model produces relatively high within-cluster similarity on most data sets and can match given class labels, and that the efficient hierarchical variant performs surprisingly well.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40752.html
notfound
=========================
Spatiotemporal Deformable Part Models for Action Detection
Proceedings of International Conference on Computer Vision and Pattern Recognition (CVPR 2013)
[u'Yicong Tian', u'Rahul Sukthankar', u'Mubarak Shah']
MachineIntelligence
Abstract: Deformable part models have achieved impressive performance for object detection, even on difficult image datasets. This paper explores the generalization of deformable part models from 2D images to 3D spatiotemporal volumes to better study their effectiveness for action detection in video. Actions are treated as spatiotemporal patterns and a deformable part model is generated for each action from a collection of examples. For each action model, the most discriminative 3D subvolumes are automatically selected as parts and the spatiotemporal relations between their locations are learned. By focusing on the most distinctive parts of each action, our models adapt to intra-class variation and show robustness to clutter. Extensive experiments on several video datasets demonstrate the strength of spatiotemporal DPMs for classifying and localizing actions.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
The Nested Chinese Restaurant Franchise Process: User Tracking and Document Modeling
International Conference on Machine Learning (ICML) (2013) (to appear)
[u'Amr Ahmed', u'Liangjie Hong', u'Alexander J Smola']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41530.html
found
=========================
Transfer Learning In MIR: Sharing Learned Latent Representations For Music Audio Classification And Similarity
14th International Conference on Music Information Retrieval (ISMIR '13) (2013)
[u'Philippe Hamel', u'Matthew E. P. Davies', u'Kazuyoshi Yoshii', u'Masataka Goto']
MachineIntelligence
Abstract: This paper discusses the concept of transfer learning and its potential applications to MIR tasks such as music audio classification and similarity. In a traditional supervised machine learning setting, a system can only use labeled data from a single dataset to solve a given task. The labels associated with the dataset define the nature of the task to solve. A key advantage of transfer learning is in leveraging knowledge from related tasks to improve performance on a given target task. One way to transfer knowledge is to learn a shared latent representation across related tasks. This method has shown to be beneficial in many domains of machine learning, but has yet to be explored in MIR. Many MIR datasets for audio classification present a semantic overlap in their labels. Furthermore, these datasets often contain relatively few songs. Thus, there is a strong case for exploring methods to share knowledge between these datasets towards a more general and robust understanding of high level musical concepts such as genre and similarity. Our results show that shared representations can improve classification accuracy. We also show how transfer learning can improve performance for music similarity.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Translating Embeddings for Modeling Multi-relational Data.
Neural Information Processing Systems (2013)
[u'Antoine Bordes', u'Nicolas Usunier', u'A. Garcia-Duran', u'Jason Weston', u'Oksana Yakhnenko']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42244.html
notfound
=========================
Using Web Co-occurrence Statistics for Improving Image Categorization
arXiv (2013)
[u'Samy Bengio', u'Jeffrey Dean', u'Dumitru Erhan', u'Eugene Ie', u'Quoc Le', u'Andrew Rabinovich', u'Jonathon Shlens', u'Yoram Singer']
MachineIntelligence
Abstract: Object recognition and localization are important tasks in computer vision. The focus of this work is the incorporation of contextual information in order to improve object recognition and localization. For instance, it is natural to expect not to see an elephant to appear in the middle of an ocean. We consider a simple approach to encapsulate such common sense knowledge using co-occurrence statistics from web documents. By merely counting the number of times nouns (such as elephants, sharks, oceans, etc.) co-occur in web documents, we obtain a good estimate of expected co-occurrences in visual data. We then cast the problem of combining textual co-occurrence statistics with the predictions of image-based classifiers as an optimization problem. The resulting optimization problem serves as a surrogate for our inference procedure. Albeit the simplicity of the resulting optimization problem, it is effective in improving both recognition and localization accuracy. Concretely, we observe significant improvements in recognition and localization rates for both ImageNet Detection 2012 and Sun 2012 datasets.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
pSVM for Learning with Label Proportions
International Conference on Machine Learning (ICML) (2013)
[u'Felix X. Yu', u'Dong Liu', u'Sanjiv Kumar', u'Tony Jebara', u'Shih-Fu Chang']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Disambiguation Algorithm for Finite Automata and Functional Transducers
CIAA (2012), pp. 265-277
[u'Mehryar Mohri', u'Andres Munoz Medina']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40498.html
found
=========================
Accuracy at the Top
NIPS: Neural Information Processing Systems Foundation (2012)
[u'Stephen Boyd', u'Corinna Cortes', u'Mehryar Mohri', u'Ana Radovanovic']
MachineIntelligence
Abstract: We introduce a new notion of classication accuracy based on the top -quantile values of a scoring function, a relevant criterion in a number of problems arising for search engines. We dene an algorithm optimizing a convex surrogate of the corresponding loss, and show how its solution can be obtained by solving a set of convex optimization problems. We also present margin-based guarantees for this algorithm based on the top -quantile of the scores of the functions in the hypothesis set. Finally, we report the results of several experiments in the bipartite setting evaluating the performance of our algorithm and comparing the results to several other algorithms seeking high precision at the top. In most examples, our algorithm achieves a better performance in precision at the top.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Algorithms for Learning Kernels Based on Centered Alignment
Journal of Machine Learning Research, vol. 13 (2012), pp. 795-828
[u'Corinna Cortes', u'Mehryar Mohri', u'Afshin Rostamizadeh']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Angular Quantization-based Binary Codes for Fast Similarity Search
Neural Information Processing Systems (NIPS) (2012)
[u'Yunchao Gong', u'Sanjiv Kumar', u'Vishal Verma', u'Svetlana Lazebnik']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38130.html
notfound
=========================
Application Of Pretrained Deep Neural Networks To Large Vocabulary Speech Recognition
Proceedings of Interspeech 2012
[u'Navdeep Jaitly', u'Patrick Nguyen', u'Andrew Senior', u'Vincent Vanhoucke']
MachineIntelligence
Abstract: The use of Deep Belief Networks (DBN) to pretrain Neural Networks has recently led to a resurgence in the use of Articial Neural Network - Hidden Markov Model (ANN/HMM) hybrid systems for Automatic Speech Recognition (ASR). In this paper we report results of a DBN-pretrained context-dependent ANN/HMM system trained on two datasets that are much larger than any reported previously with DBN-pretrained ANN/HMM systems - 5870 hours of Voice Search and 1400 hours of YouTube data. On the rst dataset, the pretrained ANN/HMM system outperforms the best Gaussian Mixture Model - Hidden Markov Model (GMM/HMM) baseline, built with a much larger dataset by 3.7% absolute WER, while on the second dataset, it outperforms the GMM/HMM baseline by 4.7% absolute. Maximum Mutual Information (MMI) ne tuning and model combination using Segmental Conditional Random Fields (SCARF) give additional gains of 0.1% and 0.4% on the rst dataset and 0.5% and 0.9% absolute on the second dataset.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38115.html
notfound
=========================
Building high-level features using large scale unsupervised learning
International Conference in Machine Learning (2012)
[u'Quoc Le', u"Marc'Aurelio Ranzato", u'Rajat Monga', u'Matthieu Devin', u'Kai Chen', u'Greg Corrado', u'Jeff Dean', u'Andrew Ng']
MachineIntelligence
Abstract: We consider the problem of building highlevel, class-specic feature detectors from only unlabeled data. For example, is it possible to learn a face detector using only unlabeled images? To answer this, we train a 9-layered locally connected sparse autoencoder with pooling and local contrast normalization on a large dataset of images (the model has 1 billion connections, the dataset has 10 million 200x200 pixel images downloaded from the Internet). We train this network using model parallelism and asynchronous SGD on a cluster with 1,000 machines (16,000 cores) for three days. Contrary to what appears to be a widely-held intuition, our experimental results reveal that it is possible to train a face detector without having to label images as containing a face or not. Control experiments show that this feature detector is robust not only to translation but also to scaling and out-of-plane rotation. We also nd that the same network is sensitive to other high-level concepts such as cat faces and human bodies. Starting with these learned features, we trained our network to obtain 15.8% accuracy in recognizing 20,000 object categories from ImageNet, a leap of 70% relative improvement over the previous state-of-the-art.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40680.html
notfound
=========================
Buildling adaptive dialogue systems via Bayes-adaptive POMDP
IEEE Journal of Selected Topics in Signal Processing, vol. vol.6(8). 2012. (2012), pp. 917-927
[u'Shaowei Png', u'Joelle Pineau', u'B. Chaib-draa']
MachineIntelligence
Abstract: Recent research has shown that effective dialogue management can be achieved through the Partially Observable Markov Decision Process (POMDP) framework. However past research on POMDP-based dialogue systems usually assumed the parameters of the decision process were known a priori. The main contribution of this paper is to present a Bayesian reinforcement learning framework for learning the POMDP parameters online from data, in a decision-theoretic manner. We discuss various approximations and assumptions which can be leveraged to ensure computational tractability, and apply these techniques to learning observation models for several simulated spoken dialogue domains.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38141.html
found
=========================
Compact Hyperplane Hashing with Bilinear Functions
International Conference on Machine Learning (ICML) (2012)
[u'Wei Liu', u'Jun Wang', u'Yadong Mu', u'Sanjiv Kumar', u'Shih-Fu Chang']
MachineIntelligence
Abstract: Hyperplane hashing aims at rapidly searching nearest points to a hyperplane, and has shown practical impact in scaling up active learning with SVMs. Unfortunately, the existing randomized methods need long hash codes to achieve reasonable search accuracy and thus suffer from reduced search speed and large memory overhead. To this end, this paper proposes a novel hyperplane hashing technique which yields compact hash codes. The key idea is the bilinear form of the proposed hash functions, which leads to higher collision probability than the existing hyperplane hash functions when using random projections. To further increase the performance, we propose a learning based framework in which the bilinear functions are directly learned from the data. This results in short yet discriminative codes, and also boosts the search performance over the random projection based solutions. Large-scale active learning experiments carried out on two datasets with up to one million samples demonstrate the overall superiority of the proposed approach.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38131.html
notfound
=========================
Deep Neural Networks for Acoustic Modeling in Speech Recognition
Signal Processing Magazine (2012)
[u'Geoffrey Hinton', u'Li Deng', u'Dong Yu', u'George Dahl', u'Abdel-rahman Mohamed', u'Navdeep Jaitly', u'Andrew Senior', u'Vincent Vanhoucke', u'Patrick Nguyen', u'Tara Sainath', u'Brian Kingsbury']
MachineIntelligence
Abstract: Most current speech recognition systems use hidden Markov models (HMMs) to deal with the temporal variability of speech and Gaussian mixture models to determine how well each state of each HMM ts a frame or a short window of frames of coefcients that represents the acoustic input. An alternative way to evaluate the t is to use a feedforward neural network that takes several frames of coefcients as input and produces posterior probabilities over HMM states as output. Deep neural networks with many hidden layers, that are trained using new methods have been shown to outperform Gaussian mixture models on a variety of speech recognition benchmarks, sometimes by a large margin. This paper provides an overview of this progress and represents the shared views of four research groups who have had recent successes in using deep neural networks for acoustic modeling in speech recognition.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37361.html
notfound
=========================
Distributed Gibbs sampling for latent variable models
Scaling up Machine Learning, Cambridge (2012) (to appear)
[u'Arthur Asuncion', u'Padhraic Smyth', u'Max Welling', u'David Newman', u'Ian Porteous', u'Scott Triglia']
MachineIntelligence
Abstract: This book presents an integrated collection of representative approaches for scaling up machine learning and data mining methods on parallel and distributed computing platforms. Demand for parallelizing learning algorithms is highly task-specific: in some settings it is driven by the enormous dataset sizes, in others by model complexity or by real-time performance requirements. Making task-appropriate algorithm and platform choices for large-scale machine learning requires understanding the benefits, trade-offs and constraints of the available options. Solutions presented in the book cover a range of parallelization platforms from FPGAs and GPUs to multi-core systems and commodity clusters, concurrent programming frameworks including CUDA, MPI, MapReduce and DryadLINQ, and learning settings (supervised, unsupervised, semi-supervised and online learning). Extensive coverage of parallelization of boosted trees, SVMs, spectral clustering, belief propagation and other popular learning algorithms and deep dives into several applications make the book equally useful for researchers, students and practitioners
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
FastEx: Hash Clustering with Exponential Families
Proceedings of the 26th Conference on Neural Information Processing Systems. (NIPS) (2012)
[u'Amr Ahmed', u'Sujith Ravi', u'Shravan Narayanamurthy', u'Alex Smola']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38346.html
found
=========================
Hokusai | Sketching Streams in Real Time
Proceedings of the 28th International Conference on Conference on Uncertainty in Artificial Intelligence (UAI) (2012)
[u'Sergiy Matusevych', u'Alex Smola', u'Amr Ahmed']
MachineIntelligence
Abstract: We describe Hokusai, a real time system which is able to capture frequency information for streams of arbitrary sequences of symbols. The algorithm uses the Count-Min sketch as its basis and exploits the fact that sketching is linear. It provides real time statistics of arbitrary events, e.g. streams of queries as a function of time. We use a factorizing approximation to provide point estimates at arbitrary (time, item) combinations.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40741.html
found
=========================
Human Computation Must Be Reproducible
WWW 2012, Lyon.
[u'Praveen Paritosh']
MachineIntelligence
Abstract: Human computation is the technique of performing a computational process by outsourcing some of the difficult-to-automate steps to humans. In the social and behavioral sciences, when using humans as measuring instruments, reproducibility guides the design and evaluation of experiments. We argue that human computation has similar properties, and that the results of human computation must be reproducible, in the least, in order to be informative. We might additionally require the results of human computation to have high validity or high utility, but the results must be reproducible in order to measure the validity or utility to a degree better than chance. Additionally, a focus on reproducibility has implications for design of task and instructions, as well as for the communication of the results. It is humbling how often the initial understanding of the task and guidelines turns out to lack reproducibility. We suggest ensuring, measuring and communicating reproducibility of human computation tasks.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40575.html
notfound
=========================
Joint Image and Word Sense Discrimination For Image Retrieval
ECCV (2012)
[u'Aurelien Lucchi', u'Jason Weston']
MachineIntelligence
Abstract: We study the task of learning to rank images given a text query, a problem that is complicated by the issue of multiple senses. That is, the senses of interest are typically the visually distinct concepts that a user wishes to retrieve. In this paper, we propose to learn a ranking function that optimizes the ranking cost of interest and simultaneously discovers the disambiguated senses of the query that are optimal for the supervised task. Note that no supervised information is given about the senses. Experiments performed on web images and the ImageNet dataset show that using our approach leads to a clear gain in performance.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40565.html
notfound
=========================
Large Scale Distributed Deep Networks
NIPS (2012)
[u'Jeffrey Dean', u'Greg S. Corrado', u'Rajat Monga', u'Kai Chen', u'Matthieu Devin', u'Quoc V. Le', u'Mark Z. Mao', u'MarcAurelio Ranzato', u'Andrew Senior', u'Paul Tucker', u'Ke Yang', u'Andrew Y. Ng']
MachineIntelligence
Abstract: Recent work in unsupervised feature learning and deep learning has shown that being able to train large models can dramatically improve performance. In this paper, we consider the problem of training a deep network with billions of parameters using tens of thousands of CPU cores. We have developed a software framework called DistBelief that can utilize computing clusters with thousands of machines to train large models. Within this framework, we have developed two algorithms for large-scale distributed training: (i) Downpour SGD, an asynchronous stochastic gradient descent procedure supporting a large number of model replicas, and (ii) Sandblaster, a framework that supports a variety of distributed batch optimization procedures, including a distributed implementation of L-BFGS. Downpour SGD and Sandblaster L-BFGS both increase the scale and speed of deep network training. We have successfully used our system to train a deep network 30x larger than previously reported in the literature, and achieves state-of-the-art performance on ImageNet, a visual object recognition task with 16 million images and 21k categories. We show that these same techniques dramatically accelerate the training of a more modestly- sized deep network for a commercial speech recognition service. Although we focus on and report performance of these methods as applied to training large neural networks, the underlying algorithms are applicable to any gradient-based machine learning algorithm.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37716.html
notfound
=========================
Large Scale Visual Semantic Extraction
Frontiers of Engineering - Reports on Leading-Edge Engineering from the 2011 Symposium, The National Academies Press, Washington, D.C. (2012), pp. 61-68
[u'Samy Bengio']
MachineIntelligence
Abstract: Image annotation is the task of providing textual semantic to new images, by ranking a large set of possible annotations according to how they correspond to a given image. In the large scale setting, there could be millions of images to process and hundreds of thousands of potential distinct annotations. In order to achieve such a task we propose to build a so-called "embedding space", into which both images and annotations can be automatically projected. In such a space, one can then find the nearest annotations to a given image, or annotations similar to a given annotation. One can even build a visio-semantic tree from these annotations, that corresponds to how concepts (annotations) are similar to each other with respect to their visual characteristics. Such a tree will be different from semantic-only trees, such as WordNet, which do not take into account the visual appearance of concepts.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40569.html
found
=========================
Latent Collaborative Retrieval
International Conference on Machine Learning (2012)
[u'Jason Weston', u'Chong Wang', u'Ron Weiss', u'Adam Berenzweig']
MachineIntelligence
Abstract: Retrieval tasks typically require a ranking of items given a query. Collaborative filtering tasks, on the other hand, learn models comparing users with items. In this paper we study the joint problem of recommending items to a user with respect to a given query, which is a surprisingly common task. This setup differs from the standard collaborative filtering one in that we are given a query user item tensor for training instead of the more traditional user item matrix. Compared to document retrieval we do have a query, but we may or may not have content features (we will consider both cases) and we can also take account of the users profile. We introduce a factorized model for this new task that optimizes the top ranked items returned for the given query and user. We report empirical results where it outperforms several baselines.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40574.html
found
=========================
Latent Structured Ranking
UAI (2012)
[u'Jason Weston', u'John Blitzer']
MachineIntelligence
Abstract: Many latent (factorized) models have been proposed for recommendation tasks like collaborative ltering and for ranking tasks like document or image retrieval and annotation. Common to all those methods is that during inference the items are scored independently by their similarity to the query in the latent embedding space. The structure of the ranked list (i.e. considering the set of items returned as a whole) is not taken into account. This can be a problem because the set of top predictions can be either too diverse (contain results that contradict each other) or are not diverse enough. In this paper we introduce a method for learning latent structured rankings that improves over existing methods by providing the right blend of predictions at the top of the ranked list. Particular emphasis is put on making this method scalable. Empirical results on large scale image annotation and music recommendation tasks show improvements over existing approaches.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41321.html
notfound
=========================
Learning Hierarchical Bag of Words Using Naive Bayes Clustering
Asian Conference on Computer Vision (2012), pp. 382-395
[u'Siddhartha Chandra', u'Shailesh Kumar', u'C. V. Jawahar']
MachineIntelligence
Abstract: Image analysis tasks such as classication, clustering, detection, and retrieval are only as good as the feature representation of the images they use. Much research in computer vision is focused on finding better or semantically richer image representations. Bag of visual Words (BoW) is a representation that has emerged as an eective one for a variety of computer vision tasks. BoW methods traditionally use low level features. We have devised a strategy to use these low level features to create \higher level" features by making use of the spatial context in images. In this paper, we propose a novel hierarchical feature learning framework that uses a Naive Bayes Clustering algorithm to convert a 2-D symbolic image at one level to a 2-D symbolic image at the next level with richer features. On two popular datasets, Pascal VOC 2007 and Caltech 101, we empirically show that classication accuracy obtained from the hierarchical features computed using our approach is signicantly higher than the traditional SIFT based BoW representation of images even though our image representations are more compact.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37178.html
notfound
=========================
Linear classifiers are nearly optimal when hidden variables have diverse effects
Machine Learning, vol. 86 (2012), pp. 209-231
[u'Nader H. Bshouty', u'Philip M. Long']
MachineIntelligence
Abstract: We analyze classification problems in which data is generated by a two-tiered random process. The class is generated first, then a layer of conditionally independent hidden variables, and finally the observed variables. For sources like this, the Bayes-optimal rule for predicting the class given the values of the observed variables is a two-layer neural network. We show that, if the hidden variables have non-negligible effects on many observed variables, a linear classifier approximates the error rate of the Bayes optimal classifier up to lower order terms. We also show that the hinge loss of a linear classifier is not much more than the Bayes error rate, which implies that an accurate linear classifier can be found efficiently.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38136.html
found
=========================
Machine learning: a probabilistic perspective
MIT Press, Cambridge, MA (2012)
[u'Kevin P Murphy']
MachineIntelligence
Abstract: Todays Web-enabled deluge of electronic data calls for automated methods of data analysis. Machine learning provides these, developing methods that can automatically detect patterns in data and then use the uncovered patterns to predict future data. This textbook offers a comprehensive and self-contained introduction to the field of machine learning, using a unified, probabilistic approach. The coverage combines breadth and depth, offering necessary background material on such topics as probability, optimization, and linear algebra as well as discussion of recent developments in the field, including conditional random fields, L1 regularization, and deep learning. The book is written in an informal, accessible style, complete with pseudo-code for the most important algorithms. All topics are copiously illustrated with color images and worked examples drawn from such application domains as biology, text processing, computer vision, and robotics. Rather than providing a cookbook of different heuristic methods, the book stresses a principled model-based approach, often using the language of graphical models to specify models in a concise and intuitive way. Almost all the models described have been implemented in a MATLAB software package--PMTK (probabilistic modeling toolkit)--that is freely available online. The book is suitable for upper-level undergraduates with an introductory-level college math background and beginning graduate students.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38352.html
found
=========================
MedLDA: Maximum Margin Supervised Topic Models
Journal of Machine Learning Research (2012) (to appear)
[u'Jun Zhu', u'Amr Ahmed', u'Eric P. Xing']
MachineIntelligence
Abstract: A supervised topic model can utilize side information such as ratings or labels associated with documents or images to discover more predictive low dimensional topical representations of the data. However, existing supervised topic models predominantly employ likelihood-driven objective functions for learning and inference, leaving the popular and potentially powerful max-margin principle unexploited for seeking predictive representations of data and more discriminative topic bases for the corpus. In this paper, we propose the maximum entropy discrimination latent Dirichlet allocation (MedLDA) model, which integrates the mechanism behind the max-margin prediction models (e.g., SVMs) with the mechanism behind the hierarchical Bayesian topic models (e.g., LDA) under a uni- ed constrained optimization framework, and yields latent topical representations that are more discriminative and more suitable for prediction tasks such as document classication or regression. The principle underlying the MedLDA formalism is quite general and can be applied for jointly max-margin and maximum likelihood learning of directed or undirected topic models when supervising side information is available. Ecient variational methods for posterior inference and parameter estimation are derived and extensive empirical studies on several real data sets are also provided. Our experimental results demonstrate qualitatively and quantitatively that MedLDA could: 1) discover sparse and highly discriminative topical representations; 2) achieve state of the art prediction performance;
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Minimizing Uncertainty in Pipelines
NIPS (2012) (to appear)
[u'Nilesh N. Dalvi', u'Aditya Parameswaran', u'Vibhor Rastogi']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38093.html
notfound
=========================
Model Recommendation for Action Recognition
IEEE International Conference on Computer Vision and Pattern Recognition (CVPR'12) (2012)
[u'Pyry Matikainen', u'Rahul Sukthankar', u'Martial Hebert']
MachineIntelligence
Abstract: Simply choosing one model out of a large set of possibilities for a given vision task is a surprisingly difficult problem, especially if there is limited evaluation data with which to distinguish among models, such as when choosing the best ``walk'' action classifier from a large pool of classifiers tuned for different viewing angles, lighting conditions, and background clutter. In this paper we suggest that this problem of selecting a good model can be recast as a recommendation problem, where the goal is to recommend a good model for a particular task based on how well a limited probe set of models appears to perform. Through this conceptual remapping, we can bring to bear all the collaborative filtering techniques developed for consumer recommender systems (e.g., Netflix, Amazon.com). We test this hypothesis on action recognition, and find that even when every model has been directly rated on a training set, recommendation finds better selections for the corresponding test set than the best performers on the training set.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
New Analysis and Algorithm for Learning with Drifting Distributions
ALT (2012), pp. 124-138
[u'Mehryar Mohri', u'Andres Munoz Medina']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40564.html
notfound
=========================
No-Regret Algorithms for Unconstrained Online Convex Optimization
Advances in Neural Information Processing Systems (NIPS) (2012)
[u'Matthew Streeter', u'H. Brendan McMahan']
MachineIntelligence
Abstract: Some of the most compelling applications of online convex optimization, including online prediction and classification, are unconstrained: the natural feasible set is R^n. Existing algorithms fail to achieve sub-linear regret in this setting unless constraints on the comparator point x* are known in advance. We present algorithms that, without such prior knowledge, offer near-optimal regret bounds with respect to any choice of x*. In particular, regret with respect to x* = 0 is constant. We then prove lower bounds showing that our guarantees are near-optimal in this setting.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40644.html
notfound
=========================
On Using Nearly-Independent Feature Families for High Precision and Confidence
Fourth Asian Machine Learning Conference, JMLR workshop and conference proceedings (2012), pp. 269-284
[u'Omid Madani', u'Manfred Georg', u'David Ross']
MachineIntelligence
Abstract: Often we require classification at a very high precision level, such as 99%. We report that when very different sources of evidence such as text, audio, and video features are available, combining the outputs of base classifiers trained on each feature type separately, aka late fusion, can substantially increase the recall of the combination at high precisions, compared to the performance of a single classifier trained on all the feature types i.e., early fusion, or compared to the individual base classifiers. We show how the probability of a joint false-positive mistake can be upper bounded by the product of individual probabilities of conditional false-positive mistakes, by identifying a simple key criterion that needs to hold. This provides an explanation for the high precision phenomenon, and motivates referring to such feature families as (nearly) independent. We assess the relevant factors for achieving high precision empirically, and explore combination techniques informed by the analysis. We compare a number of early and late fusion methods, and observe that classifier combination via late fusion can more than double the recall at high precision.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38140.html
found
=========================
On the Difficulty of Nearest Neighbor Search
International Conference on Machine Learning (ICML) (2012)
[u'Junfeng He', u'Sanjiv Kumar', u'Shih-Fu Chang']
MachineIntelligence
Abstract: Fast approximate nearest neighbor (NN) search in large databases is becoming popular and several powerful learning-based formulations have been proposed recently. However, not much attention has been paid to a more fundamental question: how difficult is (approximate) nearest neighbor search in a given data set? And which data properties affect the difficulty of nearest neighbor search and how? This paper introduces the first concrete measure called Relative Contrast that can be used to evaluate the influence of several crucial data characteristics such as dimensionality, sparsity, and database size simultaneously in arbitrary normed metric spaces. Moreover, we present a theoretical analysis to show how relative contrast affects the complexity of Local Sensitive Hashing, a popular approximate NN search method. Relative contrast also provides an explanation for a family of heuristic hashing algorithms with good practical performance based on PCA. Finally, we show that most of the previous works measuring meaningfulness or difficulty of NN search can be derived as special asymptotic cases for dense vectors of the proposed measure.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Online-to-Confidence-Set Conversions and Application to Sparse Stochastic Bandits
AISTATS 2012
[u'Yasin Abbasi-Yadkori', u'Dvid Pl', u'Csaba Szepesvri']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38137.html
found
=========================
Open Problem: Better Bounds for Online Logistic Regression
COLT/ICML Joint Open Problem Session, JMLR: Workshop and Conference Proceedings (2012)
[u'H. Brendan McMahan', u'Matthew Streeter']
MachineIntelligence
Abstract: Known algorithms applied to online logistic regression on a feasible set of L2 diameter D achieve regret bounds like O(eD log T) in one dimension, but we show a bound of O(sqrt(D) + log T) is possible in a binary 1-dimensional problem. Thus, we pose the following question: Is it possible to achieve a regret bound for online logistic regression that is O(poly(D)log(T))? Even if this is not possible in general, it would be interesting to have a bound that reduces to our bound in the one-dimensional case.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Reverse Iterative Deepening for Finite-Horizon MDPs with Large Branching Factors
International Conference on Automated Planning and Scheduling (2012)
[u'Andrey Kolobov', u'Peng Dai', u'Mausam', u'Daniel S Weld']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37715.html
notfound
=========================
Robust Local Search for Solving RCPSP/max with Durational Uncertainty
Journal of Artificial Intelligence Research, vol. 43 (2012), pp. 43-86
[u'Na Fu', u'Hoong Chuin Lau', u'Pradeep Varakantha', u'Fei Xiao']
MachineIntelligence
Abstract: Scheduling problems in manufacturing, logistics and project management have frequently been modeled using the framework of Resource Constrained Project Scheduling Problems with minimum and maximum time lags (RCPSP/max). Due to the importance of these problems, providing scalable solution schedules for RCPSP/max problems is a topic of extensive research. However, all existing methods for solving RCPSP/max assume that durations of activities are known with certainty, an assumption that does not hold in real world scheduling problems where unexpected external events such as manpower availability, weather changes, etc. lead to delays or advances in completion of activities. Thus, in this paper, our focus is on providing a scalable method for solving RCPSP/max problems with durational uncertainty. To that end, we introduce the robust local search method consisting of three key ideas: (a) Introducing and studying the properties of two decision rule approximations used to compute start times of activities with respect to dynamic realizations of the durational uncertainty; (b) Deriving the expression for robust makespan of an execution strategy based on decision rule approximations; and (c) A robust local search mechanism to efficiently compute activity execution strategies that are robust against durational uncertainty. Furthermore, we also provide enhancements to local search that exploit temporal dependencies between activities. Our experimental results illustrate that robust local search is able to provide robust execution strategies efficiently.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Sampling Methods for the Nystrom Method
Journal of Machine Learning Research (JMLR) (2012)
[u'Sanjiv Kumar', u'Mehryar Mohri', u'Ameet Talwalkar']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Scalable Active Learning for Multi-Class Image Classification
IEEE Transactions on Pattern Analysis and Machine Intelligence (2012)
[u'Ajay J. Joshi', u'Fatih Porikli', u'Nikolaos Papanikolopoulos']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub39988.html
notfound
=========================
Spectral Intersections for Non-Stationary Signal Separation
Proceedings of InterSpeech 2012, Portland, OR
[u'Trausti Kristjansson', u'Thad Hughes']
MachineIntelligence
Abstract: We describe a new method for non-stationary noise suppression that is simple to implement yet has performance rivaling far more complex algorithms. Spectral Intersections is a model based MMSE signal separation method that uses a new simple approximation to the observation likelihood. Furthermore, Spectral Intersections uses an efficient approximation to the expectation integral of the MMSE estimate that could be described as unscented importance sampling. We apply the new method to the task of separating speech mixed with music. We report results on the Google Voice Search task where the new method provides a 7% relative reduction in WER at 10dB SNR. Interestingly, the new method provides considerably greater reduction in average WER than the MAX method and approaches the performance of the more complex Algonquin algorithm.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Spectral Learning of General Weighted Automata via Constrained Matrix Completion
NIPS (2012), pp. 2168-2176
[u'Borja Balle', u'Mehryar Mohri']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41177.html
found
=========================
Student-t based Robust Spatio-Temporal Prediction
IEEE 12th International Conference on Data Mining, IEEE, Brussels, Belgium (2012), pp. 151-160
[u'Yang Chen', u'Feng Chen', u'Jing Dai', u'T. Charles Clancy', u'Yao-Jan Wu']
MachineIntelligence
Abstract: This paper describes an efficient and effective design of Robust Spatio-Temporal Prediction based on Students t distribution, namely, St-RSTP, to provide estimations based on observations over spatio-temporal neighbors. The proposed St-RSTP is more resilient to outliers or other small departures from model assumptions than its ancestor, the Spatio-Temporal Random Effects (STRE) model. STRE is a state-of-the-art statistical model with linear order complexity for large scale processing. However, it assumes Gaussian observations, which has the well-known limitation of non-robustness. In our St-RSTP design, the measurement error follows Students t distribution, instead of a traditional Gaussian distribution. This design reduces the influence of outliers, improves prediction quality, and keeps the problem analytically intractable. We propose a novel approximate inference approach, which approximates the model into the form that separates the high dimensional latent variables into groups, and then estimates the posterior distributions of different groups of variables separately in the framework of Expectation Propagation. As a good property, our approximate approach degeneralizes to the standard STRE based prediction, when the degree of freedom of the Students t distribution is set to infinite. Extensive experimental evaluations based on both simulation and real-life data sets demonstrated the robustness and the efficiency of our Student-t prediction model. The proposed approach provides critical functionality for stochastic processes on spatio-temporal data.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
The Foundations of Machine Learning
MIT Press (2012)
[u'Mehryar Mohri', u'Afshin Rostamizadeh', u'Ameet Talwalkar']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub39982.html
notfound
=========================
The multi-iterative closest point tracker: An online algorithm for tracking multiple interacting targets
Journal of Field Robotics, vol. 29.2 (2012), pp. 258-276
[u'Adam Feldman', u'Maria Hybinette', u'Tucker Balch']
MachineIntelligence
Abstract: We describe and evaluate a greedy detection-based algorithm for tracking a variable number of dynamic targets online. The algorithm leverages the well-known iterative closest point (ICP) algorithm for aligning target models with target detections. The approach differs from trackers that seek globally optimal solutions because it treats the problem as a set of individual tracking problems. The method works for multiple targets by sequentially matching models to detections, and then removing detections from further consideration once models have been matched to them. This allows targets to pass close to one another with reduced risks of tracking failure due to hijacking,'' or track merging. There has been significant previous work in this area, but we believe our approach addresses a number of tracking problems simultaneously that have only been addressed separately before. The algorithm is evaluated using four to eight laser range finders in three settings: quantitatively for a basketball game with 10 people and a 25-person social behavior experiment, and qualitatively for a full-scale soccer game. We also provide qualitative results using video to track ants in a captive habitat. During all the experiments, agents enter and leave the scene, so the number of targets to track varies with time. With eight laser range finders running, the system can locate and track targets at sensor frame rate 37.5 Hz on commodity computing hardware. Our evaluation shows that the tracking system correctly detects each track over 98% of the time.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
The word-gesture keyboard: reimagining keyboard interaction (CACM Research Highlight)
Communications of the ACM, vol. 55, no. 9 (2012), pp. 91-101
[u'Shumin Zhai', u'Per Ola Kristensson']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41100.html
notfound
=========================
Three Controversial Hypotheses Concerning Computation in the Primate Cortex
Proceedings of the Twenty-Sixth AAAI Conference on Artificial Intelligence, AAAI Press (2012)
[u'Thomas Dean', u'Greg Corrado', u'Jonathon Shlens']
MachineIntelligence
Abstract: We consider three hypotheses concerning the primate neocortex which have influenced computational neuroscience in recent years. Is the mind modular in terms of its being profitably described as a collection of relatively independent functional units? Does the regular structure of the cortex imply a single algorithm at work, operating on many different inputs in parallel? Can the cognitive differences between humans and our closest primate relatives be explained in terms of a scalable cortical architecture? We bring to bear diverse sources of evidence to argue that the answers to each of these questions - with some judicious qualifications - are in the affirmative. In particular, we argue that while our higher cognitive functions may interact in a complicated fashion, many of the component functions operate through well-defined interfaces and, perhaps more important, are built on a neural substrate that scales easily under the control of a modular genetic architecture. Processing in the primary sensory cortices seem amenable to similar algorithmic principles, and, even for those cases where alternative principles are at play, the regular structure of cortex allows the same or greater advantages as the architecture scales. Similar genetic machinery to that used by nature to scale body plans has apparently been applied to scale cortical computations. The resulting replicated computing units can be used to build larger working memory and support deeper recursions needed to qualitatively improve our abilities to handle language, abstraction and social interaction.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40358.html
notfound
=========================
Unsupervised Learning for Graph Matching
International Journal of Computer Vision, vol. 96 (2012), pp. 28-45
[u'Marius Leordeanu', u'Rahul Sukthankar', u'Martial Hebert']
MachineIntelligence
Abstract: Graph matching is an essential problem in computer vision that has been successfully applied to 2D and 3D feature matching and object recognition. Despite its importance, little has been published on learning the parameters that control graph matching, even though learning has been shown to be vital for improving the matching rate. In this paper, we show how to perform parameter learning in an unsupervised fashion, that is when no correct correspondences between graphs are given during training. Our experiments reveal that unsupervised learning compares favorably to the supervised case, both in terms of efficiency and quality, while avoiding the tedious manual labeling of ground truth correspondences. We verify experimentally that our learning method can improve the performance of several state-of-the-art matching algorithms. We also show that a similar method can be successfully applied to parameter learning for graphical models and demonstrate its effectiveness empirically.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40735.html
notfound
=========================
Weakly Supervised Learning of Object Segmentations from Web-Scale Video
ECCV'12 Proceedings of the 12th international conference on Computer Vision - Volume Part I, Springer-Verlag, Berlin, Heidelberg (2012), pp. 198-208
[u'Glenn Hartmann', u'Matthias Grundmann', u'Judy Hoffman', u'David Tsai', u'Vivek Kwatra', u'Omid Madani', u'Sudheendra Vijayanarasimhan', u'Irfan Essa', u'James Rehg', u'Rahul Sukthankar']
MachineIntelligence
Abstract: We propose to learn pixel-level segmentations of objects from weakly labeled (tagged) internet videos. Specifically, given a large collection of raw YouTube content, along with potentially noisy tags, our goal is to automatically generate spatiotemporal masks for each object, such as "dog", without employing any pre-trained object detectors. We formulate this problem as learning weakly supervised classifiers for a set of independent spatio-temporal segments. The object seeds obtained using segment-level classifiers are further refined using graphcuts to generate high-precision object masks. Our results, obtained by training on a dataset of 20,000 YouTube videos weakly tagged into 15 classes, demonstrate automatic extraction of pixel-level object masks. Evaluated against a ground-truthed subset of 50,000 frames with pixel-level annotations, we confirm that our proposed methods can learn good object masks just by watching YouTube.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38345.html
found
=========================
Web-Scale Multi-Task Feature Selection for Behavioral Targeting
Proceedings of The 21st ACM International Conference on Information and Knowledge Management (CIKM), ACM (2012) (to appear)
[u'Amr Ahmed', u'Mohamed Aly', u'Abhimanyu Das', u'Alex Smola', u'Tasos Anastasakos']
MachineIntelligence
Abstract: A typical behavioral targeting system optimizing purchase activities, called conversions, faces two main challenges: the web-scale amounts of user histories to process on a daily basis, and the relative sparsity of conversions. In this paper, we try to address these challenges through feature selection. We formulate a multi-task (or group) feature-selection problem among a set of related tasks (sharing a common set of features), namely advertising campaigns. We apply a group-sparse penalty consisting of a combination of an `1 and `2 penalty and an associated fast optimization algorithm for distributed parameter estimation. Our algorithm relies on a variant of the well known Fast Iterative Thresholding Algorithm (FISTA), a closed-form solution for mixed norm programming and a distributed subgradient oracle. To eciently handle web-scale user histories, we present a distributed inference algorithm for the problem that scales to billions of instances and millions of attributes. We show the superiority of our algorithm in terms of both sparsity and ROC performance over baseline feature selection methods (both single-task L1-regularization and multi-task mutual-information gain).
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Dual Coordinate Descent Algorithm for SVMs Combined with Rational Kernels
International Journal of Foundations of Computer Science, vol. 22 (2011), pp. 1761-1779
[u'Cyril Allauzen', u'Corinna Cortes', u'Mehryar Mohri']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Algorithms and hardness results for parallel large margin learning
NIPS (2011)
[u'Philip M. Long', u'Rocco A. Servedio']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Artificial General Intelligence. Proceedings of the 4th International Conference
Springer Lecture Notes in Artificial Intelligence (2011)
[u'Jrgen Schmidhuber', u'Kristinn Thorisson', u'Moshe Looks']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Can matrix coherence be efficiently and accurately estimated?
Thirteenth International Conference on Artificial Intelligence and Statistics (AISTATS 2011)
[u'Mehryar Mohri', u'Ameet Talwalkar']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Combinatorial and Algorithmic Aspects of Sequence Processing (Dagstuhl Seminar 11081)
Dagstuhl Reports, vol. 1 (2011), pp. 47-66
[u'Maxime Crochemore', u'Lila Kari', u'Mehryar Mohri', u'Dirk Nowotka']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38280.html
notfound
=========================
Controlling Complexity in Part-of-Speech Induction
Journal of Artificial Intelligence Research (JAIR), vol. 41 (2011), pp. 527-551
[u'Joao Graca', u'Kuzman Ganchev', u'Luisa Coheur', u'Fernando Pereira', u'Ben Taskar']
MachineIntelligence
Abstract: We consider the problem of fully unsupervised learning of grammatical (part-of-speech) categories from unlabeled text. The standard maximum-likelihood hidden Markov model for this task performs poorly, because of its weak inductive bias and large model capacity. We address this problem by refining the model and modifying the learning objective to control its capacity via para- metric and non-parametric constraints. Our approach enforces word-category association sparsity, adds morphological and orthographic features, and eliminates hard-to-estimate parameters for rare words. We develop an efficient learning algorithm that is not much more computationally intensive than standard training. We also provide an open-source implementation of the algorithm. Our experiments on five diverse languages (Bulgarian, Danish, English, Portuguese, Spanish) achieve significant improvements compared with previous methods for the same task.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37592.html
notfound
=========================
Domain Adaptation with Coupled Subspaces
Artificial Intelligence and Statistics (2011)
[u'John Blitzer', u'Sham Kakade', u'Dean Foster']
MachineIntelligence
Abstract: Domain adaptation algorithms address a key issue in applied machine learning: How can we train a system under a source distribution but achieve high performance under a different target distribution? We tackle this question for divergent distributions where crucial predictive target features may not even have support under the source distribution. In this setting, the key intuition is that that if we can link target-specic features to source features, we can learn effectively using only source labeled data. We formalize this intuition, as well as the assumptions under which such coupled learning is possible. This allows us to give nite sample target error bounds (using only source training data) and an algorithm which performs at the state-of-the-art on two natural language processing adaptation tasks which are characterized by novel target features.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Domain adaptation in regression
Proceedings of The 22nd International Conference on Algorithmic Learning Theory, ALT 2011, Springer, Heidelberg, Germany
[u'Corinna Cortes', u'Mehryar Mohri']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Ensemble Nystrom
A book chapter in Ensemble Machine Learning: Theory and Applications, Springer (2011)
[u'Sanjiv Kumar', u'Mehryar Mohri', u'Ameet Talwalkar']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Ensembles of Kernel Predictors
Proceedings of the 27th Conference on Uncertainty in Artificial Intelligence (UAI 2011)
[u'Corinna Cortes', u'Mehryar Mohri', u'Afshin Rostamizadeh']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40359.html
notfound
=========================
Feature Seeding for Action Recognition
International Conference on Computer Vision (ICCV) (2011)
[u'Pyry Matikainen', u'Rahul Sukthankar', u'Martial Hebert']
MachineIntelligence
Abstract: Progress in action recognition has been in large part due to advances in the features that drive learning-based methods. However, the relative sparsity of training data and the risk of overfitting have made it difficult to directly search for good features. In this paper, we suggest using synthetic data to search for robust features that can more easily take advantage of limited data, rather than using the synthetic data directly as a substitute for real data. We demonstrate that the features discovered by our selection method, which we call seeding, improve performance on an action classification task on real data, even though the synthetic data from which our features are seeded differs significantly from the real data, both in terms of appearance and the set of action classes.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37013.html
notfound
=========================
Follow-the-Regularized-Leader and Mirror Descent: Equivalence Theorems and L1 Regularization
Proceedings of the 14th International Conference on Artificial Intelligence and Statistics (AISTATS) (2011)
[u'H. Brendan McMahan']
MachineIntelligence
Abstract: We prove that many mirror descent algorithms for online convex optimization (such as online gradient descent) have an equivalent interpretation as follow-the-regularized-leader (FTRL) algorithms. This observation makes the relationships between many commonly used algorithms explicit, and provides theoretical insight on previous experimental observations. In particular, even though the FOBOS composite mirror descent algorithm handles L1 regularization explicitly, it has been observed that the FTRL-style Regularized Dual Averaging (RDA) algorithm is even more effective at producing sparsity. Our results demonstrate that the key difference between these algorithms is how they handle the cumulative L1 penalty. While FOBOS handles the $L_1$ term exactly on any given update, we show that it is effectively using subgradient approximations to the L1 penalty from previous rounds, leading to less sparsity than RDA, which handles the cumulative penalty in closed form. The FTRL-Proximal algorithm, which we introduce, can be seen as a hybrid of these two algorithms, and significantly outperforms both on a large, real-world dataset.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Hashing with Graphs
International Conference on Machine Learning (ICML) (2011)
[u'Wei Liu', u'Jun Wang', u'Sanjiv Kumar', u'Shih-Fu Chang']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42452.html
notfound
=========================
History Dependent Domain Adaptation
Domain Adaptation Workshop at NIPS '11 (2011)
[u'Allen Lavoie', u'Matthew Eric Otey', u'Nathan Ratliff']
MachineIntelligence
Abstract: We study a novel variant of the domain adaptation problem, in which the loss function on test data changes due to dependencies on prior predictions. One important instance of this problem area occurs in settings where it is more costly to make a new error than to repeat a previous error. We propose several methods for learning effectively in this setting, and test them empirically on the real-world tasks of malicious URL classication and adversarial advertisement detection.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37641.html
notfound
=========================
Improved Time Series Prediction and Symbolic Regression with Affine Arithmetic
Genetic Programming Theory and Practice IX, Springer, 233 Spring Street, New York, NY 10013 (2011), pp. 97-112
[u'Cassio Pennachin', u'Moshe Looks', u'J. A. de Vasconcelos']
MachineIntelligence
Abstract: We show how affine arithmetic can be used to improve both the performance and the robustness of genetic programming for problems such as symbolic regression and time series prediction. Affine arithmetic is used to estimate conservative bounds on the output range of expressions during evolution, which allows us to discard trees with potentially infinite bounds, as well as those whose output range lies outside the desired range implied by the training dataset. Benchmark experiments are performed on 15 symbolic regression problems as well as 2 well-known time series problems. Comparison with a baseline genetic programming system shows a reduced number of tness evaluations during t raining and improved generalization on test data, completely eliminating extreme errors. We also apply this technique to the problem of forecasting wind speed on a real world dataset, and the use of affine arithmetic compares favorably with baseline genetic programming, feedforward neural networks and support vector machines.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37362.html
notfound
=========================
L1 and L2 Regularization for Multiclass Hinge Loss Models
Symposium on Machine Learning in Speech and Natural Language Processing (2011)
[u'Robert C. Moore', u'John DeNero']
MachineIntelligence
Abstract: This paper investigates the relationship between the loss function, the type of regularization, and the resulting model sparsity of discriminatively-trained multiclass linear models. The effects on sparsity of optimizing log loss are straightforward: L2 regularization produces very dense models while L1 regularization produces much sparser models. However, optimizing hinge loss yields more nuanced behavior. We give experimental evidence and theoretical arguments that, for a class of problems that arises frequently in natural-language processing, both L1- and L2-regularized hinge loss lead to sparser models than L2-regularized log loss, but less sparse models than L1-regularized log loss. Furthermore, we give evidence and arguments that for models with only indicator features, there is a critical threshold on the weight of the regularizer below which L1- and L2-regularized hinge loss tends to produce models of similar sparsity.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Large-Scale Image Annotation using Visual Synset
Proc. International Conference on Computer Vision (ICCV) (2011)
[u'David Tsai', u'Yushi Jing', u'Henry Rowley', u'Yi Liu', u'Sergey Ioffe', u'James Rehg']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37179.html
notfound
=========================
Large-Scale Music Annotation and Retrieval: Learning to Rank in Joint Semantic Spaces.
Journal of New Music Research (2011)
[u'Jason Weston', u'Samy Bengio', u'Philippe Hamel']
MachineIntelligence
Abstract: Music prediction tasks range from predicting tags given a song or clip of audio, predicting the name of the artist, or predicting related songs given a song, clip, artist name or tag. That is, we are interested in every semantic relationship between the different musical concepts in our database. In realistically sized databases, the number of songs is measured in the hundreds of thousands or more, and the number of artists in the tens of thousands or more, providing a considerable challenge to standard machine learning techniques. In this work, we propose a method that scales to such datasets which attempts to capture the semantic similarities between the database items by modeling audio, artist names, and tags in a single low-dimensional semantic embedding space. This choice of space is learnt by optimizing the set of prediction tasks of interest jointly using multi-task learning. Our single model learnt by training on the joint objective function is shown experimentally to have improved accuracy over training on each task alone. Our method also outperforms the baseline methods tried and, in comparison to them, is faster and consumes less memory. We also demonstrate how our method learns an interpretable model, where the semantic space captures well the similarities of interest.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Lateen EM: Unsupervised Training with Multiple Objectives, Applied to Dependency Grammar Induction
2011 Conference on Empirical Methods in Natural Language Processing (EMNLP 2011)
[u'Valentin I. Spitkovsky', u'Hiyan Alshawi', u'Daniel Jurafsky']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Learning Highlights in Sports Videos Using a Semi-Supervised Approach: Cricket as a Test Case
ICME 2011
[u'Hao Tang', u'Vivek Kwatra', u'Mehmet Emre Sargin', u'Ullas Gargi']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Learning Structured Embeddings of Knowledge Bases
Proceedings of the 25th Conference on Artificial Intelligence (AAAI) (2011)
[u'Antoine Bordes', u'Jason Weston', u'Ronan Collobert', u'Yoshua Bengio']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Learning large-margin halfspaces with more malicious noise
NIPS (2011)
[u'Philip M. Long', u'Rocco A. Servedio']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36946.html
found
=========================
Managing Crowdsourced Human Computation
20th International World Wide Web Conference, WWW 2011
[u'Panagiotis G. Ipeirotis', u'Praveen K. Paritosh']
MachineIntelligence
Abstract: The tutorial covers an emerging topic of wide interest: Crowdsourcing. Specifically, we cover areas of crowdsourcing related to managing structured and unstructured data in a web-related content. Many researchers and practitioners today see the great opportunity that becomes available through easily-available crowdsourcing platforms. However, most newcomers face the same questions: How can we manage the (noisy) crowds to generate high quality output? How to estimate the quality of the contributors? How can we best structure the tasks? How can we get results in small amounts of time and minimizing the necessary resources? How to setup the incentives? How should such crowdsourcing markets be setup? Their presented material will cover topics from a variety of fields, including computer science, statistics, economics, and psychology. Furthermore, the material will include real-life examples and case studies from years of experience in running and managing crowdsourcing applications in business settings. The tutorial presenters have an extensive academic and systems building experience and will provide the audience with data sets that can be used for hands-on tasks.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37538.html
notfound
=========================
Models for Neural Spike Computation and Cognition
CreateSpace, Seattle, WA (2011), pp. 142
[u'David H. Staelin', u'Carl H. Staelin']
MachineIntelligence
Abstract: This monograph addresses the intertwined mathematical, neurological, and cognitive mysteries of the brain. It first evaluates the mathematical performance limits of simple spiking neuron models that both learn and later recognize complex spike excitation patterns in less than one second without using training signals unique to each pattern. Simulations validate these models, while theoretical expressions validate their simpler performance parameters. These single-neuron models are then qualitatively related to the training and performance of multi-layer neural networks that may have significant feedback. The advantages of feedback are then qualitatively explained and related to a model for cognition. This model is then compared to observed mild hallucinations that arguably include accelerated time-reversed video memories. The learning mechanism for these binary threshold-firing cognon neurons is spike-timing-dependent plasticity (STDP) that depends only on whether the spike excitation pattern presented to a given single learning-ready neuron within a period of milliseconds causes that neuron to fire or spike. The false-alarm probability that a trained neuron will fire for a random unlearned pattern can be made almost arbitrarily low by reducing the number of patterns learned by each neuron. Models that use and that do not use spike timing within patterns are evaluated. A Shannon mutual information metric (recoverable bits/neuron) is derived for binary neuron models that are characterized only by their probability of learning a random input excitation pattern presented to that neuron during learning readiness, and by their false-alarm probability for random unlearned patterns. Based on simulations, the upper bounds to recoverable information are ~0.1 bits per neuron for optimized neuron parameters and training. This information metric assumes that: 1) each neural spike indicates only that the responsible neuron input excitation pattern (a pattern lasts less than the time between consecutive patterns, say 30 milliseconds) had probably been seen earlier while that neuron was learning ready, and 2) information is stored in the binary synapse strengths. This focus on recallable learned information differs from most prior metrics such as pattern classification performance and metrics relying on pattern-specific training signals other than the normal input spikes. This metric also shows that neuron models can recall useful Shannon information only if their probability of firing randomly is lowered between learning and recall. Also discussed are: 1) how rich feedback might permit improved noise immunity, learning and recognition of pattern sequences, compression of data, associative or content-addressable memory, and development of communications links through white matter, 2) extensions of cognon models that use spike timing, dendrite compartments, and new learning mechanisms in addition to spike timing- dependent plasticity (STDP), 3) simulations that show how simple optimized neuron models can have optimum numbers of binary synapses in the range between 200 and 10,000, depending on neural parameters, and 4) simulation results for parameters like the average bits/spike, bits/neuron/second, maximum number of learnable patterns, optimum ratios between the strengths of weak and strong synapses, and probabilities of false alarms.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37074.html
notfound
=========================
On the necessity of irrelevant variables
ICML (2011)
[u'David P. Helmbold', u'Philip M. Long']
MachineIntelligence
Abstract: This work explores the effects of relevant and irrelevant boolean variables on the accuracy of classifiers. The analysis uses the assumption that the variables are conditionally independent given the class, and focuses on a natural family of learning algorithms for such sources when the relevant variables have a small advantage over random guessing. The main result is that algorithms relying predominately on irrelevant variables have error probabilities that quickly go to 0 in situations where algorithms that limit the use of irrelevant variables have errors bounded below by a positive constant. We also show that accurate learning is possible even when there are so few examples that one cannot determine with high confidence whether or not any individual variable is relevant.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36898.html
notfound
=========================
Online Learning in the Manifold of Low-Rank Matrices
Neural Information Processing Systems (NIPS 23), Curran Associates, Inc. (2011), pp. 2128-2136
[u'Gal Chechik', u'Daphna Weinshall', u'Uri Shalit']
MachineIntelligence
Abstract: When learning models that are represented in matrix forms, enforcing a low-rank constraint can dramatically improve the memory and run time complexity, while providing a natural regularization of the model. However, naive approaches for minimizing functions over the set of low-rank matrices are either prohibitively time consuming (repeated singular value decomposition of the matrix) or numerically unstable (optimizing a factored representation of the low rank matrix). We build on recent advances in optimization over manifolds, and describe an iterative online learning procedure, consisting of a gradient step, followed by a second-order retraction back to the manifold. While the ideal retraction is hard to compute, and so is the projection operator that approximates it, we describe another second-order retraction that can be computed efciently, with run time and memory complexity of O ((n + m)k) for a rank-k matrix of dimension m n, given rank-one gradients. We use this algorithm, LORETA, to learn a matrixform similarity measure over pairs of documents represented as high dimensional vectors. LORETA improves the mean average precision over a passive- aggressive approach in a factorized model, and also improves over a full model trained over pre-selected features using the same memory requirements. LORETA also showed consistent improvement over standard methods in a large (1600 classes) multi-label image classication task.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38281.html
notfound
=========================
Posterior Sparsity in Dependency Grammar Induction
Journal of Machine Learning Research, vol. 12 (2011), pp. 455-490
[u'Jennifer Gillenwater', u'Kuzman Ganchev', u'Joao Graca', u'Fernando Pereira', u'Ben Taskar']
MachineIntelligence
Abstract: A strong inductive bias is essential in unsupervised grammar induction. In this paper, we explore a particular sparsity bias in dependency grammars that encourages a small number of unique dependency types. We use part-of-speech (POS) tags to group dependencies by parent-child types and investigate sparsity-inducing penalties on the posterior distributions of parent-child POS tag pairs in the posterior regularization (PR) framework of Graa et al. (2007). In experiments with 12 different languages, we achieve significant gains in directed attachment accuracy over the standard expectation maximization (EM) baseline, with an average accuracy improvement of 6.5%, outperforming EM by at least 1% for 9 out of 12 languages. Furthermore, the new method outperforms models based on standard Bayesian sparsity-inducing parameter priors with an average improvement of 5% and positive gains of at least 1% for 9 out of 12 languages. On English text in particular, we show that our approach improves performance over other state-of-the-art techniques.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Temporal pooling and multiscale learning for automatic annotation and ranking of music audio
International Society for Music Information Retrieval (ISMIR 2011)
[u'Philippe Hamel', u'Simon Lemieux', u'Yoshua Bengio', u'Douglas Eck']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Topological Value Iteration Algorithms
Journal of Artificial Intelligence Research, vol. 42 (2011), pp. 181-209
[u'Peng Dai', u'Mausam', u'Daniel S. Weld']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37180.html
notfound
=========================
Wsabie: Scaling Up To Large Vocabulary Image Annotation
Proceedings of the International Joint Conference on Artificial Intelligence, IJCAI (2011)
[u'Jason Weston', u'Samy Bengio', u'Nicolas Usunier']
MachineIntelligence
Abstract: Image annotation datasets are becoming larger and larger, with tens of millions of images and tens of thousands of possible annotations. We propose a strongly performing method that scales to such datasets by simultaneously learning to optimize precision at the top of the ranked list of annotations for a given image and learning a low-dimensional joint embedding space for both images and annotations. Our method, called Wsabie, both outperforms several baseline methods and is faster and consumes less memory.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36364.html
notfound
=========================
A theory of learning from different domains
Machine Learning, vol. 79 (2010), pp. 151-175
[u'Shai Ben-David', u'John Blitzer', u'Koby Crammer', u'Alex Kulesza', u'Fernando Pereira', u'Jennifer Vaughan']
MachineIntelligence
Abstract: Discriminative learning methods for classification perform well when training and test data are drawn from the same distribution. Often, however, we have plentiful labeled training data from a source domain but wish to learn a classifier which performs well on a target domain with a different distribution and little or no labeled training data. In this work we investigate two questions. First, under what conditions can a classifier trained from source data be expected to perform well on target data? Second, given a small amount of labeled target data, how should we combine it during training with the large amount of labeled source data to achieve the lowest target error at test time? We address the first question by bounding a classifier's target error in terms of its source error and the divergence between the two domains. We give a classifier-induced divergence measure that can be estimated from finite, unlabeled samples from the domains. Under the assumption that there exists some hypothesis that performs well in both domains, we show that this quantity together with the empirical source error characterize the target error of a source-trained classifier. We answer the second question by bounding the target error of a model which minimizes a convex combination of the empirical source and target errors. Previous theoretical work has considered minimizing just the source error, just the target error, or weighting instances from the two domains equally. We show how to choose the optimal combination of source and target error as a function of the divergence, the sample sizes of both domains, and the complexity of the hypothesis class. The resulting bound generalizes the previously studied cases and is always at least as tight as a bound which considers minimizing only the target error or an equal weighting of source and target errors.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37518.html
notfound
=========================
Active Tuples-based Scheme for Bounding Posterior Beliefs
JAIR, vol. 39 (2010), pp. 335-371
[u'Bozhena Bidyuk', u'Rina Dechte', u'Emma Rollon']
MachineIntelligence
Abstract: The paper presents a scheme for computing lower and upper bounds on the posterior marginals in Bayesian networks with discrete variables. Its power lies in its ability to use any available scheme that bounds the probability of evidence or posterior marginals and enhance its performance in an anytime manner. The scheme uses the cutset conditioning principle to tighten existing bounding schemes and to facilitate anytime behavior, utilizing a fixed number of cutset tuples. The accuracy of the bounds improves as the number of used cutset tuples increases and so does the computation time. We demonstrate empirically the value of our scheme for bounding posterior marginals and probability of evidence using a variant of the bound propagation algorithm as a plug-in scheme.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36483.html
notfound
=========================
Adaptive Bound Optimization for Online Convex Optimization
Proceedings of the 23rd Annual Conference on Learning Theory (COLT) (2010)
[u'H. Brendan McMahan', u'Matthew Streeter']
MachineIntelligence
Abstract: We introduce a new online convex optimization algorithm that adaptively chooses its regularization function based on the loss functions observed so far. This is in contrast to previous algorithms that use a fixed regularization function such as L2-squared, and modify it only via a single time-dependent parameter. Our algorithm's regret bounds are worst-case optimal, and for certain realistic classes of loss functions they are much better than existing bounds. These bounds are problem-dependent, which means they can exploit the structure of the actual problem instance. Critically, however, our algorithm does not need to know this structure in advance. Rather, we prove competitive guarantees that show the algorithm provides a bound within a constant factor of the best possible bound (of a certain functional form) in hindsight.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Algorithms for Learning Kernels Based on Centered Alignment
Journal of Machine Learning Research, vol. 13 (2010), pp. 795-828
[u'Corinna Cortes', u'Mehryar Mohri', u'Afshin Rostamizadeh']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Bayesian Robot System Identification with Input and Output Noise
Neural Networks (2010) (to appear)
[u'Jo-Anne Ting', u"Aaron D'Souza", u'Stefan Schaal']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36738.html
notfound
=========================
Beyond Heuristics: Learning to Classify Vulnerabilities and Predict Exploits
Proceedings of the Sixteenth ACM Conference on Knowledge Discovery and Data Mining (KDD-2010), pp. 105-113
[u'Mehran Bozorgi', u'Lawrence Saul', u'Stefan Savage', u'Geoffrey M. Voelker']
MachineIntelligence
Abstract: The security demands on modern system administration are enormous and getting worse. Chief among these demands, administrators must monitor the continual ongoing disclosure of software vulnerabilities that have the potential to compromise their systems in some way. Such vulnerabilities include buffer overflow errors, improperly validated inputs, and other unanticipated attack modalities. In 2008, over 7,400 new vulnerabilities were disclosedwell over 100 per week. While no enterprise is affected by all of these disclosures, administrators commonly face many outstanding vulnerabilities across the software systems they manage. A key question for systems administrators is which vulnerabilities to prioritize. From publicly available databases that document past vulnerabilities, we show how to train classifiers that predict whether and how soon a vulnerability is likely to be exploited. As input, our classifiers operate on high dimensional feature vectors that we extract from the text fields, time stamps, cross-references, and other entries in existing vulnerability disclosure reports. Compared to current industry-standard heuristics based on expert knowledge and static formulas, our classifiers predict much more accurately whether and how soon individual vulnerabilities are likely to be exploited.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36293.html
notfound
=========================
Compression Progress, Pseudorandomness, & Hyperbolic Discounting
The Third Conference on Artificial General Intelligence, Atlantis Press, http://www.atlantis-press.com (2010), pp. 186-187
[u'Moshe Looks']
MachineIntelligence
Abstract: General intelligence requires open-ended exploratory learning. The principle of compression progress proposes that agents should derive intrinsic reward from maximizing "interestingness", the first derivative of compression progress over the agent's history. Schmidhuber posits that such a drive can explain "essential aspects of ... curiosity, creativity, art, science, music, [and] jokes", implying that such phenomena might be replicated in an artificial general intelligence programmed with such a drive. I pose two caveats: 1) as pointed out by Rayhawk, not everything that can be considered "interesting" according to this definition is interesting to humans; 2) because of (irrational) hyperbolic discounting of future rewards, humans have an additional preference for rewards that are structured to prevent premature satiation, often superseding intrinsic preferences for compression progress.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Distributed Training Strategies for the Structured Perceptron
North American Chapter of the Association for Computational Linguistics (NAACL) (2010)
[u'Ryan McDonald', u'Keith Hall', u'Gideon Mann']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Efficient Learning and Feature Selection in High-Dimensional Regression
Neural Computation, vol. 22(4) (2010), pp. 831-886
[u'Jo-Anne Ting', u"Aaron D'Souza", u'Stefan Schaal']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Exploiting Feature Covariance in High-Dimensional Online Learning
Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics, JMLR (2010), pp. 493-500
[u'Justin Ma', u'Alex Kulesza', u'Mark Dredze', u'Koby Crammer', u'Lawrence Saul', u'Fernando Pereira']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35651.html
notfound
=========================
Finding Meaning on YouTube: Tag Recommendation and Category Discovery
Computer Vision and Pattern Recognition, IEEE (2010)
[u'George Toderici', u'Hrishikesh Aradhye', u'Marius Pasca', u'Luciano Sbaiz', u'Jay Yagnik']
MachineIntelligence
Abstract: We present a system that automatically recommends tags for YouTube videos solely based on their audiovisual content. We also propose a novel framework for unsupervised discovery of video categories that exploits knowledge mined from the World-Wide Web text documents/searches. First, video content to tag association is learned by training classifiers that map audiovisual content-based features from millions of videos on YouTube.com to existing uploader-supplied tags for these videos. When a new video is uploaded, the labels provided by these classifiers are used to automatically suggest tags deemed relevant to the video. Our system has learned a vocabulary of over 20,000 tags. Secondly, we mined large volumes of Web pages and search queries to discover a set of possible text entity categories and a set of associated is-A relationships that map individual text entities to categories. Finally, we apply these is-A relationships mined from web text on the tags learned from audiovisual content of videos to automatically synthesize a reliable set of categories most relevant to videos -- along with a mechanism to predict these categories for new uploads. We then present rigorous rating studies that establish that: (a) the average relevance of tags automatically recommended by our system matches the average relevance of the uploader-supplied tags at the same or better coverage and (b) the average precision@K of video categories discovered by our system is 70% with K=5.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Finding planted partitions in nearly linear time using arrested spectral clustering
ICML (2010)
[u'Nader H. Bshouty', u'Philip M. Long']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36467.html
notfound
=========================
Generalization Bounds for Learning Kernels
Proceedings of the 27th Annual International Conference on Machine Learning (ICML 2010)
[u'Corinna Cortes', u'Mehryar Mohri', u'Afshin Rostamizadeh']
MachineIntelligence
Abstract: This paper presents several novel generalization bounds for the problem of learning kernels based on a combinatorial analysis of the Rademacher complexity of the corresponding hypothesis sets. Our bound for learning kernels with a convex combination of p base kernels using L1 regularization admits only a log p dependency on the number of kernels, which is tight and considerably more favorable than the previous best bound given for the same problem. We also give a novel bound for learning with a non-negative combination of p base kernels with an L2 regularization whose dependency on p is also tight and only in p^(1/4). We present similar results for Lq regularization with other values of q, and outline the relevance of our proof techniques to the analysis of the complexity of the class of linear functions. Experiments with a large number of kernels further validate the behavior of the generalization error as a function of p predicted by our bounds.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Generalized Expectation Criteria for Semi-supervised Learning with Weakly Labeled Data
JMLR, vol. 11 (2010)
[u'Gideon Mann', u'Andrew McCallum']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Graphical Models of the Visual Cortex
Heuristics, Probability and Causality, College Publications, King's College London, Strand, London WC2R 2LS, UK (2010), pp. 121-142
[u'Thomas Dean']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36470.html
notfound
=========================
Half Transductive Ranking
Thirteenth International Conference on Artificial Intelligence and Statistics (AISTATS 2010)
[u'Bing Bai', u'Jason Weston', u'David Grangier', u'Ronan Collobert', u'Corinna Cortes', u'Mehryar Mohri']
MachineIntelligence
Abstract: We study the standard retrieval task of ranking a fixed set of items given a previously unseen query and pose it as the half transductive ranking problem. The task is transductive as the set of items is fixed. Transductive representations (where the vector representation of each example is learned) allow the generation of highly nonlinear embeddings that capture object relationships without relying on a specific choice of features, and require only relatively simple optimization. Unfortunately, they have no direct outof- sample extension. Inductive approaches on the other hand allow for the representation of unknown queries. We describe algorithms for this setting which have the advantages of both transductive and inductive approaches, and can be applied in unsupervised (either reconstruction-based or graph-based) and supervised ranking setups. We show empirically that our methods give strong performance on all three tasks.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Hilbert Space Embeddings of Hidden Markov Models
Proceedings of the International Conference on Machine Learning (ICML) (2010)
[u'Le Song', u'Byron Boots', u'Sajid Siddiqi', u'Geoffrey J. Gordon', u'Alex Smola']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Label Embedding Trees for Large Multi-Class Tasks
Neural Information Processing Systems (NIPS) (2010)
[u'Samy Bengio', u'Jason Weston', u'David Grangier']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Label Ranking under Ambiguous Supervision: An Application for Learning Semantic Correspondences
ICML, ICML (2010)
[u'Nicolas Usunier', u'Antoine Bordes', u'Jason Weston']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35780.html
notfound
=========================
Large Scale Image Annotation: Learning to Rank with Joint Word-Image Embeddings
European Conference on Machine Learning (2010)
[u'Jason Weston', u'Samy Bengio', u'Nicolas Usunier']
MachineIntelligence
Abstract: Image annotation datasets are becoming larger and larger, with tens of millions of images and tens of thousands of possible annotations. We propose a strongly performing method that scales to such datasets by simultaneously learning to optimize precision at k of the ranked list of annotations for a given image and learning a low-dimensional joint embedding space for both images and annotations. Our method both outperforms several baseline methods and, in comparison to them, is faster and consumes less memory. We also demonstrate how our method learns an interpretable model, where annotations with alternate spellings or even languages are close in the embedding space. Hence, even when our model does not predict the exact annotation given by a human labeler, it often predicts similar annotations, a fact that we try to quantify by measuring the newly introduced ``sibling'' precision metric, where our method also obtains excellent results.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35114.html
notfound
=========================
Large Scale Online Learning of Image Similarity Through Ranking
Journal of Machine Learning Research, JMLR (2010), pp. 1109-1135
[u'Gal Chechik', u'Varun Sharma', u'Uri Shalit', u'Samy Bengio']
MachineIntelligence
Abstract: Learning a measure of similarity between pairs of objects is an important generic problem in machine learning. It is particularly useful in large scale applications like searching for an image that is similar to a given image or finding videos that are relevant to a given video. In these tasks, users look for objects that are not only visually similar but also semantically related to a given object. Unfortunately, the approaches that exist today for learning such semantic similarity do not scale to large datasets. This is both because typically their CPU and storage requirements grow quadratically with the sample size, and because many methods impose complex positivity constraints on the space of learned similarity functions. The current paper presents OASIS, an Online Algorithm for Scalable Image Similarity learning that learns a bilinear similarity measure over sparse representations. OASIS is an online dual approach using the passive-aggressive family of learning algorithms with a large margin criterion and an efficient hinge loss cost. Our experiments show that OASIS is both fast and accurate at a wide range of scales: for a dataset with thousands of images, it achieves better results than existing state-of-the-art methods, while being an order of magnitude faster. For large, web scale, datasets, OASIS can be trained on more than two million images from 150K text queries within 3 days on a single CPU. On this large scale dataset, human evaluations showed that 35% of the ten nearest neighbors of a given test image, as found by OASIS, were semantically relevant to that image. This suggests that query independent similarity could be accurately learned even for large scale datasets that could not be handled before.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Large scale image annotation: learning to rank with joint word-image embeddings
Machine Learning, vol. 81, Issue 1 (2010), pp. 21
[u'Jason Weston', u'Samy Bengio', u'Nicolas Usunier']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Large-Scale Training of SVMs with Automata Kernels
CIAA (2010), pp. 17-27
[u'Cyril Allauzen', u'Corinna Cortes', u'Mehryar Mohri']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Learning Bounds for Importance Weighting
Advances in Neural Information Processing Systems (NIPS 2010), MIT Press, Vancouver, Canada
[u'Corinna Cortes', u'Yishay Mansour', u'Mehryar Mohri']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36485.html
notfound
=========================
Learning with Global Cost in Stochastic Environments
Proceedings of the 23rd Annual Conference on Learning Theory (COLT) (2010)
[u'Eyal Even-Dar', u'Shie Mannor', u'Yishay Mansour']
MachineIntelligence
Abstract: We consider an online learning setting where at each time step the decision maker has to choose how to distribute the future loss between k alternatives, and then observes the loss of each alternative, where the losses are assumed to come from a joint distribution. Motivated by load balancing and job scheduling, we consider a global cost function (over the losses incurred by each alternative), rather than a summation of the instantaneous losses as done traditionally in online learning. Specifically, we consider the global cost functions: (1) the makespan (the maximum over the alternatives) and (2) the L_d norm (over the alternatives) for d > 1. We design algorithms that guarantee logarithmic regret for this setting, where the regret is measured with respect to the best static decision (one selects the same distribution over alternatives at every time step). We also show that the least loaded machine, a natural algorithm for minimizing the makespan, has a regret of the order of \sqrt{T} . We complement our theoretical findings with supporting experimental results.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36682.html
found
=========================
Mahout in Action
Manning, Manning Publications Co. Sound View Ct. #3B Greenwich, CT 06830 (2010), pp. 350
[u'Robin Anil', u'Sean Owen', u'Ted Dunning', u'Ellen Friedman']
MachineIntelligence
Abstract: A computer system that learns and adapts as it collects data is an extraordinarily interesting and powerful concept. With new technologies to capture, store, and process information, machine learning has moved from the academic edges of computer science to the middle of the mainstream. Mahout, an open source machine learning library, captures the core algorithms of recommendation systems, classification, and clustering in ready-to-use, scalable libraries. With Mahout, you can immediately apply the machine learning techniques that drive Amazon, Netflix, and other data-centric businesses to your own projects. Mahout in Action explores machine learning through Apache's scalable machine learning project, Mahout. Following real-world examples, it introduces practical use cases, and then illustrates how Mahout can be applied to solve them. It places particular focus on issues of scalability, and how to apply these techniques against large data sets using the Apache Hadoop framework. In this book, you'll use Mahout to dive into three practical applications of machine learning: Recommendations. Using group user history and preferences you can make accurate recommendations for individual users. This is an extremely powerful principle, because accurate recommendations are beneficial both to customers and vendors. Clustering. Learn to automatically discover logical groupings with groups of data or data sets, such as documents or lists. This technique is especially useful to search and data mining applications. Classification. Determining on the fly whether a thing fits a category based on its attributes and previous history can help instantaneously organize unstructured groups. For instance, you'll learn about filtering techniques that decide whether email messages should be considered "spam." Mahout in Action is written primarily for developers who need to become better practitioners of machine learning techniques. It is also appropriate for researchers who understand the techniques and want to understand how to apply them effectively at scale. It assumes familiarity with Java, and some basic grounding in machine learning techniques, but no previous exposure to Mahout is necessary.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36948.html
notfound
=========================
MapReduce/Bigtable for Distributed Optimization
Neural Information Processing Systems Workshop on Leaning on Cores, Clusters, and Clouds (2010)
[u'Keith B. Hall', u'Scott Gilpin', u'Gideon Mann']
MachineIntelligence
Abstract: For large data it can be very time consuming to run gradient based optimizat ion,for example to minimize the log-likelihood for maximum entropy models.Distributed methods are therefore appealing and a number of distributed gradientoptimization strategies have been proposed including: distributed gradient, asynchronousupdates, and iterative parameter mixtures. In this paper, we evaluatethese various strategies with regards to their accuracy and speed over MapReduce/Bigtable and discuss the techniques needed for high performance.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Natural Language Processing (almost) from Scratch
Journal of Machine Learning Research (2010)
[u'Ronan Collobert', u'Jason Weston', u'Leon Bottou', u'Michael Karlen', u'Koray Kavukcuoglu', u'Pavel Kuksa']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
On the Estimation of Coherence
CoRR, vol. abs/1009.0861 (2010)
[u'Mehryar Mohri', u'Ameet Talwalkar']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36469.html
notfound
=========================
On the Impact of Kernel Approximation on Learning Accuracy
Thirteenth International Conference on Artificial Intelligence and Statistics (AISTATS 2010)
[u'Corinna Cortes', u'Mehryar Mohri', u'Ameet Talwalkar']
MachineIntelligence
Abstract: Kernel approximation is commonly used to scale kernel-based algorithms to applications containing as many as several million instances. This paper analyzes the effect of such approximations in the kernel matrix on the hypothesis generated by several widely used learning algorithms. We give stability bounds based on the norm of the kernel approximation for these algorithms, including SVMs, KRR, and graph Laplacian-based regularization algorithms. These bounds help determine the degree of approximation that can be tolerated in the estimation of the kernel matrix. Our analysis is general and applies to arbitrary approximations of the kernel matrix. However, we also give a specific analysis of the Nystrom low-rank approximation in this context and report the results of experiments evaluating the quality of the Nystrom low-rank kernel approximation when used with ridge regression.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Parallel Spectral Clustering in Distributed Systems
IEEE Transactions on Pattern Analysis and Machine Intelligence (2010)
[u'Wen-Yen Chen', u'Yangqiu Song', u'Hongjie Bai', u'Chih-Jen Lin', u'Edward Y. Chang']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36678.html
notfound
=========================
Prediction of Advertiser Churn for Google AdWords
JSM Proceedings, American Statistical Association (2010) (to appear)
[u'Sangho Yoon', u'Jim Koehler', u'Adam Ghobarah']
MachineIntelligence
Abstract: Google AdWords has thousands of advertisers participating in auctions to show their advertisements. Google's business model has two goals: firrst, provide relevant information to users and second, provide advertising opportunities to advertisers to achieve their business needs. To better serve these two parties, it is important to find relevant information for users and at the same time assist advertisers in advertising more efficiently and effectively. In this paper, we try to tackle this problem of better connecting users and advertisers from a customer relationship management point of view. More specifically, we try to retain more advertisers in AdWords by identifying and helping advertisers that are not successful in using Google AdWords. In this work, we first propose a new definition of advertiser churn for AdWords advertisers; second we present a method to carefully select a homogeneous group of advertisers to use in understanding and predicting advertiser churn; and third we build a model to predict advertiser churn using machine learning algorithms.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36945.html
notfound
=========================
Preference-Based Learning to Rank
Machine Learning Journal, vol. 8 (2010), pp. 189-211
[u'Nir Ailon', u'Mehryar Mohri']
MachineIntelligence
Abstract: This paper presents an ecient preference-based ranking algorithm running in two stages. In the rst stage, the algorithm learns a preference function dened over pairs, as in a standard binary classification problem. In the second stage, it makes use of that preference function to produce an accurate ranking, thereby reducing the learning problem of ranking to binary classication. This reduction is based on the familiar QuickSort and guarantees an expected pairwise misranking loss of at most twice that of the binary classier derived in the rst stage. Furthermore, in the important special case of bipartite ranking, the factor of two in loss is reduced to one. This improved bound also applies to the regret achieved by our ranking and that of the binary classifier obtained. Our algorithm is randomized, but we prove a lower bound for any deterministic reduction of ranking to binary classication showing that randomization is necessary to achieve our guarantees. This, and a recent result by Balcan et al., who show a regret bound of two for a deterministic algorithm in the bipartite case, suggest a trade-off between achieving low regret and determinism in this context. Our reduction also admits an improved running time guarantee with respect to that deterministic algorithm. In particular, the number of calls to the preference function in the reduction is improved from (n^2) to O(n log n). In addition, when the top k ranked elements only are required (kn), as in many applications in information extraction or search engine design, the time complexity of our algorithm can be further reduced to O(k log k+n). Our algorithm is thus practical for realistic applications where the number of points to rank exceeds several thousand.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Random classification noise defeats all convex potential boosters
Machine Learning, vol. 78 (2010), pp. 287-304
[u'Philip M. Long', u'Rocco A. Servedio']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36486.html
notfound
=========================
Regret Minimization with Concept Drift
Proceedings of the 23rd Annual Conference on Learning Theory (COLT) (2010)
[u'Koby Crammer', u'Eyal Even-Dar', u'Yishay Mansour', u'Jennifer Wortman Vaughan']
MachineIntelligence
Abstract: In standard online learning, the goal of the learner is to maintain an average loss close to the loss of the best-performing function in a fixed class. Classic results show that simple algorithms can achieve an average loss arbitrarily close to that of the best function in retrospect, even when input and output pairs are chosen by an adversary. However, in many real-world applications such as spam prediction and classification of news articles, the best target function may be drifting over time. We introduce a novel model of concept drift in which an adversary is given control of both the distribution over input at each time step and the corresponding labels. The goal of the learner is to maintain an average loss close to the 0/1 loss of the best slowly changing sequence of functions with no more than K large shifts. We provide regret bounds for learning in this model using an (inefficient) reduction to the standard no-regret setting. We then go on to provide and analyze an efficient algorithm for learning d-dimensional hyperplanes with drift. We conclude with some simulations illustrating the circumstances under which this algorithm outperforms other commonly studied algorithms when the target hyperplane is drifting.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Restricted Boltzmann Machines are hard to approximately evaluate or simulate
ICML (2010)
[u'Philip M. Long', u'Rocco A. Servedio']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36294.html
notfound
=========================
Robust Symbolic Regression with Affine Arithmetic
Genetic and Evolutionary Computation COnference (GECCO) (2010)
[u'Cassio Pennachin', u'Moshe Looks', u'Joo A. de Vasconcelos']
MachineIntelligence
Abstract: We use affine arithmetic to improve both the performance and the robustness of genetic programming for symbolic regression. During evolution, we use affine arithmetic to analyze expressions generated by the genetic operators, giving an estimate of their output range given the ranges of their inputs over the training data. These estimated output ranges allow us to discard trees that contain asymptotes as well as those whose output is too far from the desired output range determined by the training instances. We also perform linear scaling of outputs before fitness evaluation. Experiments are performed on 15 problems, comparing the proposed system with a baseline genetic programming system with protected operators, and with a similar system based on interval arithmetic. Results show integrating affine arithmetic with an implementation of standard genetic programming reduces the number of fitness evaluations during training and improves generalization performance, minimizes overfitting, and completely avoids extreme errors on unseen test data.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
SPEC Hashing: Similarity Preserving algorithm for Entropy-based Coding
IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2010)
[u'Ruei-Sung Lin', u'David A. Ross', u'Jay Yagnik']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
SVM Optimization for Lattice Kernels
Mining and Learning with Graphs (2010)
[u'Cyril Allauzen', u'Corinna Cortes', u'Mehryar Mohri']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Semi-Supervised Abstraction-Augmented String Kernel for Multi-Level Bio-Relation Extraction.
ECML (2010)
[u'Pavel Kuksa', u'Yanjun Qi', u'Bing Bai', u'Ronan Collobert', u'Jason Weston']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Sequential Projection Learning for Hashing with Compact Codes
International Conference on Machine Learning (ICML) (2010)
[u'Jun Wang', u'Sanjiv Kumar', u'Shih-Fu Chang']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37042.html
notfound
=========================
Showing Relevant Ads via Lipschitz Context Multi-Armed Bandits
Thirteenth International Conference on Artificial Intelligence and Statistics, Journal of Machine Learning Research (2010)
[u'Tyler Lu', u'Dvid Pl', u'Martin Pl']
MachineIntelligence
Abstract: We study contextual multi-armed bandit problems where the context comes from a metric space and the payoff satisfies a Lipschitz condition with respect to the metric. Abstractly, a contextual multi-armed bandit problem models a situation where, in a sequence of independent trials, an online algorithm chooses, based on a given context (side information), an action from a set of possible actions so as to maximize the total payoff of the chosen actions. The payoff depends on both the action chosen and the context. In contrast, context-free multi-armed bandit problems, a focus of much previous research, model situations where no side information is available and the payoff depends only on the action chosen. Our problem is motivated by sponsored web search, where the task is to display ads to a user of an Internet search engine based on her search query so as to maximize the click-through rate (CTR) of the ads displayed. We cast this problem as a contextual multi-armed bandit problem where queries and ads form metric spaces and the payoff function is Lipschitz with respect to both the metrics. For any $\epsilon > 0$ we present an algorithm with regret $O(T^{\frac{a+b+1}{a+b+2} + \epsilon})$ where $a,b$ are the covering dimensions of the query space and the ad space respectively. We prove a lower bound $\Omega(T^{\frac{\tilde{a}+\tilde{b}+1}{\tilde{a}+\tilde{b}+2} \epsilon})$ for the regret of any algorithm where $\tilde{a}, \tilde{b}$ are packing dimensions of the query spaces and the ad space respectively. For finite spaces or convex bounded subsets of Euclidean spaces, this gives an almost matching upper and lower bound.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36274.html
notfound
=========================
Sparse Spatiotemporal Coding for Activity Recognition
Brown University (2010)
[u'Thomas Dean', u'Greg Corrado', u'Rich Washington']
MachineIntelligence
Abstract: We present a new approach to learning sparse, spatiotemporal features and demonstrate the utility of the approach by applying the resulting sparse codes to the problem of activity recognition. Learning features that discriminate among human activities in video is difficult in part because the stable space-time events that reliably characterize the relevant motions are rare. To overcome this problem, we adopt a multi-stage approach to activity recognition. In the initial preprocessing stage, we first whiten and apply local contrast normalization to each frame of the video. We then apply an additional set of filters to identify and extract salient space-time volumes that exhibit smooth periodic motion. We collect a large corpus of these space-time volumes as training data for the unsupervised learning of a sparse, over-complete basis using a variant of the two-phase analysis-synthesis algorithm of Olshausen and Field [1997]. We treat the synthesis phase, which consists of reconstructing the input as sparse a mostly coefficient zero and most importantly the time required for reconstruction in subsequent use production we adapted existing algorithms to exploit potential parallelism through the use of readily-available SIMD hardware. To obtain better codes, we developed a new approach to learning sparse, spatiotemporal codes in which the number of basis vectors, their orientations, velocities and the size of their receptive fields change over the duration of unsupervised training. The algorithm starts with a relatively small, initial basis with minimal temporal extent. This initial basis is obtained through conventional sparse coding techniques and is expanded over time by recursively constructing a new basis consisting of basis vectors with larger temporal extent that proportionally conserve regions of previously trained weights. These proportionally conserved weights are combined with the result of adjusting newly added weights to represent a greater range of primitive motion features. The size of the current basis is determined probabilistically by sampling from existing basis vectors according to their activation on the training set. The resulting algorithm produces bases consisting of filters that are bandpass, spatially oriented and temporally diverse in terms of their transformations and velocities. We demonstrate the utility of our approach by using it to recognize human activity in video.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36944.html
notfound
=========================
Stability Bounds for Stationary $\phi$-mixing and $\beta$-mixing Processes
Journal of Machine Learning Research (JMLR), vol. 11 (2010), pp. 798-814
[u'Mehryar Mohri', u'Afshin Rostamizadeh']
MachineIntelligence
Abstract: Most generalization bounds in learning theory are based on some measure of the complexity of the hypothesis class used, independently of any algorithm. In contrast, the notion of algorithmic stability can be used to derive tight generalization bounds that are tailored to specific learning algorithms by exploiting their particular properties. However, as in much of learning theory, existing stability analyses and bounds apply only in the scenario where the samples are independently and identically distributed. In many machine learning applications, however, this assumption does not hold. The observations received by the learning algorithm often have some inherent temporal dependence.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36265.html
notfound
=========================
Star Quality: Aggregating Reviews to Rank Products and Merchants
Proceedings of Fourth International Conference on Weblogs and Social Media (ICWSM), AAAI (2010)
[u'Mary McGlohon', u'Natalie Glance', u'Zach Reiter']
MachineIntelligence
Abstract: Given a set of reviews of products or merchants from a wide range of authors and several reviews websites, how can we measure the true quality of the product or merchant? How do we remove the bias of individual au- thors or sources? How do we compare reviews obtained from different websites, where ratings may be on differ- ent scales (1-5 stars, A/B/C, etc.)? How do we filter out unreliable reviews to use only the ones with star qual- ity? Taking into account these considerations, we an- alyze data sets from a variety of different reviews sites (the first paper, to our knowledge, to do this). These data sets include 8 million product reviews and 1.5 million merchant reviews. We explore statistic- and heuristic- based models for estimating the true quality of a prod- uct or merchant, and compare the performance of these estimators on the task of ranking pairs of objects. We also apply the same models to the task of using Netflix ratings data to rank pairs of movies, and discover that the performance of the different models is surprisingly similar on this data set.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
The Learning Behind Gmail Priority Inbox
LCCC : NIPS 2010 Workshop on Learning on Cores, Clusters and Clouds
[u'Douglas Aberdeen', u'Ondrey Pacovsky', u'Andrew Slater']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
The YouTube video recommendation system
Fourth ACM conference on Recommender systems (2010)
[u'James Davidson', u'Benjamin Liebald', u'Junning Liu', u'Palash Nandy', u'Taylor Van Vleet', u'Ullas Gargi', u'Sujoy Gupta', u'Yu He', u'Mike Lambert', u'Blake Livingston', u'Dasarathi Sampath']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub33013.html
notfound
=========================
Theoretical Convergence Guarantees for Cooperative Coevolutionary Algorithms
Evolutionary Computation Journal (2010)
[u'Liviu Panait']
MachineIntelligence
Abstract: Cooperative coevolutionary algorithms have the potential to significantly speed up the search process by dividing the space into parts that can be each conquered separately. Unfortunately, recent research presented theoretical and empirical arguments that these algorithms might not be fit for optimization tasks, as they might tend to drift to suboptimal solutions in the search space. This paper details an extended formal model for cooperative coevolutionary algorithms, and uses it to demonstrate that these algorithms will converge to the globally optimal solution, if properly set and if given enough resources. We also present an intuitive graphical visualization for the basins of attraction to optimal and suboptimal solutions in the search space.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Towards Understanding Situated Natural Language
Artificial Intelligence and Statistics (AISTATS) (2010)
[u'Antoine Bordes', u'Nicolas Usunier', u'Jason Weston']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36629.html
notfound
=========================
Training and Testing Low-degree Polynomial Data Mappings via Linear SVM
Journal of Machine Learning Research, vol. 11(Apr) (2010), 14711490
[u'Yin-Wen Chang', u'Cho-Jui Hsieh', u'Kai-Wei Chang', u'Michael Ringgaard', u'Chih-Jen Lin']
MachineIntelligence
Abstract: Kernel techniques have long been used in SVM to handle linearly inseparable problems by transforming data to a high dimensional space, but training and testing large data sets is often time consuming. In contrast, we can efficiently train and test much larger data sets using linear SVM without kernels. In this work, we apply fast linear-SVM methods to the explicit form of polynomially mapped data and investigate implementation issues. The approach enjoys fast training and testing, but may sometimes achieve accuracy close to that of using highly nonlinear kernels. Empirical experiments show that the proposed method is useful for certain large-scale data sets. We successfully apply the proposed method to a natural language processing (NLP) application by improving the testing accuracy under some training/testing speed requirements.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36468.html
notfound
=========================
Two-Stage Learning Kernel Algorithms
Proceedings of the 27th Annual International Conference on Machine Learning (ICML 2010)
[u'Corinna Cortes', u'Mehryar Mohri', u'Afshin Rostamizadeh']
MachineIntelligence
Abstract: This paper examines two-stage techniques for learning kernels based on a notion of alignment. It presents a number of novel theoretical, algorithmic, and empirical results for alignmentbased techniques. Our results build on previous work by Cristianini et al. (2001), but we adopt a different definition of kernel alignment and significantly extend that work in several directions: we give a novel and simple concentration bound for alignment between kernel matrices; show the existence of good predictors for kernels with high alignment, both for classification and for regression; give algorithms for learning a maximum alignment kernel by showing that the problem can be reduced to a simple QP; and report the results of extensive experimentswith this alignment-based method in classification and regression tasks, which show an improvement both over the uniformcombination of kernels and over other state-of-the-art learning kernel methods.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35536.html
notfound
=========================
Why does Unsupervised Pre-training Help Deep Learning?
Journal of Machine Learning Research (2010), pp. 625-660
[u'Dumitru Erhan', u'Yoshua Bengio', u'Aaron Courville', u'Pierre-Antoine Manzagol', u'Pascal Vincent', u'Samy Bengio']
MachineIntelligence
Abstract: Much recent research has been devoted to learning algorithms for deep architectures such as Deep Belief Networks and stacks of auto-encoder variants, with impressive results obtained in several areas, mostly on vision and language data sets. The best results obtained on supervised learning tasks involve an unsupervised learning component, usually in an unsupervised pre-training phase. Even though these new algorithms have enabled training deep models, many questions remain as to the nature of this difficult learning problem. The main question investigated here is the following: how does unsupervised pre-training work? Answering this questions is important if learning in deep architectures is to be further improved. We propose several explanatory hypotheses and test them through extensive simulations. We empirically show the influence of pre-training with respect to architecture depth, model capacity, and number of training examples. The experiments confirm and clarify the advantage of unsupervised pre-training. The results suggest that unsupervised pre-training guides the learning towards basins of attraction of minima that support better generalization from the training data set; the evidence from these results supports a regularization explanation for the effect of pre-training.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35311.html
notfound
=========================
An Online Algorithm for Large Scale Image Similarity Learning
Advances in Neural Information Processing Systems (2009)
[u'Gal Chechik', u'Varun Sharma', u'Uri Shalit', u'Samy Bengio']
MachineIntelligence
Abstract: Learning a measure of similarity between pairs of objects is a fundamental problem in machine learning. It stands in the core of classifications methods like kernel machines, and is particularly useful for applications like searching for images that are similar to a given image or finding videos that are relevant to a given video. In these tasks, users look for objects that are not only visually similar but also semantically related to a given object. Unfortunately, current approaches for learning similarity do not scale to large datasets, especially when imposing metric constraints on the learned similarity. We describe OASIS, a method for learning pairwise similarity that is fast and scales linearly with the number of objects and the number of non-zero features. Scalability is achieved through online learning of a bilinear model over sparse representations using a large margin criterion and an efficient hinge loss cost. OASIS is accurate at a wide range of scales: on a standard benchmark with thousands of images, it is more precise than state-of-the-art methods, and faster by orders of magnitude. On 2 millions images collected from the web, OASIS can be trained within 3 days on a single CPU. The non-metric similarities learned by OASIS can be transformed into metric similarities, achieving higher precisions than similarities that are learned as metrics in the first place. This suggests an approach for learning a metric from data that is larger by two orders of magnitude than was handled before.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Artificial Intelligence: A Modern Approach
Prentice Hall Press, Upper Saddle River, NJ, USA (2009)
[u'Stuart Russell', u'Peter Norvig']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34557.html
notfound
=========================
Automatic Speech and Speaker Recognition: Large Margin and Kernel Methods
Wiley (2009)
[u'Joseph Keshet', u'Samy Bengio']
MachineIntelligence
Abstract: This is the first book dedicated to uniting research related to speech and speaker recognition based on the recent advances in large margin and kernel methods. The first part of the book presents theoretical and practical foundations of large margin and kernel methods, from support vector machines to large margin methods for structured learning. The second part of the book is dedicated to acoustic modeling of continuous speech recognizers, where the grounds for practical large margin sequence learning are set. The third part introduces large margin methods for discriminative language modeling. The last part of the book is dedicated to the application of keyword spotting, speaker verification and spectral clustering. The book is an important reference to researchers and practitioners in the field of modern speech and speaker recognition. The purpose of the book is twofold; first, to set the theoretical foundation of large margin and kernel methods relevant to speech recognition domain; second, to propose a practical guide on implementation of these methods to the speech recognition domain. The reader is presumed to have basic knowledge of large margin and kernel methods and of basic algorithms in speech and speaker recognition.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Baum's algorithm learns intersections of halfspaces with respect to log-concave distributions
RANDOM (2009)
[u'Adam R. Klivans', u'Philip M. Long', u'Alex K. Tang']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Boosting with structural sparsity
ICML '09: Proceedings of the 26th Annual International Conference on Machine Learning, ACM, New York, NY, USA (2009), pp. 297-304
[u'John Duchi', u'Yoram Singer']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34619.html
notfound
=========================
Cooperative Coevolution and Univariate Estimation of Distribution Algorithms
Foundations of Genetic Algorithms (2009)
[u'Christopher Vo', u'Liviu Panait', u'Sean Luke']
MachineIntelligence
Abstract: In this paper, we discuss a curious relationship between Cooperative Coevolutionary Algorithms (CCEAs) and Univariate EDAs. Inspired by the theory of CCEAs, we also present a new EDA with theoretical convergence guarantees, and some preliminary experimental results in comparison with existing Univariate EDAs.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Des algorithmes d'apprentissage pour mieux classifier
Pour la Science, vol. 386 (2009)
[u'Corinna Cortes', u'Patrick Haffner', u'Mehryar Mohri']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34844.html
notfound
=========================
Discriminative Keyword Spotting
Speech Communication (2009), pp. 317-329
[u'Joseph Keshet', u'David Grangier', u'Samy Bengio']
MachineIntelligence
Abstract: This paper proposes a new approach for keyword spotting, which is based on large margin and kernel methods rather than on HMMs. Unlike previous approaches, the proposed method employs a discriminative learning procedure, in which the learning phase aims at achieving a high area under the ROC curve, as this quantity is the most common measure to evaluate keyword spotters. The keyword spotter we devise is based on mapping the input acoustic representation of the speech utterance along with the target keyword into a vector space. Building on techniques used for large margin and kernel methods for predicting whole sequences, our keyword spotter distills to a classifier in this vector-space, which separates speech utterances in which the keyword is uttered from speech utterances in which the keyword is not uttered. We describe a simple iterative algorithm for training the keyword spotter and discuss its formal properties, showing theoretically that it attains high area under the ROC curve. Experiments on read speech with the TIMIT corpus show that the resulted discriminative system outperforms the conventional context-independent HMM-based system. Further experiments using the TIMIT trained model, but tested on both read (HTIMIT, WSJ) and spontaneous speech (OGI-Stories), show that without further training or adaptation to the new corpus our discriminative system outperforms the conventional context-independent HMM-based system.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Domain Adaptation with Multiple Sources
Advances in Neural Information Processing Systems (NIPS 2008), MIT Press, Vancouver, Canada (2009)
[u'Yishay Mansour', u'Mehryar Mohri', u'Afshin Rostamizadeh']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Domain Adaptation: Learning Bounds and Algorithms
Proceedings of The 22nd Annual Conference on Learning Theory (COLT 2009), Omnipress, Montr\'eal, Canada
[u'Yishay Mansour', u'Mehryar Mohri', u'Afshin Rostamizadeh']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Efficient Large-Scale Distributed Training of Conditional Maximum Entropy Models
Neural Information Processing Systems (NIPS) (2009)
[u'Gideon Mann', u'Ryan McDonald', u'Mehryar Mohri', u'Nathan Silberman', u'Daniel Walker IV']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34434.html
notfound
=========================
Emotional Memory and Adaptive Personalities
Handbook of Synthetic Emotions and Sociable Robotics, Information Science Reference, an imprint of IGI Global, www.info-sci-ref.com (2009), pp. 391-412
[u'Anthony Francis', u'Manish Mehta', u'Ashwin Ram']
MachineIntelligence
Abstract: Believable agents designed for long-term interaction with human users need to adapt to them in a way which appears emotionally plausible while maintaining a consistent personality. For short-term interactions in restricted environments, scripting and state machine techniques can create agents with emotion and personality, but these methods are labor intensive, hard to extend, and brittle in new environments. Fortunately, research in memory, emotion and personality in humans and animals points to a solution to this problem. Emotions focus an animals attention on things it needs to care about, and strong emotions trigger enhanced formation of memory, enabling the animal to adapt its emotional response to the objects and situations in its environment. In humans this process becomes reflective: emotional stress or frustration can trigger re-evaluating past behavior with respect to personal standards, which in turn can lead to setting new strategies or goals. To aid the authoring of adaptive agents, we present an artificial intelligence model inspired by these psychological results in which an emotion model triggers case-based emotional preference learning and behavioral adaptation guided by personality models. Our tests of this model on robot pets and embodied characters show that emotional adaptation can extend the range and increase the behavioral sophistication of an agent without the need for authoring additional hand-crafted behaviors.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Ensemble Nystrom Method
Neural Information Processing Systems (NIPS) (2009)
[u'Sanjiv Kumar', u'Mehryar Mohri', u'Ameet Talwalkar']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Entropic Graph Regularization in Non-Parametric Semi-Supervised Classification
NIPS 2009
[u'Amarnag Subramanya', u'Jeff Bilmes']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35522.html
notfound
=========================
Finding Images and Line Drawings in Document-Scanning Systems
Proc. International Conference on Document Analysis and Retrieval, IAPR (2009)
[u'Shumeet Baluja', u'Michele Covell']
MachineIntelligence
Abstract: This work addresses the problem of finding images and line-drawings in scanned pages. It is a crucial processing step in the creation of a large-scale system to detect and index images found in books and historic documents. Within the scanned pages that contain both text and images, the images are found through the use of local-feature extraction, applied across the full scanned page. This is followed by a novel learning system to categorize the local features into either text or image. The discrimination is based on using multiple classifiers trained via stochastic sampling of weak classifiers for each AdaBoost stage. The approach taken in sampling includes stochastic hill climbing across weak detectors, allowing us to reduce our classification error by as much as 25% relative to more naive stochastic sampling. Stochastic hill climbing in the weak classifier space is possible due to the manner in which we parameterize the weak classifier space. Through the use of this system, we improve image detection by finding more line-drawings, graphics, and photographs, as well as reducing the number of spurious detections due to misclassified text, discoloration, and scanning artifacts.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Gaussian Margin Machines
Twelfth International Conference on Artificial Intelligence and Statistics (AISTATS 2009), Clearwater Beach, Florida, pp. 105-112
[u'Koby Crammer', u'Mehryar Mohri', u'Fernando Pereira']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Group Sparse Coding
Advances in Neural Information Processing Systems (2009)
[u'Samy Bengio', u'Fernando Pereira', u'Yoram Singer', u'Dennis Strelow']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Introduction
Automatic Speech and Speaker Recognition: Large Margin and Kernel Methods, Wiley (2009)
[u'Samy Bengio', u'Joseph Keshet']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Invited talk: Can learning kernels help performance?
ICML '09: Proceedings of the 26th Annual International Conference on Machine Learning, ACM, New York, NY, USA (2009), pp. 1-1
[u'Corinna Cortes']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34560.html
notfound
=========================
Kernel Based Text-Independnent Speaker Verification
Automatic Speech and Speaker Recognition: Large Margin and Kernel Methods, Wiley (2009)
[u'Johnny Mariethoz', u'Yves Grandvalet', u'Samy Bengio']
MachineIntelligence
Abstract: The goal of a person authentication system is to authenticate the claimed identity of a user. When this authentication is based on the voice of the user, without respect of what the user exactly said, the system is called a text-independent speaker verification system. Speaker verification systems are increasingly often used to secure personal information, particularly for mobile phone based applications. Furthermore, text-independent versions of speaker verification systems are the most used for their simplicity, as they do not require complex speech recognition modules. The most common approach to this task is based on Gaussian Mixture Models (GMMs), which do not take into account any temporal information. GMMs have been intensively used thanks to their good performance, especially with the use of the Maximum A Posteriori (MAP) adaptation algorithm. This approach is based on the density estimation of an impostor data distribution, followed by its adaptation to a specific client data set. Note that the estimation of these densities is not the final goal of speaker verification systems, which is rather to discriminate the client and impostor classes; hence discriminative approaches might appear good candidates for this task as well. As a matter of fact, Support Vector Machine (SVM) based systems have been the subject of several recent publications in the speaker verification community, in which they obtain similar to or even better performance than GMMs on several text-independent speaker verification tasks. In order to use SVMs or any other discriminant approaches for speaker verification, several modifications from the classical techniques need to be performed. The purpose of this chapter is to present an overview of discriminant approaches that have been used successfully for the task of text-independent speaker verification, to analyze their difference and their similarities with each other and with classical generative approaches based on GMMs. An open-source version of the C++ source code used to performed all experiments described in this chapter can be found at http://speaker.abracadoudou.com.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
L2 Regularization for Learning Kernels
Proceedings of the 25th Conference on Uncertainty in Artificial Intelligence (UAI 2009), Montr\'eal, Canada
[u'Corinna Cortes', u'Mehryar Mohri', u'Afshin Rostamizadeh']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35656.html
notfound
=========================
Large Scale Graph Transduction
NIPS 2009 Workshop on Large-Scale Machine Learning: Parallelism and Massive Datasets, NIPS
[u'Amarnag Subramanya', u'Jeff Bilmes']
MachineIntelligence
Abstract: We consider the issue of scalability of graph-based semi-supervised learning (SSL) algorithms. In this context, we propose a fast graph node ordering algorithm that improves parallel spatial locality by being cache cognizant. This approach allows for a linear speedup on a shared-memory parallel machine to be achievable, and thus means that graph-based SSL can scale to very large data sets. We use the above algorithm an a multi-threaded implementation to solve a SSL problem on a 120 million node graph in a reasonable amount of time.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Large Scale Learning to Rank
NIPS 2009 Workshop on Advances in Ranking
[u'D. Sculley']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35267.html
notfound
=========================
Large Scale Online Learning of Image Similarity Through Ranking: Extended Abstract
4th Iberian Conference on Pattern Recognition and Image Analysis, IbPRIA (2009)
[u'Gal Chechik', u'Varun Sharma', u'Uri Shalit', u'Samy Bengio']
MachineIntelligence
Abstract: Learning a measure of similarity between pairs of objects is a fundamental problem in machine learning. Pairwise similarity plays a crucial role in classification algorithms like nearest neighbors, and is practically important for applications like searching for images that are similar to a given image or finding videos that are relevant to a given video. In these tasks, users look for objects that are both visually similar and semantically related to a given object. Unfortunately, current approaches for learning semantic similarity are limited to small scale datasets, because their complexity grows quadratically with the sample size, and because they impose costly positivity constraints on the learned similarity functions. To address real-world large-scale AI problem, like learning similarity over all images on the web, we need to develop new algorithms that scale to many samples, many classes, and many features. The current abstract presents OASIS, an {\em Online Algorithm for Scalable Image Similarity} learning that learns a bilinear similarity measure over sparse representations. OASIS is an online dual approach using the passive-aggressive family of learning algorithms with a large margin criterion and an efficient hinge loss cost. Our experiments show that OASIS is both fast and accurate at a wide range of scales: for a dataset with thousands of images, it achieves better results than existing state-of-the-art methods, while being an order of magnitude faster. Comparing OASIS with different symmetric variants, provides unexpected insights into the effect of symmetry on the quality of the similarity. For large, web scale, datasets, OASIS can be trained on more than two million images from 150K text queries within two days on a single CPU. Human evaluations showed that 35\% of the ten top images ranked by OASIS were semantically relevant to a query image. This suggests that query-independent similarity could be accurately learned even for large-scale datasets that could not be handled before.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Learning Halfspaces with Malicious Noise
JMLR, vol. 10 (2009), pp. 2715-2740
[u'Adam R. Klivans', u'Philip M. Long', u'Rocco A. Servedio']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Learning non-linear combinations of kernels
NIPS 2009, Advances in Neural Information Processing Systems, MIT Press
[u'Corinna Cortes', u'Mehryar Mohri', u'Afshin Rostamizadeh']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Multiple Source Adaptation and the Renyi Divergence
UAI (2009), pp. 367-374
[u'Yishay Mansour', u'Mehryar Mohri', u'Afshin Rostamizadeh']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
On Sampling-Based Approximate Spectral Decomposition
International Conference on Machine Learning (ICML) (2009)
[u'Sanjiv Kumar', u'Mehryar Mohri', u'Ameet Talkwalkar']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Parallel Large Scale Feature Selection for Logistic Regression
SIAM International Conference on Data Mining (SDM) (2009)
[u'Sameer Singh', u'Jeremy Kubica', u'Scott Larsen', u'Daria Sorokina']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Polynomial semantic indexing
Advances in Neural Information Processing Systems (NIPS 2009), MIT Press
[u'Bing Bai', u'Jason Weston', u'David Grangier', u'Ronan Collobert', u'Kunihiko Sadamasa', u'Yanjun Qi', u'Corinna Cortes', u'Mehryar Mohri']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38284.html
notfound
=========================
Posterior vs. Parameter Sparsity in Latent Variable Models
Advances in Neural Information Processing Systems 22 (2009), pp. 664-672
[u'Joao Graca', u'Kuzman Ganchev', u'Ben Taskar', u'Fernando Pereira']
MachineIntelligence
Abstract: In this paper we explore the problem of biasing unsupervised models to favor sparsity. We extend the posterior regularization framework [8] to encourage the model to achieve posterior sparsity on the unlabeled training data. We apply this new method to learn rst-order HMMs for unsupervised part-of-speech (POS) tagging, and show that HMMs learned this way consistently and signicantly out-performs both EM-trained HMMs, and HMMs with a sparsity-inducing Dirichlet prior trained by variational EM. We evaluate these HMMs on three languages English, Bulgarian and Portuguese under four conditions. We nd that our method always improves performance with respect to both baselines, while variational Bayes actually degrades performance in most cases. We increase accuracy with respect to EM by 2.5%-8.7% absolute and we see improvements even in a semisupervised condition where a limited dictionary is provided.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub33332.html
notfound
=========================
Probabilistic Models for Melodic Prediction
Artificial Intelligence Journal, vol. 173 (2009), pp. 1266-1274
[u'Jean-Francois Paiement', u'Samy Bengio', u'Douglas Eck']
MachineIntelligence
Abstract: Chord progressions are the building blocks from which tonal music is constructed. The choice of a particular representation for chords has a strong impact on statistical modeling of the dependence between chord symbols and the actual sequences of notes in polyphonic music. Melodic prediction is used in this paper as a benchmark task to evaluate the quality of four chord representations using two probabilistic model architectures derived from Input/Output Hidden Markov Models (IOHMMs). Likelihoods and conditional and unconditional prediction error rates are used as complementary measures of the quality of each of the proposed chord representations. We observe empirically that different chord representations are optimal depending on the chosen evaluation metric. Also, representing chords only by their roots appears to be a good compromise in most of the reported experiments.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34939.html
notfound
=========================
Program Representation for General Intelligence
The Second Conference on Artificial General Intelligence (2009)
[u'Moshe Looks', u'Ben Goertzel']
MachineIntelligence
Abstract: Traditional machine learning systems work with relatively flat, uniform data representations, such as feature vectors, time-series, and context-free grammars. However, reality often presents us with data which are best understood in terms of relations, types, hierarchies, and complex functional forms. One possible representational scheme for coping with this sort of complexity is computer programs. This immediately raises the question of how programs are to be best represented. We propose an answer in the context of ongoing work towards artificial general intelligence.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Quantum Annealing for Clustering
Proceedings of the 25th Annual Conference on Uncertainty in Artificial Intelligence, AUAI Press (2009) (to appear)
[u'Kenichi Kurihara', u'Shu Tanaka', u'Seiji Miyashita']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Quantum Annealing for Variational Bayes Inference
Proceedings of the 25th Annual Conference on Uncertainty in Artificial Intelligence, AUAI Press (2009) (to appear)
[u'Issei Sato', u'Kenichi Kurihara', u'Shu Tanaka', u'Seiji Miyashita', u'Hiroshi Nakagawa']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Rademacher Complexity Bounds for Non-I.I.D. Processes
Advances in Neural Information Processing Systems (NIPS 2008), MIT Press, Vancouver, Canada (2009)
[u'Mehryar Mohri', u'Afshin Rostamizadeh']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41118.html
notfound
=========================
Recursive Sparse Spatiotemporal Coding
Proceedings of the Fifth IEEE International Workshop on Multimedia Information Processing and Retrieval, IEEE Computer Society (2009)
[u'Thomas Dean', u'Greg Corrado', u'Richard Washington']
MachineIntelligence
Abstract: We present a new approach to learning sparse, spatiotemporal codes in which the number of basis vectors, their orientations, velocities and the size of their receptive fields change over the duration of unsupervised training. The algorithm starts with a relatively small, initial basis with minimal temporal extent. This initial basis is obtained through conventional sparse coding techniques and is expanded over time by recursively constructing a new basis consisting of basis vectors with larger temporal extent that proportionally conserve regions of previously trained weights. These proportionally conserved weights are combined with the result of adjusting newly added weights to represent a greater range of primitive motion features. The size of the current basis is determined probabilistically by sampling from existing basis vectors according to their activation on the training set. The resulting algorithm produces bases consisting of filters that are bandpass, spatially oriented and temporally diverse in terms of their transformations and velocities. The basic methodology borrows inspiration from the layer-by-layer learning of multiple-layer restricted Boltzmann machines developed by Geoff Hinton and his students. Indeed, we can learn multiple-layer sparse codes by training a stack of denoising autoencoders, but we have had greater success using L1 regularized regression in a variation on Olshausen and Field's original SPARSENET. To accelerate learning and focus attention, we apply a space-time interest-point operator that selects for periodic motion. This attentional mechanism enables us to efficiently compute and compactly represent a broad range of interesting motion. We demonstrate the utility of our approach by using it to recognize human activity in video. Our algorithm meets or exceeds the performance of state-of-the-art activity-recognition methods.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Sampling Techniques for the Nystrom Method
Artificial Intelligence and Statistics (AISTATS) (2009)
[u'Sanjiv Kumar', u'Mehryar Mohri', u'Ameet Talwalkar']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35524.html
notfound
=========================
Semi-supervised Learning of Dependency Parsers using Generalized Expectation Criteria
IJCNLP-ACL (2009)
[u'Gregory Druck', u'Gideon S. Mann', u'Andrew McCallum']
MachineIntelligence
Abstract: In this paper, we propose a novel method for semi-supervised learning of nonprojective log-linear dependency parsers using directly expressed linguistic prior knowledge (e.g. a nouns parent is often a verb). Model parameters are estimated using a generalized expectation (GE) objective function that penalizes the mismatch between model predictions and linguistic expectation constraints. In a comparison with two prominent unsupervised learning methods that require indirect biasing toward the correct syntactic structure, we show that GE can attain better accuracy with as few as 20 intuitive constraints. We also present positive experimental results on longer sentences in multiple languages.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Simple Risk Bounds for Position-Sensitive Max-Margin Ranking Algorithms
Proceedings of NIPS'09 Workshop on "Advances in Ranking" (2009)
[u'Stefan Riezler', u'Fabio De Bona']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Sleeping Experts and Bandits with Stochastic Action Availability and Adversarial Rewards
Proceedings of the 12th International Conference on Artificial Intelligence and Statistic (AISTATS) (2009)
[u'Varun Kanade', u'H. Brendan McMahan', u'Brent Bryan']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Suggesting email view filters for triage and search
IJCAI'09: Proceedings of the 21st International Joint Conference on Artifical intelligence, Morgan Kaufmann Publishers Inc., San Francisco, CA, USA (2009), pp. 1414-1419
[u'Mark Dredze', u'Bill N. Schilit', u'Peter Norvig']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35521.html
notfound
=========================
Symmetric Splitting in the General Theory of Stable Models
In proc. Twenty-first International Joint Conference on Artificial Intelligence (IJCAI '09) (2009), pp. 797-803
[u'Paolo Ferraris', u'Joohyung Lee', u'Vladimir Lifschitz', u'Ravi Palla']
MachineIntelligence
Abstract: Splitting a logic program allows us to reduce the task of computing its stable models to similar tasks for smaller programs. This idea is extended here to the general theory of stable models that replaces traditional logic programs by arbitrary first-order sentences and distinguishes between intensional and extensional predicates. We discuss two kinds of splitting: a set of intensional predicates can be split into subsets, and a formula can be split into its conjunctive terms.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34923.html
notfound
=========================
The Difficulty of Training Deep Architectures and the Effect of Unsupervised Pre-Training
Twelfth International Conference on Artificial Intelligence and Statistics (AISTATS), JMLR Workshop and Conference Procedings (2009), pp. 153-160
[u'Dumitru Erhan', u'Pierre-Antoine Manzagol', u'Yoshua Bengio', u'Samy Bengio', u'Pascal Vincent']
MachineIntelligence
Abstract: Whereas theoretical work suggests that deep architectures might be more efficient at representing highly-varying functions, training deep architectures was unsuccessful until the recent advent of algorithms based on unsupervised pre-training. Even though these new algorithms have enabled training deep models, many questions remain as to the nature of this difficult learning problem. Answering these questions is important if learning in deep architectures is to be further improved. We attempt to shed some light on these questions through extensive simulations. The experiments confirm and clarify the advantage of unsupervised pre-training. They demonstrate the robustness of the training procedure with respect to the random initialization, the positive effect of pre-training in terms of optimization and its role as a regularizer. We empirically show the influence of pre-training with respect to architecture depth, model capacity, and number of training examples.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Tighter Bounds for Multi-Armed Bandits with Expert Advice
Proceedings of the 22nd Annual Conference on Learning Theory (COLT) (2009)
[u'H. Brendan McMahan', u'Matthew Streeter']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Using the Doubling Dimension to Analyze the Generalization of Learning Algorithms
JCSS (2009)
[u'Nader H. Bshouty', u'Yi Li', u'Philip M. Long']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
YouTube Scale, Large Vocabulary Video Annotation
Video Search and Mining (2009)
[u'Nick Morsillo', u'Chris Pal', u'Gideon Mann']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Bayesian Approach to Empirical Local Linearization for Robotics
International Conference on Robotics and Automation (ICRA2008)
[u'Jo-Anne Ting', u"Aaron D'Souza", u'Sethu Vijayakumar', u'Stefan Schaal']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub33027.html
notfound
=========================
A Discriminative Kernel-based Approach to Retrieval Images from Text Queries
IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 30 (2008), pp. 1371-1384
[u'David Grangier', u'Samy Bengio']
MachineIntelligence
Abstract: This paper proposes a discriminative model for the retrieval of images from text queries. Contrary to previous research, this approach does not rely on an intermediate annotation task. Instead, it addresses the retrieval problem directly, and learns from a criterion related to the final ranking performance of the retrieval model. Moreover, our learning procedure builds upon recent work on the online learning of kernel-based classifiers, yielding an efficient, scalable training algorithm. The experiments performed over stock photography data show the advantage of our discriminative ranking approach over state-of-the-art alternatives (e.g. our model yields $26.3\%$ average precision over the standard Corel benchmark, which should be compared to $22.0\%$, for the best alternative model evaluated).
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34393.html
notfound
=========================
A Distance Model for Rhythms
International Conference on Machine Learning (ICML) (2008)
[u'Jean-Francois Paiement', u'Yves Grandvalet', u'Samy Bengio', u'Douglas Eck']
MachineIntelligence
Abstract: Modeling long-term dependencies in time series has proved very difficult to achieve with traditional machine learning methods. This problem occurs when considering music data. In this paper, we introduce a model for rhythms based on the distributions of distances between subsequences. A specific implementation of the model when considering Hamming distances over a simple rhythm representation is described. The proposed model consistently outperforms a standard Hidden Markov Model in terms of conditional prediction accuracy on two different music databases.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34447.html
notfound
=========================
A Generative Model for Rhythms
Neural Information Processing Systems, Workshop on Brain, Music and Cognition (2008)
[u'Jean-Francois Paiement', u'Samy Bengio', u'Yves Grandvalet', u'Doug Eck']
MachineIntelligence
Abstract: Modeling music involves capturing long-term dependencies in time series, which has proved very difficult to achieve with traditional statistical methods. The same problem occurs when only considering rhythms. In this paper, we introduce a generative model for rhythms based on the distributions of distances between subsequences. A specific implementation of the model when considering Hamming distances over a simple rhythm representation is described. The proposed model consistently outperforms a standard Hidden Markov Model in terms of conditional prediction accuracy on two different music databases.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Machine Learning Framework for Spoken-Dialog Classification
Handbook on Speech Processing and Speech Communication, Part E: Speech recognition, Springer-Verlag, Heidelberg, Germany (2008)
[u'Corinna Cortes', u'Patrick Haffner', u'Mehryar Mohri']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Actively Learning Level-Sets of Composite Functions
ICML 2008: International Conference on Machine Learning
[u'Brent Bryan', u'Jeff Schneider']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Adaptive Martingale Boosting
NIPS (2008)
[u'Philip M. Long', u'Rocco A. Servedio']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
An Efficient Reduction of Ranking to Classification
Proceedings of The 21st Annual Conference on Learning Theory (COLT 2008), Springer, Heidelberg, Germany, Helsinki, Finland
[u'Nir Ailon', u'Mehryar Mohri']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Boosted Bayesian Network Classifier
Machine Learning Journal (2008)
[u'Yushi Jing', u'Vladimir Pavlovic', u'James M. Rehg']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34667.html
notfound
=========================
Confidence-Weighted Linear Classification
International Conference on Machine Learning (ICML) (2008)
[u'Mark Dredze', u'Koby Crammer', u'Fernando Pereira']
MachineIntelligence
Abstract: We introduce confidence-weighted linear classifiers, which add parameter confidence information to linear classifiers. Online learners in this setting update both classifier parameters and the estimate of their confidence. The particular online algorithms we study here maintain a Gaussian distribution over parameter vectors and update the mean and covariance of the distribution with each instance. Empirical evaluation on a range of NLP tasks show that our algorithm improves over other state of the art online and batch methods, learns faster in the online setting, and lends itself to better classifier combination after parallel training.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub33245.html
notfound
=========================
Delay Learning and Polychronization for Reservoir Computing
Neurocomputing, vol. 71 (2008), pp. 1143-1158
[u'Hlne Paugam-Moisy', u'Rgis Martinez', u'Samy Bengio']
MachineIntelligence
Abstract: We propose a multi-scale learning rule for spiking neuron networks, in the vein of the recently emerging field of reservoir computing. The reservoir is a network model of spiking neurons, with random topology and driven by STDP (Spike-Time-Dependent Plasticity), a temporal Hebbian unsupervised learning mode, biologically observed. The model is further driven by a supervised learning algorithm, based on a margin criterion, that effects the synaptic delays linking the network to the readout neurons, with classification as a goal task. The network processing and the resulting performance can be explained by the concept of polychronization, proposed by Izhikevich (2006, Neural Computation, 18,1), on physiological bases. The model emphasizes the computational capabilities of this concept.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Efficient projections onto the l1-ball for learning in high dimensions
ICML '08: Proceedings of the 25th international conference on Machine learning, ACM, New York, NY, USA (2008), pp. 272-279
[u'John Duchi', u'Shai Shalev-Shwartz', u'Yoram Singer', u'Tushar Chandra']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34912.html
notfound
=========================
Forecasting Web Page Views: Methods and Observations
JMLR, vol. 9(Oct) (2008), pp. 2217-2250
[u'Jia Li', u'Andrew Moore']
MachineIntelligence
Abstract: Web sites must forecast Web page views in order to plan computer resource allocation and estimate upcoming revenue and advertising growth. In this paper, we focus on extracting trends and seasonal patterns from page view series, two dominant factors in the variation of such series. We investigate the Holt-Winters procedure and a state space model for making relatively short-term prediction. It is found that Web page views exhibit strong impulsive changes occasionally. The impulses cause large prediction errors long after their occurrences. A method is developed to identify impulses and to alleviate their damage on prediction. We also develop a long-range trend and season extraction method, namely the Elastic Smooth Season Fitting (ESSF) algorithm, to compute scalable and smooth yearly seasons. ESSF derives the yearly season by minimizing the residual sum of squares under smoothness regularization, a quadratic optimization problem. It is shown that for long-term prediction, ESSF improves accuracy significantly over other methods that ignore the yearly seasonality.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Generalized Expectation Criteria for Semi-Supervised Learning of Conditional Random Fields
ACL (2008)
[u'Gideon Mann', u'Andrew McCallum']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Intelligent Email: Reply and Attachment Prediction
Proceedings of the 2008 International Conference on Intelligent User Interfaces
[u'Mark Dredze', u'Tova Brooks', u'Josh Carroll', u'Joshua Magarick', u'John Blitzer', u'Fernando Pereira']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Kernel Methods for Learning Languages
Theoretical Computer Science, vol. 405 (2008), pp. 223-236
[u'Leonid Kontorovich', u'Corinna Cortes', u'Mehryar Mohri']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub33429.html
notfound
=========================
Large Scale Content-Based Audio Retrieval from Text Queries
ACM International Conference on Multimedia Information Retrieval (MIR), ACM (2008)
[u'Gal Chechik', u'Eugene Ie', u'Martin Rehn', u'Samy Bengio', u'Richard F. Lyon']
MachineIntelligence
Abstract: In content-based audio retrieval, the goal is to find sound recordings (audio documents) based on their acoustic features. This content-based approach differs from retrieval approaches that index media files using metadata such as file names and user tags. In this paper, we propose a machine learning approach for retrieving sounds that is novel in that it (1) uses free-form text queries rather sound sample based queries, (2) searches by audio content rather than via textual meta data, and (3) can scale to very large number of audio documents and very rich query vocabulary. We handle generic sounds, including a wide variety of sound effects, animal vocalizations and natural scenes. We test a scalable approach based on a passive-aggressive model for image retrieval (PAMIR), and compare it to two state-of-the-art approaches; Gaussian mixture models (GMM) and support vector machines (SVM). We test our approach on two large real-world datasets: a collection of short sound effects, and a noisier and larger collection of user-contributed user-labeled recordings (25K files, 2000 terms vocabulary). We find that all three methods achieved very good retrieval performance. For instance, a positive document is retrieved in the first position of the ranking more than half the time, and on average there are more than 4 positive documents in the first 10 retrieved, for both datasets. PAMIR completed both training and retrieval of all data in less than 6 hours for both datasets, on a single machine. It was one to three orders of magnitude faster than the competing approaches. This approach should therefore scale to much larger datasets in the future.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Learning Bounds for Domain Adaptation
Advances in Neural Information Processing Systems 20, {MIT} Press, Cambridge, MA (2008)
[u'John Blitzer', u'Koby Crammer', u'Alex Kulesza', u'Fernando Pereira', u'Jennifer Wortman']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Learning Multiple Graphs for Document Recommendations
Proc. 17th International Conference on World Wide Web, ACM, Beijing (2008), pp. 141-150
[u'Ding Zhou', u'Shenghuo Zhu', u'Kai Yu', u'Xiaodan Song', u'Belle L. Tseng', u'Hongyuan Zha', u'C. Lee Giles']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Learning sequence kernels
Proceedings of IEEE International Workshop on Machine Learning for Signal Processing (2008)
[u'Corinna Cortes', u'Mehryar Mohri', u'Afshin Rostamizadeh']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34632.html
notfound
=========================
Learning to hash: forgiving hash functions and applications Learning to hash: forgiving hash functions and applications
Data Mining and Knowledge Discovery (2008)
[u'Shumeet Baluja', u'Michele Covell']
MachineIntelligence
Abstract: The problem of efficiently finding similar items in a large corpus of high-dimensional data points arises in many real-world tasks, such as music, image, and video retrieval. Beyond the scaling difficulties that arise with lookups in large data sets, the complexity in these domains is exacerbated by an imprecise definition of similarity. In this paper, we describe a method to learn a similarity function from only weakly labeled positive examples. Once learned, this similarity function is used as the basis of a hash function to severely constrain the number of points considered for each lookup. Tested on a large real-world audio dataset, only a tiny fraction of the points (~0.27%) are ever considered for each lookup. To increase efficiency, no comparisons in the original high-dimensional space of points are required. The performance far surpasses, in terms of both efficiency and accuracy, a state-of-the-art Locality-Sensitive-Hashing-based (LSH) technique for the same problem and data set.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Learning with weighted transducers
Proceedings of the Seventh International Workshop Finite-State Methods and Natural Language Processing (2008)
[u'Corinna Cortes', u'Mehryar Mohri']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Online Learning of Complex Prediction Problems Using Simultaneous Projections
J. Mach. Learn. Res., vol. 9 (2008), pp. 1399-1435
[u'Yonatan Amit', u'Shai Shalev-Shwartz', u'Yoram Singer']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Robust Submodular Observation Selection
Journal of Machine Learning Research (JMLR), vol. 9 (2008), pp. 2761-2801
[u'Andreas Krause', u'H. Brendan McMahan', u'Carlos Guestrin', u'Anupam Gupta']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Sample Selection Bias Correction Theory
Proceedings of The 19th International Conference on Algorithmic Learning Theory (ALT 2008), Springer, Heidelberg, Germany, Budapest, Hungary
[u'Corinna Cortes', u'Mehryar Mohri', u'Michael Riley', u'Afshin Rostamizadeh']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34406.html
notfound
=========================
Sequence Kernels for Predicting Protein Essentiality
Proceedings of ICML 2008
[u'Cyril Allauzen', u'Mehryar Mohri', u'Ameet Talwalkar']
MachineIntelligence
Abstract: The problem of identifying the minimal gene set required to sustain life is of crucial importance in understanding cellular mechanisms and designing therapeutic drugs. This work describes several kernel-based solutions for predicting essential genes that outperform existing models while using less training data. Our first solution is based on a semi-manually designed kernel derived from the Pfam database, which includes several Pfam domains. We then present novel and general {\em domain-based} sequence kernels that capture sequence similarity with respect to several domains made of large sets of protein sequences. We show how to deal with the large size of the problem -- several thousands of domains with individual domains sometimes containing thousand of sequences -- by representing and efficiently computing these kernels using automata. We report results of extensive experiments demonstrating that they compare favorably with the Pfam kernel in predicting protein essentiality, while requiring no manual tuning.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Stability Bounds for Non-i.i.d. Processes
Advances in Neural Information Processing Systems (NIPS 2007), MIT Press, Vancouver, Canada (2008)
[u'Mehryar Mohri', u'Afshin Rostamizadeh']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Stability of Transductive Regression Algorithms
Proceedings of the Twenty-fifth International Conference on Machine Learning (ICML 2008), Helsinki, Finland
[u'Corinna Cortes', u'Mehryar Mohri', u'Dmitry Pechyony', u'Ashish Rastogi']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Structured Learning with Approximate Inference
Advances in Neural Information Processing Systems 20, {MIT} Press, Cambridge, MA (2008)
[u'Alex Kulesza', u'Fernando Pereira']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub33014.html
notfound
=========================
Theoretical Advantages of Lenient Learners: An Evolutionary Game Theoretic Perspective
Journal of Machine Learning Research (2008)
[u'Liviu Panait', u'Karl Tuyls', u'Sean Luke']
MachineIntelligence
Abstract: This paper presents the dynamics of multiple learning agents from an evolutionary game theoretic perspective. We provide replicator dynamics models for cooperative coevolutionary algorithms and for traditional multiagent Q-learning, and we extend these differential equations to account for lenient learners: agents that forgive possible mismatched teammate actions that resulted in low rewards. We use these extended formal models to study the convergenceguarantees for these algorithms, and also to visualize the basins of attraction to optimal and suboptimal solutions in two benchmark coordination problems. We demonstrate that lenience provides learners with more accurate information about the benefits of performing their actions, resulting in higher likelihood of convergence to the globally optimal solution. In addition, our analysis indicates that the choice of learning algorithm has an insignificant impact on the overall performance of multiagent learning algorithms; rather, the performance of these algorithms depends primarily on the level of lenience that the agents exhibit to one another. Finally, our research supports the strength and generality of evolutionary game theory as a backbone for multiagent learning.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Web Page Language Identification Based on URLs
34th International Conference on Very Large Data Bases (VLDB), ACM Press, New York (2008), pp. 176-188
[u'Eda Baykan', u'Monika Henzinger', u'Ingmar Weber']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A General Regression Framework for Learning String-to-String Mappings
Predicting Structured Data, The MIT Press (2007)
[u'Corinna Cortes', u'Mehryar Mohri', u'Jason Weston']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub32978.html
notfound
=========================
A Generative Model for Distance Patterns in Music
NIPS Workshop on Music, Brain and Cognition (2007)
[u'Jean-Francois Paiement', u'Yves Grandvalet', u'Samy Bengio', u'Douglas Eck']
MachineIntelligence
Abstract: In order to cope for the difficult problem of long term dependencies in sequential data in general, and in musical data in particular, a generative model for distance patterns especially designed for music is introduced. A specific implementation of the model when considering Hamming distances over rhythms is described. The proposed model consistently outperforms a standard Hidden Markov Model in terms of conditional prediction accuracy over two different music databases.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Primal-Dual Perspective of Online Learning Algorithms
Machine Learning, vol. 69, no. 2-3 (2007), pp. 115-142
[u'Shai Shalev-Shwartz', u'Yoram Singer']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Automatic outlier detection: A Bayesian approach
International Conference on Robotics and Automation (ICRA 2007)
[u'Jo-Anne Ting', u"Aaron D'Souza", u'Stefan Schaal']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub32829.html
notfound
=========================
Biometric Person Authentication IS A Multiple Classifier Problem
7th International Workshop on Multiple Classifier Systems (2007)
[u'Samy Bengio', u'Johnny Marithoz']
MachineIntelligence
Abstract: Several papers have already shown the interest of using multiple classifiers in order to enhance the performance of biometric person authentication systems. In this paper, we would like to argue that the core task of Biometric Person Authentication is actually a multiple classifier problem as such: indeed, in order to reach state-of-the-art performance, we argue that all current systems , in one way or another, try to solve several tasks simultaneously and that without such joint training (or sharing), they would not succeed as well. We explain hereafter this perspective, and according to it, we propose some ways to take advantage of it, ranging from more parameter sharing to similarity learning.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub33317.html
notfound
=========================
Boosting the area under the ROC curve
NIPS (2007)
[u'Philip M. Long', u'Rocco A. Servedio']
MachineIntelligence
Abstract: We show that any weak ranker that can achieve an area under the ROC curve slightly better than 1/2 (which can be achieved by random guessing) can be efficiently boosted to achieve an area under the ROC curve arbitrarily close to 1. We further show that this boosting can be performed even in the presence of independent misclassification noise, given access to a noise-tolerant weak ranker.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub32733.html
notfound
=========================
Discriminative learning can succeed where generative learning fails
Information Processing Letters, vol. 103(4) (2007), pp. 131-135
[u'Philip M. Long', u'Rocco A. Servedio', u'Hans Ulrich Simon']
MachineIntelligence
Abstract: Generative algorithms for learning classifiers use training data to separately estimate a probability model for each class. New items are classified by comparing their probabilities under these models. In contrast, discriminative learning algorithms try to find classifiers that perform well on all the training data. We show that there is a learning problem that can be solved by a discriminative learning algorithm, but not by any generative learning algorithm. This statement is formalized using a framework inspired by previous work of Goldberg.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Euclidean Embedding of Co-occurrence Data
Journal of Machine Learning Research, vol. 8 (2007), pp. 2265-2295
[u'Amir Globerson', u'Gal Chechik', u'Fernando Pereira', u'Naftali Tishby']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Improving Embeddings by Flexible Exploitation of Side Information
Proceedings of the 20th International Joint Conference on Artificial Intelligence (IJCAI-07) (2007)
[u'Ali Ghodsi', u'Finnegan Southey', u'Dana Wilkinson']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Inferring Complex Agent Motions from Partial Trajectory Observations
Proceedings of the 20th International Joint Conference on Artificial Intelligence (IJCAI-07) (2007)
[u'Finnegan Southey', u'Wesley Loh', u'Dana Wilkinson']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Kernel Methods for Learning Languages
Theoretical Computer Science, vol. to appear (2007)
[u'Leonid Kontorovich', u'Corinna Cortes', u'Mehryar Mohri']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Lp Distance and Equivalence of Probabilistic Automata
International Journal of Foundations of Computer Science, vol. 18 (2007)
[u'Corinna Cortes', u'Mehryar Mohri', u'Ashish Rastogi']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Learning Forgiving Hash Functions: Algorithms and Large Scale Tests
IJCAI-07: International Joint Conference on Artificial Intelligence (2007)
[u'Shumeet Baluja', u'Michele Covell']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Learning and Inferring Transportation Routines
Artificial Intelligence, vol. 171 (2007), pp. 311-331
[u'Lin Liao', u'Don Patterson', u'Dieter Fox', u'Henry Kautz']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub32832.html
notfound
=========================
Learning the Inter-frame Distance for Discriminative Template-based Keyword Detection
Proceedings of the International Conference Interspeech-Eurospeech (2007)
[u'David Grangier', u'Samy Bengio']
MachineIntelligence
Abstract: This paper proposes a discriminative approach to template-based keyword detection. We introduce a method to learn the distance used to compare acoustic frames, a crucial element for template matching approaches. The proposed algorithm estimates the distance from data, with the objective to produce a detector maximizing the Area Under the receiver operating Curve (AUC), i.e. the standard evaluation measure for the keyword detection problem. The experiments performed over a large corpus, SpeechDatII, suggest that our model is effective compared to an HMM system, e.g. the proposed approach reaches 93.8\% of averaged AUC compared to 87.9\% for the HMM.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Learning to verify branching time properties
Formal Methods in System Design, vol. 31, no. 1 (2007), pp. 35-61
[u'Abhay Vardhan', u'Mahesh Viswanathan']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34771.html
notfound
=========================
On the Prospects for Building a Working Model of the Visual Cortex
Proceedings of AAAI-07, MIT Press, Cambridge, Massachusetts (2007), pp. 1597-1600
[u'Thomas Dean', u'Glenn Carroll', u'Richard Washington']
MachineIntelligence
Abstract: Human-level visual performance has remained largely beyond the reach of engineered systems despite decades of research and significant advances in problem formulation, algorithms and computing power. We posit that significant progress can be made by combining existing technologies from machine vision, insights from theoretical neuroscience and large-scale distributed computing. Such claims have been made before and so it is quite reasonable to ask what are the new ideas we bring to the table that might make a difference this time around. From a theoretical standpoint, our primary point of departure from current practice is our reliance on exploiting time in order to turn an otherwise intractable unsupervised problem into a locally semi-supervised, and plausibly tractable, learning problem. From a pragmatic perspective, our system architecture follows what we know of cortical neuroanatomy and provides a solid foundation for scalable hierarchical inference. This combination of features provides the framework for implementing a wide range of robust object-recognition capabilities.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
One-pass boosting
NIPS (2007)
[u'Zafer Barutcuoglu', u'Philip M. Long', u'Rocco A. Servedio']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Online learning of multiple tasks with a shared loss
JMLR, vol. 8 (2007), pp. 2233-2264
[u'Ofer Dekel', u'Philip M. Long', u'Yoram Singer']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Recursive Attribute Factoring
Advances in Neural Information Processing Systems 19 (2007)
[u'David Cohn', u'Deepak Verma', u'Karl Pfleger']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Selecting Observations Against Adversarial Objectives
Advances in Neural Information Processing Systems (NIPS 2007)
[u'Andreas Krause', u'H. Brendan McMahan', u'Carlos Guestrin', u'Anupam Gupta']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub32818.html
notfound
=========================
Studies in Lower Bounding Probability of Evidence using the Markov Inequality
UAI, Morgan Kaufmann (2007)
[u'Vibhav Gogate', u'Bozhena Bidyuk', u'Rina Dechter']
MachineIntelligence
Abstract: Computing the probability of evidence even with known error bounds is NP-hard. In this paper we address this hard problem by settling on an easier problem. We propose an approximation that provides high confidence lower bounds on probability of evidence. Our proposed approximation is a randomized importance sampling based scheme that uses the Markov inequality. However, a straight-forward application of the Markov inequality may lead to poor lower bounds. We, therefore propose several heuristic measures to improve its performance in practice. Empirical evaluation of our scheme with state-of-the-art lower bounding schemes reveals the promise of our approach.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Supervised Learning of Semantic Classes for Image Annotation and Retrieval
IEEE Transactions on Pattern Analysis and Machine Intelligence (2007), pp. 394-410
[u'Gustavo Carneiro', u'Antoni B. Chan', u'Pedro J. Moreno', u'Nuno Vasconcelos']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub33029.html
notfound
=========================
The Need for Open Source Software in Machine Learning
Journal of Machine Learning Research, vol. 8 (2007), pp. 2443-2466
[u'Soren Sonnenburg', u'Mikio L. Braun', u'Cheng Soon Ong', u'Samy Bengio', u'Leon Bottou', u'Geoff Holmes', u'Yann LeCun', u'Klaus-Robert Mueller', u'Fernando Pereira', u'Carl-Edward Rasmussen', u'Gunnar Raetsch', u'Bernhard Schoelkopf', u'Alexander Smola', u'Pascal Vincent', u'Jason Weston', u'Robert C. Williamson']
MachineIntelligence
Abstract: Open source tools have recently reached a level of maturity which makes them suitable for building large-scale real-world systems. At the same time, the field of machine learning has developed a large body of powerful learning algorithms for diverse applications. However, the true potential of these methods is not utilized, since existing implementations are not openly shared, resulting in software with low usability, and weak interoperability. We argue that this situation can be significantly improved by increasing incentives for researchers to publish their software under an open source model. Additionally, we outline the problems authors are faced with when trying to publish algorithmic implementations of machine learning methods. We believe that a resource of peer reviewed software accompanied by short articles would be highly valuable to both the machine learning and the general scientific community.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36954.html
notfound
=========================
The War Against Spam: A report from the front line
NIPS 2007 Workshop on Machine Learning in Adversarial Environments for Computer Security
[u'Brad Taylor', u'Dan Fingal', u'Douglas Aberdeen']
MachineIntelligence
Abstract: Fighting spam is a success story of real-world machine learning. Despite the occasional spam that does reach our inboxes, the overwhelming majority of spam and there is a lot of it is positively identified. At the same time, the rarity with which users feel the need to check their spam box for false positives demonstrates a high precision of classification. This paper is an overview of Googles approach to ghting email abuse with machine learning, and a discussion of some lessons learned.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub32579.html
notfound
=========================
Theoretical Advantages of Lenient Learners in Multiagent Systems
Proceedings of the Sixth International Conference on Autonomous Agents and Multi-agent Systems (AAMAS-07), ACM (2007)
[u'Liviu Panait', u'Karl Tuyls']
MachineIntelligence
Abstract: This paper presents the dynamics of multiple reinforcement learning agents from an Evolutionary Game Theoretic perspective. We provide a Replicator Dynamics model for traditional multiagent Q-learning, and we then extend these differential equations to account for lenient learners: agents that forgive possible mistakes of their teammates that resulted in lower rewards. We use this extended formal model to visualize the basins of attraction of both traditional and lenient multiagent Q-learners in two benchmark coordination problems. The results indicate that lenience provides learners with more accurate estimates for the utility of their actions, resulting in higher likelihood of convergence to the globally optimal solution. In addition, our research supports the strength of EGT as a backbone for multiagent reinforcement learning.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Training Conditional Random Fields using Virtual Evidence Boosting
Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI) (2007)
[u'Lin Liao', u'Tanzeem Choudhury', u'Dieter Fox', u'Henry Kautz']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Machine Learning Framework for Spoken-Dialog Classification
Handbook on Speech Processing and Speech Communication, Part E: Speech recognition, Springer-Verlag, Heidelberg, Germany (2007)
[u'Corinna Cortes', u'Patrick Haffner', u'Mehryar Mohri']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
An Alternative Ranking Problem for Search Engines
Proceedings of the 6th Workshop on Experimental Algorithms (WEA 2007), Springer-Verlag, Heidelberg, Germany, Rome, Italy, pp. 1-21
[u'Corinna Cortes', u'Mehryar Mohri', u'Ashish Rastogi']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Learning Languages with Rational Kernels
Proceedings of The 20th Annual Conference on Computational Learning Theory (COLT 2007), Springer, Heidelberg, Germany, San Diego, California
[u'Corinna Cortes', u'Leonid Kontorovich', u'Mehryar Mohri']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Magnitude-Preserving Ranking Algorithms
Proceedings of the Twenty-fourth International Conference on Machine Learning (ICML 2007), Oregon State University, Corvallis, OR
[u'Corinna Cortes', u'Mehryar Mohri', u'Ashish Rastogi']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
On Transductive Regression
Advances in Neural Information Processing Systems (NIPS 2006), MIT Press, Vancouver, Canada (2007)
[u'Corinna Cortes', u'Mehryar Mohri']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Attribute-efficient learning of linear threshold functions under unconcentrated distributions
NIPS (2006)
[u'Philip M. Long', u'Rocco A. Servedio']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Bayesian Regression with Input Noise for High-Dimensional Data
In Proceedings of the 23rd International Conference on Machine Learning, ACM Press (2006)
[u'Jo-Anne Ting', u"Aaron D'Souza", u'Stefan Schaal']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Building Personal Maps from GPS Data
Annals of the New York Academy of Sciences, vol. 1093 (2006), pp. 249-265
[u'Lin Liao', u'Don Patterson', u'Dieter Fox', u'Henry Kautz']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Clustering graphs by weighted substructure mining
Proceedings of the 23rd international conference on Machine learning, ACM (2006), pp. 953-960
[u'Koji Tsuda', u'Taku Kudo']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Data Fusion and Multicue Data Matching by Diffusion Maps
IEEE Trans. Pattern Anal. Mach. Intell., vol. 28 (2006), pp. 1784-1797
[u'Stphane Lafon', u'Yosi Keller', u'Ronald R. Coifman']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Dependency trees in sub-linear time and bounded memory
VLDB J., vol. 15 (2006), pp. 250-262
[u'Dan Pelleg', u'Andrew W. Moore']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Efficient Learning of Label Ranking by Soft Projections onto Polyhedra
Journal of Machine Learning Research (2006)
[u'S. Shalev-Shwartz', u'Y. Singer']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Extracting Places and Activities from GPS Traces Using Hierarchical Conditional Random Fields
International Journal of Robotics Research, vol. 26 (2006), pp. 119-134
[u'Lin Liao', u'Dieter Fox', u'Henry Kautz']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34743.html
notfound
=========================
Learning Invariant Features Using Inertial Priors
Annals of Mathematics and Artificial Intelligence, vol. 47 (2006), pp. 223-250
[u'Thomas Dean']
MachineIntelligence
Abstract: We address the technical challenges involved in combining key features from several theories of the visual cortex in a single coherent model. The resulting model is a hierarchical Bayesian network factored into modular component networks embedding variable-order Markov models. Each component network has an associated receptive field corresponding to components residing in the level directly below it in the hierarchy. The variable-order Markov models account for features that are invariant to naturally occurring transformations in their inputs. These invariant features give rise to increasingly stable, persistent representations as we ascend the hierarchy. The receptive fields of proximate components on the same level overlap to restore selectivity that might otherwise be lost to invariance.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Online Learning meets Optimization in the Dual
Proceedings of the Nineteenth Annual Conference on Computational Learning Theory (2006)
[u'S. Shalev-Shwartz', u'Y. Singer']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Online Multiclass Learning by Interclass Hypothesis Sharing
Proceedings of the 23rd International Conference on Machine Learning (2006)
[u'Michael Fink', u'Shai Shalev-Shwartz', u'Yoram Singer', u'Shimon Ullman']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Online Passive Aggressive Algorithms
Journal of Machine Learning Research, vol. 7 (2006)
[u'K. Crammer', u'O. Dekel', u'J. Keshet', u'S. Shalev-Shwartz', u'Y. Singer']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
PAC Learning Mixtures of Gaussians with No Separation Assumption
Proc. 19th Annual Conference on Learning Theory (COLT) (2006)
[u'Jon Feldman', u"Ryan O'Donnell", u'Rocco A. Servedio']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Predicting Electricity Distribution Feeder Failures Using Machine Learning Susceptibility Analysis
IAAI (2006)
[u'Philip Gross', u'Albert Boulanger', u'Marta Arias', u'David L. Waltz', u'Philip M. Long', u'Charles Lawson', u'Roger Anderson', u'Matthew Koenig', u'Mark Mastrocinque', u'William Fairechio', u'John A. Johnson', u'Serena Lee', u'Frank Doherty', u'Arthur Kressner']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Reasoning about Partially Observed Actions
AAAI (2006)
[u'Megan Nance', u'Adam Vogel', u'Eyal Amir']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34770.html
notfound
=========================
Scalable Inference in Hierarchical Generative Models
Proceedings of the Ninth International Symposium on Artificial Intelligence and Mathematics (2006)
[u'Thomas Dean']
MachineIntelligence
Abstract: We address the technical challenges involved in combining key features from several theories of the visual cortex in a single coherent model. The resulting model is a hierarchical Bayesian network factored into modular component networks embedding variable-order Markov models. Each component network has an associated receptive ?eld corresponding to components residing in the level directly below it in the hierarchy. The variable-order Markov models account for features that are invariant to naturally occurring transformations in their inputs. These invariant features give rise to increasingly stable, persistent representations as we ascend the hierarchy. The receptive ?elds of proximate components on the same level overlap to restore selectivity that might otherwise be lost to invariance.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Learning Linearly Separable Languages
Proceedings of The 17th International Conference on Algorithmic Learning Theory (ALT 2006), Springer, Heidelberg, Germany
[u'Leonid Kontorovich', u'Corinna Cortes', u'Mehryar Mohri']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34772.html
notfound
=========================
A Computational Model of the Cerebral Cortex
Proceedings of AAAI-05, MIT Press, Cambridge, Massachusetts (2005), pp. 938-943
[u'Thomas Dean']
MachineIntelligence
Abstract: Our current understanding of the primate cerebral cortex (neocortex) and in particular the posterior, sensory association cortex has matured to a point where it is possible to develop a family of graphical models that capture the structure, scale and power of the neocortex for purposes of associative recall, sequence prediction and pattern completion among other functions. Implementing such models using readily available computing clusters is now within the grasp of many labs and would provide scientists with the opportunity to experiment with both hard-wired connection schemes and structure-learning algorithms inspired by animal learning and developmental studies. While neural circuits involving structures external to the neocortex such as the thalamic nuclei are less well understood, the availability of a computational model on which to test hypotheses would likely accelerate our understanding of these circuits. Furthermore, the existence of an agreed-upon cortical substrate would not only facilitate our understanding of the brain but enable researchers to combine lessons learned from biology with state-of-the-art graphical-model and machine-learning techniques to design hybrid systems that combine the best of biological and traditional computing approaches.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A General Regression Technique for Learning Transductions
Proceedings of the Twenty-Second International Conference on Machine Learning (ICML 2005), Bonn, Germany
[u'Corinna Cortes', u'Mehryar Mohri', u'Jason Weston']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A New Perspective on an Old Perceptron Algorithm
Proceedings of the Eighteenth Annual Conference on Computational Learning Theory (2005)
[u'S. Shalev-Shwartz', u'Y. Singer']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Data-Driven Online to Batch Conversions
NIPS (2005)
[u'Ofer Dekel', u'Yoram Singer']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Efficient discriminative learning of Bayesian network classifier
Proc. International Conference on Machine Learning (Best student paper) (2005)
[u'Yushi Jing', u'Vladimir Pavlovic', u'James M. Rehg']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Loss Bounds for Online Category Ranking
Proceedings of the Eighteenth Annual Conference on Computational Learning Theory (2005)
[u'K. Crammer', u'Y. Singer']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Margin-Based Ranking Meets Boosting in the Middle
Proc. of the 18th Annual Conference on Computational Learning Theory (COLT 2005), Springer, Heidelberg, Germany, pp. 63-78
[u'Cynthia Rudin', u'Corinna Cortes', u'Mehryar Mohri', u'Robert E. Schapire']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Online Multiclass Learning with k-Way Limited Feedback and an Application to Utterance Classification
Machine Learning, vol. 60 (2005)
[u'Hiyan Alshawi']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Online Ranking by Projecting
Neural Computation, vol. 17 (2005)
[u'K. Crammer', u'Y. Singer']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Phoneme Alignment Based on Discriminative Learning
Interspeech (2005)
[u'J. Keshet', u'S. Shalev-Shwartz', u'Y. Singer', u'D. Chazan']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Semi-Supervised Self-Training of Object Detection Models
WACV/MOTION (2005), pp. 29-36
[u'Chuck Rosenberg', u'Martial Hebert', u'Henry Schneiderman']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Special Review Issue
Artif. Intell., vol. 169 (2005), pp. 103-212
[u'Donald Perlis', u'Peter Norvig']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
The Forgetron: A Kernel-Based Perceptron on a Fixed Budget
NIPS (2005)
[u'Ofer Dekel', u'Shai Shalev-Shwartz', u'Yoram Singer']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Comparison of Classifiers for Detecting Emotion from Speech
Proceedings of the International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2005), Philadelphia, Pennsylvania
[u'Izhak Shafran', u'Mehryar Mohri']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Confidence Intervals for the Area under the ROC Curve
Advances in Neural Information Processing Systems (NIPS 2004), MIT Press, Vancouver, Canada (2005)
[u'Corinna Cortes', u'Mehryar Mohri']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Margin-Based Ranking Meets Boosting in the Middle
Proceedings of The 18th Annual Conference on Computational Learning Theory (COLT 2005), Springer, Heidelberg, Germany, Bertinoro, Italy, pp. 63-78
[u'Cynthia Rudin', u'Corinna Cortes', u'Mehryar Mohri', u'Robert E. Schapire']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Moment Kernels for Regular Distributions
Machine Learning, vol. 60 (2005), pp. 117-134
[u'Corinna Cortes', u'Mehryar Mohri']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Multi-Armed Bandit Algorithms and Empirical Evaluation
Proceedings of the 16th European Conference on Machine Learning (ECML 2005), Springer, Heidelberg, Germany, Porto, Portugal
[u'Joann\\`es Vermorel', u'Mehryar Mohri']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Distribution Kernels Based on Moments of Counts
Proceedings of the Twenty-First International Conference on Machine Learning (ICML 2004), Banff, Alberta, Canada
[u'Corinna Cortes', u'Mehryar Mohri']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Rational Kernels: Theory and Algorithms
Journal of Machine Learning Research (JMLR), vol. 5 (2004), pp. 1035-1062
[u'Corinna Cortes', u'Patrick Haffner', u'Mehryar Mohri']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Retrospective on "Paradigms of AI Programming"
Vivek (A Quarterly in Artificial Intelligence), vol. 15 (2003)
[u'Peter Norvig']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Artificial Intelligence: A Modern Approach
Prentice Hall (2002)
[u'Stuart Russell', u'Peter Norvig']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Intelligent Help Systems for UNIX
Springer (2001)
[u'Stephen J. Hegner', u'Paul McKevitt', u'Peter Norvig', u'Robert Wilensky']
MachineIntelligence
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/MachinePerception.html
found
http://research.google.com/pubs/pub44278.html
notfound
=========================
A Subjective Study for the Design of Multi-resolution ABR Video Streams with the VP9 Codec
SPIE Electronic Imaging, Human Visual Perception (2016) (to appear)
[u'Chao Chen', u'Sasi Inguva', u'Andrew Rankin', u'Anil Kokaram']
MachinePerception
Abstract: Adaptive bitrate (ABR) streaming is one enabling technology for video streaming over modern throughput-varying communication networks. A widely used ABR streaming method is to adapt the video bitrate to channel throughput by dynamically changing the video resolution. Since videos have different rate-quality performances at different resolutions, such ABR strategy can achieve better rate-quality trade-off than single resolution ABR streaming. The key problem for resolution switched ABR is to work out the bitrate appropriate at each resolution. In this paper, we investigate optimal strategies to estimate this bitrate using both quantitative and subjective quality assessment. We use the design of 2K and 4K bitrates as an example of the performance of this strategy. We introduce strategies for selecting an appropriate corpus for subjective assessment and find that at this high resolution there is good agreement between quantitative and subjective analysis.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43989.html
notfound
=========================
Robust Estimation of Reverberation Time Using Polynomial Roots
AES 60th Conference on Dereverberation and Reverberation of Audio, Music, and Speech, Google Ireland Ltd. (2016) (to appear)
[u'Ian Kelly', u'Francis Boland', u'Jan Skoglund']
MachinePerception
Abstract: This paper further investigates previous findings that coefficients of acoustic responses can be modelled as random polynomials with certain constraints applied. In the case of room impulse responses, the median value of their clustered roots has been shown to be directly related to the reverberation time of the room. In this paper we examine the frequency dependency of reverberation time and we also demonstrate the methods robustness to truncation of impulse responses.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43280.html
notfound
=========================
A 6 W per Channel Analog Biomimetic Cochlear Implant Processor Filterbank Architecture With Across Channels AGC
IEEE Transactions on Biomedical Circuits and Systems, vol. 9 (2015), pp. 72-86
[u'Guang Wang', u'Richard F. Lyon', u'Emmanuel M. Drakakis']
MachinePerception
Abstract: A new analog cochlear implant processor filterbank architecture of increased biofidelity, enhanced across-channel contrast and very low power consumption has been designed and prototyped. Each channel implements a biomimetic, asymmetric bandpass-like One-Zero-Gammatone-Filter (OZGF) transfer function, using class-AB log-domain techniques. Each channel's quality factor and suppression are controlled by means of a new low power Automatic Gain Control (AGC) scheme which is coupled across the neighboring channels and emulates lateral inhibition (LI) phenomena in the auditory system. Detailed measurements from a five-channel silicon IC prototype fabricated in a 0.35 m AMS technology confirm the operation of the coupled AGC scheme and its ability to enhance contrast among channel outputs. The prototype is characterized by an input dynamic range of 92 dB while consuming only 28 W of power in total ~6 W per channel) under a 1.8 V power supply. The architecture is well-suited for fully-implantable cochlear implants.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43884.html
notfound
=========================
A Computational Approach for Obstruction-Free Photography
ACM Transactions on Graphics, vol. 34, no. 4 (Proc. SIGGRAPH) (2015)
[u'Tianfan Xue', u'Michael Rubinstein', u'Ce Liu', u'William T. Freeman']
MachinePerception
Abstract: We present a unified computational approach for taking photos through reflecting or occluding elements such as windows and fences. Rather than capturing a single image, we instruct the user to take a short image sequence while slightly moving the camera. Differences that often exist in the relative position of the background and the obstructing elements from the camera allow us to separate them based on their motions, and to recover the desired background scene as if the visual obstructions were not there. We show results on controlled experiments and many real and practical scenarios, including shooting through reflections, fences, and raindrop-covered windows.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A World of Movement
Scientific American, vol. 312, no. 1 (2015)
[u'Fredo Durand', u'William T. Freeman', u'Michael Rubinstein']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43993.html
found
=========================
An Exploration of Parameter Redundancy in Deep Networks with Circulant Projections
International Conference on Computer Vision (ICCV) (2015)
[u'Yu Cheng', u'Felix X. Yu', u'Rogerio Feris', u'Sanjiv Kumar', u'Shih-Fu Chang']
MachinePerception
Abstract: We explore the redundancy of parameters in deep neural networks by replacing the conventional linear projection in fully-connected layers with the circulant projection. The circulant structure substantially reduces memory footprint and enables the use of the Fast Fourier Transform to speed up the computation. Considering a fully-connected neural network layer with d input nodes, and d output nodes, this method improves the time complexity from O(d^2) to O(dlogd) and space complexity from O(d^2) to O(d). The space savings are particularly important for modern deep convolutional neural network architectures, where fully-connected layers typically contain more than 90% of the network parameters. We further show that the gradient computation and optimization of the circulant projections can be performed very efficiently. Our experiments on three standard datasets show that the proposed approach achieves this significant gain in storage and efficiency with minimal increase in error rate compared to neural networks with unstructured projections.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43841.html
notfound
=========================
Best-Buddies Similarity for Robust Template Matching
IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) (2015)
[u'Tali Dekel', u'Shaul Oron', u'Michael Rubinstein', u'Shai Avidan', u'William T. Freeman']
MachinePerception
Abstract: We propose a novel method for template matching in unconstrained environments. Its essence is the Best Buddies Similarity (BBS), a useful, robust, and parameter-free similarity measure between two sets of points. BBS is based on a count of Best Buddies Pairs (BBPs)pairs of points in which each one is the nearest neighbor of the other. BBS has several key features that make it robust against complex geometric deformations and high levels of outliers, such as those arising from background clutter and occlusions. We study these properties, provide a statistical analysis that justifies them, and demonstrate the consistent success of BBS on a challenging real-world dataset.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43793.html
found
=========================
Beyond Short Snippets: Deep Networks for Video Classification
Computer Vision and Pattern Recognition (2015)
[u'Joe Yue-Hei Ng', u'Matthew Hausknecht', u'Sudheendra Vijayanarasimhan', u'Oriol Vinyals', u'Rajat Monga', u'George Toderici']
MachinePerception
Abstract: Convolutional neural networks (CNNs) have been extensively applied for image recognition problems giving state-of-the-art results on recognition, detection, segmentation and retrieval. In this work we propose and evaluate several deep neural network architectures to combine image information across a video over longer time periods than previously attempted. We propose two methods capable of handling full length videos. The first method explores various convolutional temporal feature pooling architectures, examining the various design choices which need to be made when adapting a CNN for this task. The second proposed method explicitly models the video as an ordered sequence of frames. For this purpose we employ a recurrent neural network that uses Long Short-Term Memory (LSTM) cells which are connected to the output of the underlying CNN. Our best networks exhibit significant performance improvements over previously published results on the Sports 1 million dataset (73.1% vs. 60.9%) and the UCF-101 datasets with (88.6% vs. 88.0%) and without additional optical flow information (82.6% vs. 72.8%).
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44004.html
notfound
=========================
Convolutional Color Constancy
ICCV (2015) (to appear)
[u'Jonathan T Barron']
MachinePerception
Abstract: Color constancy is the problem of inferring the color of the light that illuminated a scene, usually so that the illumination color can be removed. Because this problem is underconstrained, it is often solved by modeling the statistical regularities of the colors of natural objects and illumination. In contrast, in this paper we reformulate the problem of color constancy as a 2D spatial localization task in a log-chrominance space, thereby allowing us to apply techniques from object detection and structured prediction to the color constancy problem. By directly learning how to discriminate between correctly white-balanced images and poorly white-balanced images, our model is able to improve performance on standard benchmarks by nearly 40%.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
DETECTION AND SUPPRESSION OF KEYBOARD TRANSIENT NOISE IN AUDIO STREAMS WITH AUXILIARY KEYBED MICROPHONE
ICASSP 2015, IEEE
[u'Simon Godsill', u'Herbert Buchner', u'Jan Skoglund']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
DIRECT-TO-REVERBERANT RATIO ESTIMATION USING A NULL-STEERED BEAMFORMER
ICASSP 2015, IEEE
[u'James Eaton', u'Alastair Moore', u'Patrick Naylor', u'Jan Skoglund']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43137.html
notfound
=========================
Egocentric Field-of-View Localization Using First-Person Point-of-View Devices
Proceedings of Winter Conference on Applications of Computer Vision (WACV), IEEE (2015)
[u'Vinay Bettadapura', u'Irfan Essa', u'Caroline Pantofaru']
MachinePerception
Abstract: We present a technique that uses images, videos and sensor data taken from first-person point-of-view devices to perform egocentric field-of-view (FOV) localization. We define egocentric FOV localization as capturing the visual information from a persons field-of-view in a given environment and transferring this information onto a reference corpus of images and videos of the same space, hence determining what a person is attending to. Our method matches images and video taken from the first-person perspective with the reference corpus and refines the results using the first-persons head orientation information obtained using the device sensors. We demonstrate single and multi-user egocentric FOV localization in different indoor and outdoor environments with applications in augmented reality, event understanding and studying social interactions.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44003.html
notfound
=========================
Fast Bilateral-Space Stereo for Synthetic Defocus
CVPR (2015)
[u'Jonathan T Barron', u'Andrew Adams', u'YiChang Shih', u'Carlos Hernndez']
MachinePerception
Abstract: Given a stereo pair it is possible to recover a depth map and use that depth to render a synthetically defocused image. Though stereo algorithms are well-studied, rarely are those algorithms considered solely in the context of producing these defocused renderings. In this paper we present a technique for efficiently producing disparity maps using a novel optimization framework in which inference is performed in "bilateral-space". Our approach produces higher-quality "defocus" results than other stereo algorithms while also being 10-100 times faster than comparable techniques.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43992.html
found
=========================
Fast Orthogonal Projection Based on Kronecker Product
International Conference on Computer Vision (ICCV) (2015)
[u'Xu Zhang', u'Felix X. Yu', u'Ruiqi Guo', u'Sanjiv Kumar', u'Shengjin Wang', u'Shih-Fu Chang']
MachinePerception
Abstract: We propose a family of structured matrices to speed up orthogonal projections for high-dimensional data commonly seen in computer vision applications. In this, a structured matrix is formed by the Kronecker product of a series of smaller orthogonal matrices. This achieves O(dlogd) computational complexity and O(logd) space complexity for d-dimensional data, a drastic improvement over the standard unstructured projections whose computational and space complexities are both O(d^2). We also introduce an efficient learning procedure for optimizing such matrices in a data dependent fashion. We demonstrate the significant advantages of the proposed approach in solving the approximate nearest neighbor (ANN) image search problem with both binary embedding and quantization. Comprehensive experiments show that the proposed approach can achieve similar or better accuracy as the existing state-of-the-art but with significantly less time and memory.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43022.html
found
=========================
Going Deeper with Convolutions
CVPR 2015
[u'Christian Szegedy', u'Wei Liu', u'Yangqing Jia', u'Pierre Sermanet', u'Scott Reed', u'Dragomir Anguelov', u'Dumitru Erhan', u'Vincent Vanhoucke', u'Andrew Rabinovich']
MachinePerception
Abstract: We propose a deep convolutional neural network architecture codenamed Inception that achieves the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC2014). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. By a carefully crafted design, we increased the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation of this architecture, GoogLeNet, a 22 layers deep network, was used to assess its quality in the context of object detection and classification.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43467.html
found
=========================
IsoMatch: Creating Informative Grid Layouts
Computer Graphics Forum (Proceedings of Eurographics), vol. 34(2) (2015) (to appear)
[u'Ohad Fried', u'Stephen DiVerdi', u'Maciej Halber', u'Elena Sizikova', u'Adam Finkelstein']
MachinePerception
Abstract: Collections of objects such as images are often presented visually in a grid because it is a compact representation that lends itself well for search and exploration. Most grid layouts are sorted using very basic criteria, such as date or filename. In this work we present a method to arrange collections of objects respecting an arbitrary distance measure. Pairwise distances are preserved as much as possible, while still producing the specific target arrangement which may be a 2D grid, the surface of a sphere, a hierarchy, or any other shape. We show that our method can be used for infographics, collection exploration, summarization, data visualization, and even for solving problems such as where to seat family members at a wedding. We present a fast algorithm that can work on large collections and quantitatively evaluate how well distances are preserved.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Learning semantic relationships for better action retrieval in images
CVPR (2015)
[u'Vignesh Ramanathan', u'Congcong Li', u'Jia Deng', u'Wei Han', u'Zhen Li', u'Kunlong Gu', u'Yang Song', u'Samy Bengio', u'Chuck Rosenberg', u'Li Fei-Fei']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43794.html
notfound
=========================
Ontological Supervision for Fine Grained Classification of Street View Storefronts
CVPR15 (2015)
[u'Yair Movshovitz-Attias', u'Qian Yu', u'Martin C. Stumpe', u'Vinay Shet', u'Sacha Arnoud', u'Liron Yatziv']
MachinePerception
Abstract: Modern search engines receive large numbers of business related, local aware queries. Such queries are best answered using accurate, up-to-date, business listings, that contain representations of business categories. Creating such listings is a challenging task as businesses often change hands or close down. For businesses with street side locations one can leverage the abundance of street level imagery, such as Google Street View, to automate the process. However, while data is abundant, labeled data is not; the limiting factor is creation of large scale labeled training data. In this work, we utilize an ontology of geographical concepts to automatically propagate business category information and create a large, multi label, training dataset for fine grained storefront classification. Our learner, which is based on the GoogLeNet/Inception Deep Convolutional Network architecture and classifies 208 categories, achieves human level accuracy.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43475.html
notfound
=========================
Palette-based Photo Recoloring
Transactions on Graphics (Proceedings of SIGGRAPH) (2015) (to appear)
[u'Huiwen Chang', u'Ohad Fried', u'Yiming Liu', u'Stephen DiVerdi', u'Adam Finkelstein']
MachinePerception
Abstract: Color manipulation is a key process in photo enhancement, and professional image editing suites incorporate an array of tools to support it. Some of these tools are easy to understand but offer a limited range of expressiveness. Other more powerful tools are difficult and time consuming to use, and inscrutable to novices. Researchers have described a variety of more sophisticated methods but these are typically not interactive, which is crucial for creative exploration. This paper introduces a simple, intuitive and interactive tool that allows non-experts to recolor an image colors by editing a color palette. This system is comprised of several components: a GUI that is easy to learn and understand, a new efficient algorithm for creating a color palette from an image, and a new efficient color transfer algorithm that recolors the image based on a user-modified palette. We evaluate our approach via a user study, showing that it is faster and easier to use than two alternatives. It also shows that untrained users can quickly achieve results comparable to those of experts using professional software.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43849.html
notfound
=========================
Pedestrian Detection with a Large-Field-Of-View Deep Network
Proceedings of ICRA 2015
[u'Anelia Angelova', u'Alex Krizhevsky', u'Vincent Vanhoucke']
MachinePerception
Abstract: Pedestrian detection is of crucial importance to autonomous driving applications. Methods based on deep learning have shown significant improvements in accuracy, which makes them particularly suitable for applications, such as pedestrian detection, where reducing miss rate is very important. Although they are accurate, their runtime has been at best in seconds per image, which makes them not practical for onboard applications. We present here a Large-Field-Of-View (LFOV) deep network for pedestrian detection, that can achieve high accuracy and is designed to make deep networks work faster for detection problems. The idea of the proposed Large-Field-of-View deep network is to learn to make classification decisions simultaneously and accurately at multiple locations. The LFOV network processes larger image areas at much faster speeds than typical deep networks have been able to do, and can intrinsically reuse computations. Our pedestrian detection solution, which is a combination of a LFOV network and a standard deep network, works at 280 ms per image on GPU and achieves 35.85 average miss rate on the Caltech Pedestrian Detection Benchmark.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44002.html
notfound
=========================
Pose Embeddings: A Deep Architecture for Learning to Match Human Poses
arXiv (2015)
[u'Greg Mori', u'Caroline Pantofaru', u'Nisarg Kothari', u'Thomas Leung', u'George Toderici', u'Alexander Toshev', u'Weilong Yang']
MachinePerception
Abstract: We present a method for learning an embedding that places images of humans in similar poses nearby. This embedding can be used as a direct method of comparing images based on human pose, avoiding potential challenges of estimating body joint positions. Pose embedding learning is formulated under a triplet-based distance criterion. A deep architecture is used to allow learning of a representation capable of making distinctions between different poses. Experiments on human pose matching and retrieval from video data demonstrate the potential of the method.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Probabilistic Label Relation Graphs with Ising Models
International Conference on Computer Vision (2015) (to appear)
[u'Nan Ding', u'Jia Deng', u'Kevin Murphy', u'Hartmut Neven']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43875.html
notfound
=========================
Real-Time Grasp Detection Using Convolutional Neural Networks
International Conference on Robotics and Automation (ICRA), IEEE (2015)
[u'Joseph Redmon', u'Anelia Angelova']
MachinePerception
Abstract: We present an accurate, real-time approach to robotic grasp detection based on convolutional neural networks. Our network performs single-stage regression to graspable bounding boxes without using standard sliding window or region proposal techniques. The model outperforms state-of- the-art approaches by 14 percentage points and runs at 13 frames per second on a GPU. Our network can simultaneously perform classification so that in a single step it recognizes the object and finds a good grasp rectangle. A modification to this model predicts multiple grasps per object by using a locally constrained prediction mechanism. The locally constrained model performs significantly better, especially on objects that can be grasped in a variety of ways.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43850.html
notfound
=========================
Real-Time Pedestrian Detection With Deep Network Cascades
Proceedings of BMVC 2015 (to appear)
[u'Anelia Angelova', u'Alex Krizhevsky', u'Vincent Vanhoucke', u'Abhijit Ogale', u'Dave Ferguson']
MachinePerception
Abstract: We present a new real-time approach to object detection that exploits the efficiency of cascade classifiers with the accuracy of deep neural networks. Deep networks have been shown to excel at classification tasks, and their ability to operate on raw pixel input without the need to design special features is very appealing. However, deep nets are notoriously slow at inference time. In this paper, we propose an approach that cascades deep nets and fast features, that is both extremely fast and extremely accurate. We apply it to the challenging task of pedestrian detection. Our algorithm runs in real-time at 15 frames per second. The resulting approach achieves a 26.2% average miss rate on the Caltech Pedestrian detection benchmark, which is competitive with the very best reported results. It is the first work we are aware of that achieves extremely high accuracy while running in real-time.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Refer-to-as Relations as Semantic Knowledge
AAAI Conference on Artificial Intelligence (2015)
[u'Song Feng', u'Sujith Ravi', u'Ravi Kumar', u'Polina Kuznetsova', u'Wei Liu', u'Alex Berg', u'Tamara Berg', u'Yejin Choi']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43274.html
found
=========================
Show and tell: A neural image caption generator
Computer Vision and Pattern Recognition (2015)
[u'Oriol Vinyals', u'Alexander Toshev', u'Samy Bengio', u'Dumitru Erhan']
MachinePerception
Abstract: Automatically describing the content of an image is a fundamental problem in artificial intelligence that connects computer vision and natural language processing. In this paper, we present a generative model based on a deep recurrent architecture that combines recent advances in computer vision and machine translation and that can be used to generate natural sentences describing an image. The model is trained to maximize the likelihood of the target description sentence given the training image. Experiments on several datasets show the accuracy of the model and the fluency of the language it learns solely from image descriptions. Our model is often quite accurate, which we verify both qualitatively and quantitatively. For instance, while the current state-of-the-art BLEU score (the higher the better) on the Pascal dataset is 25, our approach yields 59, to be compared to human performance around 69. We also show BLEU-1 score improvements on Flickr30k, from 56 to 66, and on SBU, from 19 to 28. Lastly, on the newly released COCO dataset, we achieve a BLEU-4 of 27.7, which is the current state-of-the-art.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43290.html
notfound
=========================
Speech Acoustic Modeling from Raw Multichannel Waveforms
International Conference on Acoustics, Speech, and Signal Processing, IEEE (2015)
[u'Yedid Hoshen', u'Ron Weiss', u'Kevin W Wilson']
MachinePerception
Abstract: Standard deep neural network-based acoustic models for automatic speech recognition (ASR) rely on hand-engineered input features, typically log-mel filterbank magnitudes. In this paper, we describe a convolutional neural network - deep neural network (CNN-DNN) acoustic model which takes raw multichannel waveforms as input, i.e. without any preceding feature extraction, and learns a similar feature representation through supervised training. By operating directly in the time domain, the network is able to take advantage of the signal's fine time structure that is discarded when computing filterbank magnitude features. This structure is especially useful when analyzing multichannel inputs, where timing differences between input channels can be used to localize a signal in space. The first convolutional layer of the proposed model naturally learns a filterbank that is selective in both frequency and direction of arrival, i.e. a bank of bandpass beamformers with an auditory-like frequency scale. When trained on data corrupted with noise coming from different spatial locations, the network learns to filter them out by steering nulls in the directions corresponding to the noise sources. Experiments on a simulated multichannel dataset show that the proposed acoustic model outperforms a DNN that uses log-mel filterbank magnitude features under noisy and reverberant conditions.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43844.html
found
=========================
VIP: Finding Important People in Images
Computer Vision and Pattern Recognition, Computer Vision and Pattern Recognition, Computer Vision and Pattern Recognition (2015), pp. 4858-4966
[u'Clint Solomon Mathialagan', u'Andrew C. Gallagher', u'Dhruv Batra']
MachinePerception
Abstract: People preserve memories of events such as birthdays, weddings, or vacations by capturing photos, often depicting groups of people. Invariably, some individuals in the image are more important than others given the context of the event. This paper analyzes the concept of the importance of individuals in group photographs. We address two specific questions Given an image, who are the most important individuals in it? Given multiple images of a person, which image depicts the person in the most important role? We introduce a measure of importance of people in images and investigate the correlation between importance and visual saliency. We find that not only can we automatically predict the importance of people from purely visual cues, incorporating this predicted importance results in signifi- cant improvement in applications such as im2text (generating sentences that describe images of groups of people).
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43991.html
notfound
=========================
ViSQOLAudio: An objective audio quality metric for low bitrate codecs
The Journal of the Acoustical Society of America, vol. 137 (6) (2015), EL449-EL455
[u'Andrew Hines', u'Eoin Gillen', u'Damien Kelly', u'Jan Skoglund', u'Anil Kokaram', u'Naomi Harte']
MachinePerception
Abstract: Streaming services seek to optimise their use of bandwidth across audio and visual channels to maximise the quality of experience for users. This letter evaluates whether objective quality metrics can predict the audio quality for music encoded at low bitrates by comparing objective predictions with results from listener tests. Three objective metrics were benchmarked: PEAQ, POLQA, and VISQOLAudio. The results demonstrate objective metrics designed for speech quality assessment have a strong potential for quality assessment of low bitrate audio codecs.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43842.html
notfound
=========================
Visual Vibrometry: Estimating Material Properties from Small Motion in Video
IEEE Conf. on Computer Vision and Pattern Recognition (CVPR) (2015)
[u'Abe Davis', u'Katherine L. Bouman', u'Justin G. Chen', u'Michael Rubinstein', u'Fredo Durand', u'William T. Freeman']
MachinePerception
Abstract: The estimation of material properties is important for scene understanding, with many applications in vision, robotics, and structural engineering. This paper connects fundamentals of vibration mechanics with computer vision techniques in order to infer material properties from small, often imperceptible motion in video. Objects tend to vibrate in a set of preferred modes. The shapes and frequencies of these modes depend on the structure and material properties of an object. Focusing on the case where geometry is known or fixed, we show how information about an objects modes of vibration can be extracted from video and used to make inferences about that objects material properties. We demonstrate our approach by estimating material properties for a variety of rods and fabrics by passively observing their motion in high-speed and regular frame-rate video.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43403.html
notfound
=========================
Whats Cookin? Interpreting Cooking Videos using Text, Speech and Vision
North American Chapter of the Association for Computational Linguistics Human Language Technologies (NAACL HLT 2015) (to appear)
[u'Jonathan Malmaud', u'Jonathan Huang', u'Vivek Rathod', u'Nicholas Johnston', u'Andrew Rabinovich', u'Kevin Murphy']
MachinePerception
Abstract: We present a novel method for aligning a sequence of instructions to a video of someone carrying out a task. In particular, we focus on the cooking domain, where the instructions correspond to the recipe. Our technique relies on an HMM to align the recipe steps to the (automatically generated) speech transcript. We then refine this alignment using a state-of-the-art visual food detector, based on a deep convolutional neural network. We show that our technique outperforms simpler techniques based on keyword spotting. It also enables interesting applications, such as automatically illustrating recipes with keyframes, and searching within a video for events of interest.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43249.html
found
=========================
An optimized template matching approach to intra coding in video/image compression
IS&T/SPIE Electronic Imaging, 2014, SPIE, pp. 1-6
[u'Hui Su', u'Jingning Han', u'Yaowu Xu']
MachinePerception
Abstract: The template matching prediction is an established approach to intra-frame coding that makes use of previously coded pixels in the same frame for reference. It compares the previously reconstructed upper and left boundaries in searching from the reference area the best matched block for prediction, and hence eliminates the need of sending additional information to reproduce the same prediction at decoder. In viewing the image signal as an auto-regressive model, this work is premised on the fact that pixels closer to the known block boundary are better predicted than those far apart. It significantly extends the scope of the template matching approach, which is typically followed by a conventional discrete cosine transform (DCT) for the prediction residuals, by employing an asymmetric discrete sine transform (ADST), whose basis functions vanish at the prediction boundary and reach maximum magnitude at far end, to fully exploit statistics of the residual signals. It was experimentally shown that the proposed scheme provides substantial coding performance gains on top of the conventional template matching method over the baseline.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42532.html
notfound
=========================
Auto-Rectification of User Photos
Proceedings of International Conference on Image Processing, ICIP, IEEE (2014), pp. 3479-3483
[u'Krishnendu Chaudhury (aka Krish Chaudhury)', u'Stephen DiVerdi', u'Sergey Ioffe']
MachinePerception
Abstract: The image auto rectification project at Google aims to create a pleasanter version of user photos by correcting the small, involuntary camera rotations (roll / pitch/ yaw) that often occur in non-professional photographs. Our system takes the image closer to the fronto-parallel view by performing an affine rectification on the image that restores parallelism of lines that are parallel in the fronto-parallel image view. This partially corrects perspective distortions, but falls short of full metric rectification which also restores angles between lines. On the other hand the 2D homography for our rectification can be computed from only two (as opposed to three) estimated vanishing points, allowing us to fire upon many more images. A new RANSAC based approach to vanishing point estimation has been developed. The main strength of our vanishing point detector is that it is line-less, thereby avoiding the hard, binary (line/no-line) upstream decisions that cause traditional algorithm to ignore much supporting evidence and/or admit noisy evidence for vanishing points. A robust RANSAC based technique for detecting horizon lines in an image is also proposed for analyzing correctness of the estimated rectification. We post-multiply our affine rectification homography with a 2D rotation which aligns the closer vanishing point with the image Y axis.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Co-Segmentation of Textured 3D Shapes with Sparse Annotations
Computer Vision and Pattern Recognition (CVPR) (2014)
[u'M. Ersin Yumer', u'Ameesh Makadia']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42960.html
found
=========================
DaMN Discriminative and Mutually Nearest: Exploiting Pairwise Category Proximity for Video Action Recognition
Proceedings of European Conference on Computer Vision (2014)
[u'Rui Hou', u'Amir Roshan Zamir', u'Rahul Sukthankar', u'Mubarak Shah']
MachinePerception
Abstract: We propose a method for learning discriminative category-level features and demonstrate state-of-the-art results on large-scale action recognition in video. The key observation is that one-vs-rest classifiers, which are ubiquitously employed for this task, face challenges in separating very similar categories (such as running vs. jogging). Our proposed method automatically identifies such pairs of categories using a criterion of mutual pairwise proximity in the (kernelized) feature space, using a category-level similarity matrix where each entry corresponds to the one-vs-one SVM margin for pairs of categories. We then exploit the observation that while splitting such "Siamese Twin" categories may be difficult, separating them from the remaining categories in a two-vs-rest framework is not. This enables us to augment one-vs-rest classifiers with a judicious selection of "two-vs-rest" classifier outputs, formed from such discriminative and mutually nearest (DaMN) pairs. By combining one-vs-rest and two-vs-rest features in a principled probabilistic manner, we achieve state-of-the-art results on the UCF101 and HMDB51 datasets. More importantly, the same DaMN features, when treated as a mid-level representation also outperform existing methods in knowledge transfer experiments, both cross-dataset from UCF101 to HMDB51 and to new categories with limited training data (one-shot and few-shot learning). Finally, we study the generality of the proposed approach by applying DaMN to other classification tasks; our experiments show that DaMN outperforms related approaches in direct comparisons, not only on video action recognition but also on their original image dataset tasks.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
DeepPose: Human Pose Estimation via Deep Neural Networks
Computer Vision and Pattern Recognition (2014) (to appear)
[u'Alexander Toshev', u'Christian Szegedy']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43104.html
notfound
=========================
Discovering Groups of People in Images
European Conference on Computer Vision (ECCV) (2014)
[u'Wongun Choi', u'Yu-Wei Chao', u'Caroline Pantofaru', u'Silvio Savarese']
MachinePerception
Abstract: Understanding group activities from images is an important yet challenging task. This is because there is an exponentially large number of semantic and geometrical relationships among individuals that one must model in order to effectively recognize and localize the group activities. Rather than focusing on directly recognizing group activities as most of the previous works do, we advocate the importance of introducing an intermediate representation for modeling groups of humans which we call structure groups. Such groups define the way people spatially interact with each other. People might be facing each other to talk, while others sit on a bench side by side, and some might stand alone. In this paper we contribute a method for identifying and localizing these structured groups in a single image despite their varying viewpoints, number of participants, and occlusions. We propose to learn an ensemble of discriminative interaction patterns to encode the relationships between people in 3D and introduce a novel efficient iterative augmentation algorithm for solving this complex inference problem. A nice byproduct of the inference scheme is an approximate 3D layout estimate of the structured groups in the scene. Finally, we contribute an extremely challenging new dataset that contains images each showing multiple people performing multiple activities. Extensive evaluation confirms our theoretical findings.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43206.html
notfound
=========================
Indoor Scene Understanding with Geometric and Semantic Contexts
International Journal of Computer Vision (IJCV) (2014)
[u'Wongun Choi', u'Yu-Wei Chao', u'Caroline Pantofaru', u'Silvio Savarese']
MachinePerception
Abstract: Truly understanding a scene involves integrating information at multiple levels as well as studying the interactions between scene elements. Individual object detectors, layout estimators and scene classifiers are powerful but ultimately confounded by complicated real-world scenes with high variability, different viewpoints and occlusions. We propose a method that can automatically learn the interactions among scene elements and apply them to the holistic understanding of indoor scenes from a single image. This interpretation is performed within a hierarchical interaction model which describes an image by a parse graph, thereby fusing together object detection, layout estimation and scene classification. At the root of the parse graph is the scene type and layout while the leaves are the individual detections of objects. In between is the core of the system, our 3D Geometric Phrases (3DGP). We conduct extensive experimental evaluations on single image 3D scene understanding using both 2D and 3D metrics. The results demonstrate that our model with 3DGPs can provide robust estimation of scene type, 3D space, and 3D objects by leveraging the contextual relationships among the visual elements.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Large-Scale Object Classification Using Label Relation Graphs
European Conference on Computer Vision (2014)
[u'Jia Deng', u'Nan Ding', u'Yangqing Jia', u'Andrea Frome', u'Kevin Murphy', u'Samy Bengio', u'Yuan Li', u'Hartmut Neven', u'Hartwig Adam']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42455.html
found
=========================
Large-scale Video Classication with Convolutional Neural Networks
Proceedings of International Computer Vision and Pattern Recognition (CVPR 2014), IEEE
[u'Andrej Karpathy', u'George Toderici', u'Sanketh Shetty', u'Thomas Leung', u'Rahul Sukthankar', u'Li Fei-Fei']
MachinePerception
Abstract: Convolutional Neural Networks (CNNs) have been established as a powerful class of models for image recognition problems. Encouraged by these results, we provide an extensive empirical evaluation of CNNs on large-scale video classification using a dataset of 1 million YouTube videos belonging to 487 classes. We study multiple approaches for extending the connectivity of a CNN in time domain to take advantage of local spatio-temporal information and suggest a multi-resolution, foveated architecture as a promising way of regularizing the learning problem and speeding up training. Our best spatio-temporal networks display significant performance improvements compared to strong feature-based baselines (55.3% to 63.9%), but only a surprisingly modest improvement compared to single-frame models (59.3% to 60.9%). We further study the generalization performance of our best model by retraining the top layers on the UCF-101 action Recognition dataset and observe significant performance improvements compared to the UCF-101 baseline model (63.3% up from 43.9%).
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42945.html
found
=========================
Learning Fine-grained Image Similarity with Deep Ranking
CVPR'2014, IEEE
[u'Jiang Wang', u'Yang Song', u'Thomas Leung', u'Chuck Rosenberg', u'Jingbin Wang', u'James Philbin', u'Bo Chen', u'Ying Wu']
MachinePerception
Abstract: Learning fine-grained image similarity is a challenging task. It needs to capture between-class and within-class image differences. This paper proposes a deep ranking model that employs deep learning techniques to learn similarity metric directly from images. It has higher learning capability than models based on hand-crafted features. A novel multiscale network structure has been developed to describe the images effectively. An efficient triplet sampling algorithm is proposed to learn the model with distributed asynchronized stochastic gradient. Extensive experiments show that the proposed algorithm outperforms models based on hand-crafted visual features and deep classification models.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42241.html
notfound
=========================
Multi-digit Number Recognition from Street View Imagery using Deep Convolutional Neural Networks
ICLR2014, ICLR2014 (to appear)
[u'Ian Goodfellow', u'Yaroslav Bulatov', u'Julian Ibarz', u'Sacha Arnoud', u'Vinay Shet']
MachinePerception
Abstract: Recognizing arbitrary multi-character text in unconstrained natural photographs is a hard problem. In this paper, we address an equally hard sub-problem in this domain viz. recognizing arbitrary multi-digit numbers from Street View imagery. Traditional approaches to solve this problem typically separate out the localiza- tion, segmentation, and recognition steps. In this paper we propose a unified ap- proach that integrates these three steps via the use of a deep convolutional neu- ral network that operates directly on the image pixels. We employ the DistBe- lief (Dean et al., 2012) implementation of deep neural networks in order to train large, distributed neural networks on high quality images. We find that the per- formance of this approach increases with the depth of the convolutional network, with the best performance occurring in the deepest architecture we trained, with eleven hidden layers. We evaluate this approach on the publicly available SVHN dataset and achieve over 96% accuracy in recognizing complete street numbers. We show that on a per-digit recognition task, we improve upon the state-of-the-art and achieve 97.84% accuracy. We also evaluate this approach on an even more challenging dataset generated from Street View imagery containing several tens of millions of street number annotations and achieve over 90% accuracy. Our evaluations further indicate that at specific operating thresholds, the performance of the proposed system is comparable to that of human operators. To date, our system has helped us extract close to 100 million physical street numbers from Street View imagery worldwide.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43140.html
found
=========================
Neural Networks and Neuroscience-Inspired Computer Vision
Current Biology, vol. 24 (2014), pp. 921-929
[u'David Cox', u'Tom Dean']
MachinePerception
Abstract: Brains are, at a fundamental level, biological computing machines. They transform a torrent of complex and ambiguous sensory information into coherent thought and action, allowing an organism to perceive and model its environment, synthesize and make decisions from disparate streams of information, and adapt to a changing environment. Against this backdrop, it is perhaps not surprising that computer science, the science of building artificial computational systems, has long looked to biology for inspiration. However, while the opportunities for cross-pollination between neuroscience and computer science are great, the road to achieving brain-like algorithms has been long and rocky. Here, we review the historical connections between neuroscience and computer science, and we look forward to a new era of potential collaboration, enabled by recent rapid advances in both biologically-inspired computer vision and in experimental neuroscience methods. In particular, we explore where neuroscience-inspired algorithms have succeeded, where they still fail, and we identify areas where deeper connections are likely to be fruitful.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43466.html
notfound
=========================
Painting with Triangles
Proceedings of the Workshop on Non-Photorealistic Animation and Rendering, NPAR, ACM, New York, NY, USA (2014), pp. 13-20
[u'Mark D. Benjamin', u'Stephen DiVerdi', u'Adam Finkelstein']
MachinePerception
Abstract: Although vector graphics offer a number of benefits, conventional vector painting programs offer only limited support for the traditional painting metaphor. We propose a new algorithm that translates a user's mouse motion into a triangle mesh representation. This triangle mesh can then be composited onto a canvas containing an existing mesh representation of earlier strokes. This representation allows the algorithm to render solid colors and linear gradients. It also enables painting at any resolution. This paradigm allows artists to create complex, multi-scale drawings with gradients and sharp features while avoiding pixel sampling artifacts.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43465.html
notfound
=========================
RealPigment: Paint Compositing by Example
Proceedings of the Workshop on Non-Photorealistic Animation and Rendering, NPAR, ACM, New York, NY, USA (2014), pp. 21-30
[u'Jingwan Lu', u'Stephen DiVerdi', u'Willa Chen', u'Connelly Barnes', u'Adam Finkelstein']
MachinePerception
Abstract: The color of composited pigments in digital painting is generally computed one of two ways: either alpha blending in RGB, or the Kubelka-Munk equation (KM). The former fails to reproduce paint like appearances, while the latter is difficult to use. We present a data-driven pigment model that reproduces arbitrary compositing behavior by interpolating sparse samples in a high dimensional space. The input is an of a color chart, which provides the composition samples. We propose two different prediction algorithms, one doing simple interpolation using radial basis functions (RBF), and another that trains a parametric model based on the KM equation to compute novel values. We show that RBF is able to reproduce arbitrary compositing behaviors, even non-paint-like such as additive blending, while KM compositing is more robust to acquisition noise and can generalize results over a broader range of values.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42456.html
notfound
=========================
Recognition of Complex Events: Exploiting Temporal Dynamics between Underlying Concepts
Proceedings of International Computer Vision and Pattern Recognition (CVPR 2014), IEEE
[u'Subhabrata Bhattacharya', u'Mahdi M. Kalayeh', u'Rahul Sukthankar', u'Mubarak Shah']
MachinePerception
Abstract: While approaches based on bags of features excel at low-level action classification, they are ill-suited for recognizing complex events in video, where concept-based temporal representations currently dominate. This paper proposes a novel representation that captures the temporal dynamics of windowed mid-level concept detectors in order to improve complex event recognition. We first express each video as an ordered vector time series, where each time step consists of the vector formed from the concatenated confidences of the pre-trained concept detectors. We hypothesize that the dynamics of time series for different instances from the same event class, as captured by simple linear dynamical system (LDS) models, are likely to be similar even if the instances differ in terms of low-level visual features. We propose a two-part representation composed of fusing: (1) a singular value decomposition of block Hankel matrices (SSID-S) and (2) a harmonic signature (H-S) computed from the corresponding eigen-dynamics matrix. The proposed method offers several benefits over alternate approaches: our approach is straightforward to implement, directly employs existing concept detectors and can be plugged into linear classification frameworks. Results on standard datasets such as NIST's TRECVID Multimedia Event Detection task demonstrate the improved accuracy of the proposed method.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
SUPER 4PCS Fast Global Pointcloud Registration via Smart Indexing
Eurographics Symposium on Geometry Processing 2014
[u'Nicolas Mellado', u'Dror Aiger', u'Niloy Mitra']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42238.html
notfound
=========================
Scalable Object Detection using Deep Neural Networks
Computer Vision and Pattern Recognition, IEEE (2014), pp. 2155- 2162
[u'Dumitru Erhan', u'Christian Szegedy', u'Alexander Toshev', u'Dragomir Anguelov']
MachinePerception
Abstract: Deep convolutional neural networks have recently achieved state-of-the-art performance on a number of image recognition benchmarks, including the ImageNet Large-Scale Visual Recognition Challenge (ILSVRC-2012). The winning model on the localization sub-task was a network that predicts a single bounding box and a confidence score for each object category in the image. Such a model captures the whole-image context around the objects but cannot handle multiple instances of the same object in the image without naively replicating the number of outputs for each instance. In this work, we propose a saliency-inspired neural network model for detection, which predicts a set of class-agnostic bounding boxes along with a single score for each box, corresponding to its likelihood of containing any object of interest. The model naturally handles a variable number of instances for each class and allows for cross-class generalization at the highest levels of the network. We are able to obtain competitive recognition performance on VOC2007 and ILSVRC2012, while using only the top few predicted locations in each image and a small number of neural network evaluations.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Sinusoidal Interpolation Across Missing Data
International Workshop on Acoustic Signal Enhancement 2014 (IWAENC 2014), pp. 71-75
[u'W. Bastiaan Kleijn', u'Turaj Zakizadeh Shabestary', u'Jan Skoglund']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42193.html
found
=========================
Temporal Synchronization of Multiple Audio Signals
Proceedings of the International Conference on Signal Processing (ICASSP), Florence, Italy (2014)
[u'Julius Kammerl', u'Neil Birkbeck', u'Sasi Inguva', u'Damien Kelly', u'Andy Crawford', u'Hugh Denman', u'Anil Kokaram', u'Caroline Pantofaru']
MachinePerception
Abstract: Given the proliferation of consumer media recording devices, events often give rise to a large number of recordings. These recordings are taken from different spatial positions and do not have reliable timestamp information. In this paper, we present two robust graph-based approaches for synchronizing multiple audio signals. The graphs are constructed atop the over-determined system resulting from pairwise signal comparison using cross-correlation of audio features. The first approach uses a Minimum Spanning Tree (MST) technique, while the second uses Belief Propagation (BP) to solve the system. Both approaches can provide excellent solutions and robustness to pairwise outliers, however the MST approach is much less complex than BP. In addition, an experimental comparison of audio features-based synchronization shows that spectral flatness outperforms the zero-crossing rate and signal energy.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43260.html
found
=========================
The Optical Mouse: Early Biomimetic Embedded Vision
Advnances in Embedded Computer Vision, Springer (2014), pp. 3-22
[u'Richard F. Lyon']
MachinePerception
Abstract: The 1980 Xerox optical mouse invention, and subsequent product, was a successful deployment of embedded vision, as well as of the MeadConway VLSI design methodology that we developed at Xerox PARC in the late 1970s. The design incorporated an interpretation of visual lateral inhibition, essentially mimicking biology to achieve a wide dynamic range, or light-level-independent operation. Conceived in the context of a research group developing VLSI design methodologies, the optical mouse chip represented an approach to self-timed semi-digital design, with the analog image-sensing nodes connecting directly to otherwise digital logic using a switch-network methodology. Using only a few hundred gates and pass transistors in 5-micron nMOS technology, the optical mouse chip tracked the motion of light dots in its field of view, and reported motion with a pair of 2-bit Gray codes for x and y relative positionjust like the mechanical mice of the time. Besides the chip, the only other electronic components in the mouse were the LED illuminators.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41872.html
found
=========================
Training Highly Multi-class Linear Classifiers
Journal Machine Learning Research (JMLR) (2014), 1461-1492
[u'Maya R. Gupta', u'Samy Bengio', u'Jason Weston']
MachinePerception
Abstract: Classification problems with thousands or more classes often have a large variance in the confusability between classes, and we show that the more-confusable classes add more noise to the empirical loss that is minimized during training. We propose an online solution that reduces the effect of highly confusable classes in training the classifier parameters, and focuses the training on pairs of classes that are easier to differentiate at any given time in the training. We also show that the adagrad method, recently proposed for automatically decreasing step sizes for convex stochastic gradient descent optimization, can also be profitably applied to the nonconvex optimization stochastic gradient descent training of a joint supervised dimensionality reduction and linear classifier. Experiments on ImageNet benchmark datasets and proprietary image recognition problems with 15,000 to 97,000 classes show substantial gains in classification accuracy compared to one-vs-all linear SVMs and Wsabie.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Unsupervised Discovery of Object Classes with a Mobile Robot
ICRA 2014
[u'Julian Mason', u'Bhaskara Marthi', u'Ronald Parr']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42961.html
found
=========================
Video Object Discovery and Co-segmentation with Extremely Weak Supervision
Proceedings of European Conference on Computer Vision (2014)
[u'Le Wang', u'Gang Hua', u'Rahul Sukthankar', u'Jianru Xue', u'Nanning Zheng']
MachinePerception
Abstract: Video object co-segmentation refers to the problem of simultaneously segmenting a common category of objects from multiple videos. Most existing video co-segmentation methods assume that all frames from all videos contain the target objects. Unfortunately, this assumption is rarely true in practice, particularly for large video sets, and existing methods perform poorly when the assumption is violated. Hence, any practical video object co-segmentation algorithm needs to identify the relevant frames containing the target object from all videos, and then co-segment the object only from these relevant frames. We present a spatiotemporal energy minimization formulation for simultaneous video object discovery and co-segmentation across multiple videos. Our formulation incorporates a spatiotemporal auto-context model, which is combined with appearance modeling for superpixel labeling. The superpixel-level labels are propagated to the frame level through a multiple instance boosting algorithm with spatial reasoning (Spatial-MILBoosting), based on which frames containing the video object are identified. Our method only needs to be bootstrapped with the frame-level labels for a few video frames (e.g., usually 1 to 3) to indicate if they contain the target objects or not. Experiments on three datasets validate the efficacy of our proposed method, which compares favorably with the state-of-the-art.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42110.html
notfound
=========================
Video Quality Assessment for Web Content Mirroring
Imaging and Multimedia Analytics in a Web and Mobile World 2014, IS&T/SPIE Electronic Imaging, San Francisco, California, pp. 9027-11
[u'Ye He', u'Kevin Fei', u'Gus Fernandez', u'Edward J. Delp']
MachinePerception
Abstract: Due to the increasing user expectation on watching experience, moving web high quality video streaming content from the small screen in mobile devices to the larger TV screen has become popular. It is crucial to develop video quality metrics to measure the quality change for various devices or network conditions. In this paper, we propose an automated scoring system to quantify user satisfaction. We compare the quality of local videos with the videos transmitted to a TV. Four video quality metrics, namely Image Quality, Rendering Quality, Freeze Time Ratio and Rate of Freeze Events are used to measure video quality change during web content mirroring. To measure image quality and rendering quality, we compare the matched frames between the source video and the destination video using barcode tools. Freeze time ratio and rate of freeze events are measured after extracting video timestamps. Several user studies are conducted to evaluate the impact of each objective video quality metric on the subjective user watching experience.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42371.html
found
=========================
Zero-Shot Learning by Convex Combination of Semantic Embeddings
International Conference on Learning Representations (2014)
[u'Mohammad Norouzi', u'Tomas Mikolov', u'Samy Bengio', u'Yoram Singer', u'Jonathon Shlens', u'Andrea Frome', u'Greg Corrado', u'Jeffrey Dean']
MachinePerception
Abstract: Several recent publications have proposed methods for mapping images into continuous semantic embedding spaces. In some cases the embedding space is trained jointly with the image transformation. In other cases the semantic embedding space is established by an independent natural language processing task, and then the image transformation into that space is learned in a second stage. Proponents of these image embedding systems have stressed their advantages over the traditional \nway{} classification framing of image understanding, particularly in terms of the promise for zero-shot learning -- the ability to correctly annotate images of previously unseen object categories. In this paper, we propose a simple method for constructing an image embedding system from any existing \nway{} image classifier and a semantic word embedding model, which contains the $\n$ class labels in its vocabulary. Our method maps images into the semantic embedding space via convex combination of the class label embedding vectors, and requires no additional training. We show that this simple and direct method confers many of and indeed outperforms state of the art methods on the ImageNet zero-shot learning task.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41643.html
found
=========================
3DNN: Viewpoint Invariant 3D Geometry Matching for Scene Understanding
Proceedings of the International Conference on Computer Vision (ICCV) (2013) (to appear)
[u'Scott Satkin', u'Martial Hebert']
MachinePerception
Abstract: We present a new algorithm 3DNN (3D Nearest-Neighbor), which is capable of matching an image with 3D data, independently of the viewpoint from which the image was captured. By leveraging rich annotations associated with each image, our algorithm can automatically produce precise and detailed 3D models of a scene from a single image. Moreover, we can transfer information across images to accurately label and segment objects in a scene. The true benefit of 3DNN compared to a traditional 2D nearest-neighbor approach is that by generalizing across viewpoints, we free ourselves from the need to have training examples captured from all possible viewpoints. Thus, we are able to achieve comparable results using orders of magnitude less data, and recognize objects from never-before-seen viewpoints. In this work, we describe the 3DNN algorithm and rigorously evaluate its performance for the tasks of geometry estimation and object detection/segmentation. By decoupling the viewpoint and the geometry of an image, we develop a scene matching approach which is truly 100% viewpoint invariant, yielding state-of-the-art performance on challenging data.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41418.html
found
=========================
A Butterfly Structured Design of The Hybrid Transform Coding Scheme
Picture Coding Symposium, IEEE (2013), pp. 1-4
[u'Jingning Han', u'Yaowu Xu', u'Debargha Mukherjee']
MachinePerception
Abstract: The hybrid transform coding scheme that alternates amongst the asymmetric discrete sine transform (ADST) and the discrete cosine transform (DCT) depending on the boundary prediction conditions, is an efficient tool for video and image compression. It optimally exploits the statistical characteristics of prediction residual, thereby achieving significant coding performance gains over the conventional DCT-based approach. A practical concern lies in the intrinsic conflict between transform kernels of ADST and DCT, which prevents a butterfly structured implementation for parallel computing. Hence the hybrid transform coding scheme has to rely on matrix multiplication, which presents a speed-up barrier due to under-utilization of the hardware, especially for larger block sizes. In this work, we devise a novel ADST-like transform whose kernel is consistent with that of DCT, thereby enabling butterfly structured computation flow, while largely retaining the performance advantages of hybrid transform coding scheme in terms of compression efficiency. A prototype implementation of the proposed butterfly structured hybrid transform coding scheme is available in the VP9 codec repository.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Discriminative Model for Learning Semantic and Geometric Interactions in Indoor Scenes
Proc. of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Scene Understanding Workshop (SUNw) (2013)
[u'Wongun Choi', u'Yu-Wei Chao', u'Caroline Pantofaru', u'Silvio Savarese']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Accelerating defocus blur magnification
Proceedings SPIE Vol. 8667 (Multimedia Content and Mobile Devices), SPIE (2013)
[u'Florian Kriener', u'Thomas Binder', u'Manuel Wille']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Category-Independent Object-level Saliency Detection
International Conference on Computer Vision (2013)
[u'Yangqing Jia', u'Mei Han']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41869.html
found
=========================
DeViSE: A Deep Visual-Semantic Embedding Model
Neural Information Processing Systems (NIPS) (2013)
[u'Andrea Frome', u'Greg Corrado', u'Jonathon Shlens', u'Samy Bengio', u'Jeffrey Dean', u'MarcAurelio Ranzato', u'Tomas Mikolov']
MachinePerception
Abstract: Modern visual recognition systems are often limited in their ability to scale to large numbers of object categories. This limitation is in part due to the increasing difficulty of acquiring sufficient training data in the form of labeled images as the number of object categories grows. One remedy is to leverage data from other sources such as text data both to train visual models and to constrain their predictions. In this paper we present a new deep visual-semantic embedding model trained to identify visual objects using both labeled image data as well as semantic information gleaned from unannotated text. We demonstrate that this model matches state-of-the-art performance on the 1000-class ImageNet object recognition challenge while making more semantically reasonable errors, and also show that the semantic information can be exploited to make predictions about tens of thousands of image labels not observed during training. Semantic knowledge improves such zero-shot predictions achieving hit rates of up to 18% across thousands of novel labels never seen by the visual model.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Deep Neural Networks for Object Detection
Advances in Neural Information Processing Systems (2013)
[u'Christian Szegedy', u'Alexander Toshev', u'Dumitru Erhan']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41338.html
found
=========================
Design of user interfaces for selective editing of digital photos on touchscreen devices
Proceedings SPIE 8667 (Multimedia Content and Mobile Devices), SPIE (2013)
[u'Thomas Binder', u'Meikel Steiding', u'Manuel Wille', u'Nils Kokemohr']
MachinePerception
Abstract: When editing images it is often desirable to apply a filter with a spatially varying strength. With the usual selection tools like gradient, lasso, brush, or quick selection tools, creating masks containing such spatially varying strength values is time-consuming and cumbersome. We present an interactive filtering approach which allows to process photos selectively without the intermediate step of creating a mask containing strength values. In using this approach, the user only needs to place reference points (called control points) on the image and to adjust the spatial influence and filter strength for each control point. The filter is then applied selectively to the image, with strength values interpolated for each pixel between control points. The interpolation is based on a mixture of distances in space, luminance, and color; it is therefore a low-level operation. Since the main goal of the approach is to make selective image editing intuitive, easy, and playful, emphasis is put on the user interface: We describe the process of developing an existing mouse-driven user interface into a touch-driven one. Many question needed to be answered anew, such as how to present a slider widget on a touchscreen. Several variants are discussed and compared.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40751.html
found
=========================
Discriminative Segment Annotation in Weakly Labeled Video
Proceedings of International Conference on Computer Vision and Pattern Recognition (CVPR 2013)
[u'Kevin Tang', u'Rahul Sukthankar', u'Jay Yagnik', u'Li Fei-Fei']
MachinePerception
Abstract: paper tackles the problem of segment annotation in complex Internet videos. Given a weakly labeled video, we automatically generate spatiotemporal masks for each of the concepts with which it is labeled. This is a particularly relevant problem in the video domain, as large numbers of YouTube videos are now available, tagged with the visual concepts that they contain. Given such weakly labeled videos, we focus on the problem of spatiotemporal segment classification. We propose a straightforward algorithm, CRANE, that utilizes large amounts of weakly labeled video to rank spatiotemporal segments by the likelihood that they correspond to a given visual concept. We make publicly available segment-level annotations for a subset of the Prest et al. dataset and show convincing results. We also show state-of-the-art results on Hartmann et al.'s more difficult, large-scale object segmentation dataset.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40814.html
found
=========================
Fast, Accurate Detection of 100,000 Object Classes on a Single Machine
Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, IEEE Computer Society, Washington, DC, USA (2013)
[u'Thomas Dean', u'Mark Ruzon', u'Mark Segal', u'Jonathon Shlens', u'Sudheendra Vijayanarasimhan', u'Jay Yagnik']
MachinePerception
Abstract: Many object detection systems are constrained by the time required to convolve a target image with a bank of filters that code for different aspects of an object's appearance, such as the presence of component parts. We exploit locality-sensitive hashing to replace the dot-product kernel operator in the convolution with a fixed number of hash-table probes that effectively sample all of the filter responses in time independent of the size of the filter bank. To show the effectiveness of the technique, we apply it to evaluate 100,000 deformable-part models requiring over a million (part) filters on multiple scales of a target image in less than 20 seconds using a single multi-core processor with 20GB of RAM. This represents a speed-up of approximately 20,000 times - four orders of magnitude - when compared with performing the convolutions explicitly on the same hardware. While mean average precision over the full set of 100,000 object classes is around 0.16 due in large part to the challenges in gathering training data and collecting ground truth for so many classes, we achieve a mAP of at least 0.20 on a third of the classes and 0.30 or better on about 20% of the classes.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41104.html
notfound
=========================
Fast, Accurate Detection of 100,000 Object Classes on a Single Machine: Technical Supplement
Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, IEEE Computer Society, Washington, DC, USA (2013)
[u'Thomas Dean', u'Mark Ruzon', u'Mark Segal', u'Jonathon Shlens', u'Sudheendra Vijayanarasimhan', u'Jay Yagnik']
MachinePerception
Abstract: In the companion paper published in CVPR 2013, we presented a method that can directly use deformable part models (DPMs) trained as in [Felzenszwalb et al CVPR 2008]. After training, HOG based part filters are hashed, and, during inference, counts of hashing collisions summed over all hash bands serve as a proxy for part-filter / sliding-window dot products, i.e., filter responses. These counts are an approximation and so we take the original HOG-based filters for the top hash counts and calculate the exact dot products for scoring. It is possible to train DPM models not on HOG data but on a hashed WTA [Yagnik et al ICCV 2011] version of this data. The resulting part filters are sparse, real-valued vectors the size of WTA vectors computed from sliding windows. Given the WTA hash of a window, we exactly recover dot products of the top responses using an extension of locality-sensitive hashing. In this supplement, we sketch a method for training such WTA-based models.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43996.html
found
=========================
HMM-based script identification for OCR
Proceedings of the 4th International Workshop on Multilingual OCR, ACM, New York, NY, US (2013), 2:1-2:5
[u'Dmitriy Genzel', u'Ashok Popat', u'Remco Teunen', u'Yasuhisa Fujii']
MachinePerception
Abstract: While current OCR systems are able to recognize text in an increasing number of scripts and languages, typically they still need to be told in advance what those scripts and languages are. We propose an approach that repurposes the same HMM-based system used for OCR to the task of script/language ID, by replacing character labels with script class labels. We apply it in a multi-pass overall OCR process which achieves universal OCR over 54 tested languages in 18 distinct scripts, over a wide variety of typefaces in each. For comparison we also consider a brute-force approach, wherein a singe HMM-based OCR system is trained to recognize all considered scripts. Results are presented on a large and diverse evaluation set extracted from book images, both for script identification accuracy and for overall OCR accuracy. On this evaluation data, the script ID system provided a script ID error rate of 1.73% for 18 distinct scripts. The end-to-end OCR system with the script ID system achieved a character error rate of 4.05%, an increase of 0.77% over the case where the languages are known a priori.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41611.html
notfound
=========================
Handling Packet Loss in WebRTC
International Conference on Image Processing (ICIP 2013), IEEE, pp. 1860-1864
[u'Stefan Holmer', u'Mikhal Shemer', u'Marco Paniconi']
MachinePerception
Abstract: WebRTC is an open-source real-time interactive audio and video communication framework. This paper discusses some of the mechanisms utilized in WebRTC to handle packet losses in the video communication path. Various system details are discussed and an adaptive hybrid NACK/FEC method with temporal layers is presented. Results are shown to quantify how the method controls the quality trade-offs for real-time video communication.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42119.html
found
=========================
High-Resolution Global Maps of 21st-Century Forest Cover Change
Science, vol. 342 (2013), pp. 850-853
[u'Rebecca Moore', u'Matt Hancher', u'David Thau']
MachinePerception
Abstract: Quantification of global forest change has been lacking despite the recognized importance of forest ecosystem services. In this study, Earth observation satellite data were used to map global forest loss (2.3 million square kilometers) and gain (0.8 million square kilometers) from 2000 to 2012 at a spatial resolution of 30 meters. The tropics were the only climate domain to exhibit a trend, with forest loss increasing by 2101 square kilometers per year. Brazils well-documented reduction in deforestation was offset by increasing forest loss in Indonesia, Malaysia, Paraguay, Bolivia, Zambia, Angola, and elsewhere. Intensive forestry practiced within subtropical forests resulted in the highest rates of forest change globally. Boreal forest loss due largely to fire and forestry was second to that in the tropics in absolute and proportional terms. These results depict a globally consistent and locally relevant record of forest change.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41435.html
found
=========================
Image Annotation in Presence of Noisy Labels
International Conference on Pattern Recognition and Machine Intelligence (2013) (to appear)
[u'Chandrashekhar V.', u'Shailesh Kumar', u'C. V. Jawahar']
MachinePerception
Abstract: Labels associated with social images are valuable source of information for tasks of image annotation, understanding and retrieval. These labels are often found to be noisy, mainly due to the collaborative tagging activities of users. Existing methods on annotation have been developed and verified on noise free labels of images. In this paper, we propose a novel and generic framework that exploits the collective knowledge embedded in noisy label co-occurrence pairs to derive robust annotations. We compare our method with a well-known image annotation algorithm and show its superiority in terms of annotation accuracy on benchmark Corel5K and ESP datasets in presence of noisy labels.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Image Compression via Colorization Using Semi-Regular Color Samples
Data Compression Conference (2013)
[u'Chenguang Zhang', u'Hui Fang']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41545.html
notfound
=========================
Joint Noise Level Estimation from Personal Photo Collections
ICCV 2013 (to appear)
[u'YiChang Shih', u'Vivek Kwatra', u'Troy Chinen', u'Hui Fang', u'Sergey Ioffe']
MachinePerception
Abstract: Personal photo albums are heavily biased towards faces of people, but most state-of-the-art algorithms for image denoising and noise estimation do not exploit facial information. We propose a novel technique for jointly estimating noise levels of all face images in a photo collection. Photos in a personal album are likely to contain several faces of the same people. While some of these photos would be clean and high quality, others may be corrupted by noise. Our key idea is to estimate noise levels by comparing multiple images of the same content that differ predominantly in their noise content. Specifically, we compare geometrically and photometrically aligned face images of the same person. Our estimation algorithm is based on a probabilistic formulation that seeks to maximize the joint probability of estimated noise levels across all images. We propose an approximate solution that decomposes this joint maximization into a two-stage optimization. The first stage determines the relative noise between pairs of images by pooling estimates from corresponding patch pairs in a probabilistic fashion. The second stage then jointly optimizes for all absolute noise parameters by conditioning them upon relative noise levels, which allows for a pairwise factorization of the probability distribution. We evaluate our noise estimation method using quantitative experiments to measure accuracy on synthetic data. Additionally, we employ the estimated noise levels for automatic denoising using "BM3D", and evaluate the quality of denoising on real-world photos through a user study.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40753.html
found
=========================
Learning Binary Codes for High Dimensional Data Using Bilinear Projections
IEEE Computer Vision and Pattern Recognition (2013)
[u'Yunchao Gong', u'Sanjiv Kumar', u'Henry Rowley', u'Svetlana Lazebnik']
MachinePerception
Abstract: Recent advances in visual recognition indicate that to achieve good retrieval and classication accuracy on large scale datasets like ImageNet, extremely high-dimensional visual descriptors, e.g., Fisher Vectors, are needed. We present a novel method for converting such descriptors to compact similarity-preserving binary codes that exploits their natural matrix structure to reduce their dimensionality using compact bilinear projections instead of a single large projection matrix. This method achieves comparable retrieval and classication accuracy to the original descriptors and to the state-of-the-art Product Quantization approach while having orders of magnitude faster code generation time and smaller memory footprint.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41320.html
found
=========================
Learning Multiple Non-Linear Sub-Spaces using K-RBMs
Computer Vision and Pattern Recognition (2013)
[u'Siddhartha Chandra', u'Shailesh Kumar', u'C. V. Jawahar']
MachinePerception
Abstract: Understanding the nature of data is the key to building good representations. In domains such as natural images, the data comes from very complex distributions which are hard to capture. Feature learning intends to discover or best approximate these underlying distributions and use their knowledge to weed out irrelevant information, preserving most of the relevant information. Feature learning can thus be seen as a form of dimensionality reduction. In this paper, we describe a feature learning scheme for natural images. We hypothesize that image patches do not all come from the same distribution, they lie in multiple nonlinear subspaces. We propose a framework that uses K-Restricted Boltzmann Machines (K-RBMS) to learn multiple non-linear subspaces in the raw image space. Projections of the image patches into these subspaces gives us features, which we use to build image representations. Our algorithm solves the coupled problem of nding the right non-linear subspaces in the input space and associating image patches with those subspaces in an iterative EM like algorithm to minimize the overall reconstruction error. Extensive empirical results over several popular image classication datasets show that representations based on our framework outperform the traditional feature representations such as the SIFT based Bag-of-Words (BoW) and convolutional deep belief networks.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41463.html
notfound
=========================
Learning Part-based Templates from Large Collections of 3D Shapes
ACM Transactions on Graphics (TOG) - SIGGRAPH 2013 Conference Proceedings, vol. 32, no. 4 (2013), 70:1-70:12
[u'Vladimir Kim', u'Wilmot Li', u'Niloy Mitra', u'Siddhartha Chaudhuri', u'Stephen DiVerdi', u'Thomas Funkhouser']
MachinePerception
Abstract: As large repositories of 3D shape collections continue to grow, understanding the data, especially encoding the inter-model similarity and their variations, is of central importance. For example, many data-driven approaches now rely on access to semantic segmentation information, accurate inter-model point-to-point correspondence, and deformation models that characterize the model collections. Existing approaches, however, are either supervised requiring manual labeling; or employ super-linear matching algorithms and thus are unsuited for analyzing large collections spanning many thousands of models. We propose an automatic algorithm that starts with an initial template model and then jointly optimizes for part segmentation, point-to-point surface correspondence, and a compact deformation model to best explain the input model collection. As output, the algorithm produces a set of probabilistic part-based templates that groups the original models into clusters of models capturing their styles and variations. We evaluate our algorithm on several standard datasets and demonstrate its scalability by analyzing much larger collections of up to thousands of shapes.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41900.html
notfound
=========================
Learning Query-Specific Distance Functions for Large-Scale Web Image Search
IEEE Transactions on Multimedia, vol. 15 (2013), pp. 2022-2034
[u'Yushi Jing', u'Michele Covell', u'David Tsai', u'James M. Rehg']
MachinePerception
Abstract: Current Google image search adopts a hybrid search approach in which a text-based query (e.g., "Paris landmarks") is used to retrieve a set of relevant images, which are then refined by the user (e.g., by re-ranking the retrieved images based on similarity to a selected example). We conjecture that given such hybrid image search engines, learning per-query distance functions over image features can improve the estimation of image similarity. We proposed scalable solutions to learning query-specific distance functions by 1) adopting a simple large-margin learning framework, 2) using the query-logs of a text-based image search engine to train distance functions used in content-based systems. We evaluate the feasibility and efficacy of our proposed system through comprehensive human evaluation, and compare the results with the state-of-the-art image distance function used by Google image search.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41388.html
found
=========================
Random Grids: Fast Approximate Nearest Neighbors and Range Searching for Image Search
ICCV 2013
[u'Dror Aiger', u'Efi Kokiopoulou', u'Ehud Rivlin']
MachinePerception
Abstract: We propose two solutions for both nearest neigh- bors and range search problems. For the nearest neighbors problem, we propose a c-approximate so- lution for the restricted version of the decision prob- lem with bounded radius which is then reduced to the nearest neighbors by a known reduction. For range searching we propose a scheme that learns the parameters in a learning stage adopting them to the case of a set of points with low intrinsic dimension that are embedded in high dimensional space (common scenario for image point descrip- tors). We compare our algorithms to the best known methods for these problems, i.e. LSH, ANN and FLANN. We show analytically and experimentally that we can do better for moderate approximation factor. In contrast to tree structures, our algorithms are trivial to parallelize. In the experiments con- ducted, running on couple of million images, our algorithms show meaningful speed-ups when com- pared with the above mentioned methods.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41648.html
notfound
=========================
Rate-Distortion Optimization for Multichannel Audio Compression
2013 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)
[u'Minyue Li', u'Jan Skoglund', u'W. Bastiaan Kleijn']
MachinePerception
Abstract: Multichannel audio coding is studied from a rate-distortion theoret- ical viewpoint. Two practical coding techniques, both of which are based on rate-distortion optimization, are also proposed. The first technique decorrelates a multichannel signal hierarchically using el- ementary unitary transforms. The second method rearranges a mul- tichannel signal into sub-signals and compresses them at optimized bit rates using a conventional codec. Both objective and subjective tests were conducted to illustrate the efficiency of the methods.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41462.html
notfound
=========================
RealBrush: Painting with Examples of Physical Media
ACM Transactions on Graphics (TOG) - SIGGRAPH 2013 Conference Proceedings, vol. 32, no. 4 (2013), 117:1-117:12
[u'Jingwan Lu', u'Connelly Barnes', u'Stephen DiVerdi', u'Adam Finkelstein']
MachinePerception
Abstract: Conventional digital painting systems rely on procedural rules and physical simulation to render paint strokes. We present an interactive, data-driven painting system that uses scanned images of real natural media to synthesize both new strokes and complex stroke interactions, obviating the need for physical simulation. First, users capture images of real media, including examples of isolated strokes, pairs of overlapping strokes, and smudged strokes. Online, the user inputs a new stroke path, and our system synthesizes its 2D texture appearance with optional smearing or smudging when strokes overlap. We demonstrate high-fidelity paintings that closely resemble the captured media style, and also quantitatively evaluate our synthesis quality via user studies.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41375.html
notfound
=========================
Rendering Fur in Life of Pi
ACM, New York, NY, USA
[u'Ivan Neulander', u'Toshi Kato', u'Kevin Beason']
MachinePerception
Abstract: We discuss the innovative fur rendering technology that Rhythm & Hues deployed in the photorealistic depiction of the tiger Richard Parker for Ang Lee's Academy-Award-winning feature film "Life of Pi".
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Reporting Neighbors in High-Dimensional Euclidean Space
SODA (2013)
[u'Dror Aiger', u'Haim Kaplan', u'Micha Sharir']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40752.html
found
=========================
Spatiotemporal Deformable Part Models for Action Detection
Proceedings of International Conference on Computer Vision and Pattern Recognition (CVPR 2013)
[u'Yicong Tian', u'Rahul Sukthankar', u'Mubarak Shah']
MachinePerception
Abstract: Deformable part models have achieved impressive performance for object detection, even on difficult image datasets. This paper explores the generalization of deformable part models from 2D images to 3D spatiotemporal volumes to better study their effectiveness for action detection in video. Actions are treated as spatiotemporal patterns and a deformable part model is generated for each action from a collection of examples. For each action model, the most discriminative 3D subvolumes are automatically selected as parts and the spatiotemporal relations between their locations are learned. By focusing on the most distinctive parts of each action, our models adapt to intra-class variation and show robustness to clutter. Extensive experiments on several video datasets demonstrate the strength of spatiotemporal DPMs for classifying and localizing actions.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41413.html
notfound
=========================
Street View Motion-from-Structure-from-Motion
Proceedings of the International Conference on Computer Vision, IEEE (2013)
[u'Bryan Klingner', u'David Martin', u'James Roseborough']
MachinePerception
Abstract: We describe a structure-from-motion framework that handles "generalized" cameras, such as moving rolling-shutter cameras, and works at an unprecedented scale--billions of images covering millions of linear kilometers of roads--by exploiting a good relative pose prior along vehicle paths. We exhibit a planet-scale, appearance-augmented point cloud constructed with our framework and demonstrate its practical use in correcting the pose of a street-level image collection.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41764.html
notfound
=========================
The Intervalgram: An Audio Feature for Large-Scale Cover-Song Recognition
From Sounds to Music and Emotions: 9th International Symposium, CMMR 2012, London, UK, June 19-22, 2012, Revised Selected Papers, Springer Berlin Heidelberg (2013), pp. 197-213
[u'Thomas C. Walters', u'David A. Ross', u'Richard F. Lyon']
MachinePerception
Abstract: We present a system for representing the musical content of short pieces of audio using a novel chroma-based representation known as the intervalgram, which is a summary of the local pattern of musical intervals in a segment of music. The intervalgram is based on a chroma representation derived from the temporal profile of the stabilized auditory image [10] and is made locally pitch invariant by means of a soft pitch transposition to a local reference. Intervalgrams are generated for a piece of music using multiple overlapping windows. These sets of intervalgrams are used as the basis of a system for detection of identical melodic and harmonic progressions in a database of music. Using a dynamic-programming approach for comparisons between a reference and the song database, performance is evaluated on the covers80 dataset [4]. A first test of an intervalgram-based system on this dataset yields a precision at top-1 of 53.8%, with an ROC curve that shows very high precision up to moderate recall, suggesting that the intervalgram is adept at identifying the easier-to-match cover songs in the dataset with high robustness. The intervalgram is designed to support locality-sensitive hashing, such that an index lookup from each single intervalgram feature has a moderate probability of retrieving a match, with few false matches. With this indexing approach, a large reference database can be quickly pruned before more detailed matching, as in previous content-identification systems.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41769.html
found
=========================
Tracking Large-Scale Video Remix in Real-World Events
IEEE Transactions on Multimedia, vol. 15, no. 6 (2013), pp. 1244-1254
[u'Lexing Xie', u'Apostol Natsev', u'Xuming He', u'John R. Kender', u'Matthew L. Hill', u'John R. Smith']
MachinePerception
Abstract: Content sharing networks, such as YouTube, contain traces of both explicit online interactions (such as likes, comments, or subscriptions), as well as latent interactions (such as quoting, or remixing, parts of a video). We propose visual memes, or frequently re-posted short video segments, for detecting and monitoring such latent video interactions at scale. Visual memes are extracted by scalable detection algorithms that we develop, with high accuracy. We further augment visual memes with text, via a statistical model of latent topics. We model content interactions on YouTube with visual memes, dening several measures of inuence and building predictive models for meme popularity. Experiments are carried out with over 2 million video shots from more than 40,000 videos on two prominent news events in 2009: the election in Iran and the swine u epidemic. In these two events, a high percentage of videos contain remixed content, and it is apparent that traditional news media and citizen journalists have different roles in disseminating remixed content. We perform two quantitative evaluations for annotating visual memes and predicting their popularity. The proposed joint statistical model of visual memes and words outperforms an alternative concurrence model, with an average error of 2% for predicting meme volume and 17% for predicting meme lifespan.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41340.html
notfound
=========================
Understanding Indoor Scenes using 3D Geometric Phrases
Proceedings of International Conference on Computer Vision and Pattern Recognition (CVPR 2013)
[u'Wongun Choi', u'Yu-Wei Chao', u'Caroline Pantofaru', u'Silvio Savarese']
MachinePerception
Abstract: Visual scene understanding is a difficult problem interleaving object detection, geometric reasoning and scene classification. We present a hierarchical scene model for learning and reasoning about complex indoor scenes which is computationally tractable, can be learned from a reasonable amount of training data, and avoids oversimplification. At the core of this approach is the 3D Geometric Phrase Model which captures the semantic and geometric relationships between objects which frequently co-occur in the same 3D spatial configuration. Experiments show that this model effectively explains scene semantics, geometry and object groupings from a single image, while also improving individual object detections.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42244.html
found
=========================
Using Web Co-occurrence Statistics for Improving Image Categorization
arXiv (2013)
[u'Samy Bengio', u'Jeffrey Dean', u'Dumitru Erhan', u'Eugene Ie', u'Quoc Le', u'Andrew Rabinovich', u'Jonathon Shlens', u'Yoram Singer']
MachinePerception
Abstract: Object recognition and localization are important tasks in computer vision. The focus of this work is the incorporation of contextual information in order to improve object recognition and localization. For instance, it is natural to expect not to see an elephant to appear in the middle of an ocean. We consider a simple approach to encapsulate such common sense knowledge using co-occurrence statistics from web documents. By merely counting the number of times nouns (such as elephants, sharks, oceans, etc.) co-occur in web documents, we obtain a good estimate of expected co-occurrences in visual data. We then cast the problem of combining textual co-occurrence statistics with the predictions of image-based classifiers as an optimization problem. The resulting optimization problem serves as a surrogate for our inference procedure. Albeit the simplicity of the resulting optimization problem, it is effective in improving both recognition and localization accuracy. Concretely, we observe significant improvements in recognition and localization rates for both ImageNet Detection 2012 and Sun 2012 datasets.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Video Motion for Every Visible Point
International Conference on Computer Vision (ICCV) (2013)
[u'Susanna Ricco', u'Carlo Tomasi']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40603.html
found
=========================
A QCQP Approach to Triangulation
European Conference on Computer Vision, Springer Verlag (2012)
[u'Chris Aholt', u'Rekha Thomas', u'Sameer Agarwal']
MachinePerception
Abstract: Triangulation of a three-dimensional point from n >=2 two-dimensional images can be formulated as a quadratically constrained quadratic program. We propose an algorithm to extract candidate solutions to this problem from its semidefinite programming relaxations. We then describe a sucient condition and a polynomial time test for certifying when such a solution is optimal. This test has no false positives. Experiments indicate that false negatives are rare, and the algorithm has excellent performance in practice. We explain this phenomenon in terms of the geometry of the triangulation problem.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41101.html
notfound
=========================
All Smiles : Automatic Photo Enhancement by Facial Expression Analysis
Conference for Visual Media Production (CVMP 2012) [Best Paper]
[u'Rajvi Shah', u'Vivek Kwatra']
MachinePerception
Abstract: We propose a framework for automatic enhancement of group photographs by facial expression analysis. We are motivated by the observation that group photographs are seldom perfect. Subjects may have inadvertently closed their eyes, may be looking away, or may not be smiling at that moment. Given a set of photographs of the same group of people, our algorithm uses facial analysis to determine a goodness score for each face instance in those photos. This scoring function is based on classifiers for facial expressions such as smiles and eye-closure, trained over a large set of annotated photos. Given these scores, a best composite for the set is synthesized by (a) selecting the photo with the best overall score, and (b) replacing any low-scoring faces in that photo with high-scoring faces of the same person from other photos, using alignment and seamless composition.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Apparel silhouette attributes recognition
Proceedings of the 2012 IEEE Workshop on the Applications of Computer Vision, IEEE Computer Society, Washington, DC, USA, pp. 489-496
[u'Wei Zhang', u'Emilio Antunez', u'Salih Gokturk', u'Baris Sumengen']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41422.html
found
=========================
Automatically Discovering Talented Musicians with Acoustic Analysis of YouTube Videos
Proceedings of the 2012 IEEE 12th International Conference on Data Mining (ICDM), IEEE Computer Society, Washington, DC, USA, pp. 559-565
[u'Eric Nichols', u'Charles DuHadway', u'Hrishikesh Aradhye', u'Richard F. Lyon']
MachinePerception
Abstract: Online video presents a great opportunity for up-and-coming singers and artists to be visible to a worldwide audience. However, the sheer quantity of video makes it difficult to discover promising musicians. We present a novel algorithm to automatically identify talented musicians using machine learning and acoustic analysis on a large set of "home singing" videos. We describe how candidate musician videos are identified and ranked by singing quality. To this end, we present new audio features specifically designed to directly capture singing quality. We evaluate these vis-a-vis a large set of generic audio features and demonstrate that the proposed features have good predictive performance. We also show that this algorithm performs well when videos are normalized for production quality.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38115.html
found
=========================
Building high-level features using large scale unsupervised learning
International Conference in Machine Learning (2012)
[u'Quoc Le', u"Marc'Aurelio Ranzato", u'Rajat Monga', u'Matthieu Devin', u'Kai Chen', u'Greg Corrado', u'Jeff Dean', u'Andrew Ng']
MachinePerception
Abstract: We consider the problem of building highlevel, class-specic feature detectors from only unlabeled data. For example, is it possible to learn a face detector using only unlabeled images? To answer this, we train a 9-layered locally connected sparse autoencoder with pooling and local contrast normalization on a large dataset of images (the model has 1 billion connections, the dataset has 10 million 200x200 pixel images downloaded from the Internet). We train this network using model parallelism and asynchronous SGD on a cluster with 1,000 machines (16,000 cores) for three days. Contrary to what appears to be a widely-held intuition, our experimental results reveal that it is possible to train a face detector without having to label images as containing a face or not. Control experiments show that this feature detector is robust not only to translation but also to scaling and out-of-plane rotation. We also nd that the same network is sensitive to other high-level concepts such as cat faces and human bodies. Starting with these learned features, we trained our network to obtain 15.8% accuracy in recognizing 20,000 object categories from ImageNet, a leap of 70% relative improvement over the previous state-of-the-art.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37744.html
notfound
=========================
Calibration-Free Rolling Shutter Removal
International Conference on Computational Photography [Best Paper], IEEE (2012)
[u'Matthias Grundmann', u'Vivek Kwatra', u'Daniel Castro', u'Irfan Essa']
MachinePerception
Abstract: We present a novel algorithm for efficient removal of rolling shutter distortions in uncalibrated streaming videos. Our proposed method is calibration free as it does not need any knowledge of the camera used, nor does it require calibration using specially recorded calibration sequences. Our algorithm can perform rolling shutter removal under varying focal lengths, as in videos from CMOS cameras equipped with an optical zoom. We evaluate our approach across a broad range of cameras and video sequences demonstrating robustness, scaleability, and repeatability. We also conducted a user study, which demonstrates preference for the output of our algorithm over other state-of-the art methods. Our algorithm is computationally efficient, easy to parallelize, and robust to challenging artifacts introduced by various cameras with differing technologies.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub39967.html
found
=========================
Capturing Indoor Scenes with Smartphones
Proc. UIST, 651 N. 34th St. (2012) (to appear)
[u'Aditya Sankar', u'Steve Seitz']
MachinePerception
Abstract: In this paper, we present a novel smartphone application designed to easily capture, visualize and reconstruct homes, ofces and other indoor scenes. Our application leverages data from smartphone sensors such as the camera, accelerometer, gyroscope and magnetometer to help model the indoor scene. The output of the system is two-fold; rst, an interactive visual tour of the scene is generated in real time that allows the user to explore each room and transition between connected rooms. Second, with some basic interactive photogrammetric modeling the system generates a 2D oor plan and accompanying 3D model of the scene, under a Manhattan-world assumption. The approach does not require any specialized equipment or training and is able to produce accurate oor plans.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Coherent image selection using a fast approximation to the generalized traveling salesman problem
Proceedings of the 20th ACM international conference on Multimedia, ACM, New York, NY, USA (2012), pp. 981-984
[u'Meng Wang', u'Prakash Ishwar', u'Janusz Konrad', u'Cenk Gazen', u'Rohit Saboo']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38090.html
notfound
=========================
D-Nets: Beyond Patch-Based Image Descriptors
IEEE International Conference on Computer Vision and Pattern Recognition (CVPR'12) (2012)
[u'Felix von Hundelshausen', u'Rahul Sukthankar']
MachinePerception
Abstract: Despite much research on patch-based descriptors, SIFT remains the gold standard for finding correspondences across images and recent descriptors focus primarily on improving speed rather than accuracy. In this paper we propose Descriptor-Nets (D-Nets), a computationally efficient method that significantly improves the accuracy of image matching by going beyond patch-based approaches. D-Nets constructs a network in which nodes correspond to traditional sparsely or densely sampled keypoints, and where image content is sampled from selected edges in this net. Not only is our proposed representation invariant to cropping, translation, scale, reflection and rotation, but it is also significantly more robust to severe perspective and non-linear distortions. We present several variants of our algorithm, including one that tunes itself to the image complexity and an efficient parallelized variant that employs a fixed grid. Comprehensive direct comparisons against SIFT and ORB on standard datasets demonstrate that D-Nets dominates existing approaches in terms of precision and recall while retaining computational efficiency.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41111.html
notfound
=========================
Efficient Closed-Form Solution to Generalized Boundary Detection
Proceedings of European Conference on Computer Vision (ECCV'12) (2012)
[u'Marius Leordeanu', u'Rahul Sukthankar', u'Crisitian Sminchisescu']
MachinePerception
Abstract: Boundary detection is essential for a variety of computer vision tasks such as segmentation and recognition. We propose a unified formulation for boundary detection, with closed-form solution, which is applicable to the localization of different types of boundaries, such as intensity edges and occlusion boundaries from video and RGB-D cameras. Our algorithm simultaneously combines low- and mid-level image representations, in a single eigenvalue problem, and we solve over an infinite set of putative boundary orientations. Moreover, our method achieves state of the art results at a significantly lower computational cost than current methods. We also propose a novel method for soft-segmentation that can be used in conjunction with our boundary detection algorithm and improve its accuracy at a negligible extra computational cost.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Efficient model based single and double thresholding for real time recognition
ACCV Workshop on Detection and Tracking in Challenging Environments (2012)
[u'Dror Aiger', u'Silvio Guimares']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40353.html
notfound
=========================
Embedded Voxel Colouring with Adaptive Threshold Selection Using Globally Minimal Surfaces
IJCV, vol. 99 (2012), pp. 215-231
[u'Carlos Leung', u'Ben Appleton', u'Mitchell Buckley', u'Changming Sun']
MachinePerception
Abstract: Image-based 3D reconstruction remains a competitive field of research as state-of-the-art algorithms continue to improve. This paper presents a voxel-based algorithm that adapts the earliest space-carving methods and utilises a minimal surface technique to obtain a cleaner result. Embedded Voxel Colouring is built in two stages: (a) progressive voxel carving is used to build a volume of embedded surfaces and (b) the volume is processed to obtain a surface that maximises photo-consistency data in the volume. This algorithm combines the strengths of classical carving techniques with those of minimal surface approaches. We require only a single pass through the voxel volume, this significantly reduces computation time and is the key to the speed of our approach. We also specify three requirements for volumetric reconstruction: monotonic carving order, causality of carving and water-tightness. Experimental results are presented that demonstrate the strengths of this approach.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37749.html
notfound
=========================
General and Nested Wiberg Minimization
Computer Vision and Pattern Recognition, IEEE (2012)
[u'Dennis Strelow']
MachinePerception
Abstract: Wiberg matrix factorization breaks a matrix Y into low-rank factors U and V by solving for V in closed form given U, linearizing V(U) about U, and iteratively minimizing ||Y - UV(U)||_2 with respect to U only. This approach factors the matrix while effectively removing V from the minimization. Recently Eriksson and van den Hengel extended this approach to L1, minimizing ||Y - UV(U)||_1. We generalize their approach beyond factorization to minimize an arbitrary function that is nonlinear in each of two sets of variables. We demonstrate the idea with a practical Wiberg algorithm for L1 bundle adjustment. We also show that one Wiberg minimization can be nested inside another, effectively removing two of three sets of variables from a minimization. We demonstrate this idea with a nested Wiberg algorithm for L1 projective bundle adjustment, solving for camera matrices, points, and projective depths. We also revisit L1 factorization, giving a greatly simplified presentation of Wiberg L1 factorization, and presenting a successive linear programming factorization algorithm. Successive linear programming outperforms L1 Wiberg for most large inputs, establishing a new state-of-the-art for for those cases.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38310.html
found
=========================
General and nested Wiberg minimization: L2 and maximum likelihood
European Conference on Computer Vision, Springer (2012)
[u'Dennis Strelow']
MachinePerception
Abstract: Wiberg matrix factorization breaks a matrix Y into low-rank factors U and V by solving for V in closed form given U, linearizing V (U) about U, and iteratively minimizing jjY UV (U)jj2 with respect to U only. This approach factors the matrix while eectively removing V from the minimization. We generalize the Wiberg approach beyond factorization to minimize an arbitrary function that is nonlinear in each of two sets of variables. In this paper we focus on the case of L2 minimization and maximum likelihood estimation (MLE), presenting an L2 Wiberg bundle adjustment algorithm and a Wiberg MLE algorithm for Poisson matrix factorization. We also show that one Wiberg minimization can be nested inside another, eectively removing two of three sets of variables from a minimization. We demonstrate this idea with a nested Wiberg algorithm for L2 projective bundle adjustment, solving for camera matrices, points, and projective depths.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
IMPROVED PREDICTION OF NEARLY-PERIODIC SIGNALS
International Workshop on Acoustic Signal Enhancement 2012 (IWAENC2012)
[u'Bastiaan Kleijn', u'Jan Skoglund']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37481.html
notfound
=========================
Improving Book OCR by Adaptive Language and Image Models
Proceedings of 2012 10th IAPR International Workshop on Document Analysis Systems, IEEE, pp. 115-119
[u'Dar-Shyang Lee', u'Ray Smith']
MachinePerception
Abstract: In order to cope with the vast diversity of book content and typefaces, it is important for OCR systems to leverage the strong consistency within a book but adapt to variations across books. In this work, we describe a system that combines two parallel correction paths using document-specific image and language models. Each model adapts to shapes and vocabularies within a book to identify inconsistencies as correction hypotheses, but relies on the other for effective cross-validation. Using the open source Tesseract engine as baseline, results on a large dataset of scanned books demonstrate that word error rates can be reduced by 25% using this approach.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40575.html
found
=========================
Joint Image and Word Sense Discrimination For Image Retrieval
ECCV (2012)
[u'Aurelien Lucchi', u'Jason Weston']
MachinePerception
Abstract: We study the task of learning to rank images given a text query, a problem that is complicated by the issue of multiple senses. That is, the senses of interest are typically the visually distinct concepts that a user wishes to retrieve. In this paper, we propose to learn a ranking function that optimizes the ranking cost of interest and simultaneously discovers the disambiguated senses of the query that are optimal for the supervised task. Note that no supervised information is given about the senses. Experiments performed on web images and the ImageNet dataset show that using our approach leads to a clear gain in performance.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41321.html
found
=========================
Learning Hierarchical Bag of Words Using Naive Bayes Clustering
Asian Conference on Computer Vision (2012), pp. 382-395
[u'Siddhartha Chandra', u'Shailesh Kumar', u'C. V. Jawahar']
MachinePerception
Abstract: Image analysis tasks such as classication, clustering, detection, and retrieval are only as good as the feature representation of the images they use. Much research in computer vision is focused on finding better or semantically richer image representations. Bag of visual Words (BoW) is a representation that has emerged as an eective one for a variety of computer vision tasks. BoW methods traditionally use low level features. We have devised a strategy to use these low level features to create \higher level" features by making use of the spatial context in images. In this paper, we propose a novel hierarchical feature learning framework that uses a Naive Bayes Clustering algorithm to convert a 2-D symbolic image at one level to a 2-D symbolic image at the next level with richer features. On two popular datasets, Pascal VOC 2007 and Caltech 101, we empirically show that classication accuracy obtained from the hierarchical features computed using our approach is signicantly higher than the traditional SIFT based BoW representation of images even though our image representations are more compact.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40567.html
found
=========================
MEASURING NOISE CORRELATION FOR IMPROVED VIDEO DENOISING
IEEE International Conference on Image Processing, IEEE, 1600 Amphitheatre Parkway (2012)
[u'Anil Kokaram', u'Damien Kelly', u'Hugh Denman', u'Andrew Crawford']
MachinePerception
Abstract: The vast majority of previous work in noise reduction for visual media has assumed uncorrelated, white, noise sources. In practice this is almost always violated by real media. Film grain noise is never white, and this paper highlights that the same applies to almost all consumer video content. We therefore present an algorithm for measuring the spatial and temporal spectral density of noise in archived video content, be it consumer digital camera or film orginated. As an example of how this information can be used for video denoising, the spectral density is then used for spatio-temporal noise reduction in the Fourier frequency domain. Results show improved performance for noise reduction in an easily pipelined system.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Measuring the Objectness of Image Windows
IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 34/11 (2012), pp. 2189-2202
[u'Bogdan Alexe', u'Thomas Deselaers', u'Vittorio Ferrari']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37754.html
notfound
=========================
Mobile Music Modeling, Analysis and Recognition
International Conference on Acoustics, Speech, and Signal Processing (ICASSP) (2012)
[u'Pavel Golik', u'Boulos Harb', u'Ananya Misra', u'Michael Riley', u'Alex Rudnick', u'Eugene Weinstein']
MachinePerception
Abstract: We present an analysis of music modeling and recognition techniques in the context of mobile music matching, substantially improving on the techniques presented in [Mohri et al., 2010]. We accomplish this by adapting the features specifically to this task, and by introducing new modeling techniques that enable using a corpus of noisy and channel-distorted data to improve mobile music recognition quality. We report the results of an extensive empirical investigation of the system's robustness under realistic channel effects and distortions. We show an improvement of recognition accuracy by explicit duration modeling of music phonemes and by integrating the expected noise environment into the training process. Finally, we propose the use of frame-to-phoneme alignment for high-level structure analysis of polyphonic music.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38093.html
found
=========================
Model Recommendation for Action Recognition
IEEE International Conference on Computer Vision and Pattern Recognition (CVPR'12) (2012)
[u'Pyry Matikainen', u'Rahul Sukthankar', u'Martial Hebert']
MachinePerception
Abstract: Simply choosing one model out of a large set of possibilities for a given vision task is a surprisingly difficult problem, especially if there is limited evaluation data with which to distinguish among models, such as when choosing the best ``walk'' action classifier from a large pool of classifiers tuned for different viewing angles, lighting conditions, and background clutter. In this paper we suggest that this problem of selecting a good model can be recast as a recommendation problem, where the goal is to recommend a good model for a particular task based on how well a limited probe set of models appears to perform. Through this conceptual remapping, we can bring to bear all the collaborative filtering techniques developed for consumer recommender systems (e.g., Netflix, Amazon.com). We test this hypothesis on action recognition, and find that even when every model has been directly rated on a training set, recommendation finds better selections for the corresponding test set than the best performers on the training set.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Modelling the Distortion Produced by Cochlear Compression
16th International Symposium on Hearing (2012)
[u'Roy D. Patterson', u'Timothy Ives', u'Thomas C. Walters', u'Richard F. Lyon']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Molli: Interactive Visualization for Exploratory Protein Analysis
IEEE Computer Graphics & Applications, vol. 32 (2012), pp. 62-69
[u'Sara L. Su', u'Connor Gramazio', u'Megan Strait', u'Caitlin Crumm', u'Daniela Extrum-Fernandez', u'Matt Menke', u'Lenore Cowen']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40665.html
notfound
=========================
Multi-component Models for Object Detection
European Conference on Computer Vision, Springer (2012), Volume 4, 445-458
[u'Chunhui Gu', u'Pablo Arbelaez', u'Yuanqing Lin', u'Kai Yu', u'Jitendra Malik']
MachinePerception
Abstract: In this paper, we propose a multi-component approach for object detection. Rather than attempting to represent an object category with a monolithic model, or pre-defining a reduced set of aspects, we form visual clusters from the data that are tight in appearance and configuration spaces. We train individual classifiers for each component, and then learn a second classifier that operates at the category level by aggregating responses from multiple components. In order to reduce computation cost during detection, we adopt the idea of object window selection, and our segmentation-based selection mechanism produces fewer than 500 windows per image while preserving high object recall. When compared to the leading methods in the challenging VOC PASCAL 2010 dataset, our multi-component approach obtains highly competitive results. Furthermore, unlike monolithic detection methods, our approach allows the transfer of finer-grained semantic information from the components, such as keypoint location and segmentation masks.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38105.html
found
=========================
Multimedia Semantics: Interactions Between Content and Community
Proceedings of the IEEE, vol. 100, no. 9 (2012)
[u'Hari Sundaram', u'Lexing Xie', u'Munmun De Choudhury', u'Yu-Ru Lin', u'Apostol Natsev']
MachinePerception
Abstract: This paper reviews the state of the art and some emerging issues in research areas related to pattern analysis and monitoring of web-based social communities. This research area is important for several reasons. First, the presence of near-ubiquitous low-cost computing and communication technologies has enabled people to access and share information at an unprecedented scale. The scale of the data necessitates new research for making sense of such content. Furthermore, popular websites with sophisticated media sharing and notification features allow users to stay in touch with friends and loved ones; these sites also help to form explicit and implicit social groups. These social groups are an important source of information to organize and to manage multimedia data. In this article, we study how media-rich social networks provide additional insight into familiar multimedia research problems, including tagging and video ranking. In particular, we advance the idea that the contextual and social aspects of media are as important for successful multimedia applications as is the media content. We examine the interrelationship between content and social context through the prism of three key questions. First, how do we extract the context in which social interactions occur? Second, does social interaction provide value to the media object? Finally, how do social media facilitate the repurposing of shared content and engender cultural memes? We present three case studies to examine these questions in detail. In the first case study, we show how to discover structure latent in the social media data, and use the discovered structure to organize Flickr photo streams. In the second case study, we discuss how to determine the interestingness of conversations---and of participants---around videos uploaded to YouTube. Finally, we show how the analysis of visual content, in particular tracing of content remixes, can help us understand the relationship among YouTube participants. For each case, we present an overview of recent work and review the state of the art. We also discuss two emerging issues related to the analysis of social networks---robust data sampling and scalable data analysis.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40644.html
found
=========================
On Using Nearly-Independent Feature Families for High Precision and Confidence
Fourth Asian Machine Learning Conference, JMLR workshop and conference proceedings (2012), pp. 269-284
[u'Omid Madani', u'Manfred Georg', u'David Ross']
MachinePerception
Abstract: Often we require classification at a very high precision level, such as 99%. We report that when very different sources of evidence such as text, audio, and video features are available, combining the outputs of base classifiers trained on each feature type separately, aka late fusion, can substantially increase the recall of the combination at high precisions, compared to the performance of a single classifier trained on all the feature types i.e., early fusion, or compared to the individual base classifiers. We show how the probability of a joint false-positive mistake can be upper bounded by the product of individual probabilities of conditional false-positive mistakes, by identifying a simple key criterion that needs to hold. This provides an explanation for the high precision phenomenon, and motivates referring to such feature families as (nearly) independent. We assess the relevant factors for achieving high precision empirically, and explore combination techniques informed by the analysis. We compare a number of early and late fusion methods, and observe that classifier combination via late fusion can more than double the recall at high precision.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Photo Tours
3DimPVT 2012 (to appear)
[u'Avanish Kushal', u'Ben Self', u'Yasutaka Furukawa', u'David Gallup', u'Carlos Hernandez', u'Brian Curless', u'Steve Seitz']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub39958.html
found
=========================
Real-Time Human Pose Tracking from Range Data
Proceedings of the European Conference on Computer Vision (ECCV) (2012)
[u'Varun Ganapathi', u'Christian Plagemann', u'Daphne Koller', u'Sebastian Thrun']
MachinePerception
Abstract: Tracking human pose in real-time is a difficult problem with many interesting applications. Existing solutions suffer from a variety of problems, especially when confronted with unusual human poses. In this paper, we derive an algorithm for tracking human pose in real-time from depth sequences based on MAP inference in a probabilistic temporal model. The key idea is to extend the iterative closest points (ICP) objective by modeling the constraint that the observed subject cannot enter free space, the area of space in front of the true range measurements. Our primary contribution is an extension to the articulated ICP algorithm that can efficiently enforce this constraint. Our experiments show that including this term improves tracking accuracy significantly. The resulting filter runs at 125 frames per second using a single desktop CPU core. We provide extensive experimental results on challenging real-world data, which show that the algorithm outperforms the previous state-of the-art trackers both in computational efficiency and accuracy.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub39963.html
notfound
=========================
Reconstructing the World's Museums
European Conference on Computer Vision (2012) (to appear)
[u'Jianxiong Xiao', u'Yasutaka Furukawa']
MachinePerception
Abstract: Photorealistic maps are a useful navigational guide for large indoor environments, such as museums and businesses. However, it is impossible to acquire photographs covering a large indoor environment from aerial viewpoints. This paper presents a 3D reconstruction and visualization system to automatically produce clean and well-regularized texture-mapped 3D models for large indoor scenes, from ground-level photographs and 3D laser points. The key component is a new algorithm called "Inverse CSG" for reconstructing a scene in a Constructive Solid Geometry (CSG) representation consisting of volumetric primitives, which imposes powerful regularization constraints to exploit structural regularities. We also propose several techniques to adjust the 3D model to make it suitable for rendering the 3D maps from aerial viewpoints. The visualization system enables users to easily browse a large scale indoor environment from a bird's-eye view, locate specific room interiors, fly into a place of interest, view immersive ground-level panorama views, and zoom out again, all with seamless 3D transitions. We demonstrate our system on various museums, including the Metropolitan Museum of Art in New York City -- one of the largest art galleries in the world.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40601.html
notfound
=========================
Refractive Height Fields from Single and Multiple Images
IEEE Conference on Computer Vision and Pattern Recognition, IEEE (2012)
[u'Qi Shan', u'Sameer Agarwal', u'Brian Curless']
MachinePerception
Abstract: We propose a novel framework for reconstructing homogenous, transparent, refractive height-elds from a single viewpoint. The height-eld is imaged against a known planar background, or sequence of backgrounds. Unlike existing approaches that do a point-by-point reconstruction which is known to have intractable ambiguities our method estimates and optimizes for the entire height-eld at the same time. The formulation supports shape recovery from measured distortions (deections) or directly from the images themselves, including from a single image. We report results for a variety of refractive height-elds showing signicant improvement over prior art.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Repetition Maximization based Texture Rectification
EUROGRAPHICS 2012
[u'Dror Aiger', u'Niloy Mitra', u'Daniel Cohen-Or']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41794.html
notfound
=========================
Scene Aligned Pooling for Complex Video Recognition
ECCV (2012), pp. 688-701
[u'Liangliang Cao', u'Yadong Mu', u'Apostol Natsev', u'Shih-Fu Chang', u'Gang Hua', u'John R. Smith']
MachinePerception
Abstract: Real-world videos often contain dynamic backgrounds and evolving people activities, especially for those web videos generated by users in unconstrained scenarios. This paper proposes a new visual representation, namely scene aligned pooling, for the task of event recognition in complex videos. Based on the observation that a video clip is often composed with shots of different scenes, the key idea of scene aligned pooling is to decompose any video features into concurrent scene components, and to construct classification models adaptive to different scenes. The experiments on two large scale real-world datasets including the TRECVID Multimedia Event Detection 2011 and the Human Motion Recognition Databases (HMDB) show that our new visual representation can consistently improve various kinds of visual features such as different low-level color and texture features, or middle-level histogram of local descriptors such as SIFT, or space-time interest points, and high level semantic model features, by a significant margin. For example, we improve the-state-of-the-art accuracy on HMDB dataset by 20% in terms of accuracy.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40600.html
notfound
=========================
Schematic Surface Reconstruction
IEEE Conference on Computer Vision and Pattern Recognition, IEEE (2012)
[u'Changchang Wu', u'Sameer Agarwal', u'Brian Curless', u'Steven M. Seitz']
MachinePerception
Abstract: This paper introduces a schematic representation for architectural scenes together with robust algorithms for reconstruction from sparse 3D point cloud data. The schematic models architecture as a network of transport curves, approximating a oorplan, with associated prole curves, together comprising an interconnected set of swept surfaces. The representation is extremely concise, composed of a handful of planar curves, and easily interpretable by humans. The approach also provides a principled mechanism for interpolating a dense surface, and enables lling in holes in the data, by means of a pipeline that employs a global optimization over all parameters. By incorporating a displacement map on top of the schematic surface, it is possible to recover ne details. Experiments show the ability to reconstruct extremely clean and simple models from sparse structure-from-motion point clouds of complex architectural scenes.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40666.html
notfound
=========================
Semantic Segmentation Using Regions and Parts
Computer Vision and Pattern Recognition, IEEE Computer Society Washington, DC, USA (2012), pp. 3378-3385
[u'Pablo Arbelaez', u'Bharath Hariharan', u'Chunhui Gu', u'Saurabh Gupta', u'Lubomir Bourdev', u'Jitendra Malik']
MachinePerception
Abstract: We address the problem of segmenting and recognizing objects in real world images, focusing on challenging articulated categories such as humans and other animals. For this purpose, we propose a novel design for region-based object detectors that integrates efficiently top-down information from scanning-windows part models and global appearance cues. Our detectors produce class-specific scores for bottom-up regions, and then aggregate the votes of multiple overlapping candidates through pixel classification. We evaluate our approach on the PASCAL segmentation challenge, and report competitive performance with respect to current leading techniques. On VOC2010, our method obtains the best results in 6/20 categories and the highest performance on articulated objects.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Semi-Supervised Hashing for Large Scale Search
IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI) (2012)
[u'Jun Wang', u'Sanjiv Kumar', u'Shih-Fu Chang']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37743.html
notfound
=========================
Shadow Removal for Aerial Imagery by Information Theoretic Intrinsic Image Analysis
International Conference on Computational Photography, IEEE (2012)
[u'Vivek Kwatra', u'Mei Han', u'Shengyang Dai']
MachinePerception
Abstract: We present a novel technique for shadow removal based on an information theoretic approach to intrinsic image analysis. Our key observation is that any illumination change in the scene tends to increase the entropy of observed texture intensities. Similarly, the presence of texture in the scene increases the entropy of the illumination function. Consequently, we formulate the separation of an image into texture and illumination components as minimization of entropies of each component. We employ a non-parametric kernel-based quadratic entropy formulation, and present an efficient multi-scale iterative optimization algorithm for minimization of the resulting energy functional. Our technique may be employed either fully automatically, using a proposed learning based method for automatic initialization, or alternatively with small amount of user interaction. As we demonstrate, our method is particularly suitable for aerial images, which consist of either distinctive texture patterns, e.g. building facades, or soft shadows with large diffuse regions, e.g. cloud shadows.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41923.html
notfound
=========================
Size Matters: Exhaustive Geometric Verification for Image Retrieval
12th European Conference on Computer Vision (ECCV), Springer (2012), pp. 674-687
[u'Henrik Stewenius', u'Steinar H. Gunderson', u'Julien Pilet']
MachinePerception
Abstract: The overreaching goals in large-scale image retrieval are bigger, better and cheaper. For systems based on local features we show how to get both efficient geometric verification of every match and unprecedented speed for the low sparsity situation. Large-scale systems based on quantized local features usually process the index one term at a time, forcing two separate scoring steps: First, a scoring step to find candidates with enough matches, and then a geometric verification step where a subset of the candidates are checked. Our method searches through the index a document at a time, verifying the geometry of every candidate in a single pass. We study the behavior of several algorithms with respect to index density---a key element for large-scale databases. In order to further improve the efficiency we also introduce a new new data structure, called the counting min-tree, which outperforms other approaches when working with low database density, a necessary condition for very large-scale systems. We demonstrate the effectiveness of our approach with a proof of concept system that can match an image against a database of more than 90~billion images in just a few seconds.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Street view goes indoors: Automatic pose estimation from uncalibrated unordered spherical panoramas
Proceedings of the 2012 IEEE Workshop on the Applications of Computer Vision, IEEE Computer Society, Washington, DC, USA, pp. 1-8
[u'Mohamed Aly', u'Jean-Yves Bouguet']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40358.html
found
=========================
Unsupervised Learning for Graph Matching
International Journal of Computer Vision, vol. 96 (2012), pp. 28-45
[u'Marius Leordeanu', u'Rahul Sukthankar', u'Martial Hebert']
MachinePerception
Abstract: Graph matching is an essential problem in computer vision that has been successfully applied to 2D and 3D feature matching and object recognition. Despite its importance, little has been published on learning the parameters that control graph matching, even though learning has been shown to be vital for improving the matching rate. In this paper, we show how to perform parameter learning in an unsupervised fashion, that is when no correct correspondences between graphs are given during training. Our experiments reveal that unsupervised learning compares favorably to the supervised case, both in terms of efficiency and quality, while avoiding the tedious manual labeling of ground truth correspondences. We verify experimentally that our learning method can improve the performance of several state-of-the-art matching algorithms. We also show that a similar method can be successfully applied to parameter learning for graphical models and demonstrate its effectiveness empirically.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
VISQOL: THE VIRTUAL SPEECH QUALITY OBJECTIVE LISTENER
International Workshop on Acoustic Signal Enhancement 2012 (IWAENC2012)
[u'Andrew Hines', u'Jan Skoglund', u'Anil Kokaram', u'Naomi Harte']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40346.html
found
=========================
Video Description Length Guided Constant Quality Video Coding with Bitrate Constraint
Multimedia and Expo Workshops (ICMEW), 2012 IEEE International Conference on, IEEE, 2001 L Street, NW. Suite 700 Washington, DC 20036-4910 USA, pp. 366-371
[u'Lei Yang', u'Debargha Mukherjee', u'Dapeng Wu']
MachinePerception
Abstract: In this paper, we propose a new video encoding strategy - Video description length guided Constant Quality video coding with Bitrate Constraint (V-CQBC), for large scale video transcoding systems of video charing websites with varying unknown video contents. It provides smooth quality and saves bitrate and computation for transcoding millions of videos in both real time and batch mode. The new encoding strategy is based on the average bitrate-quality regression model and adapt to the encoded videos. Furthermore, three types of video description length (VDL), describing the video overall, spatial and temporal content complexity, are proposed to guide video coding. Experimental results show that the proposed coding strategy with saved computation could achieve better or similar RD performance than other coding strategies.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40602.html
notfound
=========================
Visibility Based Preconditioning for Bundle Adjustment
IEEE Conference on Computer Vision and Pattern Recognition, IEEE (2012)
[u'Avanish Kushal', u'Sameer Agarwal']
MachinePerception
Abstract: We present Visibility Based Preconditioning (VBP) a new technique for efciently solving the linear least squares problems that arise in bundle adjustment. Using the camera-point visibility structure of the scene, we describe the construction of two preconditioners. These preconditioners when combined with an inexact step LevenbergMarquardt algorithm offer state of the art performance on the BAL data set, with 3-5x reduction in execution time over currently available methods while delivering comparable or better solution quality
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40735.html
found
=========================
Weakly Supervised Learning of Object Segmentations from Web-Scale Video
ECCV'12 Proceedings of the 12th international conference on Computer Vision - Volume Part I, Springer-Verlag, Berlin, Heidelberg (2012), pp. 198-208
[u'Glenn Hartmann', u'Matthias Grundmann', u'Judy Hoffman', u'David Tsai', u'Vivek Kwatra', u'Omid Madani', u'Sudheendra Vijayanarasimhan', u'Irfan Essa', u'James Rehg', u'Rahul Sukthankar']
MachinePerception
Abstract: We propose to learn pixel-level segmentations of objects from weakly labeled (tagged) internet videos. Specifically, given a large collection of raw YouTube content, along with potentially noisy tags, our goal is to automatically generate spatiotemporal masks for each object, such as "dog", without employing any pre-trained object detectors. We formulate this problem as learning weakly supervised classifiers for a set of independent spatio-temporal segments. The object seeds obtained using segment-level classifiers are further refined using graphcuts to generate high-precision object masks. Our results, obtained by training on a dataset of 20,000 YouTube videos weakly tagged into 15 classes, demonstrate automatic extraction of pixel-level object masks. Evaluated against a ground-truthed subset of 50,000 frames with pixel-level annotations, we confirm that our proposed methods can learn good object masks just by watching YouTube.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37125.html
notfound
=========================
A Hierarchical Conditional Random Field Model for Labeling and Images of Street Scenes
International Conference on Computer Vision and Pattern Recognition (2011)
[u'Qixing Huang', u'Mei Han', u'Bo Wu', u'Sergey Ioffe']
MachinePerception
Abstract: Simultaneously segmenting and labeling images is a fundamental problem in Computer Vision. In this paper, we introduce a hierarchical CRF model to deal with the problem of labeling images of street scenes by several distinctive object classes. In addition to learning a CRF model from all the labeled images, we group images into clusters of similar images and learn a CRF model from each cluster separately. When labeling a new image, we pick the closest cluster and use the associated CRF model to label this image. Experimental results show that this hierarchical image labeling method is comparable to, and in many cases superior to, previous methods on benchmark data sets. In addition to segmentation and labeling results, we also showed how to apply the image labeling result to rerank Google similar images.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37210.html
notfound
=========================
A Pole-Zero Filter Cascade Provides Good Fits to Human Masking Data and to Basilar Membrane and Neural Data
Mechanics of Hearing (2011)
[u'Richard F. Lyon']
MachinePerception
Abstract: A cascade of two-poletwo-zero filters with level-dependent pole and zero dampings, with few parameters, can provide a good match to human psychophysical and physiological data. The model has been fitted to data on detection threshold for tones in notched-noise masking, including bandwidth and filter shape changes over a wide range of levels, and has been shown to provide better fits with fewer parameters compared to other auditory filter models such as gammachirps. Originally motivated as an efficient machine implementation of auditory filtering related to the WKB analysis method of cochlear wave propagation, such filter cascades also provide good fits to mechanical basilar membrane data, and to auditory nerve data, including linear low-frequency tail response, level-dependent peak gain, sharp tuning curves, nonlinear compression curves, level-independent zero-crossing times in the impulse response, realistic instantaneous frequency glides, and appropriate level-dependent group delay even with minimum-phase response. As part of exploring different level-dependent parameterizations of such filter cascades, we have identified a simple sufficient condition for stable zero-crossing times, based on the shifting property of the Laplace transform: simply move all the $s$-domain poles and zeros by equal amounts in the real-$s$ direction. Such pole-zero filter cascades are efficient front ends for machine hearing applications, such as music information retrieval, content identification, speech recognition, and sound indexing.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Aesthetics and Emotions in Images
IEEE Signal Processing Magazine, vol. vol. 28, no. 5 (2011), pp. 94-115
[u'Dhiraj Joshi', u'Ritendra Datta', u'Elena Fedorovskaya', u'Quang-Tuan Luong', u'James Z. Wang', u'Jia Li', u'Jiebo Luo']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36950.html
notfound
=========================
Auditory Sparse Coding
Music Data Mining, CRC Press/Chapman Hall (2011)
[u'Steven R. Ness', u'Thomas Walters', u'Richard F. Lyon']
MachinePerception
Abstract: The concept of sparsity has attracted considerable interest in the field of machine learning in the past few years. Sparse feature vectors contain mostly values of zero and one or a few non-zero values. Although these feature vectors can be classified by traditional machine learning algorithms, such as SVM, there are various recently-developed algorithms that explicitly take advantage of the sparse nature of the data, leading to massive speedups in time, as well as improved performance. Some fields that have benefited from the use of sparse algorithms are finance, bioinformatics, text mining, and image classification. Because of their speed, these algorithms perform well on very large collections of data; large collections are becoming increasingly relevant given the huge amounts of data collected and warehoused by Internet businesses. We discuss the application of sparse feature vectors in the field of audio analysis, and specifically their use in conjunction with preprocessing systems that model the human auditory system. We present results that demonstrate the applicability of the combination of auditory-based processing and sparse coding to content-based audio analysis tasks: a search task in which ranked lists of sound effects are retrieved from text queries, and a music information retrieval (MIR) task dealing with the classification of music into genres.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37041.html
notfound
=========================
Auto-Directed Video Stabilization with Robust L1 Optimal Camera Paths
IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2011)
[u'Matthias Grundmann', u'Vivek Kwatra', u'Irfan Essa']
MachinePerception
Abstract: We present a novel algorithm for automatically applying constrainable, L1-optimal camera paths to generate stabilized videos by removing undesired motions. Our goal is to compute camera paths that are composed of constant, linear and parabolic segments mimicking the camera motions employed by professional cinematographers. To this end, our algorithm is based on a linear programming framework to minimize the first, second, and third derivatives of the resulting camera path. Our method allows for video stabilization beyond the conventional filtering of camera paths that only suppresses high frequency jitter. We incorporate additional constraints on the path of the camera directly in our algorithm, allowing for stabilized and retargeted videos. Our approach accomplishes this without the need of user interaction or costly 3D reconstruction of the scene, and works as a post-process for videos from any camera or from an online source.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Automatic Language Identification in Music Videos with Low Level Audio and Visual Features
Proceedings of the IEEE Conference on Acoustics, Speech, and Signal Processing (ICASSP) (2011)
[u'Vijay Chandrasekhar', u'Mehmet Emre Sargin', u'David A. Ross']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Boosting Video Classification Using Cross-Video Signals
Proceedings of the IEEE Conference on Acoustics, Speech, and Signal Processing (ICASSP) (2011) (to appear)
[u'Mehmet Emre Sargin', u'Hrishikesh Aradhye']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40599.html
notfound
=========================
Building Rome in a day
Communications of the ACM, vol. 54 (2011), pp. 105-112
[u'Sameer Agarwal', u'Yasutaka Furukawa', u'Noah Snavely', u'Ian Simon', u'Brian Curless', u'Steven M. Seitz', u'Rick Szeliski']
MachinePerception
Abstract: We present a system that can reconstruct 3D geometry from large, unorganized collections of photographs such as those found by searching for a given city (e.g., Rome) on Internet photo-sharing sites. Our system is built on a set of new, distributed computer vision algorithms for image matching and 3D reconstruction, designed to maximize parallelism at each stage of the pipeline and to scale gracefully with both the size of the problem and the amount of available computation. Our experimental results demonstrate that it is now possible to reconstruct city-scale image collections with more than a hundred thousand images in less than a day.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36963.html
notfound
=========================
Cascades of two-poletwo-zero asymmetric resonators are good models of peripheral auditory function
Journal of the Acoustical Society of America, vol. 130 (2011), pp. 3893-3904
[u'Richard F. Lyon']
MachinePerception
Abstract: A cascade of two-poletwo-zero filter stages is a good model of the auditory periphery in two distinct ways. First, in the form of the polezero filter cascade, it acts as an auditory filter model that provides an excellent fit to data on human detection of tones in masking noise, with fewer fitting parameters than previously reported filter models such as the roex and gammachirp models. Second, when extended to the form of the cascade of asymmetric resonators with fast-acting compression, it serves as an efficient front-end filterbank for machine-hearing applications, including dynamic nonlinear effects such as fast wide-dynamic-range compression. In their underlying linear approximations, these filters are described by their poles and zeros, that is, by rational transfer functions, which makes them simple to implement in analog or digital domains. Other advantages in these models derive from the close connection of the filter-cascade architecture to wave propagation in the cochlea. These models also reflect the automatic-gain-control function of the auditory system and can maintain approximately constant impulse-response zero-crossing times as the level-dependent parameters change. Copyright (2011) Acoustical Society of America. This article may be downloaded for personal use only. Any other use requires prior permission of the author and the Acoustical Society of America. The article appeared in J. Acoust. Soc. Am. vol. 130 and may be found via http://asadl.org/jasa/resource/1/jasman/v130/i6/p3893_s1.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37424.html
found
=========================
Crowdsourcing Event Detection in YouTube Videos
Detection, Representation, and Exploitation of Events in the Semantic Web (DeRiVE 2011), Bonn, Germany
[u'Thomas Steiner', u'Ruben Verborgh', u'Rik Van de Walle', u'Michael Hausenblas', u'Joaquim Gabarro']
MachinePerception
Abstract: Considerable efforts have been put into making video content on the Web more accessible, searchable, and navigable by research on both textual and visual analysis of the actual video content and the accompanying metadata. Nevertheless, most of the time, videos are opaque objects in websites. With Web browsers gaining more support for the HTML5 element, videos are becoming first class citizens on the Web. In this paper we show how events can be detected on-the-fly through crowdsourcing (i) textual, (ii) visual, and (iii) behavioral analysis in YouTube videos, at scale. The main contribution of this paper is a generic crowdsourcing framework for automatic and scalable semantic annotations of HTML5 videos. Eventually, we discuss our preliminary results using traditional server-based approaches to video event detection as a baseline.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37297.html
notfound
=========================
Discrete Point Based Signatures and Applications to Document Matching
ICIAP 2011
[u'Nemanja Spasojevic', u'Guillaume Poncin', u'Dan Bloomberg']
MachinePerception
Abstract: Document analysis often starts with robust signatures, for instance for document lookup from low-quality photographs, or similarity analysis between scanned books. Signatures based on OCR typically work well, but require good quality OCR, which is not always available and can be very costly. In this paper we describe a novel scheme for extracting discrete signatures from document images. It operates on points that describe the position of words, typically the centroid. Each point is extracted using one of several techniques and assigned a signature based on its relation to the nearest neighbors. We will discuss the benefits of this approach, and demonstrate its application to multiple problems including fast image similarity calculation and document lookup.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36931.html
notfound
=========================
Discriminative Tag Learning on YouTube Videos with Latent Sub-tags
Computer Vision and Pattern Recognition, IEEE (2011)
[u'Weilong Yang', u'George Toderici']
MachinePerception
Abstract: We consider the problem of content-based automated tag learning. In particular, we address semantic varia- tions (sub-tags) of the tag. Each video in the training set is assumed to be associated with a sub-tag label, and we treat this sub-tag label as latent information. A latent learning framework based on LogitBoost is proposed which jointly considers both tag label and the latent sub-tag label. The latent sub-tag information is exploited in our frame- work to assist the learning of our end goal, i.e., tag predic- tion. We use the cowatch information to initialize the learn- ing process. In experiments, we show that the proposed method achieves signicantly better results over baselines on a large-scale testing video set which contains about 50 million YouTube videos.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37394.html
notfound
=========================
Dynamic Stylized Shading Primitives
Proc. Symposium on NonPhotorealistic Animation and Rendering (NPAR 2011), ACM
[u'David Vanderhaeghe', u'Romain Vergne', u'Pascal Barla', u'William Baxter']
MachinePerception
Abstract: Shading appearance in illustrations, comics and graphic novels is designed to convey illumination, material and surface shape characteristics at once. Moreover, shading may vary depending on different configurations of surface distance, lighting, character expressions, timing of the action, to articulate storytelling or draw attention to a part of an object. In this paper, we present a method that imitates such expressive stylized shading techniques in dynamic 3D scenes, and which offers a simple and flexible means for artists to design and tweak the shading appearance and its dynamic behavior. The key contribution of our approach is to seamlessly vary appearance by using a combination of shading primitives that take into account lighting direction, material characteristics and surface features. We demonstrate their flexibility in a number of scenarios: minimal shading, comics or cartoon rendering, glossy and anisotropic material effects; including a variety of dynamic variations based on orientation, timing or depth. Our prototype implementation combines shading primitives with a layered approach and runs in real-time on the GPU
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37110.html
notfound
=========================
Exploring Photobios
ACM Trans. on Graphics (Proc. SIGGRAPH), vol. 30(4) (2011) (to appear)
[u'Ira Kemelmacher-Shlizerman', u'Eli Shechtman', u'Rahul Garg', u'Steven Seitz']
MachinePerception
Abstract: We present an approach for generating face animations from large image collections of the same person. Such collections, which we call photobios, sample the appearance of a person over changes in pose, facial expression, hairstyle, age, and other variations. By optimizing the order in which images are displayed and crossdissolving between them, we control the motion through face space and create compelling animations (e.g., render a smooth transition from frowning to smiling). Used in this context, the cross dissolve produces a very strong motion effect; a key contribution of the paper is to explain this effect and analyze its operating range. The approach operates by creating a graph with faces as nodes, and similarities as edges, and solving for walks and shortest paths on this graph. The processing pipeline involves face detection, locating ducials (eyes/nose/mouth), solving for pose, warping to frontal views, and image comparison based on Local Binary Patterns. We demonstrate results on a variety of datasets including time-lapse photography, personal photo collections, and images of celebrities downloaded from the Internet. Our approach is the basis for the Face Movies feature in Googles Picasa.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40359.html
found
=========================
Feature Seeding for Action Recognition
International Conference on Computer Vision (ICCV) (2011)
[u'Pyry Matikainen', u'Rahul Sukthankar', u'Martial Hebert']
MachinePerception
Abstract: Progress in action recognition has been in large part due to advances in the features that drive learning-based methods. However, the relative sparsity of training data and the risk of overfitting have made it difficult to directly search for good features. In this paper, we suggest using synthetic data to search for robust features that can more easily take advantage of limited data, rather than using the synthetic data directly as a substitute for real data. We demonstrate that the features discovered by our selection method, which we call seeding, improve performance on an action classification task on real data, even though the synthetic data from which our features are seeded differs significantly from the real data, both in terms of appearance and the set of action classes.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37364.html
notfound
=========================
Geometric Overpass Extraction from Vector Road Data and DSMs
Proceedings of the 19th ACM SIGSPATIAL international Conference on Advances in Geographic information Systems, 2011 (to appear)
[u'Joshua Schpok']
MachinePerception
Abstract: We present a method to extract elevated road structures, typically overpassing other roads, transit lines, and watercourses. The technique uses a digital surface model (DSM) and roughly aligned vector road data and outputs geometry approximating the shape and elevation of the elevated road deck. Our method is robust against noise in DSM elevations and can recover elevated roads partially obscured by trees and other overpasses. We demonstrate our method parallelized over city-wide DSMs, and formulate a confidence metric ranking the fidelity of the reconstruction.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Handling Label Noise in Video Classification via Multiple Instance Learning
ICCV'2011, IEEE
[u'Thomas Leung', u'Yang Song', u'John Zhang']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Image Saliency: From Local to Global Context
Proc. Conference on Computer Vision and Pattern Recognition (CVPR) (2011)
[u'Meng Wang', u'Janusz Konrad', u'Prakash Ishwar', u'Yushi Jing', u'Henry Rowley']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Improving Video Classification via YouTube Video Co-Watch Data
ACM Workshop on Social and Behavioural Networked Media Access at ACM MM 2011, ACM
[u'John Zhang', u'Yang Song', u'Thomas Leung']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36985.html
notfound
=========================
Kernelized Structural SVM Learning for Supervised Object Segmentation
Proceedings of IEEE Conference on Computer Vision and Pattern Recognition 2011
[u'Luca Bertelli', u'Tianli Yu', u'Diem Vu', u'Burak Gokturk']
MachinePerception
Abstract: Object segmentation needs to be driven by top-down knowledge to produce semantically meaningful results. In this paper, we propose a supervised segmentation approach that tightly integrates object-level top down information with low-level image cues. The information from the two levels is fused under a kernelized structural SVM learning framework. We defined a novel nonlinear kernel for comparing two image-segmentation masks. This kernel combines four different kernels: the object similarity kernel, the object shape kernel, the per-image color distribution kernel, and the global color distribution kernel. Our experiments show that the structured SVM algorithm finds bad segmentations of the training examples given the current scoring function and punishes these bad segmentations to lower scores than the example (good) segmentations. The result is a segmentation algorithm that not only knows what good segmentations are, but also learns potential segmentation mistakes and tries to avoid them. Our proposed approach can obtain comparable performance to other state-of-the-art top-down driven segmentation approaches yet is flexible enough to be applied to widely different domains.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Large-Scale Image Annotation using Visual Synset
Proc. International Conference on Computer Vision (ICCV) (2011)
[u'David Tsai', u'Yushi Jing', u'Henry Rowley', u'Yi Liu', u'Sergey Ioffe', u'James Rehg']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36984.html
notfound
=========================
Limits on the Application of Frequency-based Language Models to OCR
ICDAR, IEEE (2011), pp. 538-542
[u'Ray Smith']
MachinePerception
Abstract: Although large language models are used in speech recognition and machine translation applications, OCR systems are far behind in their use of language models. The reason for this is not the laggardness of the OCR community, but the fact that, at high accuracies, a frequency-based language model can do more damage than good, unless carefully applied. This paper presents an analysis of this discrepancy with the help of the Google Books n-gram Corpus, and concludes that noisy-channel models that closely model the underlying classifier and segmentation errors are required.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37112.html
notfound
=========================
Multicore Bundle Adjustment
Proc. IEEE Conf. on Computer Vision and Pattern Recognition (2011), pp. 3057-3064
[u'Changchang Wu', u'Sameer Agarwal', u'Brian Curless', u'Steven Seitz']
MachinePerception
Abstract: The emergence of multi-core computers represents a fundamental shift, with major implications for the design of computer vision algorithms. Most computers sold today have a multicore CPU with 2-16 cores and a GPU with anywhere from 4 to 128 cores. Exploiting this hardware parallelism will be key to the success and scalability of computer vision algorithms in the future. In this project, we consider the design and implementation of new inexact Newton type Bundle Adjustment algorithms that exploit hardware parallelism for efficiently solving large scale 3D scene reconstruction problems. We explore the use of multicore CPU as well as multicore GPUs for this purpose. We show that overcoming the severe memory and bandwidth limitations of current generation GPUs not only leads to more space efficient algorithms, but also to surprising savings in runtime. Our CPU based system is up to ten times and our GPU based system is up to thirty times faster than the current state of the art methods, while maintaining comparable convergence behavior.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36368.html
notfound
=========================
Privacy protection and face recognition
Handbook of Face recognition, Springer, 236 Gray's Inn Road | Floor 6 London | WC1X 8HL | UK (2011), pp. 671-692
[u'Andrew Senior', u'Sharat Pankanti']
MachinePerception
Abstract: Invited chapter in second edition of Handbook of Face recognition ed Stan Li & Anil K. Jain. Covers privacy protecting technologies applied to face detection and recognition.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37648.html
notfound
=========================
Reading Digits in Natural Images with Unsupervised Feature Learning
NIPS Workshop on Deep Learning and Unsupervised Feature Learning 2011
[u'Yuval Netzer', u'Tao Wang', u'Adam Coates', u'Alessandro Bissacco', u'Bo Wu', u'Andrew Y. Ng']
MachinePerception
Abstract: Detecting and reading text from natural images is a hard computer vision task that is central to a variety of emerging applications. Related problems like document character recognition have been widely studied by computer vision and machine learning researchers and are virtually solved for practical applications like reading handwritten digits. Reliably recognizing characters in more complex scenes like photographs, however, is far more difcult: the best existing methods lag well behind human performance on the same tasks. In this paper we attack the problem of recognizing digits in a real application using unsupervised feature learning methods: reading house numbers from street level photos. To this end, we introduce a new benchmark dataset for research use containing over 600,000 labeled digits cropped from Street View images. We then demonstrate the difculty of recognizing these digits when the problem is approached with hand-designed features. Finally, we employ variants of two recently proposed unsupervised feature learning methods and nd that they are convincingly superior on our benchmarks.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36864.html
notfound
=========================
Sparse coding of auditory features for machine hearing in interference
Proc. ICASSP, IEEE (2011)
[u'Richard F. Lyon', u'Gal Chechik', u'Jay Ponte']
MachinePerception
Abstract: A key problem in using the output of an auditory model as the input to a machine-learning system in a machine-hearing application is to find a good feature-extraction layer. For systems such as PAMIR (passive-aggressive model for image retrieval) that work well with a large sparse feature vector, a conversion from auditory images to sparse features is needed. For audio-file ranking and retrieval from text queries, based on stabilized auditory images, we took a multi-scale approach, using vector quantization to choose one sparse feature in each of many overlapping regions of different scales, with the hope that in some regions the features for a sound would be stable even when other interfering sounds were present and affecting other regions. We recently extended our testing of this approach using sound mixtures, and found that the sparse-coded auditory-image features degrade less in interference than vector-quantized MFCC sparse features do. This initial success suggests that our hope of robustness in interference may indeed be realizable, via the general idea of sparse features that are localized in a domain where signal components tend to be localized or stable.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41650.html
notfound
=========================
Summary of Opus listening test results
IETF, IETF (2011)
[u'Christian Hoene', u'Jean-Marc Valin', u'Koen Vos', u'Jan Skoglund']
MachinePerception
Abstract: This document describes and examines listening test results obtained for the Opus codec and how they relate to the requirements.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37261.html
notfound
=========================
Survey and Evaluation of Audio Fingerprinting Schemes for Mobile Query-By-Example Applications
12th International Society for Music Information Retrieval Conference (ISMIR) (2011)
[u'Vijay Chandrasekhar', u'Matt Sharifi', u'David Ross']
MachinePerception
Abstract: We survey and evaluate popular audio ngerprinting schemes in a common framework with short query probes captured from cell phones. We report and discuss results important for mobile applications: Receiver Operating Characteristic (ROC) performance, size of ngerprints generated compared to size of audio probe, and transmission delay if the ngerprint data were to be transmitted over a wireless link. We hope that the evaluation in this work will guide work towards reducing latency in practical mobile audio retrieval applications
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Technical Overview of VP8, an open source video codec for the web
2011 International Workshop on Acoustics and Video Coding and Communication, IEEE, Barcelona, Spain (to appear)
[u'Jim Bankoski', u'Paul Wilkins', u'Yaowu Xu']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37298.html
notfound
=========================
The Power of Comparative Reasoning
International Conference on Computer Vision, IEEE (2011)
[u'Jay Yagnik', u'Dennis Strelow', u'David Ross', u'Ruei-Sung Lin']
MachinePerception
Abstract: Rank correlation measures are known for their resilience to perturbations in numeric values and are widely used in many evaluation metrics. Such ordinal measures have rarely been applied in treatment of numeric features as a representational transformation. We emphasize the benets of ordinal representations of input features both theoretically and empirically. We present a family of algorithms for computing ordinal embeddings based on partial order statistics. Apart from having the stability benets of ordinal measures, these embeddings are highly nonlinear, giving rise to sparse feature spaces highly favored by several machine learning methods. These embeddings are deterministic, data independent and by virtue of being based on partial order statistics, add another degree of resilience to noise. These machine-learning-free methods when applied to the task of fast similarity search outperform state-of-theart machine learning methods with complex optimization setups. For solving classication problems, the embeddings provide a nonlinear transformation resulting in sparse binary codes that are well-suited for a large class of machine learning algorithms. These methods show signicant improvement on VOC 2010 using simple linear classiers which can be trained quickly. Our method can be extended to the case of polynomial kernels, while permitting very efcient computation. Further, since the popular MinHash algorithm is a special case of our method, we demonstrate an efcient scheme for computing MinHash on conjunctions of binary features. The actual method can be implemented in about 10 lines of code in most languages (2 lines in MATLAB), and does not require any data-driven optimization.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37215.html
notfound
=========================
Using a Cascade of Asymmetric Resonators with Fast-Acting Compression as a Cochlear Model for Machine-Hearing Applications
Autumn Meeting of the Acoustical Society of Japan (2011), pp. 509-512
[u'Richard F. Lyon']
MachinePerception
Abstract: Every day, machines process many thousands of hours of audio signals through a realistic cochlear model. They extract features, inform classifiers and recommenders, and identify copyrighted material. The machine-hearing approach to such tasks has taken root in recent years, because hearing-based approaches perform better than we can do with more conventional sound-analysis approaches. We use a bio-mimetic "cascade of asymmetric resonators with fast-acting compression" (CAR-FAC)an efficient sound analyzer that incorporates the hearing research community's findings on nonlinear auditory filter models and cochlear wave mechanics. The CAR-FAC is based on a polezero filter cascade (PZFC) model of auditory filtering, in combination with a multi-time-scale coupled automatic-gain-control (AGC) network. It uses simple nonlinear extensions of conventional digital filter stages, and runs fast due to its low complexity. The PZFC plus AGC network, the CAR-FAC, mimics features of auditory physiology, such as masking, compressive traveling-wave response, and the stability of zero-crossing times with signal level. Its output "neural activity pattern" is converted to a "stabilized auditory image" to capture pitch, melody, and other temporal and spectral features of the sound.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37065.html
notfound
=========================
Visual and Semantic Similarity in ImageNet
IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2011), pp. 1777-1784
[u'Thomas Deselaers', u'Vittorio Ferrari']
MachinePerception
Abstract: Many computer vision approaches take for granted positive answers to questions such as Are semantic categories visually separable? and Is visual similarity correlated to semantic similarity? In this paper, we study experimentally whether these assumptions hold and show parallels to questions investigated in cognitive science about the human visual system. The insights gained from our analysis enable building a novel distance function between images assessing whether they are from the same basic-level category. This function goes beyond direct visual distance as it also exploits semantic similarity measured through ImageNet. We demonstrate experimentally that it outperforms purely visual distances.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37111.html
notfound
=========================
Where's Waldo: Matching People in Images of Crowds
Proc. IEEE Conf. on Computer Vision and Pattern Recognition (2011), pp. 1793-1800
[u'Rahul Garg', u'Deva Ramanan', u'Steven M. Seitz', u'Noah Snavely']
MachinePerception
Abstract: Given a community-contributed set of photos of a crowded public event, this paper addresses the problem of nding all images of each person in the scene. This problem is very challenging due to large changes in camera viewpoints, severe occlusions, low resolution and photos from tens or hundreds of different photographers. Despite these challenges, the problem is made tractable by exploiting a variety of visual and contextual cues appearance, timestamps, camera pose and co-occurrence of people. This paper demonstrates an approach that integrates these cues to enable high quality person matching in community photo collections downloaded from Flickr.com
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
YouTubeEvent: On Large-Scale Video Event Classification
The 3rd International Workshop on Video Event Categorization, Tagging and Retrieval for Real-World Applications at IEEE ICCV'2011
[u'Bingbing Ni', u'Yang Song', u'Ming Zhao']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Large-Scale Taxonomic Classification System for Web-based Videos
the 11th European Conference on Computer Vision (ECCV 2010)
[u'Yang Song', u'Ming Zhao', u'Reto Strobl', u'John Zhang', u'Jay Yagnik']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Baselines for Image Annotation
International Journal on Computer Vision (IJCV) (2010)
[u'Ameesh Makadia', u'Vladimir Pavlovic', u'Sanjiv Kumar']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36579.html
notfound
=========================
Beyond Near-Duplicates: Learning Hash Codes for Efficient Similar-Image Retrieval
20th International Conference on Pattern Recognition 2010
[u'Shumeet Baluja', u'Michele Covell']
MachinePerception
Abstract: Finding similar images in a large database is an important, but often computationally expensive, task. In this paper, we present a two-tier similar-image retrieval system with the efficiency characteristics found in simpler systems designed to recognize near-duplicates. We compare the efficiency of lookups based on random projections and learned hashes to 100-times-more-frequent exemplar sampling. Both approaches significantly improve on the results from exemplar sampling, despite having significantly lower computational costs. Learned-hash keys provide the best result, in terms of both recall and efficiency.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36929.html
notfound
=========================
Comparison of Clustering Approaches for Summarizing Large Populations of Images
Proceedings ICME VCIDS, IEEE, Singapore (2010)
[u'Yushi Jing', u'Michele Covell', u'Henry A. Rowley']
MachinePerception
Abstract: This paper compares the efficacy and efficiency of different clustering approaches for selecting a set of exemplar images, to present in the context of a semantic concept. We evaluate these approaches using 900 diverse queries, each associated with 1000 web images, and comparing the exemplars chosen by clustering to the top 20 images for that search term. Our results suggest that Affinity Propagation is effective in selecting exemplars that match the top search images but at high computational cost. We improve on these early results using a simple distribution-based selection lter on incomplete clustering results. This improvement allows us to use more computationally efficient approaches to clustering, such as Hierarchical Agglomerative Clustering (HAC) and Partitioning Around Medoids (PAM), while still reaching the same (or better) quality of results as were given by Affinity Propagation in the original study. The computational savings is significant since these alternatives are 7-27 times faster than Affinity Propagation.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36246.html
notfound
=========================
Discontinuous Seam-Carving for Video Retargeting
Computer Vision and Pattern Recognition (CVPR 2010)
[u'Matthias Grundmann', u'Vivek Kwatra', u'Mei Han', u'Irfan Essa']
MachinePerception
Abstract: We introduce a new algorithm for video retargeting that uses discontinuous seam-carving in both space and time for resizing videos. We propose a novel appearance-based temporal coherence formulation that allows for frame-by-frame processing and results in temporally discontinuous seams, as opposed to geometrically smooth and continuous seams. This formulation optimizes the difference in appearance of the resultant retargeted frame to the optimal temporally coherent one, and allows for carving around fast moving salient regions. Additionally, we generalize the idea of appearance-based coherence to the spatial domain by introducing piece-wise spatial seams. Our spatial coherence measure minimizes the change in gradients during retargeting, which preserves spatial detail better than minimization of color difference alone. We also show that retargeting based on per-frame saliency (gradient-based or feature-based) does not always lead to desirable results and propose a novel automatically computed measure of spatio-temporal saliency. As needed, the user can also augment the saliency by interactive region-brushing. Our retargeting algorithm processes the video sequentially, which allows us to deal with streaming videos. We demonstrate results over a wide range of video examples and evaluate the effectiveness of each component of our algorithm.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Document Image Analysis (Chapter 18)
Mathematical morphology: theory and applications, ISTE-Wiley (2010), pp. 425-438
[u'Dan Bloomberg', u'Luc Vincent']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36247.html
notfound
=========================
Efficient Hierarchical Graph-Based Video Segmentation
Computer Vision and Pattern Recognition (CVPR 2010)
[u'Matthias Grundmann', u'Vivek Kwatra', u'Mei Han', u'Irfan Essa']
MachinePerception
Abstract: We present an efficient and scalable technique for spatio-temporal segmentation of long video sequences using a hierarchical graph-based algorithm. We begin by over-segmenting a volumetric video graph into space-time regions grouped by appearance. We then construct a ``region graph" over the obtained segmentation and iteratively repeat this process over multiple levels to create a tree of spatio-temporal segmentations. This hierarchical approach generates high quality segmentations which are temporally coherent with stable region boundaries. Additionally, the resulting segmentation hierarchy allows subsequent applications to choose from varying levels of granularity. We further improve segmentation quality by using dense optical flow when constructing the initial graph. We also propose two novel approaches to improve the scalability of our technique: (a) a parallel out-of-core algorithm that can process volumes much larger than an in-core algorithm, and (b) a clip-based processing algorithm that divides the video into overlapping clips in time, and segments them successively while enforcing consistency. We can segment video shots as long as 40 seconds without compromising quality, and even support a streaming mode for arbitrarily long videos, albeit without the ability to process them hierarchically.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36415.html
notfound
=========================
Example-based Image Compression
International Conference on Image Processing (ICIP 2010)
[u'Jing-Yu Cui', u'Saurabh Mathur', u'Michele Covell', u'Vivek Kwatra', u'Mei Han']
MachinePerception
Abstract: The current standard image-compression approaches rely on fairly simple predictions, using either block- or wavelet-based methods. While many more sophisticated texture-modeling approaches have been proposed, most do not provide a significant improvement in compression rate over the current standards at a workable encoding complexity level. We re-examine this area, using example-based texture prediction. We find that we can provide consistent and significant improvements over JPEG, reducing the bit rate by more than 20% for many PSNR levels. These improvements require consideration of the differences between residual energy and prediction/residual compressibility when selecting a texture prediction, as well as careful control of the computational complexity in encoding.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36416.html
notfound
=========================
Fast Covariance Computation and Dimensionality Reduction for Sub-Window Features in Images
European Conference on Computer Vision (ECCV 2010)
[u'Vivek Kwatra', u'Mei Han']
MachinePerception
Abstract: This paper presents algorithms for efficiently computing the covariance matrix for features that form sub-windows in a large multi-dimensional image. For example, several image processing applications, e.g. texture analysis/synthesis, image retrieval, and compression, operate upon patches within an image. These patches are usually projected onto a low-dimensional feature space using dimensionality reduction techniques such as Principal Component Analysis (PCA) and Linear Discriminant Analysis (LDA), which in-turn requires computation of the covariance matrix from a set of features. Covariance computation is usually the bottleneck during PCA or LDA (O(nd^2) where n is the number of pixels in the image and d is the dimensionality of the vector). Our approach reduces the complexity of covariance computation by exploiting the redundancy between feature vectors corresponding to overlapping patches. Specifically, we show that the covariance between two feature components can be reduced to a function of the relative displacement between those components in patch space. One can then employ a lookup table to store covariance values by relative displacement. By operating in the frequency domain, this lookup table can be computed in O(n log n) time. We allow the patches to sub-sample the image, which is useful for hierarchical processing and also enables working with filtered responses over these patches, such as local gist features. We also propose a method for fast projection of sub-window patches onto the low-dimensional space.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Feature Tracking for Wide-Baseline Image Retrieval
European Conference on Computer Vision (ECCV) (2010)
[u'Ameesh Makadia']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36899.html
notfound
=========================
Google Street View: Capturing the World at Street Level
Computer, vol. 43 (2010)
[u'Dragomir Anguelov', u'Carole Dulong', u'Daniel Filip', u'Christian Frueh', u'Stphane Lafon', u'Richard Lyon', u'Abhijit Ogale', u'Luc Vincent', u'Josh Weaver']
MachinePerception
Abstract: Street View serves millions of Google users daily with panoramic imagery captured in hundreds of cities in 20 countries across four continents. A team of Google researchers describes the technical challenges involved in capturing, processing, and serving street-level imagery on a global scale.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36895.html
notfound
=========================
History and Future of Auditory Filter Models
Proc. ISCAS, IEEE (2010), pp. 3809-3812
[u'Richard F. Lyon', u'Andreas G. Katsiamis', u'Emmanuel M. Drakakis']
MachinePerception
Abstract: Auditory filter models have a history of over a hundred years, with explicit bio-mimetic inspiration at many stages along the way. From passive analogue electric delay line models, through digital filter models, active analogue VLSI models, and abstract filter shape models, these filters have both represented and driven the state of progress in auditory research. Today, we are able to represent a wide range of linear and nonlinear aspects of the psychophysics and physiology of hearing with a rather simple and elegant set of circuits or computations that have a clear connection to underlying hydrodynamics and with parameters calibrated to human performance data. A key part of the progress in getting to this stage has been the experimental clarification of the nature of cochlear nonlinearities, and the modelling work to map these experimental results into the domain of circuits and systems. No matter how these models are built into machine-hearing systems, their bio-mimetic roots will remain key to their performance. In this paper we review some of these models, explain their advantages and disadvantages and present possible ways of implementing them. As an example, a continuous-time analogue CMOS implementation of the One Zero Gammatone Filter (OZGF) is presented together with its automatic gain control that models its level-dependent nonlinear behaviour.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36928.html
notfound
=========================
Improved Consistent Sampling, Weighted Minhash and L1 Sketching
ICDM (2010) (to appear)
[u'Sergey Ioffe']
MachinePerception
Abstract: We propose a new Consistent Weighted Sampling method, where the probability of drawing identical samples for a pair of inputs is equal to their Jaccard similarity. Our method takes deterministic constant time per non-zero weight, improving on the best previous approach which takes expected constant time. The samples can be used as Weighted Minhash for efficient retrieval and compression (sketching) under Jaccard or L1 metric. A method is presented for using simple data statistics to reduce the running time of hash computation by two orders of magnitude. We compare our method with the random projection method and show that it has better characteristics for retrieval under L1. We present a novel method of mapping hashes to short bit-strings, apply it to Weighted Minhash, and achieve more accurate distance estimates from sketches than existing methods, as long as the inputs are sufficiently distinct. We show how to choose the optimal number of bits per hash for sketching, and demonstrate experimental results which agree with the theoretical analysis.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Looking for Pieces of Needles in Millions of Haystacks: Finding Distorted Audio/Video Snippets
International Workshop on Computer Vision (2010)
[u'Michele Covell', u'Shumeet Baluja']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36608.html
notfound
=========================
Machine Hearing: An Emerging Field
IEEE Signal Processing Magazine, vol. 27 (2010), pp. 131-139
[u'Richard F. Lyon']
MachinePerception
Abstract: (intro paragraph in lieu of abstract) If we had machines that could hear as humans do, we would expect them to be able to easily distinguish speech from music and background noises, to pull out the speech and music parts for special treatment, to know what direction sounds are coming from, to learn which noises are typical and which are noteworthy. Hearing machines should be able to organize what they hear; learn names for recognizable objects, actions, events, places, musical styles, instruments, and speakers; and retrieve sounds by reference to those names. These machines should be able to listen and react in real time, to take appropriate action on hearing noteworthy events, to participate in ongoing activities, whether in factories, in musical performances, or in phone conversations.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37431.html
notfound
=========================
SemWebVid - Making Video a First Class Semantic Web Citizen and a First Class Web Bourgeois - Semantic Web Challenge
9th International Semantic Web Conference (ISWC 2010)
[u'Thomas Steiner', u'Michael Hausenblas']
MachinePerception
Abstract: SemWebVid is an online Ajax application that allows for the automatic generation of Resource Description Framework (RDF) video descriptions. These descriptions are based on two pillars: first, on a combination of user-generated metadata such as title, summary, and tags; and second, on closed captions which can be user-generated, or be auto-generated via speech recognition. The plaintext contents of both pillars are being analyzed using multiple Natural Language Processing (NLP) Web services in parallel whose results are then merged and where possible matched back to concepts in the sense of Linking Open Data (LOD). The final result is a deep-linkable RDF description of the video, and a scroll-along view of the video as an example of video visualization formats.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Semi-Supervised Hashing for Scalable Image Retrieval
IEEE Conf on Computer Vision and Pattern Recognition (CVPR) (2010)
[u'Jun Wang', u'Sanjiv Kumar', u'Shih-Fu Chang']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35479.html
notfound
=========================
Sound Retrieval and Ranking Using Sparse Auditory Representations
Neural Computation, vol. 22 (2010), pp. 2390-2416
[u'Richard F Lyon', u'Martin Rehn', u'Samy Bengio', u'Thomas C. Walters', u'Gal Chechik']
MachinePerception
Abstract: To create systems that understand the sounds that humans are exposed to in everyday life, we need to represent sounds with features that can discriminate among many different sound classes. Here, we use a sound-ranking framework to quantitatively evaluate such representations in a large scale task. We have adapted a machine-vision method, the ``passive-aggressive model for image retrieval'' (PAMIR), which efficiently learns a linear mapping from a very large sparse feature space to a large query-term space. Using this approach we compare different auditory front ends and different ways of extracting sparse features from high-dimensional auditory images. We tested auditory models that use adaptive pole--zero filter cascade (PZFC) auditory filterbank and sparse-code feature extraction from stabilized auditory images via multiple vector quantizers. In addition to auditory image models, we also compare a family of more conventional Mel-Frequency Cepstral Coefficient (MFCC) front ends. The experimental results show a significant advantage for the auditory models over vector-quantized MFCCs. Ranking thousands of sound files with a query vocabulary of thousands of words, the best precision at top-1 was 73% and the average precision was 35%, reflecting a 18% improvement over the best competing MFCC.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35652.html
notfound
=========================
Table Detection in Heterogeneous Documents
Document Analysis Systems 2010, ACM International Conference Proceedings series
[u'Faisal Shafait', u'Ray Smith']
MachinePerception
Abstract: Detecting tables in document images is important since not only do tables contain important information, but also most of the layout analysis methods fail in the presence of tables in the document image. Existing approaches for table de- tection mainly focus on detecting tables in single columns of text and do not work reliably on documents with varying layouts. This paper presents a practical algorithm for table detection that works with a high accuracy on documents with varying layouts (company reports, newspaper articles, magazine pages, . . . ). An open source implementation of the algorithm is provided as part of the Tesseract OCR engine. Evaluation of the algorithm on document images from pub- licly available UNLV dataset shows competitive performance in comparison to the table detection module of a commercial OCR system.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Taxonomic Classification for Web-based Videos
IEEE Conf on Computer Vision and Pattern Recognition (CVPR), IEEE (2010)
[u'Yang Song', u'Ming Zhao', u'Jay Yagnik', u'Xiaoyun Wu']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
YouTubeCat: Learning to Categorize Wild Web Videos
IEEE Conf on Computer Vision and Pattern Recognition (CVPR) (2010)
[u'Zheshen Wang', u'Ming Zhao', u'Yang Song', u'Sanjiv Kumar', u'Baoxin Li']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub33485.html
notfound
=========================
A Biomimetic, 4.5 W, 120+dB, Log-domain Cochlea Channel with AGC
IEEE JSSC (Journal of Solid-State Circuits), vol. 44 (2009), pp. 1006-1022
[u'Andreas G. Katsiamis', u'Emmanuel M. Drakakis', u'Richard F. Lyon']
MachinePerception
Abstract: This paper deals with the design and performance evaluation of a new analog CMOS cochlea channel of increased biorealism. The design implements a recently proposed transfer function, namely the One-Zero Gammatone filter (or OZGF), which provides a robust foundation for modeling a variety of auditory data such as realistic passband asymmetry, linear low-frequency tail and level-dependent gain. Moreover, the OZGF is attractive because it can be implemented efficiently in any technological medium-analog or digital-using standard building blocks. The channel was synthesized using novel, low-power, class-AB, log-domain, biquadratic filters employing MOS transistors operating in their weak inversion regime. Furthermore, the paper details the design of a new low-power automatic gain control circuit that adapts the gain of the channel according to the input signal strength, thereby extending significantly its input dynamic range. We evaluate the performance of a fourth-order OZGF channel (equivalent to an 8th-order cascaded filter structure) through both detailed simulations and measurements from a fabricated chip using the commercially available 0.35 mum AMS CMOS process. The whole system is tuned at 3 kHz, dissipates a mere 4.46 W of static power, accommodates 124 dB (at < 5% THD) of input dynamic range at the center frequency and is set to provide up to 70 dB of amplification for small signals.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35248.html
notfound
=========================
Adapting the Tesseract Open Source OCR Engine for Multilingual OCR
MOCR '09: Proceedings of the International Workshop on Multilingual OCR (2009)
[u'Ray Smith', u'Daria Antonova', u'Dar-Shyang Lee']
MachinePerception
Abstract: We describe efforts to adapt the Tesseract open source OCR engine for multiple scripts and languages. Effort has been concentrated on enabling generic multi-lingual operation such that negligible customization is required for a new language beyond providing a corpus of text. Although change was required to various modules, including physical layout analysis, and linguistic post-processing, no change was required to the character classifier beyond changing a few limits. The Tesseract classifier has adapted easily to Simplified Chinese. Test results on English, a mixture of European languages, and Russian, taken from a random sample of books, show a reasonably consistent word error rate between 3.72% and 5.78%, and Simplified Chinese has a character error rate of only 3.77%. ACM, 2009. This is the authors version of the work. It is posted here by permission of ACM for your personal use. Not for redistribution. The definitive version was published in Proceedings of the International Workshop on Multilingual OCR 2009, Barcelona, Spain July 25, 2009.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Adaptive, selective, automatic tonal enhancement of faces
ACM Multimedia, ACM, New York, NY, USA (2009), pp. 677-680
[u'Hrishikesh Aradhye', u'George D. Toderici', u'Jay Yagnik']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Audiovisual Celebrity Recognition in Unconstrained Web Videos
Proceedings of the IEEE Conference on Acoustics, Speech, and Signal Processing (ICASSP) (2009)
[u'Mehmet Emre Sargin', u'Hrishikesh Aradhye', u'Pedro Moreno', u'Ming Zhao']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35264.html
notfound
=========================
Automatic, Efficient, Temporally-Coherent Video Enhancement for Large Scale Applications
ACM Multimedia, ACM (2009), pp. 609-612
[u'George Toderici', u'Jay Yagnik']
MachinePerception
Abstract: A fast and robust method for video contrast enhancement is presented. The method uses the histogram of each frame, along with upper and lower bounds computed per shot in order to enhance the current frame. This ensures that the artifacts introduced during the enhancement is reduced to a minimum. Traditional methods that do not compute per-shot estimates tend to over-enhance parts of the video such as fades and transitions. Our method does not suffer from this problem, which is essential for a fully automatic algorithm. We present the parameters for our methods which yielded the best human feedback, which showed that out of 208 videos, 203 were enhanced, while the remaining 5 were of too poor quality to be enhanced. Additionally, we present a visual comparison of our work with the recently-proposed Weighted Thresholded Histogram Equalization (WTHE) algorithm.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35506.html
notfound
=========================
Combined Orientation and Script Detection using the Tesseract OCR Engine
Workshop on Multilingual OCR (MOCR), Proc. 10th Intl. Conf. on Document Analysis and Recognition (ICDAR), (2009)
[u'Ranjith Unnikrishnan', u'Ray Smith']
MachinePerception
Abstract: This paper proposes a simple but effective algorithm to estimate the script and dominant page orientation of the text contained in an image. A candidate set of shape classes for each script is generated using synthetically rendered text and used to train a fast shape classifier. At run time, the classifier is applied independently to connected components in the image for each possible orientation of the component, and the accumulated confidence scores are used to determine the best estimate of page orientation and script. Results demonstrate the effectiveness of the approach on a dataset of 1846 documents containing a diverse set of images in 14 scripts and any of four possible page orientations.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Computer Vision Interfaces for Interactive Art
Human-Centric Interfaces for Ambient Intelligence, Elsevier (2009)
[u'Andrew Senior', u'Alejandro Jaimes']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Efficient and Robust Music Identification with Weighted Finite-State Transducers
IEEE Transactions on Audio, Speech, and Language Processing, vol. to appear (2009)
[u'Mehryar Mohri', u'Pedro Moreno', u'Eugene Weinstein']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Flight patterns
SIGGRAPH ASIA '09: ACM SIGGRAPH ASIA 2009 Art Gallery & Emerging Technologies: Adaptation, ACM, New York, NY, USA, pp. 29-29
[u'Aaron Koblin']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Google Newspaper Search Image Processing and Analysis Pipeline
10th International Conference on Document Analysis and Recognition, ICDAR 2009, pp. 621-625
[u'Krishnendu Chaudhury', u'Ankur Jain', u'Sriram Thirthala', u'Vivek Sahasranaman', u'Shobhit Saxena', u'Selvam Mahalingam']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35094.html
notfound
=========================
Hybrid Page Layout Analysis via Tab-Stop Detection
Proceedings of the 10th international conference on document analysis and recognition, IEEE (2009)
[u'Ray Smith']
MachinePerception
Abstract: A new hybrid page layout analysis algorithm is proposed, which uses bottom-up methods to form an initial data-type hypothesis and locate the tab-stops that were used when the page was formatted. The detected tab-stops are used to deduce the column layout of the page. The column layout is then applied in a top-down manner to impose structure and reading-order on the detected regions. The complete C++ source code implementation is available as part of the Tesseract open source OCR engine at http://code.google.com/p/tesseract-ocr.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35578.html
notfound
=========================
Image Reconstruction in the Gigavision Camera
ICCV workshop OMNIVIS 2009
[u'Feng Yang', u'Luciano Sbaiz', u'Edoardo Charbon', u'Sabine Susstrunk', u'Martin Vetterli']
MachinePerception
Abstract: the gigavision camera. The main feature of this camera is that the pixels have a binary response. The response function of a gigavision sensor is non-linear and similar to a logarithmic function, which makes the camera suitable for high dynamic range imaging. Since the sensor can detect a single photon, the camera is very sensitive and can be used for night vision and astronomical imaging. One important aspect of the gigavision camera is how to estimate the light intensity through binary observations. We model the light intensity field as 2D piecewise constant and use Maximum Penalized Likelihood Estimation (MPLE) to recover it. Dynamic programming is used to solve the optimization problem. Due to the complex computation of dynamic programming, greedy algorithm and pruning quadtrees are proposed. They show acceptable reconstruction performance with low computational complexity. Experimental results with synthesized images and real images taken by a single-photon avalanche diode (SPAD) camera are given.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35244.html
notfound
=========================
LSH Banding for Large-Scale Retrieval with Memory and Recall Constraints
International Conference on Acoustics, Speech, and Signal Processing, IEEE (2009)
[u'Michele Covell', u'Shumeet Baluja']
MachinePerception
Abstract: Locality Sensitive Hashing (LSH) is widely used for efficient retrieval of candidate matches in very large audio, video, and image systems. However, extremely large reference databases necessitate a guaranteed limit on the memory used by the table lookup itself, no matter how the entries crowd different parts of the signature space, a guarantee that LSH does not give. In this paper, we provide such guaranteed limits, primarily through the design of the LSH bands. When combined with data-adaptive bin splitting (needed on only 0.04% of the occupied bins), this approach provides the required guarantee on memory usage. At the same time, it avoids the reduced recall that more extensive use of bin splitting would give.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35481.html
notfound
=========================
Large-scale Privacy Protection in Google Street View
IEEE International Conference on Computer Vision (2009)
[u'Andrea Frome', u'German Cheung', u'Ahmad Abdulkader', u'Marco Zennaro', u'Bo Wu', u'Alessandro Bissacco', u'Hartwig Adam', u'Hartmut Neven', u'Luc Vincent']
MachinePerception
Abstract: The last two years have witnessed the introduction and rapid expansion of products based upon large, systematically-gathered, street-level image collections, such as Google Street View, EveryScape, and Mapjack. In the process of gathering images of public spaces, these projects also capture license plates, faces, and other information considered sensitive from a privacy standpoint. In this work, we present a system that addresses the challenge of automatically detecting and blurring faces and license plates for the purpose of privacy protection in Google Street View. Though some in the field would claim face detection is "solved", we show that state-of-the-art face detectors alone are not sufficient to achieve the recall desired for large-scale privacy protection. In this paper we present a system that combines a standard sliding-window detector tuned for a high recall, low-precision operating point with a fast post-processing stage that is able to remove additional false positives by incorporating domain-specific information not available to the sliding-window detector. Using a completely automatic system, we are able to sufficiently blur more than 89% of faces and 94-96% of license plates in evaluation sets sampled from Google Street View imagery. The full paper will appear from IEEE.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35525.html
notfound
=========================
Low Cost Correction of OCR Errors Using Learning in a Multi-Engine Environment
Proceedings of the 10th international conference on document analysis and recognition, IEEE (2009)
[u'Ahmad Abdulkader', u'Matthew R. Casey']
MachinePerception
Abstract: We propose a low cost method for the correction of the output of OCR engines through the use of human labor. The method employs an error estimator neural network that learns to assess the error probability of every word from ground-truth data. The error estimator uses features computed from the outputs of multiple OCR engines. The output probability error estimate is used to decide which words are inspected by humans. The error estimator is trained to optimize the area under the word error ROC leading to an improved efficiency of the human correction process. A significant reduction in cost is achieved by clustering similar words together during the correction process. We also show how active learning techniques are used to further improve the efficiency of the error estimator.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Media on the web, in post-production and broadcasting: the practitioner day of the ACM 2009 International Conference on Image and Video Retrieval
CIVR '09: Proceeding of the ACM International Conference on Image and Video Retrieval, ACM, New York, NY, USA (2009), pp. 1-5
[u"S\\'{e}bastien Marcel", u'Roelof van Zwol', u'Ricardo Baeza-Yates', u'Oliver Heckmann', u'Jan Erik Solem', u'Johan Oomen', u'Hans van Gageldonk', u'Jean-Pierre Gehrig', u'Xavier Vives', u'Baris Sumengen']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Models for patch-based image restoration
J. Image Video Process., vol. 2009 (2009), pp. 1-12
[u'Mithun Das Gupta', u'Shyamsundar Rajaram', u'Nemanja Petrovic', u'Thomas S. Huang']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34342.html
notfound
=========================
Predictive Models for Music
Connection Science, vol. 21 (2009), pp. 253-272
[u'Jean-Francois Paiement', u'Yves Grandvalet', u'Samy Bengio']
MachinePerception
Abstract: Modeling long-term dependencies in time series has proved very difficult to achieve with traditional machine learning methods. This problem occurs when considering music data. In this paper, we introduce predictive models for melodies. We decompose melodic modeling into two subtasks. We first propose a rhythm model based on the distributions of distances between subsequences. Then, we define a generative model for melodies given chords and rhythms based on modeling sequences of Narmour features. The rhythm model consistently outperforms a standard Hidden Markov Model in terms of conditional prediction accuracy on two different music databases. Using a similar evaluation procedure, the proposed melodic model consistently outperforms an Input/Output Hidden Markov Model. Furthermore, these models are able to generate realistic melodies given appropriate musical contexts.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34729.html
notfound
=========================
Privacy Protection in Video Surveillance
Springer (2009)
[u'Andrew W. Senior']
MachinePerception
Abstract: An edited book dealing with various aspects of privacy protection in automatic video surveillance systems. Chapters deal with redaction/obscuration, cryptography, detection, integration with RFID, performance analysis, social issues and acceptance.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
SD-VBS: The San Diego Vision Benchmark Suite
IEEE Workload Characterization Symposium, vol. 0 (2009), pp. 55-64
[u'Sravanthi Kota Venkata', u'Ikkjin Ahn', u'Donghwan Jeon', u'Anshuman Gupta', u'Christopher Louie', u'Saturnino Garcia', u'Serge Belongie', u'Michael Bedford Taylor']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Shape-based Object Recognition in Videos Using 3D Synthetic Object Models
Computer Vision and Pattern Recognition (2009)
[u'Alexander Toshev', u'Ameesh Makadia', u'Kostas Daniilidis']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Softcuts: A Soft Edge Smoothness Prior for Color Image Super Resolution
IEEE Transactions on Image Processing (T-IP), vol. 18 (2009), pp. 969-981
[u'Shengyang Dai', u'Mei Han', u'Wei Xu', u'Ying Wu', u'Yihong Gong', u'Aggelos K. Katsaggelos']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35269.html
notfound
=========================
Sound Ranking Using Auditory Sparse-Code Representations
ICML 2009 Workshop on Sparse Method for Music Audio
[u'Martin Rehn', u'Richard F. Lyon', u'Samy Bengio', u'Thomas C. Walters', u'Gal Chechik']
MachinePerception
Abstract: The task of ranking sounds from text queries is a good test application for machine-hearing techniques, and particularly for comparison and evaluation of alternative sound representations in a large-scale setting. We have adapted a machine-vision system, ``passive-aggressive model for image retrieval'' (PAMIR), which efficiently learns, using a ranking-based cost function, a linear mapping from a very large sparse feature space to a large query-term space. Using this system allows us to focus on comparison of different auditory front ends and different ways of extracting sparse features from high-dimensional auditory images. In addition to two main auditory-image models, we also include and compare a family of more conventional MFCC front ends. The experimental results show a significant advantage for the auditory models over vector-quantized MFCCs. The two auditory models tested use the adaptive pole-zero filter cascade (PZFC) auditory filterbank and sparse-code feature extraction from stabilized auditory images via multiple vector quantizers. The models differ in their implementation of the strobed temporal integration used to generate the stabilized image. Using ranking precision-at-top-k performance measures, the best results are about 70% top-1 precision and 35% average precision, using a test corpus of thousands of sound files and a query vocabulary of hundreds of words.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
State of the Art in Example-based Texture Synthesis
Eurographics 2009, State of the Art Report, EG-STAR, Eurographics Association
[u'Li-Yi Wei', u'Sylvain Lefebvre', u'Vivek Kwatra', u'Greg Turk']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Tour the World: building a web-scale landmark recognition engine
International Conference on Computer Vision and Pattern Recognition (CVPR) (2009)
[u'Yantao Zheng', u'Ming Zhao', u'Yang Song', u'Hartwig Adam', u'Ulrich Buddemeier', u'Alessandro Bissacco', u'Fernando Brucher', u'Tat-Seng Chua', u'Hartmut Neven']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Tree detection from aerial imagery
Proceedings of the 17th ACM SIGSPATIAL international Conference on Advances in Geographic information Systems, Seattle, Washington (2009)
[u'Lin Yang', u'Xiaqing Wu', u'Emil Praun', u'Xiaoxu Ma']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Visualizing Web Images via Google Image Swirl
NIPS Workshop on Statistical Machine Learning for Visual Analytics (2009)
[u'Yushi Jing', u'Henry A. Rowley', u'Chuck Rosenberg', u'Jingbin Wang', u'Michele Covell']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A New Baseline For Image Annotation
European Conference on Computer Vision (ECCV) (2008)
[u'Ameesh Makadia', u'Vladimir Pavlovic', u'Sanjiv Kumar']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Beyond Sliding Windows: Object Localization by Efficient Subwindow Search
IEEE Computer Vision and Pattern Recognition (CVPR), Anchorage, AK (2008)
[u'Christoph H. Lampert', u'Matthew B. Blaschko', u'Thomas Hofmann']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Coordinated Multi-Device Presentations: Ambient-Audio Identification
Encyclopedia of Wireless and Mobile Communications, Taylor & Francis (2008), pp. 274-285
[u'Michael Fink', u'Michele Covell', u'Shumeet Baluja']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34854.html
notfound
=========================
Estimating the Spectral Reflectance of Natural Imagery Using Color Image Features
Workshop on Applications, Systems, and Algorithms for Image Sensing (2008)
[u'Josh Hyman', u'Mark Hansen', u'Eric Graham', u'Deborah Estrin']
MachinePerception
Abstract: Relative spectral reectance is an illumination invariant image feature that is related to many ecological phenomena that are difcult to measure, such as plant CO2 uptake. We describe a procedure to estimate the relative spectral reectance of known subject using color image features. Through application, we show that this procedure produces accurate estimates in the presence of changing eld conditions. Using this procedure, we can use imagers as sensors to measure natural phenomena that cannot be easily measured using any other available sensing modality.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34394.html
notfound
=========================
Face Tracking and Recognition with Visual Constraints in Real-World Videos
IEEE Computer Vision and Pattern Recognition (CVPR) (2008)
[u'Minyoung Kim', u'Sanjiv Kumar', u'Vladimir Pavlovic', u'Henry A. Rowley']
MachinePerception
Abstract: We address the problem of tracking and recognizing faces in real-world, noisy videos. We track faces using a tracker that adaptively builds a target model reflecting changes in appearance, typical of a video setting. However, adaptive appearance trackers often suffer from drift, a gradual adaptation of the tracker to non-targets. To alleviate this problem, our tracker introduces visual constraints using a combination of generative and discriminative models in a particle filtering framework. The generative term conforms the particles to the space of generic face poses while the discriminative one ensures rejection of poorly aligned targets. This leads to a tracker that significantly improves robustness against abrupt appearance changes and occlusions, critical for the subsequent recognition phase. Identity of the tracked subject is established by fusing pose-discriminant and person-discriminant features over the duration of a video sequence. This leads to a robust video-based face recognizer with state-of-the-art recognition performance. We test the quality of tracking and face recognition on realworld noisy videos from YouTube as well as the standard Honda/UCSD database. Our approach produces successful face tracking results on over 80% of all videos without video or person-specific parameter tuning. The good tracking performance induces similarly high recognition rates: 100% on Honda/UCSD and over 70% on the YouTube set containing 35 celebrities in 1500 sequences.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Fluid in Video: Augmenting Real Video with Simulated Fluids
Comput. Graph. Forum (Proc. Eurographics), vol. 27 (2008), pp. 487-496
[u'Vivek Kwatra', u'Philippos Mordohai', u'Rahul Narain', u'Sashi Kumar Penta', u'Mark Carlson', u'Marc Pollefeys', u'Ming C. Lin']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Large Scale Learning and Recognition of Faces in Web Videos
FG2008
[u'Ming Zhao', u'Jay Yagnik', u'Hartwig Adam', u'David Bau']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34395.html
notfound
=========================
Large-Scale Manifold Learning
Computer Vision and Pattern Recognition (CVPR) (2008)
[u'Ameet Talwalkar', u'Sanjiv Kumar', u'Henry A. Rowley']
MachinePerception
Abstract: This paper examines the problem of extracting low-dimensional manifold structure given millions of high-dimensional face images. Specifically, we address the computational challenges of nonlinear dimensionality reduction via Isomap and Laplacian Eigenmaps, using a graph containing about 18 million nodes and 65 million edges. Since most manifold learning techniques rely on spectral decomposition, we first analyze two approximate spectral decomposition techniques for large dense matrices (Nystrom and Column-sampling), providing the first direct theoretical and empirical comparison between these techniques. We next show extensive experiments on learning low-dimensional embeddings for two large face datasets: CMU-PIE (35 thousand faces) and a web dataset (18 million faces). Our comparisons show that the Nystrom approximation is superior to the Column-sampling method. Furthermore, approximate Isomap tends to perform better than Laplacian Eigenmaps on both clustering and classification with the labeled CMU-PIE dataset.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Linear Time Maximally Stable Extremal Regions
Proc. 10th Europ. Conf. Comput. Vision (2008), pp. 183-196
[u"David Nist{\\'e}r", u'Henrik Stewnius']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34391.html
notfound
=========================
Markovian Mixture Face Recognition with discriminative face alignment
automatic face and gesture recognition, ieee (2008)
[u'Ming Zhao']
MachinePerception
Abstract: A typical automatic face recognition system is composed of three parts: face detection, face alignment and face recognition. Conventionally, these three parts are processed in a bottom-up manner: face detection is performed first, then the results are passed to face alignment, and finally to face recognition. The bottom-up approach is one extreme of vision approaches. The other extreme approach is top-down. In this paper, we proposed a stochastic mixture approach for combining bottom-up and top-down face recognition: face recognition is performed from the results of face alignment in a bottom-up way, and face alignment is performed based on the results of face recognition in a top-down way. By modeling the mixture face recognition as a stochastic process, the recognized person is decided probabilistically according to the probability distribution coming from the stochastic face recognition, and the recognition problem becomes that who the most probable person is when the stochastic process of face recognition goes on for a long time or ideally for an infinite duration. This problem is solved with the theory of Markov chains by modeling the stochastic process of face recognition as a Markov chain. As conventional face alignment is not suitable for this mixture approach, discriminative face alignment is proposed. And we also prove that the stochastic mixture face recognition results only depend on discriminative face alignment, not on conventional face alignment. The effectiveness of our approach is shown by extensive experiments.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Mass Personalization: Social and Interactive Applications using Sound-Track Identification
Journal of Multimedia Tools and Applications, vol. 36 (2008), pp. 115-132
[u'Michael Fink', u'Michele Covell', u'Shumeet Baluja']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
PageRank for Product Image Search
WWW-2008
[u'Yushi Jing', u'Shumeet Baluja']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Permutation Grouping: Intelligent Hash Function Design for Audio & Image Retrieval
International Conference on Acoustics, Speech and Signal Processing (ICASSP-2008)
[u'Shumeet Baluja', u'Michele Covell', u'Sergey Ioffe']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub33468.html
notfound
=========================
Reducing Photon Mapping Bandwidth by Query Reordering
IEEE Transactions on Visualization and Computer Graphics, vol. 14 (2008)
[u'Joshua Steinhurst', u'Greg Coombe', u'Anselmo Lastra']
MachinePerception
Abstract: Photon mapping places an enormous burden on the memory hierarchy. Rendering a 512512 image of a simple scene can require more than 196GB of raw bandwidth to the photon map data structure. This bandwidth is a major obstacle to real time photon mapping. This paper investigates two approaches for reducing the required bandwidth: 1) reordering the kNN searches; and 2) cache conscious data structures. Using a Hilbert curve reordering, we demonstrate an experimental lower bound of 15MB of bandwidth for the same scene. Unfortunately, this improvement of four orders of magnitude requires a prohibitive amount of intermediate storage. We introduce two novel cost-effective algorithms that reduce the bandwidth by one order of magnitude. Scenes of different complexities are shown to exhibit similar reductions in bandwidth. We explain why the choice of data structure does not achieve similar reductions. We also examine the interaction of query reordering with two photon map acceleration techniques, importance sampling and the irradiance cache. Query reordering exploits the additional coherence that arises from the use of importance sampling in scenes with glossy surfaces. Irradiance caching also benefits from query reordering, even when complex surface geometry reduces the effectiveness of the irradiance cache.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Solving the label resolution problem in supervised video content classification
MIR '08: Proceeding of the 1st ACM international conference on Multimedia information retrieval, ACM, New York, NY, USA (2008), pp. 276-282
[u'Ullas Gargi', u'Jay Yagnik']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Stereo Matching with Color-weighted Correlation, Hierarchical Belief Propagation and Occlusion Handling
IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI) (2008)
[u'Qingxiong Yang', u'Liang Wang', u'Ruigang Yang', u'Henrik Stewnius', u'David Nistr']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Visual Synset: Towards a Higher-level Visual Representation
CVPR (2008)
[u'Yantao Zheng', u'Ming Zhao', u'Shi-Yong Neo', u'Tat-Seng Chua', u'Qi Tian']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34634.html
notfound
=========================
VisualRank: Applying PageRank to Large-Scale Image Search
IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 30 (2008), pp. 1877-1890
[u'Yushi Jing', u'Shumeet Baluja']
MachinePerception
Abstract: Because of the relative ease in understanding and processing text, commercial image-search systems often rely on techniques that are largely indistinguishable from text search. Recently, academic studies have demonstrated the effectiveness of employing image-based features to provide either alternative or additional signals to use in this process. However, it remains uncertain whether such techniques will generalize to a large number of popular Web queries and whether the potential improvement to search quality warrants the additional computational cost. In this work, we cast the image-ranking problem into the task of identifying authority nodes on an inferred visual similarity graph and propose VisualRank to analyze the visual link structures among images. The images found to be authorities are chosen as those that answer the image-queries well. To understand the performance of such an approach in a real system, we conducted a series of large-scale experiments based on the task of retrieving images for 2,000 of the most popular products queries. Our experimental results show significant improvement, in terms of user satisfaction and relevancy, in comparison to the most recent Google Image Search results. Maintaining modest computational cost is vital to ensuring that this procedure can be used in practice; we describe the techniques required to make this system practical for large-scale deployment in commercial search engines.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Waveprint: Efficient Wavelet-Based Audio Fingerprinting
Pattern Recognition (2008)
[u'Shumeet Baluja', u'Michele Covell']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Web-scale Image Annotation
Pacific-Rim Conference on Multimedia (2008) (to appear)
[u'Jiakai Liu', u'Rong Hu', u'Meihong Wang', u'Yi Wang', u'Edward Chang']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub33418.html
notfound
=========================
An Overview of the Tesseract OCR Engine
Proc. Ninth Int. Conference on Document Analysis and Recognition (ICDAR), IEEE Computer Society (2007), pp. 629-633
[u'Ray Smith']
MachinePerception
Abstract: The Tesseract OCR engine, as was the HP Research Prototype in the UNLV Fourth Annual Test of OCR Accuracy[1], is described in a comprehensive overview. Emphasis is placed on aspects that are novel or at least unusual in an OCR engine, including in particular the line finding, features/classification methods, and the adaptive classifier.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Audio Fingerprinting: Combining Computer Vision & Data Stream Processing
Proceedings of the 2007 International Conference on Acoustics, Speech, and Signal Processing
[u'Shumeet Baluja', u'Michele Covell']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Automated Image Orientation Detection: A Scalable Boosting Approach
Pattern Analysis and Applications (2007)
[u'Shumeet Baluja']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Automatic Alignment of Large-scale Aerial Rasters to Road-maps
ACM GIS 2007, ACM
[u'James Xiaqing Wu', u'Rodrigo Carceroni', u'Hui Fang', u'Steve Zelinka', u'Andrew Kirmse']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Boosting Sex Identification Performance
International Journal of Computer Vision, vol. 71 (2007), pp. 111-119
[u'Shumeet Baluja', u'Henry A. Rowley']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Canonical Image Selection from the Web
ACM International Conference on Image and Video Retrieval (2007)
[u'Yushi Jing', u'Shumeet Baluja', u'Henry A. Rowley']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Classification of Weakly-Labeled Data with Partial Equivalence Relations
International Conference on Computer Vision (ICCV) (2007)
[u'Sanjiv Kumar', u'Henry A. Rowley']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Detail Preserving Shape Deformation in Image Editing
Proc. SIGGRAPH 2007, ACM, San Diego, no. 12
[u'Hui Fang', u'John C. Hart']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Efficient Complete and Incomplete Path Openings and Closings
Image and Vision Computing, vol. 25, no. 4 (2007), pp. 416-425
[u'Hugues Talbot', u'Ben Appleton']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
GRADE-IV: Visualizing Graphics Library Operations in an Executing Program
SIGGRAPH 2007 Posters, ACM, no. 118
[u'Hidehiko Abe', u'Takeo Igarashi']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Google Books: Making the public domain universally accessible
Document Recognition and Retrieval XIV, SPIE (2007), 65000H1-65000H10
[u'Adam Langley', u'Dan Bloomberg']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub33255.html
notfound
=========================
Imagers as sensors: Correlating plant CO2 uptake with digital visible-light imagery
Data Management for Sensor Networks (2007)
[u'Josh Hyman', u'Eric Graham', u'Mark Hansen', u'Deborah Estrin']
MachinePerception
Abstract: There exist many natural phenomena where direct measurement is either impossible or extremely invasive. To obtain approximate measurements of these phenomena we can build prediction models based on other sensing modalities such as features extracted from data collected by an imager. These models are derived from controlled experiments performed under laboratory conditions, and can then be applied to the associated event in nature. In this paper we explore various different methods for generating such models and discuss their accuracy, robustness, and computational complexity. Given sufficiently computationally simple models, we can eventually push their computation down towards the sensor nodes themselves to reduce the amount of data required to both flow through the network and be stored in a database. The addition of these models turn in-situ imagers into powerful biological sensors, and image databases into useful records of biological activity.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Known-Audio Detection Using Waveprint: Spectrogram Fingerprinting By Wavelet Hashing
Proceedings of the 2007 International Conference on Acoustics, Speech, and Signal Processing
[u'Michele Covell', u'Shumeet Baluja']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Music Identification with Weighted Finite-State Transducers
Proceedings of the International Conference in Acoustics, Speech and Signal Processing (ICASSP) (2007)
[u'Eugene Weinstein', u'Pedro J. Moreno']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Ordinal Regression Based Subpixel Shift Estimation for Video Super-Resolution
EURASIP Journal on Advances in Signal Processing, vol. 85963 (2007)
[u'Mithun Das Gupta', u'Shyamsundar Rajaram', u'Thomas S. Huang', u'Nemanja Petrovic']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub33012.html
notfound
=========================
Practical Gammatone-Like Filters for Auditory Modeling
EURASIP Journal on Audio, Speech, and Music Processing, vol. 2007 (2007), pp. 12
[u'Andreas G. Katsiamis', u'Emmanuel M. Drakakis', u'Richard F. Lyon']
MachinePerception
Abstract: This paper deals with continuous-time filter transfer functions that resemble tuning curves at particular set of places on the basilar membrane of the biological cochlea and that are suitable for practical VLSI implementations. The resulting filters can be used in a filterbank architecture to realize cochlea implants or auditory processors of increased biorealism. To put the reader into context, the paper starts with a short review on the gammatone filter and then exposes two of its variants, namely, the differentiated all-pole gammatone filter (DAPGF) and one-zero gammatone filter (OZGF), filter responses that provide a robust foundation for modeling cochlea transfer functions. The DAPGF and OZGF responses are attractive because they exhibit certain characteristics suitable for modeling a variety of auditory data: level-dependent gain, linear tail for frequencies well below the center frequency, asymmetry, and so forth. In addition, their form suggests their implementation by means of cascades of N identical two-pole systems which render them as excellent candidates for efficient analog or digital VLSI realizations. We provide results that shed light on their char- acteristics and attributes and which can also serve as design curves for fitting these responses to frequency-domain physiological data. The DAPGF and OZGF responses are essentially a missing link between physiological, electrical, and mechanical models for auditory filtering.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub32813.html
notfound
=========================
Practical MythTV: Building a PVR and Media Center PC
Apress (2007), pp. 350
[u'Michael Still', u'Stewart Smith']
MachinePerception
Abstract: MythTV is a powerful open source personal video recorder (PVR) application that runs on Linux. Developed for several years by volunteers, it offers a stable and extensible platform for automating all of the things you would expect from a PVR, and much more. Practical MythTV: Open Source PVR and Media Center takes a project-based approach to implementing your own MythTV setup. You get to pick and choose the functionality you want to install for your PVR, and will learn the details of everything from selecting hardware to advanced customization. You will learn how to record your favorite television shows, store your DVDs for later playback, create a music library out of your CD collection, and even use your PVR for Voice over IP. Your PVR wouldn't be complete without a remote control or the ability to play back content to other TVs in your home. You'll learn how to do both of these things in this book. You'll even learn to how to utilize your Xbox as a remote front end to play back content. Beyond these basics, you will learn advanced techniques like commercial detection and skipping, auto-expiring content, creating your own themes for MythTV, and utilizing plug-ins to do things like display weather conditions, RSS feeds, and photo slide shows.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Raising Global Awareness with Google Earth
Imaging Notes, vol. 22, no. 2 (2007), pp. 24-29
[u'Rebecca Moore']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Robust music identification, detection, and analysis
Proceedings of the International Conference on Music Information Retrieval (ISMIR) (2007)
[u'M. Mohri', u'Pedro J. Moreno', u'Eugene Weinstein']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Temporally Consistent Reconstruction from Multiple Video Streams using Enhanced Belief Propagation
Eleventh IEEE International Conference on Computer Vision (2007)
[u'E. Scott Larsen', u'Philippos Mordohai', u'Marc Pollefeys', u'Henry Fuchs']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Advertisement Detection and Replacement using Acoustic and Visual Repetition
Proceedings of the 2006 International Workshop on Multimedia Signal Processing, IEEE
[u'Michele Covell', u'Shumeet Baluja', u'Michael Fink']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Content Fingerprinting Using Wavelets
Proceedings of the Conference of Visual Media Production, IET (2006)
[u'Shumeet Baluja', u'Michele Covell']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Detecting Ads in Video Streams using Acoustic and Visual Cues
Computer Magazine (2006), pp. 135-137
[u'Michele Covell', u'Shumeet Baluja', u'Michael Fink']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub32799.html
notfound
=========================
Globally Minimal Surfaces by Continuous Maximal Flows
IEEE Trans. Pattern Anal. Mach. Intell., vol. 28 (2006), pp. 106-118
[u'Ben Appleton', u'Hugues Talbot']
MachinePerception
Abstract: In this paper we address the computation of globally minimal curves and surfaces for image segmentation and stereo reconstruction. We present a solution, simulating a continuous maximal flow by a novel system of partial differential equations. Existing methods are either grid-biased (graph-based methods) or sub-optimal (active contours and surfaces). The solution simulates the flow of an ideal fluid with isotropic velocity constraints. Velocity constraints are defined by a metric derived from image data. An auxiliary potential function is introduced to create a system of partial differential equations. It is proven that the algorithm produces a globally maximal continuous flow at convergence, and that the globally minimal surface may be obtained trivially from the auxiliary potential. The bias of minimal surface methods toward small objects is also addressed. An efficient implementation is given for the flow simulation. The globally minimal surface algorithm is applied to segmentation in 2D and 3D as well as to stereo matching. Results in 2D agree with an existing minimal contour algorithm for planar images. Results in 3D segmentation and stereo matching demonstrate that the new algorithm is robust and free from grid bias.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Large Scale Image-Based Adult-Content Filtering
1st International Conference on Computer Vision Theory, Sebutal, Portugal (2006)
[u'Henry A. Rowley', u'Yushi Jing', u'Shumeet Baluja']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Query by Semantic Example
CIVR (2006), pp. 51-60
[u'Nikhil Rasiwasia', u'Nuno Vasconcelos', u'Pedro J. Moreno']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Social- and Interactive-Television Applications Based on Real-Time Ambient-Audio Identification
European Interactive TV Conference (Euro-ITV) (2006)
[u'Michael Fink', u'Michele Covell', u'Shumeet Baluja']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Time-Scale Modification for 3G-Telephony Video
Proceedings of the 2006 International Workshop on Multimedia Signal Processing, IEEE
[u'Michele Covell', u'Sumit Roy', u'Bo Shen']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Boosting Sex Identification Performance
Proceedings of the Seventeenth Innovative Applications of Artificial Intelligence Conference, AAAI (2005), pp. 1508-1513
[u'Shumeet Baluja', u'Henry A. Rowley']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Large Scale Performance Measurement of Content-Based Automated Image-Orientation Detection
International Conference on Image Processing, Genova, Italy (2005)
[u'Shumeet Baluja', u'Henry A. Rowley']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub27809.html
notfound
=========================
The Definitive Guide to ImageMagick
Apress, Apress, Inc. 2560 Ninth St., Ste. 219 Berkeley, CA 94710 (2005), pp. 335
[u'Michael Still']
MachinePerception
Abstract: An open source project backed by years of continual development, ImageMagick supports over 90 image formats and can perform impressive operations such as creating images from scratch; changing colors; stretching, rotating, and overlaying images; and overlaying text on images. Whether you use ImageMagick to manage the family photos or to embark on a job involving millions of images, this book will provide you with the knowledge to manage your images with ease. The Definitive Guide to ImageMagick explains all of these capabilities and more in a practical, learn-by-example fashion. Youll get comfortable using ImageMagick for any image-processing task. Through the books coverage of the ImageMagick interfaces for C, Perl, PHP, and Ruby, youll learn how to incorporate ImageMagick features into a variety of applications.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Efficient Face Orientation Discrimination
International Conference on Image Processing (ICIP-2004)
[u'Shumeet Baluja', u'Mehran Sahami', u'Henry A. Rowley']
MachinePerception
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/MachineTranslation.html
found
http://research.google.com/pubs/pub43848.html
notfound
=========================
Efficient Top-Down BTG Parsing for Machine Translation Preordering
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), Association for Computational Linguistics (2015), pp. 208-218
[u'Tetsuji Nakagawa']
MachineTranslation
Abstract: We present an efficient incremental top-down parsing method for preordering based on Bracketing Transduction Grammar (BTG). The BTG-based preordering framework (Neubig et al., 2012) can be applied to any language using only parallel text, but has the problem of computational efficiency. Our top-down parsing algorithm allows us to use the early update technique easily for the latent variable structured Perceptron algorithm with beam search, and solves the problem. Experimental results showed that the top-down method is more than 10 times faster than a method using the CYK algorithm. A phrase-based machine translation system with the top-down method had statistically significantly higher BLEU scores for 7 language pairs without relying on supervised syntactic parsers, compared to baseline systems using existing preordering methods.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Pushdown automata in statistical machine translation
Computational Linguistics, vol. 40 (2014), pp. 687-723
[u'Cyril Allauzen', u'Bill Byrne', u'Adri de Gispert', u'Gonzalo Iglesias', u'Michael Riley']
MachineTranslation
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41389.html
notfound
=========================
Enlisting the Ghost: Modeling Empty Categories for Machine Translation
Proceedings of ACL, ACL (2013), pp. 822-831
[u'Bing Xiang', u'Xiaoqiang Luo', u'Bowen Zhou']
MachineTranslation
Abstract: Empty categories (EC) are articial elements in Penn Treebanks motivated by the government-binding (GB) theory to explain certain language phenomena such as pro-drop. ECs are ubiquitous in languages like Chinese, but they are tacitly ignored in most machine translation (MT) work because of their elusive nature. In this paper we present a comprehensive treatment of ECs by rst recovering them with a structured MaxEnt model with a rich set of syntactic and lexical features, and then incorporating the predicted ECs into a Chinese-to-English machine translation task through multiple approaches, including the extraction of EC-specic sparse features. We show that the recovered empty categories not only improve the word alignment quality, but also lead to signicant improvements in a large-scale state-of-the-art syntactic MT system.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41651.html
notfound
=========================
Source-Side Classifier Preordering for Machine Translation
Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP '13) (2013)
[u'Uri Lerner', u'Slav Petrov']
MachineTranslation
Abstract: We present a simple and novel classifier-based preordering approach. Unlike existing preordering models, we train feature-rich discriminative classifiers that directly predict the target-side word order. Our approach combines the strengths of lexical reordering and syntactic preordering models by performing long-distance reorderings using the structure of the parse tree, while utilizing a discriminative model with a rich set of features, including lexical features. We present extensive experiments on 22 language pairs, including preordering into English from 7 other languages. We obtain improvements of up to 1.4 BLEU on language pairs in the WMT 2010 shared task. For languages from different families the improvements often exceed 2 BLEU. Many of these gains are also significant in human evaluations.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38107.html
notfound
=========================
A Class-Based Agreement Model For Generating Accurately Inflected Translations
50th Annual Meeting of the Association for Computational Linguistics (ACL 2012)
[u'Spence Green', u'John DeNero']
MachineTranslation
Abstract: When automatically translating from a weakly inflected source language like English to a target language with richer grammatical features such as gender and dual number, the output commonly contains morpho-syntactic agreement errors. To address this issue, we present a target-side, class-based agreement model. Agreement is promoted by scoring a sequence of fine-grained morpho-syntactic classes that are predicted during decoding for each translation hypothesis. For English-to-Arabic translation, our model yields a +1.04 BLEU average improvement over a state-of-the-art baseline. The model does not require bitext or phrase table annotations and can be easily implemented as a feature in many phrase-based decoders.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38279.html
notfound
=========================
A Systematic Comparison of Phrase Table Pruning Techniques
Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, Association for Computational Linguistics, Jeju Island, Korea, pp. 972-983
[u'Richard Zens', u'Daisy Stanton', u'Peng Xu']
MachineTranslation
Abstract: When trained on very large parallel corpora, the phrase table component of a machine translation system grows to consume vast computational resources. In this paper, we introduce a novel pruning criterion that places phrase table pruning on a sound theoretical foundation. Systematic experiments on four language pairs under various data conditions show that our principled approach is superior to existing ad hoc pruning methods.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40409.html
notfound
=========================
Fast and Scalable Decoding with Language Model Look-Ahead for Phrase-based Statistical Machine Translation
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics, Jeju, Republic of Korea (2012), pp. 28-32
[u'Joern Wuebker', u'Hermann Ney', u'Richard Zens']
MachineTranslation
Abstract: In this work we present two extensions to the well-known dynamic programming beam search in phrase-based statistical machine translation (SMT), aiming at increased ef- ciency of decoding by minimizing the number of language model computations and hypothesis expansions. Our results show that language model based pre-sorting yields a small improvement in translation quality and a speedup by a factor of 2. Two look-ahead methods are shown to further increase translation speed by a factor of 2 without changing the search space and a factor of 4 with the side-effect of some additional search errors. We compare our approach with Moses and observe the same performance, but a substantially better trade-off between translation quality and speed. At a speed of roughly 70 words per second, Moses reaches 17.2% BLEU, whereas our approach yields 20.0% with identical models.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40803.html
notfound
=========================
Improved Domain Adaptation for Statistical Machine Translation
AMTA-2012, The Association for Machine Translation in the Americas
[u'Wei Wang', u'Klaus Macherey', u'Wolfgang Macherey', u'Franz Och', u'Peng Xu']
MachineTranslation
Abstract: We present a simple and effective infrastructure for domain adaptation for statistical machine translation (MT). To build MT systems for different domains, it trains, tunes and deploys a single translation system that is capable of producing adapted domain translations and preserving the original generic accuracy at the same time. The approach uni?es automatic domain detection and domain model parameterization into one system. Experiment results on 20 language pairs demonstrate its viability
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38138.html
notfound
=========================
Unsupervised Translation Sense Clustering
the North American Association of Computational Linguistics (2012)
[u'Mohit Bansal', u'John DeNero', u'Dekang Lin']
MachineTranslation
Abstract: We propose an unsupervised method for clustering the translations of a word, such that the translations in each cluster share a common semantic sense. Words are assigned to clusters based on their usage distribution in large monolingual and parallel corpora using the soft K-Means algorithm. In addition to describing our approach, we formalize the task of translation sense clustering and describe a procedure that leverages WordNet for evaluation. By comparing our induced clusters to reference clusters generated from WordNet, we demonstrate that our method effectively identifies sense-based translation clusters and benefits from both monolingual and parallel corpora. Finally, we describe a method for annotating clusters with usage examples.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Lightweight Evaluation Framework for Machine Translation Reordering
Proceedings of the 6th Workshop on Statistical Machine Translation (2011), pp. 468-476
[u'David Talbot', u'Hideto Kazawa', u'Hiroshi Ichikawa']
MachineTranslation
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Binarized Forest to String Translation
ACL (2011), pp. 835-845
[u'Hao Zhang', u'Licheng Fang', u'Peng Xu', u'Xiaoyun Wu']
MachineTranslation
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Hierarchical Phrase-Based Translation Representations
Proceedings of EMNLP 2011
[u'Gonzalo Iglesias', u'Cyril Allauzen', u'William Byrne', u'Adri de Gispert', u'Michael Riley']
MachineTranslation
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37163.html
notfound
=========================
Inducing Sentence Structure from Parallel Corpora for Reordering
Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing (EMNLP), Association for Computational Linguistics
[u'John DeNero', u'Jakob Uszkoreit']
MachineTranslation
Abstract: When translating among languages that differ substantially in word order, machine translation (MT) systems benet from syntactic preorderingan approach that uses features from a syntactic parse to permute source words into a target-language-like order. This paper presents a method for inducing parse trees automatically from a parallel corpus, instead of using a supervised parser trained on a treebank. These induced parses are used to preorder source sentences. We demonstrate that our induced parser is effective: it not only improves a state-of-the-art phrase-based system with integrated reordering, but also approaches the performance of a recent preordering method based on a supervised parser. These results show that the syntactic structure which is relevant to MT pre-ordering can be learned automatically from parallel text, thus establishing a new application for unsupervised grammar induction.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37093.html
notfound
=========================
Language-independent Compound Splitting with Morphological Operations
ACL HLT 2011, pp. 10
[u'Klaus Macherey', u'Andrew M. Dai', u'David Talbot', u'Ashok C. Popat', u'Franz Och']
MachineTranslation
Abstract: Translating compounds is an important problem in machine translation. Since many compounds have not been observed during training, they pose a challenge for translation systems. Previous decompounding methods have often been restricted to a small set of languages as they cannot deal with more complex compound forming processes. We present a novel and unsupervised method to learn the compound parts and morphological operations needed to split compounds into their compound parts. The method uses a bilingual corpus to learn the morphological operations required to split a compound into its parts. Furthermore, monolingual corpora are used to learn and filter the set of compound part candidates. We evaluate our method within a machine translation task and show significant improvements for various languages to show the versatility of the approach.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37256.html
notfound
=========================
Model-Based Aligner Combination Using Dual Decomposition
Proceedings of the Association for Computational Linguistics (ACL), 2011
[u'John DeNero', u'Klaus Macherey']
MachineTranslation
Abstract: Unsupervised word alignment is most often modeled as a Markov process that generates a sentence f conditioned on its translation e. A similar model generating e from f will make different alignment predictions. Statistical machine translation systems combine the predictions of two directional models, typically using heuristic combination procedures like grow-diag-final. This paper presents a graphical model that embeds two directional aligners into a single model. Inference can be performed via dual decomposition, which reuses the efficient inference algorithms of the directional models. Our bidirectional model enforces a one-to-one phrase constraint while accounting for the uncertainty in the underlying directional models. The resulting alignments improve upon baseline combination heuristics in word-level and phrase-level evaluations.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37159.html
notfound
=========================
Training a Parser for Machine Translation Reordering
Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing (EMNLP '11)
[u'Jason Katz-Brown', u'Slav Petrov', u'Ryan McDonald', u'Franz Och', u'David Talbot', u'Hiroshi Ichikawa', u'Masakazu Seno']
MachineTranslation
Abstract: We propose a simple training regime that can improve the extrinsic performance of a parser, given only a corpus of sentences and a way to automatically evaluate the extrinsic quality of a candidate parse. We apply our method to train parsers that excel when used as part of a reordering component in a statistical machine translation system. We use a corpus of weakly-labeled reference reorderings to guide parser training. Our best parsers contribute significant improvements in subjective translation quality while their intrinsic attachment scores typically regress.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37260.html
notfound
=========================
Translation-Inspired OCR
ICDAR-2011
[u'Dmitriy Genzel', u'Ashok C. Popat', u'Nemanja Spasojevic', u'Michael Jahr', u'Andrew Senior', u'Eugene Ie', u'Frank Yung-Fong Tang']
MachineTranslation
Abstract: Optical character recognition is carried out using techniques borrowed from statistical machine translation. In particular, the use of multiple simple feature functions in linear combination, along with minimum-error-rate training, integrated decoding, and $N$-gram language modeling is found to be remarkably effective, across several scripts and languages. Results are presented using both synthetic and real data in five languages.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37162.html
notfound
=========================
Watermarking the Outputs of Structured Prediction with an application in Statistical Machine Translation
Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing (EMNLP), Association for Computational Linguistics
[u'Ashish Venugopal', u'Jakob Uszkoreit', u'David Talbot', u'Franz Och', u'Juri Ganitkevitch']
MachineTranslation
Abstract: We propose a general method to watermark and probabilistically identify the structured outputs of machine learning algorithms. Our method is robust to local editing operations and provides well dened trade-os between the ability to identify algorithm outputs and the quality of the watermarked output. Unlike previous work in the eld, our approach does not rely on controlling the inputs to the algorithm and provides probabilistic guarantees on the ability to identify collections of results from ones own algorithm. We present an application in statistical machine translation, where machine translated output is watermarked at minimal loss in translation quality and detected with high recall.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36484.html
notfound
=========================
Automatically Learning Source-side Reordering Rules for Large Scale Machine Translation
COLING-2010
[u'Dmitriy Genzel']
MachineTranslation
Abstract: We describe an approach to automatically learn reordering rules to be applied as a preprocessing step in phrase-based machine translation. We learn rules for 8 different language pairs, showing BLEU improvements for all of them, and demonstrate that many important order transformations (SVO to SOV or VSO, head-modifier, verb movement) can be captured by this approach.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Large Scale Parallel Document Mining for Machine Translation
Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), Coling 2010 Organizing Committee, Beijing, China, pp. 1101-1109
[u'Jakob Uszkoreit', u'Jay Ponte', u'Ashok Popat', u'Moshe Dubiner']
MachineTranslation
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Model Combination for Machine Translation
Proceedings of the North American Chapter of the Association for Computational Linguistics (NAACL) (2010), pp. 975-983
[u'John DeNero', u'Shankar kumar', u'Ciprian Chelba', u'Franz Och']
MachineTranslation
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36557.html
notfound
=========================
Statistical Language Modeling
The Handbook of Computational Linguistics and Natural Language Processing, Wiley-Blackwell, John Wiley & Sons Ltd, The Atrium, Southern Gate, Chichester, West Sussex, PO19 8SQ United Kingdom (2010), pp. 74-104
[u'Ciprian Chelba']
MachineTranslation
Abstract: Many practical applications such as automatic speech recognition, statistical machine translation, spelling correction resort to variants of the well established source-channel model for producing the correct string of words W given an input speech signal, sentence in foreign language, or typed text with possible mistakes, respectively. A basic component of such systems is a statistical language model which estimates the prior probability values for strings of words W.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Syntax based reordering with automatically derived rules for improved statistical machine translation
Proceedings of the 23rd International Conference on Computational Linguistics, Association for Computational Linguistics, Stroudsburg, PA, USA (2010), pp. 1119-1127
[u'Karthik Visweswariah', u'Jiri Navratil', u'Jeffrey Sorensen', u'Vijil Chenthamarakshan', u'Nanda Kambhatla']
MachineTranslation
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36745.html
notfound
=========================
Poetic Statistical Machine Translation: Rhyme and Meter
EMNLP (2010), pp. 158-166
[u'Dmitriy Genzel', u'Jakob Uszkoreit', u'Franz Och']
MachineTranslation
Abstract: As a prerequisite to translation of poetry, we implement the ability to produce translations with meter and rhyme for phrase-based MT, examine whether the hypothesis space of such a system is flexible enough to accommodate such constraints, and investigate the impact of such constraints on translation quality.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Compiling a massive, multilingual dictionary via probabilistic inference
ACL-IJCNLP '09: Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 1, Association for Computational Linguistics, Morristown, NJ, USA (2009), pp. 262-270
[u'Mausam', u'Stephen Soderland', u'Oren Etzioni', u'Daniel S. Weld', u'Michael Skinner', u'Jeff Bilmes']
MachineTranslation
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Creating a High-Quality Machine Translation System for a Low-Resource Language: Yiddish
MT Summit XII (2009)
[u'Dmitriy Genzel', u'Klaus Macherey', u'Jakob Uszkoreit']
MachineTranslation
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Efcient Minimum Error Rate Training and Minimum Bayes-Risk Decoding for Translation Hypergraphs and Lattices
Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, ACL and AFNLP (2009), pp. 163-171
[u'Shankar Kumar', u'Wolfgang Macherey', u'Chris Dyer', u'Franz Och']
MachineTranslation
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Learning linear ordering problems for better translation
EMNLP '09: Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics, Morristown, NJ, USA, pp. 1007-1016
[u'Roy Tromble', u'Jason Eisner']
MachineTranslation
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Using a dependency parser to improve SMT for subject-object-verb languages
NAACL '09: Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, Association for Computational Linguistics, Morristown, NJ, USA, pp. 245-253
[u'Peng Xu', u'Jaeho Kang', u'Michael Ringgaard', u'Franz Och']
MachineTranslation
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A systematic comparison of phrase-based, hierarchical and syntax-augmented statistical MT
Proceedings of the 22nd International Conference on Computational Linguistics (COLING) (2008)
[u'Andreas Zollmann', u'Ashish Venugopal', u'Franz Josef Och', u'Jay Ponte']
MachineTranslation
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Distributed Word Clustering for Large Scale Class-Based Language Modeling in Machine Translation
Proceedings of ACL-08: HLT, Association for Computational Linguistics, Columbus, Ohio (2008), pp. 755-762
[u'Jakob Uszkoreit', u'Thorsten Brants']
MachineTranslation
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34628.html
notfound
=========================
Lattice Minimum Bayes-Risk Decoding for Statistical Machine Translation
Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics, pp. 620-629
[u'Roy Tromble', u'Shankar Kumar', u'Franz Och', u'Wolfgang Macherey']
MachineTranslation
Abstract: We present Minimum Bayes-Risk (MBR) decoding over translation lattices that compactly encode a huge number of translation hypotheses. We describe conditions on the loss function that will enable efficient implementation of MBR decoders on lattices. We introduce an approximation to the BLEU score~\cite{papineni01} that satisfies these conditions. The MBR decoding under this approximate BLEU is realized using Weighted Finite State Automata. Our experiments show that the Lattice MBR decoder yields moderate, consistent gains in translation performance over N-best MBR decoding on Arabic-to-English, Chinese-to-English and English-to-Chinese translation tasks. We conduct a range of experiments to understand why Lattice MBR improves upon N-best MBR and also study the impact of various parameters on MBR performance.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34629.html
notfound
=========================
Lattice-based Minimum Error Rate Training for Statistical Machine Translation
Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing (EMNLP), Association for Computational Linguistics, pp. 725-734
[u'Wolfgang Macherey', u'Franz Och', u'Ignacio Thayer', u'Jakob Uszkoreit']
MachineTranslation
Abstract: Minimum Error Rate Training (MERT) is an effective means to estimate the feature function weights of a linear model such that an automated evaluation criterion for measuring system performance can directly be optimized in training. To accomplish this, the training procedure determines for each feature function its exact error surface on a given set of candidate translations. The feature function weights are then adjusted by traversing the error surface combined over all sentences and picking those values for which the resulting error count reaches a minimum. Typically, candidates in MERT are represented as N-best lists which contain the N most probable translation hypotheses produced by a decoder. In this paper, we present a novel algorithm that allows for efficiently constructing and representing the exact error surface of all translations that are encoded in a phrase lattice. Compared to N-best MERT, the number of candidate translations thus taken into account increases by several orders of magnitudes. The proposed method is used to train the feature function weights of a phrase-based statistical machine translation system. Experiments conducted on the NIST 2008 translation tasks show significant runtime improvements and moderate BLEU score gains over N-best MERT.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Mining Parenthetical Translations from the Web by Word Alignment
Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL-2008), Columbus, Ohio, pp. 994-1002
[u'Dekang Lin', u'Shaojun Zhao', u'Benjamin Van Durme', u'Marius Pasca']
MachineTranslation
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Using Word Space Models for Enriching Multilingual Lexical Resources and Detecting the Relation Between Morphological and Semantic Composition
International Conference on Web and Information Tecnologies (ICWIT '08) (2008), pp. 195-201
[u'Adil Toumouh', u'Dominic Widdows', u'Ahmed Lehireche']
MachineTranslation
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34506.html
notfound
=========================
An Empirical Study on Computing Consensus Translations from Multiple Machine Translation Systems
Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), Association for Computational Linguistics, 209 N. Eighth Street, East Stroudsburg, PA, USA, pp. 986-995
[u'Wolfgang Macherey', u'Franz J. Och']
MachineTranslation
Abstract: This paper presents an empirical study on how different selections of input translation systems affect translation quality in system combination. We give empirical evidence that the systems to be combined should be of similar quality and need to be almost uncorrelated in order to be beneficial for system combination. Experimental results are presented for composite translations computed from large numbers of different research systems as well as a set of translation systems derived from one of the best-ranked machine translation engines in the 2006 NIST machine translation evaluation.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub33430.html
notfound
=========================
Improving Word Alignment with Bridge Languages
Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, Association for Computational Linguistics, 209 N. Eighth Street, East Stroudsburg, PA, USA (2007)
[u'Shankar Kumar', u'Franz Och', u'Wolfgang Macherey']
MachineTranslation
Abstract: We describe an approach to improve Statistical Machine Translation (SMT) performance using multi-lingual, parallel, sentence-aligned corpora in several bridge languages. Our approach consists of a simple method for utilizing a bridge language to create a word alignment system and a procedure for combining word alignment systems from multiple bridge languages. The final translation is obtained by consensus decoding that combines hypotheses obtained using all bridge language word alignments. We present experiments showing that multilingual, parallel text in Spanish, French, Russian, and Chinese can be utilized in this framework to improve translation performance on an Arabic-to-English task.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Inversion transduction grammar for joint phrasal translation modeling
SSST '07: Proceedings of the NAACL-HLT 2007/AMTA Workshop on Syntax and Structure in Statistical Translation, Association for Computational Linguistics, Morristown, NJ, USA, pp. 17-24
[u'Colin Cherry', u'Dekang Lin']
MachineTranslation
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Large Language Models in Machine Translation
Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), pp. 858-867
[u'Thorsten Brants', u'Ashok C. Popat', u'Peng Xu', u'Franz J. Och', u'Jeffrey Dean']
MachineTranslation
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A path-based transfer model for machine translation
COLING '04: Proceedings of the 20th international conference on Computational Linguistics, Association for Computational Linguistics, Morristown, NJ, USA (2004), pp. 625
[u'Dekang Lin']
MachineTranslation
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/MobileSystems.html
found
http://research.google.com/pubs/pub43311.html
notfound
=========================
CQIC: Revisiting Cross-Layer Congestion Control f or Cellular Networks
Proceedings of The 16th International Workshop on Mobile Computing Systems and Applications (HotMobile), ACM (2015), pp. 45-50
[u'Feng Lu', u'Hao Du', u'Ankur Jain', u'Geoffrey M. Voelker', u'Alex C. Snoeren', u'Andreas Terzis']
MobileSystems
Abstract: With the advent of high-speed cellular access and the overwhelming popularity of smartphones, a large percent of todays Internet content is being delivered via cellular links. Due to the nature of long-range wireless signal propagation, the capacity of the last hop cellular link can vary by orders of magnitude within a short period of time (e.g., a few seconds). Unfortunately, TCP does not perform well in such fast-changing environments, potentially leading to poor spectrum utilization and high end-to-end packet delay. In this paper we revisit seminal work in cross-layer optimization the context of 4G cellular networks. Specifically, we leverage the rich physical layer information exchanged between base stations (NodeB) and mobile phones (UE) to predict the capacity of the underlying cellular link, and propose CQIC, a cross-layer congestion control design. Experiments on real cellular networks confirm that our capacity estimation method is both accurate and precise. A CQIC sender uses these capacity estimates to adjust its packet sending behavior. Our preliminary evaluation reveals that CQIC improves throughput over TCP by 1.082.89 for small and medium flows. For large flows, CQIC attains throughput comparable to TCP while reducing the average RTT by 2.382.65x.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43272.html
found
=========================
Effects of Language Modeling and its Personalization on Touchscreen Typing Performance
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI 2015), ACM, New York, NY, USA, pp. 649-658
[u'Andrew Fowler', u'Kurt Partridge', u'Ciprian Chelba', u'Xiaojun Bi', u'Tom Ouyang', u'Shumin Zhai']
MobileSystems
Abstract: Modern smartphones correct typing errors and learn userspecific words (such as proper names). Both techniques are useful, yet little has been published about their technical specifics and concrete benefits. One reason is that typing accuracy is difficult to measure empirically on a large scale. We describe a closed-loop, smart touch keyboard (STK) evaluation system that we have implemented to solve this problem. It includes a principled typing simulator for generating human-like noisy touch input, a simple-yet-effective decoder for reconstructing typed words from such spatial data, a large web-scale background language model (LM), and a method for incorporating LM personalization. Using the Enron email corpus as a personalization test set, we show for the first time at this scale that a combined spatial/language model reduces word error rate from a pre-model baseline of 38.4% down to 5.7%, and that LM personalization can improve this further to 4.6%.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43447.html
notfound
=========================
Flywheel: Google's Data Compression Proxy for the Mobile Web
Proceedings of the 12th USENIX Symposium on Networked Systems Design and Implementation (NSDI 2015)
[u'Victor Agababov', u'Michael Buettner', u'Victor Chudnovsky', u'Mark Cogan', u'Ben Greenstein', u'Shane McDaniel', u'Michael Piatek', u'Colin Scott', u'Matt Welsh', u'Bolian Yin']
MobileSystems
Abstract: Mobile devices are increasingly the dominant Internet access technology. Nevertheless, high costs, data caps, and throttling are a source of widespread frustration, and a significant barrier to adoption in emerging markets. This paper presents Flywheel, an HTTP proxy service that extends the life of mobile data plans by compressing responses in-flight between origin servers and client browsers. Flywheel is integrated with the Chrome web browser and reduces the size of proxied web pages by 50% for a median user. We report measurement results from millions of users as well as experience gained during three years of operating and evolving the production service at Google.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44263.html
found
=========================
Gesture On: Always-On Touch Gestures for Fast Mobile Access from Device Standby Mode
CHI 2015: ACM Conference on Human Factors in Computing Systems, ACM, pp. 3355-3364
[u'Hao Lu', u'Yang Li']
MobileSystems
Abstract: Contributes a system that overrides the mobile platform kernel behavior to enable touchscreen gesture shortcuts in standby mode. A user can issue a gesture on the touchscreen before the screen is even turned on.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43127.html
found
=========================
GyroPen: Gyroscopes for Pen-input with Mobile Phones
IEEE Transactions on Human-Machine Systems, vol. 45 (2015), pp. 263-271
[u'Thomas Deselaers', u'Daniel Keysers', u'Jan Hosang', u'Henry Rowley']
MobileSystems
Abstract: We present GyroPen, a method for text entry into mobile devices using pen-like writing interaction reconstructed from standard built-in sensors. The key idea is to reconstruct a representation of the trajectory of the phone's corner that is touching a writing surface from the measurements obtained from the phone's gyroscopes and accelerometers. We propose to directly use the angular trajectory for this reconstruction, which removes the necessity for accurate absolute 3D position estimation, a task that can be difficult using low-cost accelerometers. Recognition is then performed using an off-the-shelf handwriting recognition system, allowing easy extension to new languages and scripts. In a small user study (n=10), the average novice participant was able to write the first word only 37 seconds after the starting to use GyroPen for the first time. With some experience, users were able to write at the speed of 3-4s for one English word and with a character error rate of 18%.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44311.html
notfound
=========================
Mantis: Efficient Predictions of Execution Time, Energy Usage, Memory Usage and Network Usage on Smart Mobile Devices
IEEE Transactions on Mobile Computing, vol. 14 (2015), pp. 2059-2072
[u'Yongin Kwon', u'Sangmin Lee', u'Hayoon Yi', u'Donghyun Kwon', u'Seungjun Yang', u'Byung-Gon Chun', u'Ling Huang', u'Petros Maniatis', u'Mayur Naik', u'Yunheung Paek']
MobileSystems
Abstract: We present Mantis, a framework for predicting the computational resource consumption (CRC) of Android applications on given inputs accurately, and efficiently. A key insight underlying Mantis is that program codes often contain features that correlate with performance and these features can be automatically computed efficiently. Mantis synergistically combines techniques from program analysis and machine learning. It constructs concise CRC models by choosing from many program execution features only a handful that are most correlated with the programs CRC metric yet can be evaluated efficiently from the programs input. We apply program slicing to reduce evaluation time of a feature and automatically generate executable code snippets for efficiently evaluating features. Our evaluation shows that Mantis predicts four CRC metrics of seven Android apps with estimation error in the range of 0-11.1 percent by executing predictor code spending at most 1.3 percent of their execution time on Galaxy Nexus.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43271.html
found
=========================
Optimizing Touchscreen Keyboards for Gesture Typing
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI 2015), ACM, New York, NY, USA, pp. 3365-3374
[u'Brian Smith', u'Xiaojun Bi', u'Shumin Zhai']
MobileSystems
Abstract: Despite its growing popularity, gesture typing suffers from a major problem not present in touch typing: gesture ambiguity on the Qwerty keyboard. By applying rigorous mathematical optimization methods, this paper systematically investigates the optimization space related to the accuracy, speed, and Qwerty similarity of a gesture typing keyboard. Our investigation shows that optimizing the layout for gesture clarity (a metric measuring how unique word gestures are on a keyboard) drastically improves the accuracy of gesture typing. Moreover, if we also accommodate gesture speed, or both gesture speed and Qwerty similarity, we can still reduce error rates by 52% and 37% over Qwerty, respectively. In addition to investigating the optimization space, this work contributes a set of optimized layouts such as GK-D and GK-T that can immediately benefit mobile device users.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43828.html
found
=========================
SpecTrans: Versatile Material Classification for Interaction with Textureless, Specular and Transparent Surfaces
SIGCHI Conference on Human Factors in Computing Systems, ACM (2015), pp. 2191-2200
[u'Munehiko Sato', u'Shigeo Yoshida', u'Alex Olwal', u'Boxin Shi', u'Atsushi Hiyama', u'Tomohiro Tanikawa', u'Michitaka Hirose', u'Ramesh Raskar']
MobileSystems
Abstract: Surface and object recognition is of significant importance in ubiquitous and wearable computing. While various techniques exist to infer context from material properties and appearance, they are typically neither designed for real-time applications nor for optically complex surfaces that may be specular, textureless, and even transparent. These materials are, however, becoming increasingly relevant in HCI for transparent displays, interactive surfaces, and ubiquitous computing. We present SpecTrans, a new sensing technology for surface classification of exotic materials, such as glass, transparent plastic, and metal. The proposed technique extracts optical features by employing laser and multi-directional, multispectral LED illumination that leverages the materials optical properties. The sensor hardware is small in size, and the proposed classification method requires significantly lower computational cost than conventional image-based methods, which use texture features or reflectance analysis, thereby providing real-time performance for ubiquitous computing. Our evaluation of the sensing technique for nine different transparent materials, including air, shows a promising recognition rate of 99.0%. We demonstrate a variety of possible applications using SpecTrans capabilities.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44264.html
found
=========================
Weave: Scripting Cross-Device Wearable Interaction
CHI 2015: ACM Conference on Human Factors in Computing Systems, ACM, pp. 3923-3932
[u'Pei-Yu (Peggy) Chi', u'Yang Li']
MobileSystems
Abstract: Provides a set of high-level APIs, based on JavaScript, and integrated tool support for developers to easily distribute UI output and combine user input and sensing events across devices for cross-device interaction.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Both Complete and Correct? Multi-Objective Optimization of Touchscreen Keyboard
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI 2014), ACM, New York, NY, USA, pp. 2297-2306
[u'Xiaojun Bi', u'Tom Ouyang', u'Shumin Zhai']
MobileSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Designing an Energy-Efficient Could Messaging Service for Smartphones
IEEE Pervasive Computing (2014)
[u'Ashish Sharma', u'Paul Eastham', u'Francesco Nerieri']
MobileSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42488.html
found
=========================
Designing for Healthy Lifestyles: Design Considerations for Mobile Technologies to Encourage Consumer Health and Wellness
Foundations and Trends in Human-Computer Interaction, vol. 6 (2014), 167315
[u'Sunny Consolvo', u'Predrag Klasnja', u'David W. McDonald', u'James A. Landay']
MobileSystems
Abstract: As the rates of lifestyle diseases such as obesity, diabetes, and heart disease continue to rise, the development of eective tools that can help people adopt and sustain healthier habits is becoming ever more important. Mobile computing holds great promise for providing eective support for helping people manage their health in everyday life. Yet, for this promise to be realized, mobile wellness systems need to be well designed, not only in terms of how they implement specic behavior-change techniques but also, among other factors, in terms of how much burden they put on the user, how well they integrate into the users daily life, and how they address the users privacy concerns. Designing for all of these constraints is dicult, and it is often not clear what tradeos particular design decisions have on how a wellness application is experienced and used. In this monograph, we provide an account of dierent design approaches to common features of mobile wellness applications and we discuss the tradeos inherent in those approaches. We also outline the key challenges that HCI researchers and designers will need to address to move the state of the art for mobile wellness technologies forward.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Detecting Tapping Motion on the Side of Mobile Devices By Probabilistically Combining Hand Postures
UIST 2014: ACM Symposium on User Interface Software and Technology, ACM
[u'William McGrath', u'Yang Li']
MobileSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
InkAnchor: Enhancing Informal Ink-Based Note Taking on Touchscreen Mobile Phones
CHI 2014: ACM Conference on Human Factors in Computing Systems
[u'Yi Ren', u'Yang Li', u'Edward Lank']
MobileSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Optimistic Programming of Touch Interaction
TOCHI: ACM Transactions on Computer-Human Interaction (2014)
[u'Yang Li', u'Hao Lu', u'Haimo Zhang']
MobileSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Reflection: Enabling Event Prediction As an On-Device Service for Mobile Interaction
UIST 2014: ACM Symposium on User Interface Software and Technology
[u'Yang Li']
MobileSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43152.html
found
=========================
T(ether): Spatially-Aware Handhelds, Gestures and Proprioception for Multi-User 3D Modeling and Animation
ACM Symposium on Spatial User Interaction, ACM (2014), pp. 90-93
[u'Dvid Lakatos', u'Matthew Blackshaw', u'Alex Olwal', u'Zachary Barryte', u'Ken Perlin', u'Hiroshi Ishii']
MobileSystems
Abstract: T(ether) is a spatially-aware display system for multi-user, collaborative manipulation and animation of virtual 3D objects. The handheld display acts as a window into virtual reality, providing users with a perspective view of 3D data. T(ether) tracks users' heads, hands, fingers and pinching, in addition to a handheld touch screen, to enable rich interaction with the virtual scene. We introduce gestural interaction techniques that exploit proprioception to adapt the UI based on the hand's position above, behind or on the surface of the display. These spatial interactions use a tangible frame of reference to help users manipulate and animate the model in addition to controlling environment properties. We report on initial user observations from an experiment for 3D modeling, which indicate T(ether)'s potential for embodied viewport control and 3D modeling interactions.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Teaching Motion Gestures via Recognizer Feedback
IUI 2014: International Conference on Intelligent User Interfaces
[u'Ankit Kamal', u'Yang Li', u'Edward Lank']
MobileSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42922.html
found
=========================
The Power of Smartphones
IEEE Pervasive Computing, vol. 13-03 (2014), pp. 76-79
[u'Roy Want']
MobileSystems
Abstract: If youre new to power monitoring in the mobile design process, either when building mobile hardware or writing software-based applications, this article will point you in the right direction, helping you identify what characteristics to consider and what test equipment to use.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41644.html
found
=========================
Bayesian Touch - A Statistic Criterion of Target Selection with Finger Touch
Proceedings of UIST 2013 The ACM Symposium on User Interface Software and Technology, ACM, New York, NY, USA, pp. 51-60
[u'Xiaojun Bi', u'Shumin Zhai']
MobileSystems
Abstract: To improve the accuracy of target selection for finger touch, we conceptualize finger touch input as an uncertain process, and derive a statistical target selection riterion, Bayesian Touch Criterion, from combining the basic Bayes rule of probability with the generalized dual Gaussian distribution hypothesis of finger touch. Bayesian Touch Criterion states that the selected target is the candidate with the shortest Bayesian Touch Distance to the touch point, which is computed from the touch point to target center distance and the size of the target. We give the derivation of the Bayesian touch criterion and its empirical evaluation with two experiments. The results show for 2D circular target selection, Bayesian Touch Criterion is significantly more accurate than the commonly used Visual Boundary Criterion (i.e., a target is selected if and only if the touch point falls within its boundary) and its two variants.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41346.html
found
=========================
Behavior-Oriented Data Resource Management in Medical Sensing Systems
ACM Transactions on Sensor Networks (TOSN), vol. 9 (2013), 12:1-12:26
[u'Hyduke Noshadi', u'Foad Dabiri', u'Saro Meguerdichian', u'Miodrag Potkonjak', u'Majid Sarrafzadeh']
MobileSystems
Abstract: Wearable sensing systems have recently enabled a variety of medical monitoring and diagnostic applications in wireless health. The need for multiple sensors and constant monitoring leads these systems to be power hungry and expensive with short operating lifetimes. We introduce a novel methodology that takes advantage of contextual and semantic properties in human behavior to enable efficient design and optimization of such systems from the data and information point of view. This, in turn, directly influences the wireless communication and local processing power consumption. We exploit intrinsic space and temporal correlations between sensor data while considering both user and system contextual behavior. Our goal is to select a small subset of sensors that accurately capture and/or predict all possible signals of a fully instrumented wearable sensing system. Our approach leverages novel modeling, partitioning, and behavioral optimization, which consists of signal characterization, segmentation and time shifting, mutual signal prediction, and a simultaneous minimization composed of subset sensor selection and opportunistic sampling. We demonstrate the effectiveness of the technique on an insole instrumented with 99 pressure sensors placed in each shoe, which cover the bottom of the entire foot, resulting in energy reduction of 72% to 97% for error rates of 5% to 17.5%.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41590.html
notfound
=========================
Capturing Mobile Experience in the Wild: A Tale of Two Apps
8th International Conference on emerging Networking EXperiments and Technologies (CoNEXT), ACM (Association for Computing Machinery) (2013), NA (to appear)
[u'Ashish Patro', u'Shravan Rayanchu', u'Michael Griepentrog']
MobileSystems
Abstract: We present Insight, a framework that collects mobile application analytics with minimal overhead on the application and the developers. Insight offers information about application usage, device and platform statistics, application footprint, user behavior and retention properties and factors affecting application revenues. Further, Insight leverages the vast and diverse mobile user base of the applications to continuously crowd-source network measurements from across the world. This allows us to carry out interesting longitudinal studies about the long term trends in usage and performance characteristics of these networks. Further, by coupling network measurements along with application analytics, Insight also helps understand how network performance can impact application usage, performance and revenues. We deployed Insight on two applications in Apples AppStore and Googles Android Market. One of them, Parallel Kingdom (PK), is a popular Massively Multiplayer Online Role Playing Game (MMORPG) which has over 600,000 unique users distributed across 118 countries. The second application was more recently released and currently has a few thousand users. Our measurements span almost the entire life of the PK game starting from its inception on October 31, 2008 to Nov 10, 2011 (1104 days in total). Through deployment of Insight on this game, we also perform the rst study analyzing the characteristics of a mobile MMORPG.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41878.html
found
=========================
Chale, How Much it Cost to Browse? Results from a Mobile Data Price Transparency Trial in Ghana
Proceedings of the Sixth International Conference on Information and Communication Technologies and Development: Full Papers - Volume 1 (ICTD '13), ACM, New York, NY, USA (2013), pp. 13-23
[u'Nithya Sambasivan', u'Paul Lee', u'Greg Hecht', u'Paul M. Aoki', u'Maria-Ines Carrera', u'Jenny Chen', u'David Pablo Cohn', u'Pete Kruskall', u'Everett Wetchler', u'Michael Youssefmir', u'Astrid Twenebowa Larssen']
MobileSystems
Abstract: Mobile data usage is on the rise globally. In emerging regions, mobile data is particularly expensive and suffers from the lack of price and data usage transparency needed to make informed decisions about Internet use. To measure and address this problem, we designed SmartBrowse, an Internet proxy system that shows mobile data usage information and provides controls to avoid overspending. In this paper, we discuss the results of a 10-week study with SmartBrowse, involving 299 participants in Ghana. Half the users were given SmartBrowse, and the other half was given a regular Internet experience. Our findings suggest that, compared with the control group, using SmartBrowse led to a significant reduction in Internet credit spend and increased online activity among SmartBrowse users, while providing the same or better mobile Internet user experience. Additionally, SmartBrowse users who were prior mobile data non-users increased their webpage views while spending less money than control users. Our discussion contributes to the understanding of how forward-looking ICTD research in the wild can empower mobile data users, in this case, through increased price transparency.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
CrowdLearner: Rapidly Creating Mobile Recognizers Using Crowdsourcing
UIST'13: Proceedings of the 26th annual ACM symposium on User interface software and technology (2013), pp. 163-172
[u'Shahriyar Amini', u'Yang Li']
MobileSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41347.html
notfound
=========================
HERMES: Mobile system for instability analysis and balance assessment
ACM Transactions on Embedded Computing Systems (TECS), vol. 12 (2013), 57:1-57:24
[u'Hyduke Noshadi', u'Foad Dabiri', u'Shaun Ahmadian', u'Navid Amini', u'Majid Sarrafzadeh']
MobileSystems
Abstract: We introduce Hermes, a lightweight smart shoe and its supporting infrastructure aimed at extending gait and instability analysis and human instability/balance monitoring outside of a laboratory environment. We aimed to create a scientific tool capable of high-level measures, by combining embedded sensing, signal processing and modeling techniques. Hermes monitors walking behavior and uses an instability assessment model to generate quantitative value with episodes of activity identified by physician, researchers or investigators as important. The underlying instability assessment model incorporates variability and correlation of features extracted during ambulation that have been identified by geriatric motion study experts as precursor to instability, balance abnormality and possible fall risk. Hermes provides a mobile, affordable and long-term instability analysis and detection system that is customizable to individual users, and is context-aware, with the capability of being guided by experts. Our experiments demonstrate the feasibility of our model and the complimentary role our system can play by providing long-term monitoring of patients outside a hospital or clinical setting at a reduced cost, with greater user convenience, compliance and inference capabilities that meet the physician's or investigator's needs.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Open project: a lightweight framework for remote sharing of mobile applications
UIST '13: Proceedings of the 26th annual ACM symposium on User interface software and technology (2013), pp. 281-290
[u'Matei Negulescu', u'Yang Li']
MobileSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41201.html
found
=========================
Swipe vs. scroll: web page switching on mobile browsers
In Proc. of CHI2013, ACM, pp. 2171-2174
[u'Andrew Warr', u'Ed H. Chi']
MobileSystems
Abstract: Tabbed web browsing interfaces enable users to multi-task and easily switch between open web pages. However, tabbed browsing is difficult for mobile web browsers due to the limited screen space and the reduced precision of touch. We present an experiment comparing Safari's pages-based switching interface using horizontal swiping gestures with the stacked cards-based switching interface using vertical scrolling gestures, introduced by Chrome. The results of our experiment show that cards-based switching interface allows for faster switching and is less frustrating, with no significant effect on error rates. We generalize these findings, and provide design implications for mobile information spaces.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
ADEL: An automatic detector of energy leaks for smartphone applications
Proceeding of International Conference on Hardware/Software Codesign and System Synthesis, (2012) (to appear)
[u'Lide Zhang', u'M. S. Gordon', u'Robert P. Dick', u'Z. Morley Mao', u'Peter Dinda', u'Lei Yang']
MobileSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41647.html
found
=========================
Bimanual gesture keyboard
Proceeding of UIST 2012 The ACM Symposium on User Interface Software and Technology, ACM, New York, NY, USA, pp. 137-146
[u'Xiaojun Bi', u'Ciprian Chelba', u'Tom Ouyang', u'Kurt Partridge', u'Shumin Zhai']
MobileSystems
Abstract: Gesture keyboards represent an increasingly popular way to input text on mobile devices today. However, current gesture keyboards are exclusively unimanual. To take advantage of the capability of modern multi-touch screens, we created a novel bimanual gesture text entry system, extending the gesture keyboard paradigm from one finger to multiple fingers. To address the complexity of recognizing bimanual gesture, we designed and implemented two related interaction methods, finger-release and space-required, both based on a new multi-stroke gesture recognition algorithm. A formal experiment showed that bimanual gesture behaviors were easy to learn. They improved comfort and reduced the physical demand relative to unimanual gestures on tablets. The results indicated that these new gesture keyboards were valuable complements to unimanual gesture and regular typing keyboards.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub39962.html
notfound
=========================
Bridging communications and the physical world
IEEE Internet Computing, vol. 16 (2012), pp. 35-43
[u'Omer Boyaci', u'Victoria Beltran Martinez', u'Henning Schulzrinne']
MobileSystems
Abstract: Sense Everything, Control Everything (SECE) is an event-driven system that lets nontechnical users create services that combine communication, location, social networks, presence, calendaring, and physical devices such as sensors and actuators. SECE combines information from multiple sources to personalize services and adapt them to changes in the user's context and preferences. Events trigger associated actions, which can control email delivery, change how phone calls are handled, update the user's social network status, and set the state of actuators such as lights, thermostats, and electrical appliances.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Cost-effective voting
Patent (2012)
[u'Lantian Zheng']
MobileSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
DIPLOMA: Consistent and Coherent Shared Memory over Mobile Phones
30th IEEE International Conference on Computer Design (2012)
[u'Niket Agarwal']
MobileSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Gesture-based interaction: a new dimension for mobile user interfaces
Proceedings of the International Working Conference on Advanced Visual Interfaces, ACM, New York, NY, USA (2012), pp. 6-6
[u'Yang Li']
MobileSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40355.html
notfound
=========================
Google's C/C++ toolchain for smart handheld devices
VLSI Design, Automation, and Test (VLSI-DAT), 2012 International Symposium on, IEEE
[u'Doug Kwan', u'Jing Yu', u'Bhaskar Janakiraman']
MobileSystems
Abstract: Smart handheld devices are ubiquitous today and software plays an important role on them. Therefore a compiler and related tools can improve devices by generating efficient, compact and secure code. In this paper, we share our experience of applying various compilation techniques at Google to improve software running on smart handheld devices, using our mobile platforms as examples. At Google we use the GNU toolchain for generating code on different platforms and for conducting compiler research and development. We have developed new techniques, added features and functionality in the GNU tools. Some of these results are now used for smart handheld devices.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Inter-contact Routing for Energy-constrained Disaster Response Networks
IEEE Transaction on Mobile Computing (2012) (to appear)
[u'Md Yusuf S Uddin', u'Hossein Ahmadi', u'Tarek Abdelzaher', u'Robin Kravets']
MobileSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Interactive Digital Signage
Computer, vol. 45(5) (2012), pp. 21-24
[u'Roy Want', u'Bill Schilit']
MobileSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
MOIST: A Scalable and Parallel Moving Object Indexer with School Tracking
Proceedings of VLDB 2012, 38th International Conference on Very Large Data Bases, pp. 1838-1849
[u'Junchen Jiang', u'Hongji Bao', u'Edward Y. Chang', u'Yuqian Li']
MobileSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Notification of event by mobile communications device using radio frequency transmitter
Patent (2012)
[u'Lantian Zheng', u'Zhi D. Weng']
MobileSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Tap, swipe, or move: attentional demands for distracted smartphone input
Proceedings of the International Working Conference on Advanced Visual Interfaces, ACM, New York, NY, USA (2012), pp. 173-180
[u'Matei Negulescu', u'Jaime Ruiz', u'Yang Li', u'Edward Lank']
MobileSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Ubiquitous search for smart workspaces
Universal Access in the Information Society, vol. 10 (2012), pp. 11-20
[u'Daniel M. Russell']
MobileSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Mobile Computing: Looking to the Future
IEEE Computer, vol. 44 (2011), pp. 28-29
[u'Bill N. Schilit']
MobileSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Programming Micro-Aerial Vehicle Swarms With Karma
Proceedings of ACM SenSys 2011
[u'Karthik Dantu', u'Bryan Kate', u'Jason Waterman', u'Peter Bailis', u'Matt Welsh']
MobileSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub39990.html
found
=========================
Accurate Online Power Estimation and Automatic Battery Behavior Based Power Model Generation for Smartphones
Proceeding of Internation Conference on Hardware/Software Codesign and System Synthesis (2010), pp. 105-114
[u'Lide Zhang', u'Birjodh Tiwana', u'Zhiyun Qian', u'Zhaoguang Wang', u'Robert P. Dick', u'Z. Morley Mao', u'Lei Yang']
MobileSystems
Abstract: This paper describes PowerBooter, an automated power model construction technique that uses built-in battery voltage sensors and knowledge of battery discharge behavior to monitor power consumption while explicitly controlling the power management and activity states of individual components. It requires no external measurement equipment. We also describe PowerTutor, a component power management and activity state introspection based tool that uses the model generated by PowerBooter for online power estimation. PowerBooter is intended to make it quick and easy for application developers and end users to generate power models for new smartphone variants, which each have different power consumption properties and therefore require different power models. PowerTutor is intended to ease the design and selection of power efficient software for embedded systems. Combined, PowerBooter and PowerTutor have the goal of opening power modeling and analysis for more smartphone variants and their users.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41366.html
found
=========================
Energy Optimization in Wireless Medical Systems Using Physiological Behavior
In Proceedings of the ACM, BMES conference of Wireless Health, ACM (2010), pp. 128-136
[u'Hyduke Noshadi', u'Foad Dabiri', u'Saro Meguerdichian', u'Miodrag Potkonjak', u'Majid Sarrafzadeh']
MobileSystems
Abstract: Wearable sensing systems are becoming widely used for a variety of applications, including sports, entertainment, and military. These systems have recently enabled a variety of medical monitoring and diagnostic applications in Wireless Health. The need for multiple sensors and constant monitoring lead these systems to be power hungry and expensive, with short operating lifetimes. In this paper, we introduce a novel methodology that takes advantage of the influence of human behavior on signal properties and reduces those three metrics from the data size point of view. This, in turn, directly influences the wireless communication and local processing power consumption. We exploit intrinsic space and temporal correlations between sensor data while considering both user and system behavior. Our goal is to select a small subset of sensors to accurately capture and/or predict all possible signals of a fully instrumented wearable sensing system. Our approach leverages novel modeling, partitioning, and behavioral optimization, which consists of signal characterization, segmentation and time shifting, mutual signal prediction, and subset sensor selection. We demonstrate the effectiveness of the technique on an insole instrumented with 99 pressure sensors placed in each shoe, which cover the bottom of the entire foot, resulting in energy reduction of 56% to 96% for error rates of 5% to 17.5%.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36598.html
notfound
=========================
Juggler: Virtual Networks for Fun and Profit
IEEE Transactions on Mobile Computing, vol. 9 (2010), pp. 31-43
[u'Anthony J. Nicholson', u'Scott Wolchok', u'Brian D. Noble']
MobileSystems
Abstract: There are many situations in which an additional network interfaceor twocan provide benefits to a mobile user. Additional interfaces can support parallelism in network flows, improve handoff times, and provide sideband communication with nearby peers. Unfortunately, such benefits are outweighed by the added costs of an additional physical interface. Instead, virtual interfaces have been proposed as the solution, multiplexing a single physical interface across more than one communication endpoint. However, the switching time of existing implementations is too high for some potential applications, and the benefits of this approach to real applications are not yet clear. This paper directly addresses these two shortcomings. It describes a link-layer implementation of a virtual 802.11 networking layer, called Juggler, that achieves switching times of approximately 3 ms, and less than 400 \mu{\rm s} in certain conditions. We demonstrate the performance of this implementation on three application scenarios. By devoting 10 percent of the duty cycle to background tasks, Juggler can provide nearly instantaneous handoff between base stations or support a modest sideband channel with peer nodes, without adversely affecting foreground throughput. Furthermore, when the client issues concurrent network flows, Juggler is able to assign these flows across more than one AP, providing significant speedup when wired-side bandwidth from the AP constrains end-to-end performance.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub39965.html
notfound
=========================
Usage Patterns in an Urban WiFi Network
IEEE/ACM Transactions on Networking, vol. 18 , Issue: 5 (2010), 1359 - 1372
[u'Mikhail Afanasyev', u'Tsuwei Chen']
MobileSystems
Abstract: While WiFi was initially designed as a local-area access network, mesh networking technologies have led to increasingly expansive deployments of WiFi networks. In urban environments, the WiFi mesh frequently supplements a number of existing access technologies, including wired broadband networks, 3G cellular, and commercial WiFi hotspots. It is an open question what role citywide WiFi deployments play in the increasingly diverse access network spectrum. We study the usage of the Google WiFi network deployed in Mountain View, CA, and find that usage naturally falls into three classes based almost entirely on client device type, which we divide into traditional laptop users, fixed-location access devices, and PDA-like smartphone devices. Moreover, each of these classes of use has significant geographic locality, following the distribution of residential, commercial, and transportation areas of the city. When comparing the network usage of each device class, we find a diverse set of mobility patterns that map well to the archetypal use cases for traditional access technologies. To help place our results in context, we also provide key performance measurements of the mesh backbone and, where possible, compare them to those of previously studied urban mesh networks.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
CENTAUR: realizing the full potential of centralized wlans through a hybrid data path
MobiCom '09: Proceedings of the 15th annual international conference on Mobile computing and networking, ACM, New York (2009), pp. 297-308
[u'Vivek Shrivastava', u'Nabeel Ahmed', u'Shravan Rayanchu', u'Suman Banerjee', u'Srinivasan Keshav', u'Konstantina Papagiannaki', u'Arunesh Mishra']
MobileSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Activity Recognition for the Digital Home
IEEE Computer, vol. 41 (2008), pp. 102-104
[u'Jeonghwa Yang', u'Bill N. Schilit', u'David W. McDonald']
MobileSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34430.html
notfound
=========================
Analysis of a Mixed-Use Urban WiFi Network: When Metropolitan becomes Neapolitan
IMC '08 Proceedings of the 8th ACM SIGCOMM conference on Internet measurement, ACM, New York, NY, USA (2008), pp. 85-98
[u'Mikhail Afanasyev', u'Tsuwei Chen', u'Geoffrey M. Voelker', u'Alex C. Snoeren']
MobileSystems
Abstract: In this paper, we study the usage of the Google WiFi network deployed in Mountain View, California. We find that usage naturally falls into three categories, based almost entirely on client device type. Moreover, each of these classes of use has significant geographical, and transportation areas of the city. Finally, we find a diverse set of mobility patterns that map well to the archetypal use cases for traditional access technologies.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Architecture-Driven Software Mobility in Support of QoS Requirements
Proc. 1st International Workshop on Software Architectures and Mobility, ACM, Leipzig (2008), pp. 3-8
[u'Marija Mikic-Rakic', u'Sam Malek', u'Nenad Medvidovic']
MobileSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
RFID (Radio Frequency Identification)
Wiley Publishing (2008)
[u'Stephen A. Weis']
MobileSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Deciphering Trends in Mobile Search
IEEE Computer, vol. 40, no. 8 (2007), pp. 58-62
[u'Maryam Kamvar', u'Shumeet Baluja']
MobileSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
TOLB: A Traffic-Oblivious Load-Balancing Protocol for Next-Generation Sensornets
Proceedings of the International Conference on Distributed Computing in Sensor Networks (DCOSS) (2007)
[u'Mohamed Aly', u'Anandha Gopalan']
MobileSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
The Role of Context in Query Input: Using contexual signals to complete queries on mobile devices
Human Computer Interaction with Mobile Devices and Services (Mobile HCI) (2007)
[u'Maryam Kamvar', u'Shumeet Baluja']
MobileSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Large Scale Study of Wireless Search Behavior: Google Mobile Search
Proceedings of the SIGCHI conference on Human Factors in computing systems (CHI) (2006)
[u'Maryam Kamvar', u'Shumeet Baluja']
MobileSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Pervasive Computing in the Home and Community
Pervasive Computing in Healthcare (2006), pp. 79-103
[u'Don Patterson', u'Lin Liao', u'Henry Kautz', u'Dieter Fox']
MobileSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Report on the Mobile Search Workshop at WWW 2002
SIGMOD Record, vol. 31 (2002), pp. 68-71
[u'Aya Soffer', u'Yoelle S. Maarek', u'Bay-Wei Chang']
MobileSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/NaturalLanguageProcessing.html
found
http://research.google.com/pubs/pub43891.html
notfound
=========================
A Computationally Efficient Algorithm for Learning Topical Collocation Models
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, Association for Computational Linguistics, Beijing, China (2015), pp. 1460-1469
[u'Zhendong Zhao', u'Lan Du', u'Benjamin Borschinger', u'John K Pate', u'Massimiliano Ciaramita', u'Mark Steedman', u'Mark Johnson']
NaturalLanguageProcessing
Abstract: Most existing topic models make the bagof-words assumption that words are generated independently, and so ignore potentially useful information about word order. Previous attempts to use collocations (short sequences of adjacent words) in topic models have either relied on a pipeline approach, restricted attention to bigrams, or resulted in models whose inference does not scale to large corpora. This paper studies how to simultaneously learn both collocations and their topic assignments. We present an efficient reformulation of the Adaptor Grammar-based topical collocation model (AG-colloc) (Johnson, 2010), and develop a point-wise sampling algorithm for posterior inference in this new formulation. We further improve the efficiency of the sampling algorithm by exploiting sparsity and parallelising inference. Experimental results derived in text classification, information retrieval and human evaluation tasks across a range of datasets show that this reformulation scales to hundreds of thousands of documents while maintaining the good performance of the AG-colloc model.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43801.html
notfound
=========================
A Linear-Time Transition System for Crossing Interval Trees
NAACL (2015), 662-671
[u'Emily Pitler', u'Ryan McDonald']
NaturalLanguageProcessing
Abstract: We define a restricted class of non-projective trees that 1) covers many natural language sentences; and 2) can be parsed exactly with a generalization of the popular arc-eager system for projective trees (Nivre, 2003). Crucially, this generalization only adds constant overhead in run-time and space keeping the parsers total run-time linear in the worst case. In empirical experiments, our proposed transition-based parser is more accurate on average than both the arc-eager system or the swap-based system, an unconstrained non-projective transition system with a worst-case quadratic runtime (Nivre, 2009).
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43289.html
notfound
=========================
Automatic Gain Control and Multi-style Training for Robust Small-Footprint Keyword Spotting with Deep Neural Networks
Proceedings of International Conference on Acoustics, Speech and Signal Processing (ICASSP), IEEE (2015), pp. 4704-4708
[u'Rohit Prabhavalkar', u'Raziel Alvarez', u'Carolina Parada', u'Preetum Nakkiran', u'Tara Sainath']
NaturalLanguageProcessing
Abstract: We explore techniques to improve the robustness of small-footprint keyword spotting models based on deep neural networks (DNNs) in the presence of background noise and in far-field conditions. We find that system performance can be improved significantly, with relative improvements up to 75% in far-field conditions, by employing a combination of multi-style training and a proposed novel formulation of automatic gain control (AGC) that estimates the levels of both speech and background noise. Further, we find that these techniques allow us to achieve competitive performance, even when applied to DNNs with an order of magnitude fewer parameters than our baseline.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Composition-based on-the-fly rescoring for salient n-gram biasing
Interspeech 2015, International Speech Communications Association
[u'Keith Hall', u'Eunjoon Cho', u'Cyril Allauzen', u'Francoise Beaufays', u'Noah Coccaro', u'Kaisuke Nakajima', u'Michael Riley', u'Brian Roark', u'David Rybach', u'Linda Zhang']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43251.html
found
=========================
Efficient Inference and Structured Learning for Semantic Role Labeling
Transactions of the Association for Computational Linguistics, vol. 3 (2015), pp. 29-41
[u'Oscar Tckstrm', u'Kuzman Ganchev', u'Dipanjan Das']
NaturalLanguageProcessing
Abstract: We present a dynamic programming algorithm for efficient constrained inference in semantic role labeling. The algorithm tractably captures a majority of the structural constraints examined by prior work in this area, which has resorted to either approximate methods or off-the-shelf integer linear programming solvers. In addition, it allows training a globally-normalized log-linear model with respect to constrained conditional likelihood. We show that the dynamic program is several times faster than an off-the-shelf integer linear programming solver, while reaching the same solution. Furthermore, we show that our structured model results in significant improvements over its local counterpart, achieving state-of-the-art results on both PropBank- and FrameNet-annotated corpora.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Geo-location for Voice Search Language Modeling
Interspeech 2015, International Speech Communications Association, pp. 1438-1442
[u'Ciprian Chelba', u'Xuedong Zhang', u'Keith Hall']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Grammar as a Foreign Language
Arxiv (2015)
[u'Oriol Vinyals', u'Lukasz Kaiser', u'Terry Koo', u'Slav Petrov', u'Ilya Sutskever', u'Geoffrey Hinton']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Idest: Learning a Distributed Representation for Event Patterns
Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL'15), pp. 1140-1149
[u'Sebastian Krause', u'Enrique Alfonseca', u'Katja Filippova', u'Daniele Pighin']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Improved Transition-Based Parsing and Tagging with Neural Networks
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP '15)
[u'Chris Alberti', u'David Weiss', u'Greg Coppola', u'Slav Petrov']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Improved recognition of contact names in voice commands
ICASSP 2015
[u'Petar Aleksic', u'Cyril Allauzen', u'David Elson', u'Aleks Kracun', u'Diego Melendo Casado', u'Pedro J. Moreno']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43258.html
notfound
=========================
Language Modeling in the Era of Abundant Data
Stanford Information Theory Forum (2015)
[u'Ciprian Chelba']
NaturalLanguageProcessing
Abstract: The talk presents an overview of statistical language modeling as applied to real-word problems: speech recognition, machine translation, spelling correction, soft keyboards to name a few prominent ones. We summarize the most successful estimation techniques, and examine how they fare for applications with abundant data, e.g. voice search. We conclude by highlighting a few open problems: getting an accurate estimate for the entropy of text produced by a very specific source, e.g. query stream); optimally leveraging data that is of different degrees of relevance to a given "domain"; does a bound on the size of a "good" model for a given source exist?
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Long Short-Term Memory Language Models with Additive Morphological Features for Automatic Speech Recognition
IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP) (2015)
[u'Daniel Renshaw', u'Keith B. Hall']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44018.html
notfound
=========================
Machine Learning for Dialog State Tracking: A Review
Proceedings of The First International Workshop on Machine Learning in Spoken Language Processing (2015)
[u'Matthew Henderson']
NaturalLanguageProcessing
Abstract: Spoken dialog systems help users achieve a task using natural language. Noisy speech recognition and ambiguity in natural language motivate statistical approaches that exploit distributions over the user's goal at every step in the dialog. The task of tracking these distributions, termed Dialog State Tracking, is therefore an essential component of any Spoken dialog system. In recent years, the Dialog State Tracking Challenges have provided a common test-bed and evaluation framework for this task, as well as labeled dialog data. As a result, a variety of machine-learned methods have been successfully applied to Dialog State Tracking. This paper reviews the machine-learning techniques that have been adapted to Dialog State Tracking, and gives an overview of published evaluations. Discriminative machine-learned methods outperform generative and rule-based methods, the previous state-of-the-art.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Mining Subjective Properties on the Web
SIGMOD (2015) (to appear)
[u'Immanuel Trummer', u'Alon Halevy', u'Hongrae Lee', u'Sunita Sarawagi', u'Rahul Gupta']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43407.html
found
=========================
Modeling the Lifespan of Discourse Entities with Application to Coreference Resolution
Journal of Artificial Intelligence Research, vol. 52 (2015), pp. 445-475
[u'Marie-Catherine de Marneffe', u'Marta Recasens', u'Christopher Potts']
NaturalLanguageProcessing
Abstract: A discourse typically involves numerous entities, but few are mentioned more than once. Distinguishing those that die out after just one mention (singleton) from those that lead longer lives (coreferent) would dramatically simplify the hypothesis space for coreference resolution models, leading to increased performance. To realize these gains, we build a classifier for predicting the singleton/coreferent distinction. The models feature representations synthesize linguistic insights about the factors affecting discourse entity lifespans (especially negation, modality, and attitude predication) with existing results about the benefits of surface (part-of-speech and n-gram-based) features for coreference resolution. The model is effective in its own right, and the feature representations help to identify the anchor phrases in bridging anaphora as well. Furthermore, incorporating the model into two very different state-of-the-art coreference resolution systems, one rule-based and the other learning-based, yields significant performance improvements.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43449.html
notfound
=========================
Multilingual Open Relation Extraction Using Cross-lingual Projection
Proceedings of NAACL (2015)
[u'Manaal Faruqui', u'Shankar Kumar']
NaturalLanguageProcessing
Abstract: Open domain relation extraction systems identify relation and argument phrases in a sentence without relying on any underlying schema. However, current state-of-the-art relation extraction systems are available only for English because of their heavy reliance on linguistic tools such as part-of-speech taggers and dependency parsers. We present a cross-lingual annotation projection method for language independent relation extraction. We evaluate our method on a manually annotated test set and present results on three typologically different languages. We release these manual annotations and extracted relations in ten languages from Wikipedia.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44280.html
found
=========================
Multinomial Loss on Held-out Data for the Sparse Non-negative Matrix Language Model
ArXiv, Google (2015)
[u'Ciprian Chelba', u'Fernando Pereira']
NaturalLanguageProcessing
Abstract: We describe Sparse Non-negative Matrix (SNM) language model estimation using multinomial loss on held-out data. Being able to train on held-out data is important in practical situations where the training data is usually mismatched from the held-out/test data. It is also less constrained than the previous training algorithm using leave-one-out on training data: it allows the use of richer meta-features in the adjustment model, e.g. the diversity counts used by Kneser-Ney smoothing which would be difficult to deal with correctly in leave-one-out training. In experiments on the one billion words language modeling benchmark, we are able to slightly improve on our previous results which use a different loss function, and employ leave-one-out training on a subset of the main training set. Surprisingly, an adjustment model with meta-features that discard all lexical information can perform as well as lexicalized meta-features. We find that fairly small amounts of held-out data (on the order of 30-70 thousand words) are sufficient for training the adjustment model. In a real-life scenario where the training data is a mix of data sources that are imbalanced in size, and of different degrees of relevance to the held-out and test data, taking into account the data source for a given skip-/n-gram feature and combining them for best performance on held-out/test data improves over skip-/n-gram SNM models trained on pooled data by about 8%. The ability to mix various data sources based on how relevant they are to a mismatched held-out set is probably the most attractive feature of the new estimation method for SNM LM.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44016.html
notfound
=========================
Plato: A Selective Context Model for Entity Resolution
Transactions of the Association for Computational Linguistics, vol. 3 (2015), pp. 503-515
[u'Nevena Lazic', u'Amarnag Subramanya', u'Michael Ringgaard', u'Fernando Pereira']
NaturalLanguageProcessing
Abstract: We present Plato, a probabilistic model for entity resolution that includes a novel approach for handling noisy or uninformative features,and supplements labeled training data derived from Wikipedia with a very large unlabeled text corpus. Training and inference in the proposed model can easily be distributed across many servers, allowing it to scale to over 10^7 entities. We evaluate Plato on three standard datasets for entity resolution. Our approach achieves the best results to-date on TAC KBP 2011 and is highly competitive on both the CoNLL 2003 and TAC KBP 2012 datasets.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43830.html
notfound
=========================
Pruning Sparse Non-negative Matrix N-gram Language Models
Proceedings of Interspeech 2015, ISCA, pp. 1433-1437
[u'Joris Pelemans', u'Noam M. Shazeer', u'Ciprian Chelba']
NaturalLanguageProcessing
Abstract: In this paper we present a pruning algorithm and experimental results for our recently proposed Sparse Non-negative Matrix (SNM) family of language models (LMs). We show that when trained with only n-gram features SNMLM pruning based on a mutual information criterion yields the best known pruned model on the One Billion Word Language Model Benchmark, reducing perplexity with 18% and 57% over Katz and Kneser-Ney LMs, respectively. We also illustrate a method for converting an SNMLM to ARPA back-off format which can be readily used in a single-pass decoder for Automatic Speech Recognition.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Rapid Vocabulary Addition to Context-Dependent Decoder Graphs
Interspeech 2015
[u'Cyril Allauzen', u'Michael Riley']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Refer-to-as Relations as Semantic Knowledge
AAAI Conference on Artificial Intelligence (2015)
[u'Song Feng', u'Sujith Ravi', u'Ravi Kumar', u'Polina Kuznetsova', u'Wei Liu', u'Alex Berg', u'Tamara Berg', u'Yejin Choi']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43433.html
found
=========================
Resolving Discourse-Deictic Pronouns: A Two-Stage Approach to Do It
Proceedings of the 4th Joint Conference on Lexical and Computational Semantics (*SEM 2015), pp. 299-308
[u'Sujay Kumar Jauhar', u'Raul D. Guerra', u'Edgar Gonzlez Pellicer', u'Marta Recasens']
NaturalLanguageProcessing
Abstract: Discourse deixis is a linguistic phenomenon in which pronouns have verbal or clausal, rather than nominal, antecedents. Studies have estimated that between 5% and 10% of pronouns in non-conversational data are discourse deictic. However, current coreference resolution systems ignore this phenomenon. This paper presents an automatic system for the detection and resolution of discourse-deictic pronouns. We introduce a two-step approach that first recognizes instances of discourse-deictic pronouns, and then resolves them to their verbal antecedent. Both components rely on linguistically motivated features. We evaluate the components in isolation and in combination with two state-of-the-art coreference resolvers. Results show that our system outperforms several baselines, including the only comparable discourse deixis system, and leads to small but statistically significant improvements over the full coreference resolution systems. An error analysis lays bare the need for a less strict evaluation of this task.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43892.html
notfound
=========================
Semantic Role Labeling with Neural Network Factors
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP '15), Association for Computational Linguistics (to appear)
[u'Nicholas FitzGerald', u'Oscar Tckstrm', u'Kuzman Ganchev', u'Dipanjan Das']
NaturalLanguageProcessing
Abstract: We present a new method for semantic role labeling in which arguments and semantic roles are jointly embedded in a shared vector space for a given predicate. These embeddings belong to a neural network, whose output represents the potential functions of a graphical model designed for the SRL task. We consider both local and structured learning methods and obtain strong results on standard PropBank and FrameNet corpora with a straightforward product-of-experts model. We further show how the model can learn jointly from PropBank and FrameNet annotations to obtain additional improvements on the smaller FrameNet dataset.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Sentence Compression by Deletion with LSTMs
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP'15)
[u'Katja Filippova', u'Enrique Alfonseca', u'Carlos Colmenares', u'Lukasz Kaiser', u'Oriol Vinyals']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Sequence-based Class Tagging for Robust Transcription in ASR
Interspeech 2015, International Speech Communications Association (to appear)
[u'Lucy Vasserman', u'Vlad Schogol', u'Keith Hall']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43829.html
found
=========================
Sparse Non-negative Matrix Language Modeling For Skip-grams
Proceedings of Interspeech 2015, ISCA, pp. 1428-1432
[u'Noam M. Shazeer', u'Joris Pelemans', u'Ciprian Chelba']
NaturalLanguageProcessing
Abstract: We present a novel family of language model (LM) estimation techniques named Sparse Non-negative Matrix (SNM) estimation. A first set of experiments empirically evaluating these techniques on the One Billion Word Benchmark [3] shows that with skip-gram features SNMLMs are able to match the state-of-the art recurrent neural network (RNN) LMs; combining the two modeling techniques yields the best known result on the benchmark. The computational advantages of SNM over both maximum entropy and RNNLM estimation are probably its main strength, promising an approach that has the same flexibility in combining arbitrary features effectively and yet should scale to very large amounts of data as gracefully as n-gram LMs do.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Structured Training for Neural Network Transition-Based Parsing
Proceedings of the 53th Annual Meeting of the Association for Computational Linguistics (ACL '15) (2015)
[u'David Weiss', u'Chris Alberti', u'Michael Collins', u'Slav Petrov']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43403.html
found
=========================
Whats Cookin? Interpreting Cooking Videos using Text, Speech and Vision
North American Chapter of the Association for Computational Linguistics Human Language Technologies (NAACL HLT 2015) (to appear)
[u'Jonathan Malmaud', u'Jonathan Huang', u'Vivek Rathod', u'Nicholas Johnston', u'Andrew Rabinovich', u'Kevin Murphy']
NaturalLanguageProcessing
Abstract: We present a novel method for aligning a sequence of instructions to a video of someone carrying out a task. In particular, we focus on the cooking domain, where the instructions correspond to the recipe. Our technique relies on an HMM to align the recipe steps to the (automatically generated) speech transcript. We then refine this alignment using a state-of-the-art visual food detector, based on a deep convolutional neural network. We show that our technique outperforms simpler techniques based on keyword spotting. It also enables interesting applications, such as automatically illustrating recipes with keyframes, and searching within a video for events of interest.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42214.html
notfound
=========================
A Crossing-Sensitive Third-Order Factorization for Dependency Parsing
Transactions of the Association for Computational Linguistics, vol. 2 (2014), pp. 41-54
[u'Emily Pitler']
NaturalLanguageProcessing
Abstract: Parsers that parametrize over wider scopes are generally more accurate than edge-factored models. For graph-based non-projective parsers, wider factorizations have so far implied large increases in the computational complexity of the parsing problem. This paper introduces a crossing-sensitive generalization of a third-order factorization that trades off complexity in the model structure (i.e., scoring with features over multiple edges) with complexity in the output structure (i.e., producing crossing edges). Under this model, the optimal 1-Endpoint-Crossing tree can be found in O(n^4) time, matching the asymptotic run-time of both the third-order projective parser and the edge-factored 1-Endpoint-Crossing parser. The crossing-sensitive third-order parser is significantly more accurate than the third-order projective parser under many experimental settings and significantly less accurate on none.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42526.html
notfound
=========================
A Database for Measuring Linguistic Information Content.
Language Resources and Evaluation Conference, ELDA, 330 W 58th St (2014)
[u'Richard Sproat', u'Bruno Cartoni', u'HyunJeong Choe', u'David Huynh', u'Linne Ha', u'Ravindran Rajakumar', u'Evelyn Wenzel-Grondie']
NaturalLanguageProcessing
Abstract: Which languages convey the most information in a given amount of space? This is a question often asked of linguists, especially by engineers who often have some information theoretic measure of ``information'' in mind, but rarely define exactly how they would measure that information. The question is, in fact remarkably hard to answer, and many linguists consider it unanswerable. But it is a question that seems as if it ought to have an answer. If one had a database of close translations between a set of typologically diverse languages, with detailed marking of morphosyntactic and morphosemantic features, one could hope to quantify the differences between how these different languages convey information. Since no appropriate database exists we decided to construct one. The purpose of this paper is to present our work on the database, along with some preliminary results. We plan to release the dataset once complete.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42183.html
found
=========================
A Discriminative Latent Variable Model for Online Clustering
International Conference on Machine Learning (2014) (to appear)
[u'Rajhans Samdani', u'Kai-Wei Chang', u'Dan Roth']
NaturalLanguageProcessing
Abstract: This paper presents a latent variable structured prediction model for discriminative supervised clustering of items called the Latent Left-linking Model (L3M). We present an online clustering algorithm for L3M based on a feature-based item similarity function. We provide a learning framework for estimating the similarity function and present a fast stochastic gradient-based learning technique. In our experiments on coreference resolution and document clustering, L3M outperforms several existing online as well as batch supervised clustering techniques.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42235.html
notfound
=========================
A New Entity Salience Task with Millions of Training Examples
Proceedings of the European Association for Computational Linguistics, Association for Computational Linguistics (2014) (to appear)
[u'Dan Gillick', u'Jesse Dunietz']
NaturalLanguageProcessing
Abstract: Although many NLP systems are moving toward entity-based processing, most still identify important phrases using classical keyword-based approaches. To bridge this gap, we introduce the task of entity salience: assigning a relevance score to each entity in a document. We demonstrate how a labeled corpus for the task can be automatically generated from a corpus of documents and accompanying abstracts. We then show how a classifier with features derived from a standard NLP pipeline outperforms a strong baseline by 34%. Finally, we outline initial experiments on further improving accuracy by leveraging background knowledge about the relationships between entities.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42453.html
found
=========================
A Scalable Gibbs Sampler for Probabilistic Entity Linking
Advances in Information Retrieval (ECIR 2014), Springer International Publishing, pp. 335-346
[u'Neil Houlsby', u'Massimiliano Ciaramita']
NaturalLanguageProcessing
Abstract: Entity linking involves labeling phrases in text with their referent entities, such as Wikipedia or Freebase entries. This task is challenging due to the large number of possible entities, in the millions, and heavy-tailed mention ambiguity. We formulate the problem in terms of probabilistic inference within a topic model, where each topic is associated with a Wikipedia article. To deal with the large number of topics we propose a novel efficient Gibbs sampling scheme which can also incorporate side information, such as the Wikipedia graph. This conceptually simple probabilistic approach achieves state-of-the-art performance in entity-linking on the Aida-CoNLL dataset.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Acquisition of Noncontiguous Class Attributes from Web Search Queries
Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics (EACL-2014)
[u'Marius Pasca']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Acquisition of Open-Domain Classes via Intersective Semantics
Proceedings of the 23rd International World Wide Web Conference (WWW-2014)
[u'Marius Pasca']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Adapting taggers to Twitter with not-so-distant supervision
International Conference on Computational Linguistics (2014)
[u'Barbara Plank', u'Dirk Hovy', u'Anders Sogaard', u'Ryan McDonald']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42559.html
notfound
=========================
An Extension of BLANC to System Mentions
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers) (2014), pp. 24-29
[u'Xiaoqiang Luo', u'Sameer Pradhan', u'Marta Recasens', u'Eduard Hovy']
NaturalLanguageProcessing
Abstract: BLANC is a link-based coreference evaluation metric for measuring the quality of coreference systems on gold mentions. This paper extends the original BLANC (BLANC-gold henceforth) to system mentions, removing the gold mention assumption. The proposed BLANC falls back seamlessly to the original one if system mentions are identical to gold mentions, and it is shown to strongly correlate with existing metrics on the 2011 and 2012 CoNLL data.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42533.html
found
=========================
Applications of Maximum Entropy Rankers to Problems in Spoken Language Processing
Interspeech 2014, International Speech Communications Association
[u'Richard Sproat', u'Keith Hall']
NaturalLanguageProcessing
Abstract: We report on two applications of Maximum Entropy-based ranking models to problems of relevance to automatic speech recognition and text-to-speech synthesis. The first is stress prediction in Russian, a language with notoriously complex morphology and stress rules. The second is the classification of alphabetic non-standard words, which may be read as words (NATO), as letter sequences (USA), or as a mixed (mymsn). For this second task we report results on English, and five other European languages.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43114.html
notfound
=========================
Backoff Inspired Features for Maximum Entropy Language Models
Proceedings of Interspeech, ISCA (2014)
[u'Fadi Biadsy', u'Keith Hall', u'Pedro Moreno', u'Brian Roark']
NaturalLanguageProcessing
Abstract: Maximum Entropy (MaxEnt) language models are linear models that are typically regularized via well-known L1 or L2 terms in the likelihood objective, hence avoiding the need for the kinds of backoff or mixture weights used in smoothed n-gram language models using Katz backoff and similar techniques. Even though backoff cost is not required to regularize the model, we investigate the use of backoff features in MaxEnt models, as well as some backoff-inspired variants. These features are shown to improve model quality substantially, as shown in perplexity and word-error rate reductions, even in very large scale training scenarios of tens or hundreds of billions of words and hundreds of millions of features.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43016.html
found
=========================
Bridging Text and Knowledge with Frames
ACL Workshop on Frame Semantics (in honor of Charles FIllmore) (2014)
[u'Srini Narayanan']
NaturalLanguageProcessing
Abstract: FrameNet is the current best operational version of Chuck Fillmores Frame Semantics. As FrameNet has evolved over the years, we have been building a series of increasingly ambitious prototype applications that exploit the ideas of frame semantics and FrameNet as a resource. Results from this work suggest that frames are a natural semantic representation linking issue of textual meaning and world knowledge.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42502.html
notfound
=========================
Computer-aided quality assurance of an Icelandic pronunciation dictionary
LREC 2014, Reykjavik
[u'Martin Jansche']
NaturalLanguageProcessing
Abstract: We propose a model-driven method for ensuring the quality of pronunciation dictionaries. The key ingredient is computing an alignment between letter strings and phoneme strings, a standard technique in pronunciation modeling. The novel aspect of our method is the use of informative, parametric alignment models which are refined iteratively as they are tested against the data. We discuss the use of alignment failures as a signal for detecting and correcting problematic dictionary entries. We illustrate this method using an existing pronunciation dictionary for Icelandic. Our method is completely general and has been applied in the construction of pronunciation dictionaries for commercially deployed speech recognition systems in several languages.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Constrained Arc-Eager Dependency Parsing
Computational Linguistics (2014)
[u'Joakim Nivre', u'Yoav Goldberg', u'Ryan McDonald']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43240.html
notfound
=========================
Context-Dependent Fine-Grained Entity Type Tagging
arXiv.org (2014)
[u'Dan Gillick', u'Nevena Lazic', u'Kuzman Ganchev', u'Jesse Kirchner', u'David Huynh']
NaturalLanguageProcessing
Abstract: Entity type tagging is the task of assigning category labels to each mention of an entity in a document. While standard systems focus on a small set of types, recent work (Ling and Weld, 2012) suggests that using a large fine-grained label set can lead to dramatic improvements in downstream tasks. In the absence of labeled training data, existing fine-grained tagging systems obtain examples automatically, using resolved entities and their types extracted from a knowledge base. However, since the appropriate type often depends on context (e.g. Washington could be tagged either as city or government), this procedure can result in spurious labels, leading to poorer generalization. We propose the task of context-dependent fine type tagging, where the set of acceptable labels for a mention is restricted to only those deducible from the local context (e.g. sentence or document). We introduce new resources for this task: 11,304 mentions annotated with their context-dependent fine types, and we provide baseline experimental results on this data.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42900.html
notfound
=========================
Discriminative pronunciation modeling for dialectal speech recognition
Proc. Interspeech (2014) (to appear)
[u'Maider Lehr', u'Kyle Gorman', u'Izhak Shafran']
NaturalLanguageProcessing
Abstract: Speech recognizers are typically trained with data from a standard dialect and do not generalize to non-standard dialects. Mismatch mainly occurs in the acoustic realization of words, which is represented by acoustic models and pronunciation lexicon. Standard techniques for addressing this mismatch are generative in nature and include acoustic model adaptation and expansion of lexicon with pronunciation variants, both of which have limited effectiveness. We present a discriminative pronunciation model whose parameters are learned jointly with parameters from the language models. We tease apart the gains from modeling the transitions of canonical phones, the transduction from surface to canonical phones, and the language model. We report experiments on African American Vernacular English (AAVE) using NPR's StoryCorps corpus. Our models improve the performance over the baseline by about 2.1% on AAVE, of which 0.6% can be attributed to the pronunciation model. The model learns the most relevant phonetic transformations for AAVE speech.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Enforcing Structural Diversity in Cube-pruned Dependency Parsing
ACL (2014)
[u'Hao Zhang', u'Ryan McDonald']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Enhanced Search with Wildcards and Morphological Inections in the Google Books Ngram Viewer
Proceedings of the 52th Annual Meeting of the Association for Computational Linguistics (Demonstrations), Association for Computational Linguistics (2014)
[u'Jason Mann', u'David Zhang', u'Lu Yang', u'Dipanjan Das', u'Slav Petrov']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41227.html
found
=========================
Frame-Semantic Parsing
Computational Linguistics, vol. 40:1 (2014), pp. 9-56
[u'Dipanjan Das', u'Desai Chen', u'Andr F. T. Martins', u'Nathan Schneider', u'Noah A. Smith']
NaturalLanguageProcessing
Abstract: Frame semantics (Fillmore 1982) is a linguistic theory that has been instantiated for English in the FrameNet lexicon (Fillmore, Johnson, and Petruck 2003). We solve the problem of frame-semantic parsing using a two-stage statistical model that takes lexical targets (i.e., content words and phrases) in their sentential contexts and predicts frame-semantic structures. Given a target in context, the first stage disambiguates it to a semantic frame. This model employs latent variables and semi-supervised learning to improve frame disambiguation for targets unseen at training time. The second stage finds the target's locally expressed semantic arguments. At inference time, a fast exact dual decomposition algorithm collectively predicts all the arguments of a frame at once in order to respect declaratively stated linguistic constraints, resulting in qualitatively better structures than nave local predictors. Both components are feature-based and discriminatively trained on a small set of annotated frame-semantic parses. On the SemEval 2007 benchmark dataset, the approach, along with a heuristic identifier of frame-evoking targets, outperforms the prior state of the art by significant margins. Additionally, we present experiments on the much larger FrameNet 1.5 dataset. We have released our frame-semantic parser as open-source software.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Great Question! Question Quality in Community Q&A
International AAAI Conference on Weblogs and Social Media (ICWSM) (2014)
[u'Sujith Ravi', u'Bo Pang', u'Vibhor Rastogi', u'Ravi Kumar']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42527.html
notfound
=========================
Hippocratic Abbreviation Expansion
ACL, ACL (2014) (to appear)
[u'Brian Roark', u'Richard Sproat']
NaturalLanguageProcessing
Abstract: Incorrect normalization of text can be particularly damaging for applications like text-to-speech synthesis (TTS) or typing auto-correction, where the resulting normalization is directly presented to the user, versus feeding downstream applications. In this paper, we focus on abbreviation expansion for TTS, which requires a ``do no harm'', high precision approach yielding few expansion errors at the cost of leaving relatively many abbreviations unexpanded. In the context of a large-scale, real-world TTS scenario, we present methods for training classifiers to establish whether a particular expansion is apt. We achieve a large increase in correct abbreviation expansion when combined with the baseline text normalization component of the TTS system, together with a substantial reduction in incorrect expansions.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Learning Compact Lexicons for CCG Semantic Parsing
Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP '14)
[u'Yoav Artzi', u'Dipanjan Das', u'Slav Petrov']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Modelling Events through Memory-based, Open-IE Patterns for Abstractive Summarization
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (ACL'14) (2014), pp. 892-901
[u'Daniele Pighin', u'Marco Cornolti', u'Enrique Alfonseca', u'Katja Filippova']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Opinion Mining on YouTube
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (ACL'14) (2014), pp. 1252-1261
[u'Aliaksei Severyn', u'Olga Uryupina', u'Barbara Plank', u'Alessandro Moschitti', u'Katja Filippova']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42946.html
notfound
=========================
ParTes. Test Suite for Parsing Evaluation
Procesamiento del Lenguaje Natural, vol. 53 (2014), pp. 87-94
[u'Marina Lloberes', u'Irene Castelln', u'Llus Padr', u'Edgar Gonzlez']
NaturalLanguageProcessing
Abstract: This paper presents ParTes, the first test suite in Spanish and Catalan for parsing qualitative evaluation. This resource is a hierarchical test suite of the representative syntactic structure and argument order phenomena. ParTes proposes a simplification of the qualitative evaluation by contributing to the automatization of this task.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Parallel Algorithms for Unsupervised Tagging
Transactions of the ACL (2014)
[u'Sujith Ravi', u'Sergei Vassilivitskii', u'Vibhor Rastogi']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Projecting the Knowledge Graph to Syntactic Parsing
EACL 2014: 15th Conference of the European Chapter of the Association for Computational Linguistics
[u'Andrea Gesmundo', u'Keith Hall']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Pushdown automata in statistical machine translation
Computational Linguistics, vol. 40 (2014), pp. 687-723
[u'Cyril Allauzen', u'Bill Byrne', u'Adri de Gispert', u'Gonzalo Iglesias', u'Michael Riley']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Queries as a Source of Lexicalized Commonsense Knowledge
Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP-2014)
[u'Marius Pasca']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
ReNoun: Fact Extraction for Nominal Attributes
Proc. 2014 Conf. on Empirical Methods in Natural Language Processing (EMNLP)
[u'Mohamed Yahya', u'Steven Whang', u'Rahul Gupta', u'Alon Halevy']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
SUIT: A Supervised User-Item based Topic model for Sentiment Analysis
Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence (AAAI-14) (2014) (to appear)
[u'Fangtao Li', u'Sheng Wang', u'Shenghua Liu', u'Ming Zhang']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42562.html
notfound
=========================
Scoring Coreference Partitions of Predicted Mentions: A Reference Implementation
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers) (2014), pp. 30-35
[u'Sameer Pradhan', u'Xiaoqiang Luo', u'Marta Recasens', u'Eduard Hovy', u'Vincent Ng', u'Michael Strube']
NaturalLanguageProcessing
Abstract: The definitions of two coreference scoring metricsB3 and CEAFare underspecified with respect to predicted, as opposed to key (or gold) mentions. Several variations have been proposed that manipulate either, or both, the key and predicted mentions in order to get a one-to-one mapping. On the other hand, the metric BLANC was, until recently, limited to scoring partitions of key mentions. In this paper, we (i) argue that mention manipulation for scoring predicted mentions is unnecessary, and potentially harmful as it could produce unintuitive results; (ii) illustrate the application of all these measures to scoring predicted mentions; (iii) make available an open source, thoroughly-tested reference implementation of the main coreference evaluation measures; and (iv) rescore the results of the CoNLL-2011/2012 shared task systems with this implementation. This will help the community accurately measure and compare new end-to-end coreference resolution algorithms.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42245.html
found
=========================
Semantic Frame Identification with Distributed Word Representations
Proceedings of the 52th Annual Meeting of the Association for Computational Linguistics (2014)
[u'Karl Moritz Hermann', u'Dipanjan Das', u'Jason Weston', u'Kuzman Ganchev']
NaturalLanguageProcessing
Abstract: We present a novel technique for semantic frame identification using distributed representations of predicates and their syntactic context; this technique leverages automatic syntactic parses and a generic set of word embeddings. Given labeled data annotated with frame-semantic parses, we learn a model that projects the set of word representations for the syntactic context around a predicate to a low dimensional representation. The latter is used for semantic frame identification; with a standard argument identification method inspired by prior work, we achieve state-of-the-art results on FrameNet-style frame-semantic analysis. Additionally, we report strong results on PropBank-style semantic role labeling in comparison to prior work.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43222.html
found
=========================
Skip-gram Language Modeling Using Sparse Non-negative Matrix Probability Estimation
Google (2014)
[u'Noam M. Shazeer', u'Joris Pelemans', u'Ciprian Chelba']
NaturalLanguageProcessing
Abstract: We present a novel family of language model (LM) estimation techniques named Sparse Non-negative Matrix (SNM) estimation. A first set of experiments empirically evaluating it on the One Billion Word Benchmark shows that SNM n-gram LMs perform almost as well as the well-established Kneser-Ney (KN) models. When using skip-gram features the models are able to match the state-of-the-art recurrent neural network (RNN) LMs; combining the two modeling techniques yields the best known result on the benchmark. The computational advantages of SNM over both maximum entropy and RNN LM estimation are probably its main strength, promising an approach that has the same flexibility in combining arbitrary features effectively and yet should scale to very large amounts of data as gracefully as n-gram LMs do.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42720.html
found
=========================
The SMAPH System for Query Entity Recognition and Disambiguation
ERD 2014: Entity Recognition and Disambiguation Challenge. SIGIR Forum., ACM
[u'Marco Cornolti', u'Paolo Ferragina', u'Massimiliano Ciaramita', u'Stefan Rued', u'Hinrich Schuetze']
NaturalLanguageProcessing
Abstract: The SMAPH system implements a pipeline of four main steps: (1) Fetching it fetches the search results returned by a search engine given the query to be annotated; (2) Spotting search result snippets are parsed to identify candidate mentions for the entities to be annotated. This is done in a novel way by detecting the keywords-in-context by looking at the bold parts of the search snippets; (3) Candidate generation candidate entities are generated in two ways: from the Wikipedia pages occurring in the search results, and from an existing annotator, using the mentions identified in the spotting step as input; (4) Pruning a binary SVM classifier is used to decide which entities to keep/discard in order to generate the final annotation set for the query. The SMAPH system ranked third on the development set and first on the final blind test of the 2014 ERD Challenge short text track.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Dataset of Syntactic-Ngrams over Time from a Very Large Corpus of English Books
Second Joint Conference on Lexical and Computational Semantics, Association for Computational Linguistics, Atlanta, Georgia, USA (2013), pp. 241-247
[u'Yoav Goldberg', u'Jon Orwant']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Breaking Out of Local Optima with Count Transforms and Model Recombination: A Study in Grammar Induction
2013 Conference on Empirical Methods in Natural Language Processing (EMNLP 2013; Best Paper Award)
[u'Valentin I. Spitkovsky', u'Daniel Jurafsky', u'Hiyan Alshawi']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Connecting Language and Knowledge Bases with Embedding Models for Relation Extraction
Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing.
[u'Jason Weston', u'Antoine Bordes', u'Oksana Yakhnenko', u'Nicolas Usunier']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41533.html
found
=========================
Cross-Lingual Discriminative Learning of Sequence Models with Posterior Regularization
Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing
[u'Kuzman Ganchev', u'Dipanjan Das']
NaturalLanguageProcessing
Abstract: We present a framework for cross-lingual transfer of sequence information from a resource-rich source language to a resource-impoverished target language that incorporates soft constraints via posterior regularization. To this end, we use automatically word aligned bitext between the source and target language pair, and learn a discriminative conditional random field model on the target side. Our posterior regularization constraints are derived from simple intuitions about the task at hand and from cross-lingual alignment information. We show improvements over strong baselines for two tasks: part-of-speech tagging and named-entity segmentation.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Deceptive Answer Prediction with User Preference Graph
The 51st Annual Meeting of the Association for Computational Linguistics (ACL 2013) (to appear)
[u'Fangtao Li', u'Yang Gao', u'Shuchang Zhou', u'Xiance Si', u'Decheng Dai']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41224.html
found
=========================
Efficient Estimation of Word Representations in Vector Space
International Conference on Learning Representations (2013)
[u'Tomas Mikolov', u'Kai Chen', u'Greg S. Corrado', u'Jeffrey Dean']
NaturalLanguageProcessing
Abstract: We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41096.html
notfound
=========================
Empirical Exploration of Language Modeling for the google.com Query Stream as Applied to Mobile Voice Search
Mobile Speech and Advanced Natural Language Solutions, Springer Science+Business Media, New York (2013), pp. 197-229
[u'Ciprian Chelba', u'Johan Schalkwyk']
NaturalLanguageProcessing
Abstract: Mobile is poised to become the predominant platform over which people are accessing the World Wide Web. Recent developments in speech recognition and understanding, backed by high bandwidth coverage and high quality speech signal acquisition on smartphones and tablets are presenting the users with the choice of speaking their web search queries instead of typing them. A critical component of a speech recognition system targeting web search is the language model. The chapter presents an empirical exploration of the google.com query stream with the end goal of high quality statistical language modeling for mobile voice search. Our experiments show that after text normalization the query stream is not as ``wild'' as it seems at first sight. One can achieve out-of-vocabulary rates below 1% using a one million word vocabulary, and excellent n-gram hit ratios of 77/88% even at high orders such as n=5/4, respectively. A more careful analysis shows that a significantly larger vocabulary (approx. 10 million words) may be required to guarantee at most 1% out-of-vocabulary rate for a large percentage (95%) of users. Using large scale, distributed language models can improve performance significantly---up to 10% relative reductions in word-error-rate over conventional models used in speech recognition. We also find that the query stream is non-stationary, which means that adding more past training data beyond a certain point provides diminishing returns, and may even degrade performance slightly. Perhaps less surprisingly, we have shown that locale matters significantly for English query data across USA, Great Britain and Australia. In an attempt to leverage the speech data in voice search logs, we successfully build large-scale discriminative N-gram language models and derive small but significant gains in recognition performance.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41389.html
found
=========================
Enlisting the Ghost: Modeling Empty Categories for Machine Translation
Proceedings of ACL, ACL (2013), pp. 822-831
[u'Bing Xiang', u'Xiaoqiang Luo', u'Bowen Zhou']
NaturalLanguageProcessing
Abstract: Empty categories (EC) are articial elements in Penn Treebanks motivated by the government-binding (GB) theory to explain certain language phenomena such as pro-drop. ECs are ubiquitous in languages like Chinese, but they are tacitly ignored in most machine translation (MT) work because of their elusive nature. In this paper we present a comprehensive treatment of ECs by rst recovering them with a structured MaxEnt model with a rich set of syntactic and lexical features, and then incorporating the predicted ECs into a Chinese-to-English machine translation task through multiple approaches, including the extraction of EC-specic sparse features. We show that the recovered empty categories not only improve the word alignment quality, but also lead to signicant improvements in a large-scale state-of-the-art syntactic MT system.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41671.html
found
=========================
Filling Knowledge Base Gaps for Distant Supervision of Relation Extraction
ACL 2013
[u'Wei Xu', u'Raphael Hoffmann', u'Le Zhao', u'Ralph Grishman']
NaturalLanguageProcessing
Abstract: (first author email should be xuwei@cs.nyu.edu) Abstract: Distant supervision has attracted recent in- terest for training information extraction systems because it does not require any human annotation but rather employs ex- isting knowledge bases to heuristically la- bel a training corpus. However, previous work has failed to address the problem of false negative training examples misla- beled due to the incompleteness of knowl- edge bases. To tackle this problem, we propose a simple yet novel framework that combines a passage retrieval model using coarse features into a state-of-the-art rela- tion extractor using multi-instance learn- ing with ne features. We adapt the in- formation retrieval technique of pseudo- relevance feedback to expand knowledge bases, assuming entity pairs in top-ranked passages are more likely to express a rela- tion. Our proposed technique signicantly improves the quality of distantly super- vised relation extraction, boosting recall from 47.7% to 61.2% with a consistently high level of precision of around 93% in the experiments.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41185.html
notfound
=========================
HEADY: News headline abstraction through event pattern clustering
Proceedings of ACL-2013
[u'Enrique Alfonseca', u'Daniele Pighin', u'Guillermo Garrido']
NaturalLanguageProcessing
Abstract: This paper presents HEADY: a novel, ab- stractive approach for headline generation from news collections. From a web-scale corpus of English news, we mine syntactic patterns that a Noisy-OR model generalizes into event descriptions. At inference time, we query the model with the patterns observed in an unseen news collection, identify the event that better captures the gist of the collection and retrieve the most appropriate pattern to generate a headline. HEADY improves over a state-of-the- art open-domain title abstraction method, bridging half of the gap that separates it from extractive methods using human-generated titles in manual evaluations, and performs comparably to human-generated headlines as evaluated with ROUGE.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Hierarchical Geographical Modeling of User locations from Social Media Posts
Proceedings of the 22nd International World Wide Web Conference (WWW 2013) (to appear)
[u'Amr Ahmed', u'Liangjie Hong', u'Alexander J Smola']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41851.html
notfound
=========================
Identifying Phrasal Verbs Using Many Bilingual Corpora
Proceedings of Empirical Methods in Natural Language Processing (2013)
[u'Karl Pichotta', u'John DeNero']
NaturalLanguageProcessing
Abstract: We address the problem of identifying multiword expressions in a language, focusing on English phrasal verbs. Our polyglot ranking approach integrates frequency statistics from translated corpora in 50 different languages. Our experimental evaluation demonstrates that combining statistical evidence from many parallel corpora using a novel ranking-oriented boosting algorithm produces a comprehensive set of English phrasal verbs, achieving performance comparable to a human-curated set.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Language Model Verbalization for Automatic Speech Recognition
Proc ICASSP, IEEE (2013)
[u'Hasim Sak', u'Franoise Beaufays', u'Kaisuke Nakajima', u'Cyril Allauzen']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41188.html
found
=========================
Language-Independent Discriminative Parsing of Temporal Expressions
The 51st Annual Meeting of the Association for Computational Linguistics (ACL 2013) (to appear)
[u'Gabor Angeli', u'Jakob Uszkoreit']
NaturalLanguageProcessing
Abstract: Temporal resolution systems are traditionally tuned to a particular language, requiring significant human effort to translate them to new languages. We present a language independent semantic parser for learning the interpretation of temporal phrases given only a corpus of utterances and the times they reference. We make use of a latent parse that encodes a language-flexible representation of time, and extract rich features over both the parse and associated temporal semantics. The parameters of the model are learned using a weakly supervised bootstrapping approach, without lexical cues or language-specific tuning. We achieve state-of-the-art accuracy on all languages in the TempEval-2 temporal normalization task, reporting a 4% improvement in both English and Spanish accuracy, and to our knowledge the first results for four other languages.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Mixture of mixture n-gram language models
ASRU (2013), pp. 31-36
[u'Hasim Sak', u'Cyril Allauzen', u'Kaisuke Nakajima', u'Franoise Beaufays']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41880.html
found
=========================
One Billion Word Benchmark for Measuring Progress in Statistical Language Modeling
ArXiv, Google (2013)
[u'Ciprian Chelba', u'Tomas Mikolov', u'Mike Schuster', u'Qi Ge', u'Thorsten Brants', u'Phillipp Koehn', u'Tony Robinson']
NaturalLanguageProcessing
Abstract: We propose a new benchmark corpus to be used for measuring progress in statistical language modeling. With almost one billion words of training data, we hope this benchmark will be useful to quickly evaluate novel language modeling techniques, and to compare their contribution when combined with other advanced techniques. We show performance of several well-known types of language models, with the best results achieved with a recurrent neural network based language model. The baseline unpruned Kneser-Ney 5-gram model achieves perplexity 67.6; a combination of techniques leads to 35% reduction in perplexity, or 10% reduction in cross-entropy (bits), over that baseline. The benchmark is available as a code.google.com project at https://code.google.com/p/1-billion-word-language-modeling-benchmark/; besides the scripts needed to rebuild the training/held-out data, it also makes available log-probability values for each word in each of ten held-out data sets, for each of the baseline n-gram models.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Online Learning for Inexact Hypergraph Search
Proc. of EMNLP (2013)
[u'Hao Zhang', u'Liang Huang', u'Kai Zhao', u'Ryan McDonald']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Open-Domain Fine-Grained Class Extraction from Web Search Queries
Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP-2013)
[u'Marius Pasca']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41393.html
notfound
=========================
Overcoming the Lack of Parallel Data in Sentence Compression
Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing (EMNLP '13), pp. 1481-1491
[u'Katja Filippova', u'Yasemin Altun']
NaturalLanguageProcessing
Abstract: A subset of the described data (10,000 sentence & extracted headlines pairs, with source URL and annotations) is available for download.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41531.html
found
=========================
ReFr: An Open-Source Reranker Framework
Interspeech 2013, pp. 756-758
[u'Daniel M. Bikel', u'Keith B. Hall']
NaturalLanguageProcessing
Abstract: ReFr (http://refr.googlecode.com) is a software architecture for specifying, training and using reranking models, which take the n-best output of some existing system and produce new scores for each of the n hypotheses that potentially induce a different ranking, ideally yielding better results than the original system. The Reranker Framework has some special support for building discriminative language models, but can be applied to any reranking problem. The framework is designed with parallelism and scalability in mind, being able to run on any Hadoop cluster out of the box. While extremely efcient, ReFr is also quite exible, allowing researchers to explore a wide variety of features and learning methods. ReFr has been used for building state-of-the-art discriminative LMs for both speech recognition and machine translation systems.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Russian Stress Prediction using Maximum Entropy Ranking
EMNLP, ACL (2013)
[u'Keith Hall', u'Richard Sproat']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Scalable Decipherment for Machine Translation via Hash Sampling
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL) (2013)
[u'Sujith Ravi']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41345.html
notfound
=========================
Smoothed marginal distribution constraints for language modeling
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL) (2013), pp. 43-52
[u'Brian Roark', u'Cyril Allauzen', u'Michael Riley']
NaturalLanguageProcessing
Abstract: We present an algorithm for re-estimating parameters of backoff n-gram language models so as to preserve given marginal distributions, along the lines of well-known Kneser-Ney smoothing. Unlike Kneser-Ney, our approach is designed to be applied to any given smoothed backoff model, including models that have already been heavily pruned. As a result, the algorithm avoids issues observed when pruning Kneser-Ney models (Siivola et al., 2007; Chelba et al., 2010), while retaining the benefits of such marginal distribution constraints. We present experimental results for heavily pruned backoff n-gram models, and demonstrate perplexity and word error rate reductions when used with various baseline smoothing methods. An open-source version of the algorithm has been released as part of the OpenGrm ngram library.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41117.html
notfound
=========================
Speech and Natural Language: Where Are We Now And Where Are We Headed?
Mobile Voice Conference, San Francisco (2013)
[u'Ciprian Chelba']
NaturalLanguageProcessing
Abstract: Slides from a presentation on invited panel at the Mobile Voice Conference 2013, San Francisco.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Summarization Through Submodularity and Dispersion
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL) (2013)
[u'Anirban Dasgupta', u'Ravi Kumar', u'Sujith Ravi']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41850.html
notfound
=========================
Supervised Learning of Complete Morphological Paradigms
Proceedings of the North American Chapter of the Association for Computational Linguistics (2013)
[u'Greg Durrett', u'John DeNero']
NaturalLanguageProcessing
Abstract: We describe a supervised approach to predicting the set of all inflected forms of a lexical item. Our system automatically acquires the orthographic transformation rules of morphological paradigms from labeled examples, and then learns the contexts in which those transformations apply using a discriminative sequence model. Because our approach is completely data-driven and the model is trained on examples extracted from Wiktionary, our method can extend to new languages without change. Our end-to-end system is able to predict complete paradigms with 86.1% accuracy and individual inflected forms with 94.9% accuracy, averaged across three languages and two parts of speech.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42182.html
found
=========================
System and method for determining active topics
Patent (2013)
[u'Michael Jeffrey Procopio']
NaturalLanguageProcessing
Abstract: A method for determining active topics may include receiving topic information for a document, the information including at least one topic and a weight for each topic, where the topic relates to content of the document, and the weight represents how strongly the topic is associated with the document. User activity information for the document, including a user activity value including at least one of a number of viewers and a number of editors of the document may be received. A topic intensity for each topic may be generated and stored by multiplying the user activity value for the document by the weight of the topic in the document. The topic intensity may be monitored over time. An alert may be generated based on the topic intensity.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Target Language Adaptation of Discriminative Transfer Parsers
Proceedings of the North American Chapter of the Association for Computational Linguistics (2013)
[u'Oscar Tackstrom', u'Ryan McDonald', u'Joakim Nivre']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Token and Type Constraints for Cross-Lingual Part-of-Speech Tagging
Transactions of the Association for Computational Linguistics (2013), 1-12
[u'Oscar Tackstrom', u'Dipanjan Das', u'Slav Petrov', u'Ryan McDonald', u'Joakim Nivre']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Universal Dependency Annotation for Multilingual Parsing
Association for Computational Linguistics (2013)
[u'Ryan McDonald', u'Joakim Nivre', u'Yoav Goldberg', u'Yvonne Quirmbach-Brundage', u'Dipanjan Das', u'Kuzman Ganchev', u'Keith Hall', u'Slav Petrov', u'Hao Zhang', u'Oscar Tackstrom', u'Claudia Bedini', u'Nuria Bertomeu Castello', u'Jungmee Lee']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41184.html
notfound
=========================
WHAD: Wikipedia historical attributes data
Language Resources and Evaluation (2013), pp. 28
[u'Enrique Alfonseca', u'Guillermo Garrido', u'Jean-Yves Delort', u'Anselmo Peas']
NaturalLanguageProcessing
Abstract: This paper describes the generation of temporally anchored infobox attribute data from the Wikipedia history of revisions. By mining (attribute, value) pairs from the revision history of the English Wikipedia we are able to collect a comprehensive knowledge base that contains data on how attributes change over time. When dealing with the Wikipedia edit history, vandalic and erroneous edits are a concern for data quality. We present a study of vandalism identication in Wikipedia edits that uses only features from the infoboxes, and show that we can obtain, on this dataset, an accuracy comparable to a state-of-the-art vandalism identication method that is based on the whole article. Finally, we discuss different characteristics of the extracted dataset, which we make available for further study.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Written-Domain Language Modeling for Automatic Speech Recognition
Interspeech (2013)
[u'Hasim Sak', u'Yun-hsuan Sung', u'Franoise Beaufays', u'Cyril Allauzen']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38107.html
found
=========================
A Class-Based Agreement Model For Generating Accurately Inflected Translations
50th Annual Meeting of the Association for Computational Linguistics (ACL 2012)
[u'Spence Green', u'John DeNero']
NaturalLanguageProcessing
Abstract: When automatically translating from a weakly inflected source language like English to a target language with richer grammatical features such as gender and dual number, the output commonly contains morpho-syntactic agreement errors. To address this issue, we present a target-side, class-based agreement model. Agreement is promoted by scoring a sequence of fine-grained morpho-syntactic classes that are predicted during decoding for each translation hypothesis. For English-to-Arabic translation, our model yields a +1.04 BLEU average improvement over a state-of-the-art baseline. The model does not require bitext or phrase table annotations and can be easily implemented as a feature in many phrase-based decoders.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Comparison of Chinese Parsers for Stanford Dependencies
50th Annual Meeting of the Association for Computational Linguistics (ACL 2012)
[u'Wanxiang Che', u'Valentin I. Spitkovsky', u'Ting Liu']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Data-Driven Approach to Question Subjectivity Identification in Community Question Answering
Proceedings of the 26th AAAI Conference on Artificial Intelligence (AAAI-12) (2012)
[u'Tom Chao Zhou', u'Xiance Si', u'Edward Y.', u'Irwin King', u'Michael R. Lyu']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38273.html
notfound
=========================
A Feature-Rich Constituent Context Model for Grammar Induction
Proceedings of the Association for Computational Linguistics (2012)
[u'Dave Golland', u'John DeNero', u'Jakob Uszkoreit']
NaturalLanguageProcessing
Abstract: We present LLCCM, a log-linear variant of the constituent context model (CCM) of grammar induction. LLCCM retains the simplicity of the original CCM but extends robustly to long sentences. On sentences of up to length 40, LLCCM outperforms CCM by 13.9% brack- eting F1 and outperforms a right-branching baseline in regimes where CCM does not.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Pushdown Transducer Extension for the OpenFst Library
CIAA, Springer (2012), pp. 66-77
[u'Cyril Allauzen', u'Michael Riley']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Universal Part-of-Speech Tagset
Proceedings of the 8th International Conference on Language Resources and Evaluation (LREC '12) (2012)
[u'Slav Petrov', u'Dipanjan Das', u'Ryan McDonald']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Attribute Extraction from Conjectural Queries
Proceedings of the 24th International Conference on Computational Linguistics (COLING-2012)
[u'Marius Pasca']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Bootstrapping Dependency Grammar Inducers from Incomplete Sentence Fragments via Austere Models
11th International Conference on Grammatical Inference (ICGI 2012)
[u'Valentin I. Spitkovsky', u'Hiyan Alshawi', u'Daniel Jurafsky']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Capitalization Cues Improve Dependency Grammar Induction
NAACL HLT 2012 Workshop on Inducing Linguistic Structure (WILS 2012)
[u'Valentin I. Spitkovsky', u'Hiyan Alshawi', u'Daniel Jurafsky']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Cross-lingual Word Clusters for Direct Transfer of Linguistic Structure
North American Association for Computational Linguistics (2012)
[u'Oscar Tackstrom', u'Ryan McDonald', u'Jakob Uszkoreit']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
DualSum: A Topic-Model for Update Summarization
Proceedings of EACL-2012, Brandschenkestrasse 110
[u'Enrique Alfonseca', u'Jean-Yves Delort']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Entity Disambiguation with Freebase
The 2012 IEEE/WIC/ACM International Conference on Web Intelligence (WI'2012) (to appear)
[u'Zhicheng Zheng', u'Xiance Si', u'Fangtao Li', u'Edward Y. Chang', u'Xiaoyan Zhu']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Generalized Higher-Order Dependency Parsing with Cube Pruning
EMNLP (2012)
[u'Hao Zhang', u'Ryan McDonald']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Hallucinated N-Best Lists for Discriminative Language Modeling
Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP) (2012)
[u'Kenji Sagae', u'Maider Lehr', u'Emily Tucker Prudhommeaux', u'Puyang Xu', u'Nathan Glenn', u'Damianos Karakos', u'Sanjeev Khudanpur', u'Brian Roark', u'Murat Saralar', u'Izhak Shafran', u'Daniel M. Bikel', u'Chris Callison-Burch', u'Yuan Cao', u'Keith Hall', u'Eva Hassler', u'Philipp Koehn', u'Adam Lopez', u'Matt Post', u'Darcey Riley']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Haptic Voice Recognition Grand Challenge
14th ACM International Conference on Multimodal Interaction. (2012)
[u'K. Sim', u'S. Zhao', u'K. Yu', u'H. Liao']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40803.html
found
=========================
Improved Domain Adaptation for Statistical Machine Translation
AMTA-2012, The Association for Machine Translation in the Americas
[u'Wei Wang', u'Klaus Macherey', u'Wolfgang Macherey', u'Franz Och', u'Peng Xu']
NaturalLanguageProcessing
Abstract: We present a simple and effective infrastructure for domain adaptation for statistical machine translation (MT). To build MT systems for different domains, it trains, tunes and deploys a single translation system that is capable of producing adapted domain translations and preserving the original generic accuracy at the same time. The approach uni?es automatic domain detection and domain model parameterization into one system. Experiment results on 20 language pairs demonstrate its viability
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Instance-Driven Attachment of Semantic Annotations over Conceptual Hierarchies
Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics (EACL-2012), pp. 503-513
[u'Janara Christensen', u'Marius Pasca']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Joint Learning of Words and Meaning Representations for Open-Text Semantic Parsing.
AISTATS (2012)
[u'Antoine Bordes', u'Xavier Glorot', u'Jason Weston', u'Yoshua Bengio']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40380.html
notfound
=========================
Language Modeling for Automatic Speech Recognition Meets the Web: Google Search by Voice
University of Toronto (2012)
[u'Ciprian Chelba', u'Johan Schalkwyk', u'Boulos Harb', u'Carolina Parada', u'Cyril Allauzen', u'Leif Johnson', u'Michael Riley', u'Peng Xu', u'Preethi Jyothi', u'Thorsten Brants', u'Vida Ha', u'Will Neveitt']
NaturalLanguageProcessing
Abstract: A critical component of a speech recognition system targeting web search is the language model. The talk presents an empirical exploration of the google.com query stream with the end goal of high quality statistical language modeling for mobile voice search. Our experiments show that after text normalization the query stream is not as ``wild'' as it seems at first sight. One can achieve out-of-vocabulary rates below 1% using a one million word vocabulary, and excellent n-gram hit ratios of 77/88% even at high orders such as n=5/4, respectively. Using large scale, distributed language models can improve performance significantly---up to 10\% relative reductions in word-error-rate over conventional models used in speech recognition. We also find that the query stream is non-stationary, which means that adding more past training data beyond a certain point provides diminishing returns, and may even degrade performance slightly. Perhaps less surprisingly, we have shown that locale matters significantly for English query data across USA, Great Britain and Australia. In an attempt to leverage the speech data in voice search logs, we successfully build large-scale discriminative N-gram language models and derive small but significant gains in recognition performance.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40491.html
notfound
=========================
Large Scale Language Modeling in Automatic Speech Recognition
Google (2012)
[u'Ciprian Chelba', u'Dan Bikel', u'Maria Shugrina', u'Patrick Nguyen', u'Shankar Kumar']
NaturalLanguageProcessing
Abstract: Large language models have been proven quite beneficial for a variety of automatic speech recognition tasks in Google. We summarize results on Voice Search and a few YouTube speech transcription tasks to highlight the impact that one can expect from increasing both the amount of training data, and the size of the language model estimated from such data. Depending on the task, availability and amount of training data used, language model size and amount of work and care put into integrating them in the lattice rescoring step we observe reductions in word error rate between 6% and 10% relative, for systems on a wide range of operating points between 17% and 52% word error rate.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38145.html
notfound
=========================
Large-scale Discriminative Language Model Reranking for Voice Search
Proceedings of the NAACL-HLT 2012 Workshop: Will We Ever Really Replace the N-gram Model? On the Future of Language Modeling for HLT, Association for Computational Linguistics, pp. 41-49
[u'Preethi Jyothi', u'Leif Johnson', u'Ciprian Chelba', u'Brian Strope']
NaturalLanguageProcessing
Abstract: We present a distributed framework for large-scale discriminative language models that can be integrated within a large vocabulary continuous speech recognition (LVCSR) system using lattice rescoring. We intentionally use a weakened acoustic model in a baseline LVCSR system to generate candidate hypotheses for voice-search data; this allows us to utilize large amounts of unsupervised data to train our models. We propose an efficient and scalable MapReduce framework that uses a perceptron-style distributed training strategy to handle these large amounts of data. We report small but significant improvements in recognition accuracies on a standard voice-search data set using our discriminative reranking model. We also provide an analysis of the various parameters of our models including model size, types of features, size of partitions in the MapReduce framework with the help of supporting experiments.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Multilingual Natural Language Processing Applications: From Theory to Practice
IBM Press (2012)
[u'Daniel M. Bikel', u'Imed Zitouni']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40492.html
notfound
=========================
Optimal Size, Freshness and Time-frame for Voice Search Vocabulary
Google (2012)
[u'Maryam Kamvar', u'Ciprian Chelba']
NaturalLanguageProcessing
Abstract: In this paper, we investigate how to optimize the vocabulary for a voice search language model. The metric we optimize over is the out-of-vocabulary (OoV) rate since it is a strong indicator of user experience. In a departure from the usual way of measuring OoV rates, web search logs allow us to compute the per-session OoV rate and thus estimate the percentage of users that experience a given OoV rate. Under very conservative text normalization, we nd that a voice search vocabulary consisting of 2 to 2.5M words extracted from 1 week of search query data will result in an aggregate OoV rate of 0.01; at that size, the same OoV rate will also be experienced by 90% of users. The number of words included in the vocabulary is a stable indicator of the OoV rate. Altering the freshness of the vocabulary or the duration of the time window over which the training data is gathered does not signicantly change the OoV rate. Surprisingly, a signicantly larger vocabulary (approx. 10 million words) is required to guarantee OoV rates below 0.01 (1%) for 95% of the users.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Overview of the 2012 Shared Task on Parsing the Web
Notes of the First Workshop on Syntactic Analysis of Non-Canonical Language (SANCL) (2012)
[u'Slav Petrov', u'Ryan McDonald']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Pattern Learning for Relation Extraction with Hierarchical Topic Models
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (ACL'12) (2012)
[u'Enrique Alfonseca', u'Katja Filippova', u'Jean-Yves Delort', u'Guillermo Garrido']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Syntactic Annotations for the Google Books Ngram Corpus
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, Volume 2: Demo Papers (ACL '12) (2012)
[u'Yuri Lin', u'Jean-Baptiste Michel', u'Erez Lieberman Aiden', u'Jon Orwant', u'William Brockman', u'Slav Petrov']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
The OpenGrm Open-Source Finite-State Grammar Software Libraries
ACL (System Demonstrations) (2012), pp. 61-66
[u'Brian Roark', u'Richard Sproat', u'Cyril Allauzen', u'Michael Riley', u'Jeffrey Sorensen', u'Terry Tai']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Three Dependency-and-Boundary Models for Grammar Induction
2012 Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL 2012)
[u'Valentin I. Spitkovsky', u'Hiyan Alshawi', u'Daniel Jurafsky']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38138.html
found
=========================
Unsupervised Translation Sense Clustering
the North American Association of Computational Linguistics (2012)
[u'Mohit Bansal', u'John DeNero', u'Dekang Lin']
NaturalLanguageProcessing
Abstract: We propose an unsupervised method for clustering the translations of a word, such that the translations in each cluster share a common semantic sense. Words are assigned to clusters based on their usage distribution in large monolingual and parallel corpora using the soft K-Means algorithm. In addition to describing our approach, we formalize the task of translation sense clustering and describe a procedure that leverages WordNet for evaluation. By comparing our induced clusters to reference clusters generated from WordNet, we demonstrate that our method effectively identifies sense-based translation clusters and benefits from both monolingual and parallel corpora. Finally, we describe a method for annotating clusters with usage examples.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
User Demographics and Language in an Implicit Social Network
Proceedings of the 2012 Conference on Empirical Methods in Natural Language Processing (EMNLP'12), Jeju, Korea
[u'Katja Filippova']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Using Search-Logs to Improve Query Tagging
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, Volume 2: Short Papers (ACL '12) (2012)
[u'Kuzman Ganchev', u'Keith B. Hall', u'Ryan McDonald', u'Slav Petrov']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37844.html
notfound
=========================
Vine Pruning for Efficient Multi-Pass Dependency Parsing
The 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL '12), Best Paper Award
[u'Alexander Rush', u'Slav Petrov']
NaturalLanguageProcessing
Abstract: Coarse-to-fine inference has been shown to be a robust approximate method for improving the efficiency of structured prediction models while preserving their accuracy. We propose a multi-pass coarse-to-fine architecture for dependency parsing using linear-time vine pruning and structured prediction cascades. Our first-, second-, and third-order models achieve accuracies comparable to those of their unpruned counterparts, while exploring only a fraction of the search space. We observe speed-ups of up to two orders of magnitude compared to exhaustive search. Our pruned third-order model is twice as fast as an unpruned first-order model and also compares favorably to a state-of-the-art transition-based parser for multiple languages.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37428.html
notfound
=========================
A Tweet Consumers' Look At Twitter Trends
Workshop Making Sense of Microposts (MSM 2011) at the Extended Semantic Web Conference (ESWC 2011), Heraklion, Crete
[u'Thomas Steiner', u'Arnaud Brousseau', u'Raphael Troncy']
NaturalLanguageProcessing
Abstract: Twitter Trends allows for a global or local view on whats happening in my world right now from a tweet producers point of view. In this paper, we explore a way to complete Twitter Trends by having a closer look at the other side: the tweet consumers point of view. While Twitter Trends works by analyzing the frequency of terms and their velocity of appearance in tweets being written, our approach is based on the popularity of extracted named entities in tweets being read.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37426.html
notfound
=========================
Adding Meaning to Facebook Microposts via a Mash-up API and Tracking Its Data Provenance
The 7th International Conference on Next Generation Web Services Practices (NWeSP 2011)
[u'Thomas Steiner', u'Ruben Verborgh', u'Joaquim Gabarro', u'Rik Van de Walle']
NaturalLanguageProcessing
Abstract: The social networking website Facebook offers to its users a feature called status updates (or just status), which allows users to create microposts directed to all their contacts, or a subset thereof. Readers can respond to microposts, or in addition to that also click a Like button to show their appreciation for a certain micropost. Adding semantic meaning in the sense of unambiguous intended ideas to such microposts can, for example, be achieved via Natural Language Processing (NLP). Therefore, we have implemented a RESTful mash-up NLP API, which is based on a combination of several third party NLP APIs in order to retrieve more accurate results in the sense of emergence. In consequence, our API uses third party APIs opaquely in the background in order to deliver its output. In this paper, we describe how one can keep track of provenance, and credit back the contributions of each single API to the combined result of all APIs. In addition to that, we show how the existence of provenance metadata can help understand the way a combined result is formed, and optimize the result combination process. Therefore, we use the HTTP Vocabulary in RDF and the Provenance Vocabulary. The main contribution of our work is a description of how provenance metadata can be automatically added to the output of mash-up APIs like the one presented here.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Analyzing and Integrating Dependency Parsers
Computational Linguistics, vol. 37 (2011)
[u'Ryan McDonald', u'Joakim Nivre']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Asking What No One Has Asked Before: Using Phrase Similarities to Generate Synthetic Web Search Queries
Proceedings of the 20th ACM Conference on Information and Knowledge Management (CIKM-2011), ACM, Glasgow, Scotland, pp. 1347-1352
[u'Marius Pasca']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Beam-Width Prediction for Efcient Context-Free Parsing
Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics (2011)
[u'Nathan Bodenstab', u'Aaron Dunlop', u'Keith Hall', u'Brian Roark']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Binarized Forest to String Translation
ACL (2011), pp. 835-845
[u'Hao Zhang', u'Licheng Fang', u'Peng Xu', u'Xiaoyun Wu']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37126.html
notfound
=========================
Blognoon: Exploring a Topic in the Blogosphere
WWW 2011, ACM, New York, NY, USA, pp. 213-216
[u'Maria Grineva', u'Maxim Grinev', u'Dmitry Lizorkin', u'Alexander Boldakov', u'Denis Turdakov', u'Andrey Sysoe', u'Alexander Kiyko']
NaturalLanguageProcessing
Abstract: We demonstrate Blognoon, a semantic blog search engine with the focus on topic exploration and navigation. Blognoon provides concept search instead of traditional keywords search and improves ranking by identifying main topics of posts. It enhances navigation over the Blogosphere with faceted interfaces and recommendations.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38280.html
found
=========================
Controlling Complexity in Part-of-Speech Induction
Journal of Artificial Intelligence Research (JAIR), vol. 41 (2011), pp. 527-551
[u'Joao Graca', u'Kuzman Ganchev', u'Luisa Coheur', u'Fernando Pereira', u'Ben Taskar']
NaturalLanguageProcessing
Abstract: We consider the problem of fully unsupervised learning of grammatical (part-of-speech) categories from unlabeled text. The standard maximum-likelihood hidden Markov model for this task performs poorly, because of its weak inductive bias and large model capacity. We address this problem by refining the model and modifying the learning objective to control its capacity via para- metric and non-parametric constraints. Our approach enforces word-category association sparsity, adds morphological and orthographic features, and eliminates hard-to-estimate parameters for rare words. We develop an efficient learning algorithm that is not much more computationally intensive than standard training. We also provide an open-source implementation of the algorithm. Our experiments on five diverse languages (Bulgarian, Danish, English, Portuguese, Spanish) achieve significant improvements compared with previous methods for the same task.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Corrective Dependency Parsing
Trends in Parsing Technologies, Springer (2011)
[u'Keith B. Hall', u'Vaclav Novak']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Deterministic Statistical Mapping of Sentences to Underspecied Semantics
Proceedings of the Ninth International Conference on Computational Semantics (IWCS 2011)
[u'Hiyan Alshawi', u'Pi-Chuan Chang', u'Michael Ringgaard']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Discovering fine-grained sentiment with latent variable structured prediction models
European Conference on Information Retrieval (2011)
[u'Oscar Tackstrom', u'Ryan McDonald']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Efficient Parallel CKY Parsing on GPUs
Proceedings of the International Conference on Parsing Technologies (IWPT '11) (2011)
[u'Youngmin Yi', u'Chao-Yue Lai', u'Slav Petrov', u'Kurt Keutzer']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Fine-Grained Class Label Markup of Search Queries
Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics (ACL-2011), pp. 1200-1209
[u'Joseph Reisinger', u'Marius Pasca']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Gappy Phrasal Alignment by Agreement
Proc. 49th Annual Meeting of the Association for Computational Linguistics, ACL, Portland, Oregon (2011), pp. 1308-1317
[u'Mohit Bansal', u'Chris Quirk', u'Robert C. Moore']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Improved Video Categorization from Text Metadata and User Comments
Proceedings of the 34th international ACM SIGIR conference on Research and development in Information (SIGIR-2011), Beijing, China, pp. 835-842
[u'Katja Filippova', u'Keith B. Hall']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37566.html
notfound
=========================
K2Q: Generating Natural Language Questions from Keywords with User Refinements
Proceedings of the 5th International Joint Conference on Natural Language Processing, ACL (2011), 947955
[u'Zhicheng Zheng', u'Xiance Si', u'Edward Y. Chang', u'Xiaoyan Zhu']
NaturalLanguageProcessing
Abstract: Garbage in and garbage out. A Q&A system must receive a well formulated question that matches the users intent or she has no chance to receive satisfactory answers. In this paper, we propose a keywords to questions (K2Q) system to assist a user to articulate and refine questions. K2Q generates candidate questions and refinement words from a set of input keywords. After specifying some initial keywords, a user receives a list of candidate questions as well as a list of refinement words. The user can then select a satisfactory question, or select a refinement word to generate a new list of candidate questions and refinement words. We propose a User Inquiry Intent (UII) model to de- scribe the joint generation process of keywords and questions for ranking questions, suggesting refinement words, and generating questions that may not have previously appeared. Empirical study shows UII to be useful and effective for the K2Q task.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37560.html
notfound
=========================
Large-Scale Cross-Document Coreference Using Distributed Inference and Hierarchical Models
Association for Computational Linguistics (ACL) (2011)
[u'Sameer Singh', u'Amarnag Subramanya', u'Fernando Pereira', u'Andrew McCallum']
NaturalLanguageProcessing
Abstract: Cross-document coreference, the task of grouping all the mentions of each entity in a document collection, arises in information extraction and automated knowledge base construction. For large collections, it is clearly impractical to consider all possible groupings of mentions into distinct entities. To solve the problem we propose two ideas: (a) a distributed inference technique that uses parallelism to enable large scale processing, and (b) a hierarchical model of coreference that represents uncertainty over multiple granularities of entities to facilitate more effective approximate inference. To evaluate these ideas, we constructed a labeled corpus of 1:5 million disambiguated mentions in Web pages by selecting link anchors referring to Wikipedia entities. We show that the combination of the hierarchical model with distributed inference quickly obtains high accuracy (with error reduction of 38%) on this large dataset, demonstrating the scalability of our approach.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37119.html
notfound
=========================
Learning to Rank Answers to Non-Factoid Questions from Web Collections
Computational Linguistics, vol. 37 (2011), pp. 351-383
[u'Mihai Surdeanu', u'Massimiliano Ciaramita', u'Hugo Zaragoza']
NaturalLanguageProcessing
Abstract: This work investigates the use of linguistically motivated features to improve search, in particular for ranking answers to non-factoid questions. We show that it is possible to exploit existing large collections of questionanswer pairs (from online social Question Answering sites) to extract such features and train ranking models which combine them effectively. We investigate a wide range of feature types, some exploiting natural language processing such as coarse word sense disambiguation, named-entity identication, syntactic parsing, and semantic role labeling. Our experiments demonstrate that linguistic features, in combination, yield considerable improvements in accuracy. Depending on the system settings we measure relative improvements of 14% to 21% in Mean Reciprocal Rank and Precision@1, providing one of the most compelling evidence to date that complex linguistic features such as word senses and semantic roles can have a signicant impact on large-scale information retrieval tasks.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Multi-Source Transfer of Delexicalized Dependency Parsers
Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing (EMNLP '11)
[u'Ryan McDonald', u'Slav Petrov', u'Keith B. Hall']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37143.html
notfound
=========================
Piggyback: Using Search Engines for Robust Cross-Domain Named Entity Recognition
49th Annual Meeting of the Association for Computational Linguistics (ACL-HLT), Association for Computational Linguistics (2011), pp. 965-975
[u'Stefan Rued', u'Massimiliano Ciaramita', u'Jens Mueller', u'Hinrich Schuetze']
NaturalLanguageProcessing
Abstract: We use search engine results to address a particularly dif?cult cross-domain language processing task, the adaptation of named entity recognition (NER) from news text to web queries. The key novelty of the method is that we submit a token with context to a search engine and use similar contexts in the search results as additional information for correctly classifying the token. We achieve strong gains in NER performance on news, in-domain and out-of-domain, and on web queries.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38281.html
found
=========================
Posterior Sparsity in Dependency Grammar Induction
Journal of Machine Learning Research, vol. 12 (2011), pp. 455-490
[u'Jennifer Gillenwater', u'Kuzman Ganchev', u'Joao Graca', u'Fernando Pereira', u'Ben Taskar']
NaturalLanguageProcessing
Abstract: A strong inductive bias is essential in unsupervised grammar induction. In this paper, we explore a particular sparsity bias in dependency grammars that encourages a small number of unique dependency types. We use part-of-speech (POS) tags to group dependencies by parent-child types and investigate sparsity-inducing penalties on the posterior distributions of parent-child POS tag pairs in the posterior regularization (PR) framework of Graa et al. (2007). In experiments with 12 different languages, we achieve significant gains in directed attachment accuracy over the standard expectation maximization (EM) baseline, with an average accuracy improvement of 6.5%, outperforming EM by at least 1% for 9 out of 12 languages. Furthermore, the new method outperforms models based on standard Bayesian sparsity-inducing parameter priors with an average improvement of 5% and positive gains of at least 1% for 9 out of 12 languages. On English text in particular, we show that our approach improves performance over other state-of-the-art techniques.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Punctuation: Making a Point in Unsupervised Dependency Parsing
Fifteenth Conference on Computational Natural Language Learning (CoNLL-2011)
[u'Valentin I. Spitkovsky', u'Hiyan Alshawi', u'Daniel Jurafsky']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37565.html
notfound
=========================
Question Identification on Twitter, Accepted by CIKM 2011
Proceedings of the 20th ACM international conference on Information and knowledge management, ACM, New York, NY, USA (2011)
[u'Baichuan Li', u'Xiance Si', u'Michael R. Lyu', u'Irwin King', u'Edward Y. Chang']
NaturalLanguageProcessing
Abstract: In this paper, we investigate the novel problem of auto- matic question identification in the microblog environment. It contains two steps: detecting tweets that contain ques- tions (we call them interrogative tweets) and extracting the tweets which really seek information or ask for help (so called qweets) from interrogative tweets. To detect inter- rogative tweets, both traditional rule-based approach and state-of-the-art learning-based method are employed. To extract qweets, context features like short urls and Tweet- specific features like Retweets are elaborately selected for classification. We conduct an empirical study with sampled one hours English tweets and report our experimental re- sults for question identification on Twitter.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Ranking Class Labels Using Query Sessions
Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics (ACL-2011), pp. 1607-1615
[u'Marius Pasca']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Semi-supervised Latent Variable Models for Fine-grained Sentiment Analysis
Association for Computational Linguistics (2011)
[u'Oscar Tackstrom', u'Ryan McDonald']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Training Structured Prediction Models with Extrinsic Loss Functions
Domain Adaptation Workshop at NIPS 2011
[u'Keith Hall', u'Ryan McDonald', u'Slav Petrov']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37159.html
found
=========================
Training a Parser for Machine Translation Reordering
Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing (EMNLP '11)
[u'Jason Katz-Brown', u'Slav Petrov', u'Ryan McDonald', u'Franz Och', u'David Talbot', u'Hiroshi Ichikawa', u'Masakazu Seno']
NaturalLanguageProcessing
Abstract: We propose a simple training regime that can improve the extrinsic performance of a parser, given only a corpus of sentences and a way to automatically evaluate the extrinsic quality of a candidate parse. We apply our method to train parsers that excel when used as part of a reordering component in a statistical machine translation system. We use a corpus of weakly-labeled reference reorderings to guide parser training. Our best parsers contribute significant improvements in subjective translation quality while their intrinsic attachment scores typically regress.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Training dependency parsers by jointly optimizing multiple objectives
Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing
[u'Keith B. Hall', u'Ryan McDonald', u'Jason Katz-Brown', u'Michael Ringgaard']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Unsupervised Dependency Parsing without Gold Part-of-Speech Tags
2011 Conference on Empirical Methods in Natural Language Processing (EMNLP 2011)
[u'Valentin I. Spitkovsky', u'Hiyan Alshawi', u'Angel X. Chang', u'Daniel Jurafsky']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37071.html
notfound
=========================
Unsupervised Part-of-Speech Tagging with Bilingual Graph-Based Projections
Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics (ACL '11) (2011), Best Paper Award
[u'Dipanjan Das', u'Slav Petrov']
NaturalLanguageProcessing
Abstract: We describe a novel approach for inducing unsupervised part-of-speech taggers for languages that have no labeled training data, but have translated text in a resource-rich language. Our method does not assume any knowledge about the target language (in particular no tagging dictionary is assumed), making it applicable for a wide array of resource-poor languages. We use graph-based label propagation for cross-lingual knowledge transfer and use the projected labels as constraints in an unsupervised model. Across six European languages, our approach results in an average absolute improvement of 9.7\% over the state-of-the-art baseline, and 17.0\% over vanilla hidden Markov models induced with EM.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36449.html
notfound
=========================
A Comparison of Features for Automatic Readability Assessment
23rd International Conference on Computational Linguistics (COLING 2010), Poster Volume, pp. 276-284
[u'Lijun Feng', u'Martin Jansche', u'Matt Huenerfauth', u'Nomie Elhadad']
NaturalLanguageProcessing
Abstract: Several sets of explanatory variables including shallow, language modeling, POS, syntactic, and discourse features are compared and evaluated in terms of their impact on predicting the grade level of reading material for primary school students. We find that features based on in-domain language models have the highest predictive power. Entity-density (a discourse feature) and POS-features, in particular nouns, are individually very useful but highly correlated. Average sentence length (a shallow feature) is more useful and less expensive to compute than individual syntactic features. A judicious combination of features examined here results in a significant improvement over the state of the art.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A novel approach for proper name transliteration verification
Chinese Spoken Language Processing (ISCSLP), 2010 7th International Symposium on, pp. 89 -94
[u'Ea-Ee Jan', u'Niyu Ge', u'Shih-Hsiang Lin', u'S. Roukos', u'J. Sorensen']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Acquisition of Instance Attributes via Labeled and Related Instances
Proceedings of the 33rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR-10) (2010)
[u'Enrique Alfonseca', u'Marius Pasca', u'Enrique Robledo-Arnuncio']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36801.html
notfound
=========================
Building Transcribed Speech Corpora Quickly and Cheaply for Many Languages
Proceedings of the 11th Annual Conference of the International Speech Communication Association (INTERSPEECH 2010), International Speech Communication Association, pp. 1914-1917
[u'Thad Hughes', u'Kaisuke Nakajima', u'Linne Ha', u'Atul Vasu', u'Pedro Moreno', u'Mike LeBeau']
NaturalLanguageProcessing
Abstract: We present a system for quickly and cheaply building transcribed speech corpora containing utterances from many speakers in a variety of acoustic conditions. The system consists of a client application running on an Android mobile device with an intermittent Internet connection to a server. The client application collects demographic information about the speaker, fetches textual prompts from the server for the speaker to read, records the speakers voice, and uploads the audio and associated metadata to the server. The system has so far been used to collect over 3000 hours of transcribed audio in 17 languages around the world.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36834.html
notfound
=========================
Direct Construction of Compact Context-Dependency Transducers From Data
Interspeech 2010, ISCA
[u'David Rybach', u'Michael Riley']
NaturalLanguageProcessing
Abstract: This paper describes a new method for building compact con-text-dependency transducers for finite-state transducer-based ASR decoders. Instead of the conventional phonetic decision-tree growing followed by FST compilation, this approach incorporates the phonetic context splitting directly into the transducer construction. The objective function of the split optimization is augmented with a regularization term that measures the number of transducer states introduced by a split. We give results on a large spoken-query task for various n-phone orders and other phonetic features that show this method can greatly reduce the size of the resulting context-dependency transducer with no significant impact on recognition accuracy. This permits using context sizes and features that might otherwise be unmanageable.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Distributed MAP Inference for Undirected Graphical Models
Workshop on Learning on Cores, Clusters and Clouds (LCCC), Neural Information Processing Society (NIPS) (2010)
[u'Sameer Singh', u'Amarnag Subramanya', u'Fernando Pereira', u'Andrew McCallum']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Efficient Graph-Based Semi-Supervised Learning of Structured Tagging Models
Proceedings of the 2010 Conference on Empirical Methods on Natural Language Processing (EMNLP '10)
[u'Amarnag Subramanya', u'Slav Petrov', u'Fernando Pereira']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Evaluation of Dependency Parsers on Unbounded Dependencies
International Conference on Computational Linguistics (2010)
[u'Joakim Nivre', u'Laura Rimell', u'Ryan McDonald', u'Carlos Gmez Rodrguez']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Expected Sequence Similarity Maximization
NAACL HLT (2010)
[u'Cyril Allauzen', u'Shankar Kumar', u'Wolfgang Macherey', u'Mehryar Mohri', u'Michael Riley']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Experiments in Graph-based Semi-Supervised Learning Methods for Class-Instance Acquisition
48th Annual Meeting of the Association for Computational Linguistics (ACL 2010)
[u'Partha Pratim Talukdar', u'Fernando Pereira']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
From Baby Steps to Leapfrog: How Less is More in Unsupervised Dependency Parsing
Human Language Technologies: The 11th Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL HLT 2010)
[u'Valentin I. Spitkovsky', u'Hiyan Alshawi', u'Daniel Jurafsky']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Learning Better Monolingual Models with Unannotated Bilingual Text
Fourteenth Conference on Computational Natural Language Learning (CoNLL '10) (2010)
[u'David Burkett', u'Slav Petrov', u'John Blitzer', u'Dan Klein']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Learning Dense Models of Query Similarity from User Click Logs
Proceedings of NAACL-HLT 2010
[u'Fabio De Bona', u'Stefan Riezler', u'Keith Hall', u'Massimiliano Ciaramita', u'Amac Herdagdelen', u'Maria Holmqvist']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Lightly Supervised Learning of Text Normalization: Russian Number Names
IEEE Workshop on Spoken Language Technology, Berkeley, CA (2010) (to appear)
[u'Richard Sproat']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36657.html
notfound
=========================
Logical Leaps and Quantum Connectives: Forging Paths through Predication Space
AAAI-Fall 2010 Symposium on Quantum Informatics for Cognitive, Social, and Semantic Processes. (to appear)
[u'Trevor Cohen', u'Dominic Widdows', u'Roger W. Schvaneveldt', u'Thomas C. Rindflesch']
NaturalLanguageProcessing
Abstract: The Predication-based Semantic Indexing (PSI) approach encodes both symbolic and distributional information into a semantic space using a permutation-based variant of Random Indexing. In this paper, we develop and evaluate a computational model of abductive reasoning based on PSI. Using distributional information, we identify pairs of concepts that are likely to be predicated about a common third concept, or middle term. As this occurs without the explicit identification of the middle term concerned, we refer to this process as a logical leap. Subsequently, we use further operations in the PSI space to retrieve this middle term and identify the predicate types involved. On evaluation using a set of 1000 randomly selected cue concepts, the model is shown to retrieve with accuracy concepts that can be connected to a cue concept by a middle term, as well as the middle term concerned, using nearest-neighbor search in the PSI space. The utility of quantum logical operators as a means to identify alternative paths through this space is also explored.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Multi-Sentence Compression: Finding Shortest Paths in Word Graphs
Proceedings of the 23rd International Conference on Computational Linguistics (Coling'10) (2010)
[u'Katja Filippova']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Products of Random Latent Variable Grammars
Human Language Technologies: The 11th Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL/HLT '10) (2010)
[u'Slav Petrov']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Profiting from Mark-Up: Hyper-Text Annotations for Guided Parsing
48th Annual Meeting of the Association for Computational Linguistics (ACL 2010)
[u'Valentin I. Spitkovsky', u'Daniel Jurafsky', u'Hiyan Alshawi']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36450.html
notfound
=========================
Proper Name Transcription/Transliteration with ICU Transforms
34th Internationalization & Unicode Conference (2010)
[u'Sascha Brawer', u'Martin Jansche', u'Hiroshi Takenaka', u'Yui Terashima']
NaturalLanguageProcessing
Abstract: We describe our experience with a deep localization of Google Maps, where millions of geographic names from diverse origins had to be represented in several target languages, including Russian, Mandarin, and Japanese. For example, a map of Western Europe on maps.google.co.jp shows Japanese labels for almost all labeled features. We tackle the problem of transliterating from several source languages into several target languages by pivoting through an explicit intermediate phonetic representation. Each transliteration scheme is implemented as a sequence of ICU transforms, reusing a few existing transforms from ICU and CLDR, but consisting mostly of transforms that we wrote specifically for this problem. Dividing the problem this way results in many reusable components that make it simple to transliterate between multiple languages. We discuss the steps that go into building transliteration rules, describe existing official and de facto standards and guidelines, and give suggestions for what to do when no consistent guidelines are available. We provide general recommendations for developing and testing custom ICU transforms. The presentation is available here.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36732.html
notfound
=========================
Query Language Modeling for Voice Search
Proceedings of the 2010 IEEE Workshop on Spoken Language Technology, IEEE, pp. 127-132
[u'Ciprian Chelba', u'Johan Schalkwyk', u'Thorsten Brants', u'Vida Ha', u'Boulos Harb', u'Will Neveitt', u'Carolina Parada', u'Peng Xu']
NaturalLanguageProcessing
Abstract: The paper presents an empirical exploration of google.com query stream language modeling. We describe the normalization of the typed query stream resulting in out-of-vocabulary (OoV) rates below 1% for a one million word vocabulary. We present a comprehensive set of experiments that guided the design decisions for a voice search service. In the process we re-discovered a less known interaction between Kneser-Ney smoothing and entropy pruning, and found empirical evidence that hints at non-stationarity of the query stream, as well as strong dependence on various English locales---USA, Britain and Australia.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Query Rewriting using Monolingual Statistical Machine Translation
Computational Linguistics, vol. 36 (2010)
[u'Stefan Riezler', u'Yi Liu']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Self-training with Products of Latent Variable Grammars
Proceedings of the 2010 Conference on Empirical Methods on Natural Language Processing (EMNLP '10)
[u'Zhongqiang Huang', u'Mary Harper', u'Slav Petrov']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Sparsity in Dependency Grammar Induction
48th Annual Meeting of the Association for Computational Linguistics (ACL 2010)
[u'Jennifer Gillenwater', u'Kuzman Ganchev', u'Joo Graa', u'Fernando Pereira', u'Ben Taskar']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Speech Recognition for Mobiles Devices at Google
PRICAI 2010, Lecture Notes in Artificial Intelligence volume 6230, Springer, Heidelberg, pp. 8-10
[u'Mike Schuster']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36472.html
notfound
=========================
Study on Interaction between Entropy Pruning and Kneser-Ney Smoothing
Proceedings of Interspeech (2010), pp. 2242-2245
[u'Ciprian Chelba', u'Thorsten Brants', u'Will Neveitt', u'Peng Xu']
NaturalLanguageProcessing
Abstract: The paper presents an in-depth analysis of a less known interaction between Kneser-Ney smoothing and entropy pruning that leads to severe degradation in language model performance under aggressive pruning regimes. Experiments in a data-rich setup such as google.com voice search show a significant impact in WER as well: pruning Kneser-Ney and Katz models to 0.1% of their original impacts speech recognition accuracy significantly, approx. 10% relative. Any third party with LDC membership should be able to reproduce our experiments using the scripts available at http://code.google.com/p/kneser-ney-pruning-experiments.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
The Role of Queries in Ranking Labeled Instances Extracted from Text
Proceedings of the 23rd International Conference on Computational Linguistics (COLING-2010), pp. 955-962
[u'Marius Pasca']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
The Role of Query Sessions in Extracting Instance Attributes from Web Search Queries
Proceedings of the 32nd European Conference on Information Retrieval (ECIR-2010), pp. 62-74
[u'Marius Pasca', u'Enrique Alfonseca', u'Enrique Robledo-Arnuncio', u'Ricardo Martin-Brualla', u'Keith Hall']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36654.html
notfound
=========================
The Semantic Vectors Package: New Algorithms and Public Tools for Distributional Semantics
Fourth IEEE International Conference on Semantic Computing (IEEE ICSC2010), IEEE
[u'Dominic Widdows', u'Trevor Cohen']
NaturalLanguageProcessing
Abstract: Distributional semantics is the branch of natural language processing that attempts to model the meanings of words, phrases and documents from the distribution and usage of words in a corpus of text. In the past three years, research in this area has been accelerated by the availability of the Semantic Vectors package, a stable, fast, scalable, and free software package for creating and exploring concepts in distributional models. This paper introduces the broad field of distributional semantics, the role of vector models within this field, and describes some of the results that have been made possible by the Semantic Vectors package. These applications of Semantic Vectors have so far included contributions to medical informatics and knowledge discovery, analysis of scientific articles, and even Biblical scholarship. Of particular interest is the recent emergence of models that take word order and other ordered structures into account, using permutation of coordinates to model directional relationships and semantic predicates.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
The Viability of Web-derived Polarity Lexicons
North American Chapter of the Association for Computational Linguistics (2010)
[u'Leonid Velikovich', u'Sasha Blair-Goldensohn', u'Kerry Hannan', u'Ryan McDonald']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Uptraining for Accurate Deterministic Question Parsing
Proceedings of the 2010 Conference on Empirical Methods on Natural Language Processing (EMNLP '10)
[u'Slav Petrov', u'Pi-Chuan Chang', u'Michael Ringgaard', u'Hiyan Alshawi']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Using Web-scale N-grams to Improve Base NP Parsing Performance
Proceedings of COLING (2010), 886894
[u'Emily Pitler', u'Shane Bergsma', u'Dekang Lin', u'Ken Church']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Viterbi Training Improves Unsupervised Dependency Parsing
Fourteenth Conference on Computational Natural Language Learning (CoNLL-2010)
[u'Valentin I. Spitkovsky', u'Hiyan Alshawi', u'Daniel Jurafsky', u'Christopher D. Manning']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36833.html
notfound
=========================
Voice Search for Development
Interspeech 2010
[u'Etienne Barnard', u'Johan Schalkwyk', u'Charl van Heerden', u'Pedro J. Moreno']
NaturalLanguageProcessing
Abstract: In light of the serious problems with both illiteracy and information access in the developing world, there is a widespread belief that speech technology can play a significant role in improving the quality of life of developing-world citizens. We review the main reasons why this impact has not occurred to date, and propose that voice-search systems may be a useful tool in delivering on the original promise. The challenges that must be addressed to realize this vision are analyzed, and initial experimental results in developing voice search for two languages of South Africa (Zulu and Afrikaans) are summarized
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Whats great and whats not: learning to classify the scope of negation for improved sentiment analysis
Workshop on Negation and Speculation in Natural Language Processing (2010)
[u'Isaac Councill', u'Ryan McDonald', u'Leonid Velikovich']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35539.html
notfound
=========================
A Generalized Composition Algorithm for Weighted Finite-State Transducers
Interspeech 2009
[u'Cyril Allauzen', u'Michael Riley', u'Johan Schalkwyk']
NaturalLanguageProcessing
Abstract: This paper describes a weighted finite-state transducer composition algorithm that generalizes the notion of the composition filter and present filters that remove useless epsilon paths and push forward labels and weights along epsilon paths. This filtering allows us to compose together large speech recognition context-dependent lexicons and language models much more efficiently in time and space than previously possible. We present experiments on Broadcast News and Google Search by Voice that demonstrate a 5% to 10% overhead for dynamic, runtime composition compared to a static, offline composition of the recognition transducer. To our knowledge, this is the first such system with such small overhead.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Panlingual Anomalous Text Detector
DocEng '09: Proceedings of the 9th ACM symposium on Document Engineering, ACM, New York (2009), pp. 201-204
[u'Ashok C. Popat']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Study on Similarity and Relatedness Using Distributional and WordNet-based Approaches
Proceedings of NAACL-HLT 2009
[u'Eneko Agirre', u'Enrique Alfonseca', u'Keith Hall', u'Jana Kravalova', u'Marius Pasca', u'Aitor Soroa']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
An Approach to Web-Scale Named-Entity Disambiguation
MLDM '09: Proceedings of the 6th International Conference on Machine Learning and Data Mining in Pattern Recognition, Springer-Verlag, Berlin, Heidelberg (2009), pp. 689-703
[u'Lus Sarmento', u'Alexander Kehlenbeck', u'Eugnio C. Oliveira', u'Lyle Ungar']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Automatic Adaptation of Annotation Standards: Chinese Word Segmentation and POS Tagging - A Case Study
Proceedings of ACL-IJCNLP (2009)
[u'Wenbin Jiang', u'Liang Huang', u'Qun Liu']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Baby Steps: How Less is More in Unsupervised Dependency Parsing
NIPS 2009 Workshop on Grammar Induction, Representation of Language and Language Learning
[u'Valentin I. Spitkovsky', u'Hiyan Alshawi', u'Daniel Jurafsky']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35612.html
notfound
=========================
Back-off Language Model Compression
Proceedings of Interspeech 2009, International Speech Communication Association (ISCA), pp. 325-355
[u'Boulos Harb', u'Ciprian Chelba', u'Jeffrey Dean', u'Sanjay Ghemawat']
NaturalLanguageProcessing
Abstract: With the availability of large amounts of training data relevant to speech recognition scenarios, scalability becomes a very productive way to improve language model performance. We present a technique that represents a back-off n-gram language model using arrays of integer values and thus renders it amenable to effective block compression. We propose a few such compression algorithms and evaluate the resulting language model along two dimensions: memory footprint, and speed reduction relative to the uncompressed one. We experimented with a model that uses a 32-bit word vocabulary (at most 4B words) and log-probabilities/back-off-weights quantized to 1 byte, respectively. The best compression algorithm achieves 2.6 bytes/n-gram at 18X slower than uncompressed. For faster LM operation we found it feasible to represent the LM at 4.0 bytes/n-gram, and 3X slower than the uncompressed LM. The memory footprint of a LM containing one billion n-grams can thus be reduced to 34 Gbytes without impacting its speed too much. See the presentation material from a talk about this paper.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Bilingually-Constrained (Monolingual) Shift-Reduce Parsing
Proceedings of EMNLP (2009), pp. 1222-1231
[u'Liang Huang', u'Wenbin Jiang', u'Qun Liu']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Combining Language Modeling and Discriminative Classification for Word Segmentation
CICLing '09: Proceedings of the 10th International Conference on Computational Linguistics and Intelligent Text Processing, Springer-Verlag, Berlin, Heidelberg (2009), pp. 170-182
[u'Dekang Lin']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Contrastive summarization: An experiment with consumer reviews
North American Association for Computational Linguistics (2009)
[u'Kevin Lerman', u'Ryan McDonald']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Dependency Parsing
Morgan & Claypool (2009)
[u'Sandra Kubler', u'Ryan McDonald', u'Joakim Nivre']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Distributed language models
NAACL '09: Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, Companion Volume: Tutorial Abstracts, Association for Computational Linguistics, Morristown, NJ, USA, pp. 3-4
[u'Thorsten Brants', u'Peng Xu']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Finite-State Machines for Mining Patterns in Very Large Text Repositories
Proceeding of the 2009 conference on Finite-State Methods and Natural Language Processing, IOS Press, Amsterdam, The Netherlands, The Netherlands, pp. 23-23
[u'Wojciech Skut']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Gazpacho and summer rash: lexical relationships from temporal patterns of web search queries
Proceedings of the conference on Empirical Methods in Natural Language Processing (EMNLP) (2009)
[u'Enrique Alfonseca', u'Massimiliano Ciaramita', u'Keith Hall']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Generative and Discriminative Latent Variable Grammars
The Generative and Discriminative Learning Interface Workshop at NIPS 2009
[u'Slav Petrov']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Glen, Glenda or Glendale: Unsupervised and Semi-supervised Learning of English Noun Gender
CoNLL, Boulder, CO (2009)
[u'Shane Bergsma', u'Dekang Lin', u'Randy Goebel']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Integrating sentence- and word-level error identification for disfluency correction
EMNLP '09: Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics, Morristown, NJ, USA, pp. 765-774
[u'Erin Fitzgerald', u'Frederick Jelinek', u'Keith B. Hall']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Language modelling for what-with-where on GOOG-411
Proc. International Speech Communication Association (Interspeech 2009), pp. 991-994
[u'Charl Van Heerden', u'Johan Schalkwyk', u'Brian Strope']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Large-scale Computation of Distributional Similarities for Queries
Proceedings of NAACL-HLT-2009
[u'Enrique Alfonseca', u'Keith Hall', u'Silvana Hartmann']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Large-scale Semantic Networks: Annotation and Evaluation
Proceedings of the Semantic Evaluations Workshop at NAACL-HLT (2009)
[u'Vaclav Novak', u'Sven Hartrumpf', u'Keith B. Hall']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Latent Variable Models of Concept-Attribute Attachment
Proceedings of the 47th Annual Meeting of the Association for Computational Linguistics (ACL-IJCNLP-2009), pp. 620-628
[u'Joseph Reisinger', u'Marius Pasca']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Low-Cost Supervision for Multiple-Source Attribute Extraction
Proceedings of the 10th International Conference on Computational Linguistics and Intelligent Text Processing (CICLing-2009), Mexico City, Mexico, pp. 382-393
[u'Joseph Reisinger', u'Marius Pasca']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35254.html
notfound
=========================
Named Entity Transcription with Pair n-Gram Models
2009 Named Entities Workshop: Shared Task on Transliteration (NEWS 2009), ACL-IJCNLP 2009, pp. 32-35
[u'Martin Jansche', u'Richard Sproat']
NaturalLanguageProcessing
Abstract: We submitted results for each of the eight shared tasks. Except for Japanese name kanji restoration, which uses a noisy channel model, our Standard Run submissions were produced by generative long-range pair ngram models, which we mostly augmented with publicly available data (either from LDC datasets or mined from Wikipedia) for the Non-Standard Runs.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35189.html
notfound
=========================
OpenFst: An Open-Source, Weighted Finite-State Transducer Library and its Applications to Speech and Language
Proceedings of the North American Chapter of the Association for Computational Linguistics - Human Language Technologies (NAACL HLT) 2009 conference, Tutorials
[u'Michael Riley', u'Cyril Allauzen', u'Martin Jansche']
NaturalLanguageProcessing
Abstract: Finite-state methods are well established in language and speech processing. OpenFst (available from www.openfst.org) is a free and open-source software library for building and using nite automata, in particular, weighted nite-state transducers (FSTs). This tutorial is an introduction to weighted nitestate transducers and their uses in speech and language processing. While there are other weighted nite-state transducer libraries, OpenFst (a) offers, we believe, the most comprehensive, general and efcient set of operations; (b) makes available full source code; (c) exposes high- and low-level C++ APIs that make it easy to embed and extend; and (d) is a platform for active research and use among many colleagues.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Outclassing Wikipedia in Open-Domain Information Extraction: Weakly-Supervised Acquisition of Attributes over Conceptual Hierarchies
Proceedings of the 12th Conference of the European Chapter of the Association of Computational Linguistics (EACL-2009), Athens, Greece, pp. 639-647
[u'Marius Pasca']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Phrase Clustering for Discriminative Learning
Proceedings of ACL/IJCNLP, Singapore (2009), pp. 1030-1038
[u'Dekang Lin', u'Xiaoyun Wu']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38284.html
found
=========================
Posterior vs. Parameter Sparsity in Latent Variable Models
Advances in Neural Information Processing Systems 22 (2009), pp. 664-672
[u'Joao Graca', u'Kuzman Ganchev', u'Ben Taskar', u'Fernando Pereira']
NaturalLanguageProcessing
Abstract: In this paper we explore the problem of biasing unsupervised models to favor sparsity. We extend the posterior regularization framework [8] to encourage the model to achieve posterior sparsity on the unlabeled training data. We apply this new method to learn rst-order HMMs for unsupervised part-of-speech (POS) tagging, and show that HMMs learned this way consistently and signicantly out-performs both EM-trained HMMs, and HMMs with a sparsity-inducing Dirichlet prior trained by variational EM. We evaluate these HMMs on three languages English, Bulgarian and Portuguese under four conditions. We nd that our method always improves performance with respect to both baselines, while variational Bayes actually degrades performance in most cases. We increase accuracy with respect to EM by 2.5%-8.7% absolute and we see improvements even in a semisupervised condition where a limited dictionary is provided.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Randomized Pruning: Efficiently Calculating Expectations in Large Dynamic Programs
Advances in Neural Information Processing Systems 22 (NIPS '09) (2009)
[u'Alexandre Bouchard-Ct', u'Slav Petrov', u'Dan Klein']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Reconstructing false start errors in spontaneous speech text
Proceedings of the European Chapter of the Association for Computational Linguistics (2009)
[u'Erin Fitzgerald', u'Keith B. Hall', u'Frederick Jelinek']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Semantic Vector Combinations and the Synoptic Gospels
Third International Symposium on Quantum Interaction (2009)
[u'Dominic Widdows', u'Trevor Cohen']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Semi-Supervised Polarity Lexicon Induction
EACL - 2009
[u'Delip Rao', u'Deepak Ravichandran']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Sentiment Summarization: Evaluating and Learning User Preferences
European Association for Computational Linguistics (2009)
[u'Kevin Lerman', u'Sasha Blair-Goldensohn', u'Ryan McDonald']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
The CoNLL-2009 Shared Task: Syntactic and Semantic Dependencies in Multiple Languages
Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL 2009): Shared Task, Association for Computational Linguistics, 209 N. Eight Street, Stroudsburg, PA 18360, pp. 1-18
[u'Jan Haji', u'Massimiliano Ciaramita', u'Richard Johansson', u'Daisuke Kawahara', u'Maria Antnia Mart', u'Llus Mrquez', u'Adam Meyers', u'Joakim Nivre', u'Sebastian Pad', u'Jan tepnek', u'Pavel Strak', u'Mihai Surdeanu', u'Nianwen Xue', u'Yi Zhang']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Using a dependency parser to improve SMT for subject-object-verb languages
NAACL '09: Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, Association for Computational Linguistics, Morristown, NJ, USA, pp. 245-253
[u'Peng Xu', u'Jaeho Kang', u'Michael Ringgaard', u'Franz Och']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Using the web for language independent spellchecking and autocorrection
EMNLP '09: Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics, Morristown, NJ, USA, pp. 890-899
[u'Casey Whitelaw', u'Ben Hutchinson', u'Grace Y. Chung', u'Gerard Ellis']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Web-Derived Resources for Web Information Retrieval: From Conceptual Hierarchies to Attribute Hierarchies
Proceedings of the 32nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR-09), Boston, Massachusetts (2009), pp. 596-603
[u'Marius Pasca', u'Enrique Alfonseca']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Web-Scale N-gram Models for Lexical Disambiguation
Proceedings of IJCAI, Los Angeles, CA (2009), pp. 1507-1512
[u'Shane Bergsma', u'Dekang Lin', u'Randy Goebel']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Joint Model of Text and Aspect Ratings for Sentiment Summarization
Association for Computational Linguistics (2008)
[u'Ivan Titov', u'Ryan McDonald']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Answering Definition Questions via Temporally-Anchored Text Snippets
Proceedings of the 3rd International Joint Conference on Natural Language Processing (IJCNLP-2008), Hyderabad, India, pp. 411-417
[u'Marius Pasca']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Building a Sentiment Summarizer for Local Service Reviews
WWW Workshop on NLP Challenges in the Information Explosion Era (NLPIX) (2008)
[u'Sasha Blair-Goldensohn', u'Kerry Hannan', u'Ryan McDonald', u'Tyler Neylon', u'George Reis', u'Jeff Reynar']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Decompounding query keywords from compounding languages
Proceedings of ACL-2008
[u'Enrique Alfonseca', u'Slaven Bilac', u'Stefan Pharies']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Discriminative learning of selectional preference from unlabeled text
EMNLP '08: Proceedings of the Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics, Morristown, NJ, USA (2008), pp. 59-68
[u'Shane Bergsma', u'Dekang Lin', u'Randy Goebel']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Distributional Identification of Non-Referential Pronouns
Proceedings of ACL-08: HLT, Association for Computational Linguistics, Columbus, Ohio (2008), pp. 10-18
[u'Shane Bergsma', u'Dekang Lin', u'Randy Goebel']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Finding Cars, Goddesses and Enzymes: Parametrizable Acquisition of Labeled Instances for Open-Domain Information Extraction
Proceedings of the 23rd Annual Conference on Artificial Intelligence (AAAI-2008), pp. 1243-1248
[u'Benjamin Van Durme', u'Marius Pasca']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
German decompounding in a difficult corpus
Proceedings of CICLING-2008, Lecture Notes in Computer Science, Springer, pp. 128-139
[u'Enrique Alfonseca', u'Slaven Bilac', u'Stefan Pharies']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Integrating Graph-based and Transition-based Dependency Parsers
Association for Computational Linguistics (2008)
[u'Joakim Nivre', u'Ryan McDonald']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Large Scale Acquisition of Paraphrases for Learning Surface Patterns
ACL-2008
[u'Rahul Bhagat', u'Deepak Ravichandran']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Randomized Language Models via Perfect Hash Functions
Proceedings of ACL-08: HLT, Association for Computational Linguistics, Columbus, Ohio (2008), pp. 505-513
[u'David Talbot', u'Thorsten Brants']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34666.html
notfound
=========================
Reading the Markets: Forecasting Public Opinion of Political Candidates by News Analysis
Conference on Computational Linguistics (Coling) (2008)
[u'Kevin Lerman', u'Ari Gilder', u'Mark Dredze', u'Fernando Pereira']
NaturalLanguageProcessing
Abstract: Media reporting shapes public opinion which can in turn influence events, particularly in political elections, in which candidates both respond to and shape public perception of their campaigns. We use computational linguistics to automatically predict the impact of news on public perception of political candidates. Our system uses daily newspaper articles to predict shifts in public opinion as reflected in prediction markets. We discuss various types of features designed for this problem. The news system improves market prediction over baseline market systems.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub33477.html
notfound
=========================
Semantic Vector Products: Some Initial Investigations
Proceedings of the Second AAAI Symposium on Quantum Interaction, AAAI (2008)
[u'Dominic Widdows']
NaturalLanguageProcessing
Abstract: Semantic vector models have proven their worth in a number of natural language applications whose goals can be accomplished by modelling individual semantic concepts and measuring similarities between them. By comparison, the area of semantic compositionality in these models has so far remained underdeveloped. This will be a crucial hurdle for semantic vector models: in order to play a fuller part in the modelling of human language, these models will need some way of modelling the way in which single concepts are put together to form more complex conceptual structures. This paper explores some of the opportunities for using vector product operations to model compositional phenomena in natural language. These vector operations are all well-known and used in mathematics and physics, particularly in quantum mechanics. Instead of designing new vector composition operators, this paper gathers a list of existing operators, and a list of typical composition operations in natural language, and describes two small experiments that begin to investigate the use of certain vector operators to model certain language phenomena. Though preliminary, our results are encouraging. It is our hope that these results, and the gathering of other untested semantic and vector compositional challenges into a single paper, will stimulate further research in this area.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Towards Temporal Web Search
Proceedings of the 23rd ACM Symposium on Applied Computing (SAC-2008), Fortaleza, Brazil, pp. 1117-1121
[u'Marius Pasca']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34382.html
found
=========================
Translating Queries into Snippets for Improved Query Expansion
Proceedings of the 22nd International Conference on Computational Linguistics (COLING'08), Manchester, England (2008)
[u'Stefan Riezler', u'Yi Liu', u'Alexander Vasserman']
NaturalLanguageProcessing
Abstract: User logs of search engines have recently been applied successfully to improve various aspects of web search quality. In this paper, we will apply pairs of user queries and snippets of clicked results to train a machine translation model to bridge the ``lexical gap'' between query and document space. We show that the combination of a query-to-snippet translation model with a large n-gram language model trained on queries achieves improved contextual query expansion compared to a system based on term correlations.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Turning Web Text and Search Queries into Factual Knowledge: Hierarchical Class Attribute Extraction
Proceedings of the 23rd Annual Conference on Artificial Intelligence (AAAI-2008), pp. 1225-1230
[u'Marius Pasca']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Using Structured Text for Large-Scale Attribute Extraction
Proceedings of the 17th ACM Conference on Information and Knowledge Management (CIKM-2008), pp. 1183-1192
[u'Sujith Ravi', u'Marius Pasca']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Weakly-Supervised Acquisition of Labeled Class Instances using Graph Random Walks
Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP-08), Association for Computational Linguistics, Honolulu, Hawaii (2008), pp. 582-590
[u'Partha Pratim Talukdar', u'Joseph Reisinger', u'Marius Pasca', u'Deepak Ravichandran', u'Rahul Bhagat', u'Fernando Pereira']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Weakly-Supervised Acquisition of Open-Domain Classes and Class Attributes from Web Documents and Query Logs
Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL-2008), pp. 19-27
[u'Marius Pasca', u'Benjamin Van Durme']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Web-scale named entity recognition
CIKM '08: Proceeding of the 17th ACM conference on Information and knowledge management, ACM, New York, NY, USA (2008), pp. 123-132
[u'Casey Whitelaw', u'Alex Kehlenbeck', u'Nemanja Petrovic', u'Lyle Ungar']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Wide-Coverage Deep Statistical Parsing using Automatic Dependency Structure Annotation
Computational Linguistics, vol. 34 (1) (2008), pp. 81-124
[u'Aoife Cahill', u"Ruth O'Donovan", u'Josef van Genabith', u'Michael Burke', u'Stefan Riezler', u'Andy Way']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Study of Global Inference Algorithms in Multi-Document Summarization
European Conference on Information Retrieval (ECIR) (2007)
[u'Ryan McDonald']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Characterizing the Errors of Data-Driven Dependency Parsers
Empirical Methods in Natural Language Processing (2007)
[u'Ryan McDonald', u'Joakim Nivre']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Frustratingly Hard Domain Adaptation for Dependency Parsing
Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL 2007, pp. 1051-1055
[u'Mark Dredze', u'John Blitzer', u'Partha Pratim Talukdar', u'Kuzman Ganchev', u'Jo~{a}o V. Gra&ccedil;a', u'Fernando Pereira']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub32805.html
notfound
=========================
How difficult is it to develop a perfect spell-checker? A cross-linguistic analysis through complex network approach
Textgraphs 2 Workshop, at HLT/NAACL, ACL (2007), pp. 8
[u'Monojit Choudhury', u'Markose Thomas', u'Animesh Mukherjee', u'Niloy Ganguly', u'Anupam Basu']
NaturalLanguageProcessing
Abstract: The difficulties involved in spelling error detection and correction in a language have been investigated in this work through the conceptualization of SpellNet - a weighted network of words, where edges indicate orthographic proximity between two words. We construct SpellNets for three languages - Bengali, English and Hindi. Through appropriate mathematical analysis and/or intuitive justification, we interpret the different topological metrics of SpellNet from the perspective of the issues related to spell-checking. We make many interesting observations, the most significant being that the probability of making a read word error in a language is proportionate to the average weighted degree of SpellNet, which is found to be highest for Hindi, followed by Bengali and English.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Inference in Text Understanding
AAAI Spring Symposium on Machine Reading (2007)
[u'Peter Norvig']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Lightweight Web-Based Fact Repositories for Textual Question Answering
Proceedings of the 16th ACM Conference on Information and Knowledge Management (CIKM-2007), Lisboa, Portugal, pp. 87-96
[u'Marius Pasca']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub33035.html
notfound
=========================
N-Gram Statistical Similarities and Differences between Chinese and English
First IEEE International Conference on Semantic Computing, IEEE (2007)
[u'Pei Cao', u'Stewart Yang', u'Hongjun Zhu']
NaturalLanguageProcessing
Abstract: Chinese and English belong to two very different families of human languages. Yet, since the underlying human concepts are universal, one can expect that there are many statistics similarities between Chinese texts and English texts. In this paper, we present results of analyzing quantity and frequency of N-grams in 100 million randomly-sampled English web pages and 100 million randomly-sampled Chinese web papges. We found that 1-gram and 2-gram frequency distributions are very different between Chinese and English; this is understandable since one character in Chinese does not consistitute a word in English. However, we found that 3-gram and 4-grams frequency distributions are surprisingly similar between Chinese and English, leading us to conjecture that in both languages, frequent 3-grams and 4-grams represent a set of concepts that are similar. The distribution of unique numbers of n-grams is quite different between English and Chinese. However, the distribution appears to indicate that, on average, 1.5 Chinese characters corresponds to 1 English word.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
On the Complexity of Non-Projective Data-Driven Dependency Parsing
International Conference on Parsing Technologies (2007), pp. 121-132
[u'Ryan McDonald', u'Giorgio Satta']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Organizing and Searching the World Wide Web of Facts - Step Two: Harnessing the Wisdom of the Crowds
Proceedings of the 16th International World Wide Web Conference (WWW-07) (2007), pp. 101-110
[u'Marius Pasca']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Reconocimiento de Entidades, Resolucin de Correferencia y Extraccin de Relaciones
F. Verdejo (ed.), Acceso y viabilidad de la informacin multilinge en la red: el rol de la semntica, Fundacin Duques de Soria (2007)
[u'Enrique Alfonseca']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Simple training of dependency parsers via structured boosting
IJCAI'07: Proceedings of the 20th international joint conference on Artifical intelligence, Morgan Kaufmann Publishers Inc., San Francisco, CA, USA (2007), pp. 1756-1762
[u'Qin Iris Wang', u'Dekang Lin', u'Dale Schuurmans']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub32707.html
found
=========================
Statistical Machine Translation for Query Expansion in Answer Retrieval
Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics (ACL'07), Prague, Czech Republic (2007)
[u'Stefan Riezler', u'Alexander Vasserman', u'Ioannis Tsochantaridis', u'Vibhu Mittal', u'Yi Liu']
NaturalLanguageProcessing
Abstract: This paper presents a novel approach to query expansion in answer retrieval that uses Statistical Machine Translation (SMT) techniques to bridge the lexical gap between questions and answers. SMT-based query expansion is performed on the one hand by using a SMT-based full-sentence paraphraser to introduce synonyms in the context the full query, and on the other hand by training an SMT model on question-answer pairs and expanding queries by answer terms taken from translations of full queries. We compare these global, context-aware query expansion techniques with a baseline tfidf model and local query expansion on a database of 10 million question-answer pairs extracted from FAQ pages. Experimental results show a significant improvement of SMT-based query expansion over both baselines.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Structured Models for Fine-to-Coarse Sentiment Analysis
45th Annual Meeting of the Association for Computational Linguistics (ACL 2007)
[u'Ryan McDonald', u'Kerry Hannan', u'Tyler Neylon', u'Mike Wells', u'Jeff Reynar']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
The Role of Documents vs. Queries in Extracting Class Attributes from Text
Proceedings of the 16th ACM Conference on Information and Knowledge Management (CIKM-2007), Lisboa, Portugal, pp. 485-494
[u'Marius Pasca', u'Benjamin Van Durme', u'Nikesh Garera']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Weakly-Supervised Discovery of Named Entities Using Web Search Queries
Proceedings of the 16th ACM Conference on Information and Knowledge Management (CIKM-2007), Lisboa, Portugal, pp. 683-690
[u'Marius Pasca']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
What You Seek is What You Get: Extraction of Class Attributes from Query Logs
Proceedings of the 20th International Joint Conference on Artificial Intelligence (IJCAI-07) (2007), pp. 2832-2837
[u'Marius Pasca', u'Benjamin Van Durme']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Context Pattern Induction Method for Named Entity Extraction
Proceedings of CoNLL-X (2006), pp. 141-148
[u'Partha Pratim Talukdar', u'Thorsten Brants', u'Mark Liberman', u'Fernando Pereira']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Bootstrapping Path-Based Pronoun Resolution
Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics, Sydney, Australia (2006), pp. 33-40
[u'Shane Bergsma', u'Dekang Lin']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Comparative Experiments on Sentiment Classification for Online Product Reviews
Proceedings of the 21st National Conference on Artificial Intelligence, AAAI, Boston, MA (2006)
[u'Hang Cui', u'Vibhu Mittal', u'Mayur Datar']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Integrating probabilistic extraction models and data mining to discover relations and patterns in text
HLT-NAACL, New York, NY (2006), pp. 296-303
[u'Aron Culotta', u'Andrew McCallum', u'Jonathan Betz']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Names and Similarities on the Web: Fact Extraction in the Fast Lane
Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics (COLING-ACL-06), Sydney, Australia (2006), pp. 809-816
[u'Marius Pasca', u'Dekang Lin', u'Jeffrey Bigham', u'Andrei Lifchits', u'Alpa Jain']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Organizing and Searching the World Wide Web of Facts - Step One: the One-Million Fact Extraction Challenge
Proceedings of the 21st National Conference on Artificial Intelligence (AAAI-06), Boston, Massachusetts (2006), pp. 1400-1405
[u'Marius Pasca', u'Dekang Lin', u'Jeffrey Bigham', u'Andrei Lifchits', u'Alpa Jain']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Probabilistic Context-Free Grammar Induction Based on Structural Zeros
Proceedings of the Seventh Meeting of the Human Language Technology conference - North American Chapter of the Association for Computational Linguistics (HLT-NAACL 2006), New York, NY
[u'Mehryar Mohri', u'Brian Roark']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Soft Syntactic Constraints for Word Alignment through Discriminative Training
Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, Association for Computational Linguistics, Sydney, Australia, pp. 105-112
[u'Colin Cherry', u'Dekang Lin']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Using Encyclopedic Knowledge for Named Entity Disambiguation
Proceedings of the 11th Conference of the European Chapter of the Association of Computational Linguistics (EACL-2006), Trento, Italy, pp. 9-16
[u'Razvan Bunescu', u'Marius Pasca']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
On a Common Fallacy in Computational Linguistics
A Man of Measure: Festschrift in Honour of Fred Karlsson on this 60th Birthday, SKY Journal of Linguistics, Volume 19 (2006), pp. 432-439
[u'Mehryar Mohri', u'Richard Sproat']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Aligning Needles in a Haystack: Paraphrase Acquisition Across the Web
Proceedings of the 2nd International Joint Conference on Natural Language Processing (IJCNLP-2005), Jeju Island, Republic of Korea, pp. 119-130
[u'Marius Pasca', u'Peter Dienes']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Finding Instance Names and Alternative Glosses on the Web: WordNet Reloaded
Proceedings of the 6th International Conference on Computational Linguistics and Intelligent Text Processing (CICLing-2005), Mexico City, Mexico, pp. 280-292
[u'Marius Pasca']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Local Grammar Algorithms
Inquiries into Words, Constraints, and Contexts. Festschrift in Honour of Kimmo Koskenniemi on his 60th Birthday, CSLI Publications, Stanford University (2005), pp. 84-93
[u'Mehryar Mohri']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Mining Paraphrases from Self-Anchored Web Sentence Fragments
Proceedings of the 9th European Conference on Principles and Practice of Knowledge Discovery in Databases (PKDD-2005), Porto, Portugal, pp. 193-204
[u'Marius Pasca']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Strictly lexical dependency parsing
Parsing '05: Proceedings of the Ninth International Workshop on Parsing Technology, Association for Computational Linguistics, Morristown, NJ, USA (2005), pp. 152-159
[u'Qin Iris Wang', u'Dale Schuurmans', u'Dekang Lin']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Statistical Natural Language Processing
Applied Combinatorics on Words, Cambridge University Press (2005)
[u'Mehryar Mohri']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
The Design Principles and Algorithms of a Weighted Grammar Library
International Journal of Foundations of Computer Science, vol. 16 (2005)
[u'Cyril Allauzen', u'Mehryar Mohri', u'Brian Roark']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Acquisition of Categorized Named Entities for Web Search
Proceedings of the 13th ACM Conference on Information and Knowledge Management (CIKM-04), Washington, D.C. (2004), pp. 137-145
[u'Marius Pasca']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Searching the Web by Voice
Proceedings of the 19th International Conference on Computational Linguistics (COLING) (2002), pp. 1213-1217
[u'Alexander Franz', u'Brian Milch']
NaturalLanguageProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/Networking.html
found
http://research.google.com/pubs/pub43929.html
notfound
=========================
Temporospatial SDN for Aerospace Communications
AIAA SPACE 2015 Conference and Exposition, American Institute of Aeronautics and Astronautics (2016) (to appear)
[u'Brian Barritt', u'Wesley Eddy']
Networking
Abstract: This paper describes the development of new methods and software leveraging Software Defined Networking (SDN) technology that has become common in terrestrial networking. We are using SDN to improve the state-of-the-art in design and operation of aerospace communication networks. SDN enables the implementation of services and applications that control, monitor, and reconfigure the network layer and switching functionality. SDN provides a software abstraction layer that yields a logically centralized view of the network for control plane services and applications. Recently, new requirements have led to proposals to extend this concept for Software-Defined Wireless Networks (SDWN), which decouple radio control functions, such as spectrum management, mobility management, and interference management, from the radio data-plane. By combining these concepts with high-fidelity modeling of predicted mobility patterns and wireless communications models, we can enable SDN applications that optimally and autonomously handle aerospace network operations, including steerable beam control, RF interference mitigation, and network routing updates. This approach is specifically applicable to new constellation designs for LEO relay networks that include hundreds or thousands of spacecraft, serving millions of users, and exceed the ability of legacy network management tools.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43838.html
notfound
=========================
BwE: Flexible, Hierarchical Bandwidth Allocation for WAN Distributed Computing
Sigcomm '15, Google Inc (2015)
[u'Alok Kumar', u'Sushant Jain', u'Uday Naik', u'Nikhil Kasinadhuni', u'Enrique Cauich Zermeno', u'C. Stephen Gunn', u'Jing Ai', u'Bjrn Carlin', u'Mihai Amarandei-Stavila', u'Mathieu Robin', u'Aspi Siganporia', u'Stephen Stuart', u'Amin Vahdat']
Networking
Abstract: WAN bandwidth remains a constrained resource that is economically infeasible to substantially overprovision. Hence, it is important to allocate capacity according to service priority and based on the incremental value of additional allocation. For example, it may be the highest priority for one service to receive 10Gb/s of bandwidth but upon reaching such an allocation, incremental priority may drop sharply favoring allocation to other services. Motivated by the observation that individual flows with fixed priority may not be the ideal basis for bandwidth allocation, we present the design and implementation of Bandwidth Enforcer (BwE), a global, hierarchical bandwidth allocation infrastructure. BwE supports: i) service-level bandwidth allocation following prioritized bandwidth functions where a service can represent an arbitrary collection of flows, ii) independent allocation and delegation policies according to user-defined hierarchy, all accounting for a global view of bandwidth and failure conditions, iii) multi-path forwarding common in traffic-engineered networks, and iv) a central administrative point to override (perhaps faulty) policy during exceptional conditions. BwE has delivered more service-efficient bandwidth utilization and simpler management in production for multiple years.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43311.html
found
=========================
CQIC: Revisiting Cross-Layer Congestion Control f or Cellular Networks
Proceedings of The 16th International Workshop on Mobile Computing Systems and Applications (HotMobile), ACM (2015), pp. 45-50
[u'Feng Lu', u'Hao Du', u'Ankur Jain', u'Geoffrey M. Voelker', u'Alex C. Snoeren', u'Andreas Terzis']
Networking
Abstract: With the advent of high-speed cellular access and the overwhelming popularity of smartphones, a large percent of todays Internet content is being delivered via cellular links. Due to the nature of long-range wireless signal propagation, the capacity of the last hop cellular link can vary by orders of magnitude within a short period of time (e.g., a few seconds). Unfortunately, TCP does not perform well in such fast-changing environments, potentially leading to poor spectrum utilization and high end-to-end packet delay. In this paper we revisit seminal work in cross-layer optimization the context of 4G cellular networks. Specifically, we leverage the rich physical layer information exchanged between base stations (NodeB) and mobile phones (UE) to predict the capacity of the underlying cellular link, and propose CQIC, a cross-layer congestion control design. Experiments on real cellular networks confirm that our capacity estimation method is both accurate and precise. A CQIC sender uses these capacity estimates to adjust its packet sending behavior. Our preliminary evaluation reveals that CQIC improves throughput over TCP by 1.082.89 for small and medium flows. For large flows, CQIC attains throughput comparable to TCP while reducing the average RTT by 2.382.65x.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43839.html
notfound
=========================
Condor: Better Topologies through Declarative Design
Sigcomm '15, Google Inc (2015)
[u'Brandon Schlinker', u'Radhika Niranjan Mysore', u'Sean Smith', u'Jeffrey C. Mogul', u'Amin Vahdat', u'Minlan Yu', u'Ethan Katz-Bassett', u'Michael Rubin']
Networking
Abstract: The design space for large, multipath datacenter networks is large and complex, and no one design fits all purposes. Network architects must trade off many criteria to design cost-effective, reliable, and maintainable networks, and typically cannot explore much of the design space. We present Condor, our approach to enabling a rapid, efficient design cycle. Condor allows architects to express their requirements as constraints via a Topology Description Language (TDL), rather than having to directly specify network structures. Condor then uses constraint-based synthesis to rapidly generate candidate topologies, which can be analyzed against multiple criteria. We show that TDL supports concise descriptions of topologies such as fat-trees, BCube, and DCell; that we can generate known and novel variants of fat-trees with simple changes to a TDL file; and that we can synthesize large topologies in tens of seconds. We also show that Condor supports the daunting task of designing multi-phase network expansions that can be carried out on live networks.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44273.html
found
=========================
Efficient Traffic Splitting on Commodity Switches
Proceedings of the 11th ACM International on Conference on emerging Networking Experiments and Technologies (CoNEXT), ACM (2015) (to appear)
[u'Nanxi Kang', u'Monia Ghobadi', u'John Reumann', u'Alexander Shraer', u'Jennifer Rexford']
Networking
Abstract: Traffic often needs to be split over multiple equivalent backend servers, links, paths, or middleboxes. For example, in a load-balancing system, switches distribute requests of online services to backend servers. Hash-based approaches like Equal-Cost Multi-Path (ECMP) have low accuracy due to hash collision and incur significant churn during update. In a Software-Defined Network (SDN) the accuracy of traffic splits can be improved by crafting a set of wildcard rules for switches that better match the actual traffic distribution. The drawback of existing SDN-based traffic-splitting solutions is poor scalability as they generate too many rules for small rule-tables on switches. In this paper, we propose Niagara, an SDN-based traffic-splitting scheme that achieves accurate traffic splits while being extremely efficient in the use of rule-table space available on commodity switches. Niagara uses an incremental update strategy to minimize the traffic churn given an update. Experiments demonstrate that Niagara (1) achieves nearly optimal accuracy using only 1.2%37% of the rule space of the current state-of-art, (2) scales to tens of thousands of services with the constrained rule-table capacity and (3) offers nearly minimum churn.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43458.html
notfound
=========================
Flywheel: Googles Data Compression Proxy for the Mobile Web
Proceedings of the 12th USENIX Symposium on Networked Systems Design and Implementation, NSDI 2015, USENIX, 2560 Ninth Street, Suite 215, Berkeley, CA, 94710 USA
[u'Victor Agababov', u'Michael Buettner', u'Victor Chudnovsky']
Networking
Abstract: Mobile devices are increasingly the dominant Internet access technology. Nevertheless, high costs, data caps, and throttling are a source of widespread frustration, and a significant barrier to adoption in emerging markets. This paper presents Flywheel, an HTTP proxy service that extends the life of mobile data plans by compressing responses in-flight between origin servers and client browsers. Flywheel is integrated with the Chrome web browser and reduces the size of proxied web pages by 50% for a median user. We report measurement results from millions of users as well as experience gained during three years of operating and evolving the production service at Google.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43867.html
notfound
=========================
Inferring the Network Latency Requirements of Cloud Tenants
15th Workshop on Hot Topics in Operating Systems (HotOS XV), USENIX Association (2015)
[u'Jeffrey C Mogul', u'Ramana Rao Kompella']
Networking
Abstract: Cloud IaaS and PaaS tenants rely on cloud providers to provide network infrastructures that make the appropriate tradeoff between cost and performance. This can include mechanisms to help customers understand the performance requirements of their applications. Previous research (e.g., Proteus and Cicada) has shown how to do this for network-bandwidth demands, but cloud tenants may also need to meet latency objectives, which in turn may depend on reliable limits on network latency, and its variance, within the cloud providers infrastructure. On the other hand, if network latency is sufficient for an application, further decreases in latency might add cost without any benefit. Therefore, both tenant and provider have an interest in knowing what network latency is good enough for a given application. This paper explores several options for a cloud provider to infer a tenants network-latency demands, with varying tradeoffs between requirements for tenant participation, accuracy of inference, and instrumentation overhead. In particular, we explore the feasibility of a hypervisor-only mechanism, which would work without any modifications to tenant code, even in IaaS clouds.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43837.html
notfound
=========================
Jupiter Rising: A Decade of Clos Topologies and Centralized Control in Googles Datacenter Network
Sigcomm '15, Google Inc (2015)
[u'Arjun Singh', u'Joon Ong', u'Amit Agarwal', u'Glen Anderson', u'Ashby Armistead', u'Roy Bannon', u'Seb Boving', u'Gaurav Desai', u'Bob Felderman', u'Paulie Germano', u'Anand Kanagala', u'Jeff Provost', u'Jason Simmons', u'Eiichi Tanda', u'Jim Wanderer', u'Urs Hlzle', u'Stephen Stuart', u'Amin Vahdat']
Networking
Abstract: We present our approach for overcoming the cost, operational complexity, and limited scale endemic to datacenter networks a decade ago. Three themes unify the five generations of datacenter networks detailed in this paper. First, multi-stage Clos topologies built from commodity switch silicon can support cost-effective deployment of building-scale networks. Second, much of the general, but complex, decentralized network routing and management protocols supporting arbitrary deployment scenarios were overkill for single-operator, pre-planned datacenter networks. We built a centralized control mechanism based on a global configuration pushed to all datacenter switches. Third, modular hardware design coupled with simple, robust software allowed our design to also support inter-cluster and wide-area networks. Our datacenter networks run at dozens of sites across the planet, scaling in capacity by 100x over ten years to more than 1Pbps of bisection bandwidth.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43822.html
found
=========================
RFC7535 - AS112 Redirection Using DNAME
IETF RFCs, Internet Engineering Task Force (2015), pp. 16
[u'Warren Kumari', u'Joe Abley', u'Brian Dickson', u'George Michaelson']
Networking
Abstract: AS112 provides a mechanism for handling reverse lookups on IP addresses that are not unique (e.g., RFC 1918 addresses). This document describes modifications to the deployment and use of AS112 infrastructure that will allow zones to be added and dropped much more easily, using DNAME resource records. This approach makes it possible for any DNS zone administrator to sink traffic relating to parts of the global DNS namespace under their control to the AS112 infrastructure without coordination with the operators of AS112 infrastructure.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43954.html
notfound
=========================
RFC7607 - Codification of AS 0 Processing
IETF RFCs, Internet Engineering Task Force (2015), pp. 5
[u'Warren Kumari', u'Randy Bush', u'Heather Schiller', u'Keyur Patel']
Networking
Abstract: This document updates RFC 4271 and proscribes the use of Autonomous System (AS) 0 in the Border Gateway Protocol (BGP) OPEN, AS_PATH, AS4_PATH, AGGREGATOR, and AS4_AGGREGATOR attributes in the BGP UPDATE message.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43840.html
notfound
=========================
TIMELY: RTT-based Congestion Control for the Datacenter
Sigcomm '15, Google Inc (2015)
[u'Radhika Mittal', u'Terry Lam', u'Nandita Dukkipati', u'Emily Blem', u'Hassan Wassel', u'Monia Ghobadi', u'Amin Vahdat', u'Yaogong Wang', u'David Wetherall', u'David Zats']
Networking
Abstract: Datacenter transports aim to deliver low latency messaging together with high throughput. We show that simple packet delay, measured as round-trip times at hosts, is an effective congestion signal without the need for switch feedback. First, we show that advances in NIC hardware have made RTT measurement possible with microsecond accuracy, and that these RTTs are sufficient to estimate switch queueing. Then we describe how TIMELY can adjust transmission rates using RTT gradients to keep packet latency low while delivering high bandwidth. We implement our design in host software running over NICs with OS-bypass capabilities. We show using experiments with up to hundreds of machines on a Clos network topology that it provides excellent performance: turning on TIMELY for OS-bypass messaging over a fabric with PFC lowers 99 percentile tail latency by 9X while maintaining near line-rate throughput. Our system also outperforms DCTCP running in an optimized kernel, reducing tail latency by 13X. To the best of our knowledge, TIMELY is the first delay-based congestion control protocol for use in the datacenter, and it achieves its results despite having an order of magnitude fewer RTT signals (due to NIC offload) than earlier delay-based schemes such as Vegas.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43831.html
found
=========================
Advanced DSP for 400 Gb/s and Beyond Optical Networks
J. Lightwave Technology, vol. 32 (2014), pp. 2716-2725
[u'Xiang Zou', u'Lynn Nelson']
Networking
Abstract: This paper presents a systematic review of several digital signal processing (DSP)-enabled technologies recently proposed and demonstrated for high spectral efficiency (SE) 400 Gb/sclass and beyond optical networks. These include 1) a newly proposed SE-adaptable optical modulation technologytime-domain hybrid quadrature amplitude modulation (QAM), 2) two advanced transmitter side digital spectral shaping technologiesNyquist signaling (for spectrally-efficient multiplexing) and digital preequalization (for improving tolerance toward channel narrowing effects), and 3) a newly proposed training-assisted two-stage carrier phase recovery algorithm that is designed to address the detrimental cyclic phase slipping problem with minimal training overhead. Additionally, this paper presents a novel DSP-based method for mitigation of equalizer-enhanced phase noise impairments. It is shown that performance degradation caused by the interaction between the long-memory chromatic dispersion compensating filter/equalizer and local oscillator laser phase noise can be effectively mitigated by replacing the commonly used fast single-tap phaserotation-based equalizer (for typical carrier phase recovery) with a fast multi-tap linear equalizer. Finally, brief reviews of two high-SE 400 Gb/s-class WDM transmission experiments employing these advanced DSP algorithms are presented.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44204.html
found
=========================
Advanced DSP for 400Gb/s and beyond Optical Networks
JOURNAL OF LIGHTWAVE TECHNOLOGY, vol. Vol. 32 (2014), pp. 2716-2725
[u'Xiang Zhou', u'Lynn Nelson']
Networking
Abstract: This paper presents a systematic review of several digital signal processing (DSP)-enabled technologies recently proposed and demonstrated for high spectral efficiency (SE) 400Gb/s class and beyond optical networks. These include 1) a newly proposed SE-adaptable optical modulation technology time-domain hybrid quadrature amplitude modulation (QAM), 2) two advanced transmitter side digital spectral shaping technologies Nyquist signaling (for spectrally-efficient multiplexing) and digital pre-equalization (for improving tolerance toward channel narrowing effects), and 3) a newly proposed training-assisted two-stage carrier phase recovery algorithm that is designed to address the detrimental cyclic phase slipping problem with minimal training overhead. Additionally, this paper presents a novel DSP-based method for mitigation of equalizer-enhanced phase noise impairments. It is shown that performance degradation caused by the interaction between the long-memory chromatic dispersion (CD) compensating filter/equalizer and local oscillator (LO) laser phase noise can be effectively mitigated by replacing the commonly used fast single-tap phase-rotation-based equalizer (for typical carrier phase recovery) with a fast multi-tap linear equalizer. Finally, brief reviews of two high-SE 400Gb/s-class WDM transmission experiments employing these advanced DSP algorithms are presented.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
An Adaptable Rule Placement for Software Defined Networks
DSN, IEEE (2014)
[u'Shuyuan Zhang', u'Franjo Ivancic', u'Cristian Lumezanu', u'Yifei Yuan', u'Aarti Gupta', u'Sharad Malik']
Networking
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42462.html
found
=========================
Cicada: Predictive Guarantees for Cloud Network Bandwidth
MIT (2014), MIT-CSAIL-TR-2014-004
[u'Katrina LaCurts', u'Jeffrey C Mogul', u'Hari Balakrishnan', u'Yoshio Turner']
Networking
Abstract: In cloud-computing systems, network-bandwidth guarantees have been shown to improve predictability of application performance and cost. Most previous work on cloud-bandwidth guarantees has assumed that cloud tenants know what bandwidth guarantees they want. However, application bandwidth demands can be complex and time-varying, and many tenants might lack sufficient information to request a bandwidth guarantee that is well-matched to their needs. A tenant's lack of accurate knowledge about its future bandwidth demands can lead to over-provisioning (and thus reduced cost-efficiency) or under-provisioning (and thus poor user experience in latency-sensitive user-facing applications). We analyze traffic traces gathered over six months from an HP Cloud Services datacenter, finding that application bandwidth consumption is both time-varying and spatially inhomogeneous. This variability makes it hard to predict requirements. To solve this problem, we develop a prediction algorithm usable by a cloud provider to suggest an appropriate bandwidth guarantee to a tenant. The key idea in the prediction algorithm is to treat a set of previously observed traffic matrices as "experts" and learn online the best weighted linear combination of these experts to make its prediction. With tenant VM placement using these predictive guarantees, we find that the inter-rack network utilization in certain datacenter topologies can be more than doubled.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43860.html
notfound
=========================
Cutting the Cord: a Robust Wireless Facilities Network for Data Centers
Proceedings of the ACM Conference on Mobile Computing and Networking (Mobicom) (2014)
[u'Yibo Zhu', u'Xia Zhou', u'Zengbin Zhang', u'Lin Zhou', u'Amin Vahdat', u'Ben Y. Zhao', u'Haitao Zheng']
Networking
Abstract: Todays network control and management traffic are limited by their reliance on existing data networks. Fate sharing in this context is highly undesirable, since control traffic has very different availability and traffic delivery requirements. In this paper, we explore the feasibility of building a dedicated wireless facilities network for data centers. We propose Angora, a low-latency facilities network using low-cost, 60GHz beamforming radios that provides robust paths decoupled from the wired network, and flexibility to adapt to workloads and network dynamics. We describe our solutions to address challenges in link coordination, link interference and network failures. Our testbed measurements and simulation results show that Angora enables large number of low-latency control paths to run concurrently, while providing low latency end-to-end message delivery with high tolerance for radio and rack failures.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
DREAM: Dynamic Resource Allocation for Software-defined Measurement
Proceedings of the ACM SIGCOMM Conference (2014)
[u'Masoud Moshref', u'Minlan Yu', u'Ramesh Govindan', u'Amin Vahdat']
Networking
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43871.html
notfound
=========================
Flexible Network Bandwidth and Latency Provisioning in the Datacenter
arxiv.org (2014)
[u'Vimalkumar Jeyakumar', u'Abdul Kabbani', u'Jeffrey C. Mogul', u'Amin Vahdat']
Networking
Abstract: Predictably sharing the network is critical to achieving high utilization in the datacenter. Past work has focussed on providing bandwidth to endpoints, but often we want to allocate resources among multi-node services. In this paper, we present Parley, which provides service-centric minimum bandwidth guarantees, which can be composed hierarchically. Parley also supports service-centric weighted sharing of bandwidth in excess of these guarantees. Further, we show how to configure these policies so services can get low latencies even at high network load. We evaluate Parley on a multi-tiered oversubscribed network connecting 90 machines, each with a 10Gb/s network interface, and demonstrate that Parley is able to meet its goals.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Generating Consistent Updates for Software-Defined Network Configurations
HotSDN, ACM (2014)
[u'Yifei Yuan', u'Franjo Ivancic', u'Cristian Lumezanu', u'Shuyuan Zhang', u'Aarti Gupta']
Networking
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43857.html
notfound
=========================
Gestalt: Fast, Unied Fault Localization for Networked Systems
Proceedings of the USENIX Annual Technical Conference (2014)
[u'Radhika Niranjan Mysore', u'Amin Vahdat', u'Ratul Mahajan', u'George Varghese']
Networking
Abstract: We show that the performance of existing fault localization algorithms differs markedly for different networks; and no algorithm simultaneously provides high localization accuracy and low computational overhead. We develop a framework to explain these behaviors by anatomizing the algorithms with respect to six important characteristics of real networks, such as uncertain dependencies, noise, and covering relationships. We use this analysis to develop Gestalt, a new algorithm that combines the best elements of existing ones and includes a new technique to explore the space of fault hypotheses. We run experiments on three real, diverse networks. For each, Gestalt has either significantly higher localization accuracy or an order of magnitude lower running time. For example, when applied to the Lync messaging system that is used widely within corporations, Gestalt localizes faults with the same accuracy as Sherlock, while reducing fault localization time from days to 23 seconds
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42805.html
notfound
=========================
Libra: Divide and Conquer to Verify Forwarding Tables in Huge Networks
11th USENIX Symposium on Networked Systems Design and Implementation (NSDI 14), USENIX Association (2014), pp. 87-99
[u'Amin Vahdat', u'Fei Ye', u'Shidong Zhang', u'Junda Liu']
Networking
Abstract: Data center networks often have errors in the forwarding tables, causing packets to loop indefinitely, fall into black-holes or simply get dropped before they reach the correct destination. Finding forwarding errors is possible using static analysis, but none of the existing tools scale to a large data center network with thousands of switches and millions of forwarding entries. Worse still, in a large data center network the forwarding state is constantly in flux, which makes it hard to take an accurate snapshot of the state for static analysis. We solve these problems with Libra, a new tool for verifying forwarding tables in very large networks. Libra runs fast because it can exploit the scaling properties of MapReduce. We show how Libra can take an accurate snapshot of the forwarding state 99.9% of the time, and knows when the snapshot cannot be trusted. We show results for Libra analyzing a 10,000 switch
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43269.html
notfound
=========================
RFC 7413 - TCP Fast Open
Internet Engineering Task Force (IETF) (2014)
[u'Yuchung Cheng', u'Jerry Chu', u'Sivasankar Radhakrishnan', u'Arvind Jain']
Networking
Abstract: This document describes an experimental TCP mechanism called TCP Fast Open (TFO). TFO allows data to be carried in the SYN and SYN-ACK packets and consumed by the receiving end during the initial connection handshake, and saves up to one full round-trip time (RTT) compared to the standard TCP, which requires a three-way handshake (3WHS) to complete before data can be exchanged. However, TFO deviates from the standard TCP semantics, since the data in the SYN could be replayed to an application in some rare circumstances.Applications should not use TFO unless they can tolerate this issue, as detailed in the Applicability section.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42897.html
found
=========================
RFC7304 - A Method for Mitigating Namespace Collisions
IETF RFCs, Internet Engineering Task Force (2014)
[u'Warren Kumari']
Networking
Abstract: This document outlines a possible, but not recommended, method to mitigate the effect of collisions in the DNS namespace by providing a means for end users to disambiguate the conflict.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42919.html
notfound
=========================
RFC7342 - Practices for Scaling ARP and Neighbor Discovery (ND) in Large Data Centers
IETF RFC, Internet Engineering Task Force (2014)
[u'Warren Kumari']
Networking
Abstract: This memo documents some operational practices that allow ARP and Neighbor Discovery (ND) to scale in data center environments.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42943.html
notfound
=========================
RFC7344 - Automating DNSSEC Delegation Trust Maintenance
IETF RFCs, Internet Engineering Task Force (2014)
[u'Warren Kumari']
Networking
Abstract: This document describes a method to allow DNS Operators to more easily update DNSSEC Key Signing Keys using the DNS as a communication channel. The technique described is aimed at delegations in which it is currently hard to move information from the Child to Parent.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43448.html
found
=========================
Security Vulnerability in Processor-Interconnect Router Design
Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security, ACM, New York, NY, pp. 358-368
[u'WonJun Song', u'John Kim', u'Jae W. Lee', u'Dennis Abts']
Networking
Abstract: Servers that consist of multiple nodes and sockets are interconnected together with a high-bandwidth, low latency processor interconnect network, such as Intel QPI or AMD Hypertransport technologies. The different nodes exchange packets through routers which communicate with other routers. A key component of a router is the routing table which determines which output port an arriving packet should be forwarded through. However, because of the flexibility (or programmability) of the routing tables, we show that it can result in security vulnerability. We describe the procedures for how the routing tables in a processor-interconnect router can be modified. Based on these modifications, we propose new system attacks in a server, which include both performance attacks by degrading the latency and/or the bandwidth of the processor interconnect as well as a livelock attack that hangs the system. We implement these system on an 8-node AMD server and show how performance can be significantly degraded. Based on this vulnerability, we propose alternative solutions that provide various trade-off in terms of flexibility and cost while minimizing the routing table security vulnerability.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42948.html
found
=========================
Software Defined Networking at Scale
Light Reading (2014), pp. 22
[u'Bikash Koley']
Networking
Abstract: Software Defined Networks require Software Defined Operations. Google made great progress in SDN data and control plane. This talk discusses how we are working with the industry to transform the network management plane into a software defined framework.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42848.html
found
=========================
Sources of Traffic Demand Variability and Use of Monte Carlo for Network Capacity Planning
Performance and Capacity 2014 by CMG Conference, Performance and Capacity 2014 by CMG Conference, Performance and Capacity 2014 by CMG Conference
[u'Alexander Gilgur', u'Brian Eck']
Networking
Abstract: When sizing any network capacity, several factors, such as Traffic, Quality of Service (QoS), and Total Cost of Ownership (TCO) are usually taken into account. Generally, it boils down to a joint minimization of cost and maximization of traffic subject to the constraints of protocol and QoS requirements. Stochastic nature of network traffic and link saturation queueing issues add uncertainty to the already complex optimization problem. In this paper, we examine the sources of traffic demand variability and dive into Monte-Carlo methodology as an efficient way for solving these problems. Other sources of uncertainty in network capacity forecasting are briefly discussed in the Attachment.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43121.html
found
=========================
TRAM: Optimizing Fine-grained Communication with Topological Routing and Aggregation of Messages
International Conference on Parallel Processing (2014)
[u'Lukasz Wesolowski', u'Ramprasad Venkataraman', u'A Gupta', u'Jae-Seung Yeom', u'Keith Bisset', u'Yanhua Sun', u'Pritish Jetley', u'Thomas Quinn', u'Laxmikant Kale']
Networking
Abstract: Fine-grained communication in supercomputing applications often limits performance through high communication overhead and poor utilization of network bandwidth. This paper presents Topological Routing and Aggregation Module (TRAM), a library that optimizes fine-grained communication performance by routing and dynamically combining short messages. TRAM collects units of fine-grained communication from the application and combines them into aggregated messages with a common intermediate destination. It routes these messages along a virtual mesh topology mapped onto the physical topology of the network. TRAM improves network bandwidth utilization and reduces communication overhead. It is particularly effective in optimizing patterns with global communication and large message counts, such as all to-all and many-to-many, as well as sparse, irregular, dynamic or data dependent patterns. We demonstrate how TRAM improves performance through theoretical analysis and experimental verification using benchmarks and scientific applications. We present speedups on petascale systems of 6x for communication benchmarks and up to 4x for applications.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42528.html
notfound
=========================
Troubleshooting PON networks effectively with Carrier-grade Ethernet and WDM-PON
IEEE Communications Magazine, vol. 52 (2014), S7-S13
[u'Rafael Sanchez', u'Jose Alberto Hernandez', u'David Larrabeiti']
Networking
Abstract: WDM-PONs have recently emerged to provide dedicated and separated point-to-point wavelengths to individual Optical Network Units (ONTs). In addition, the recently standardised Ethernet OAM capabilities under the IEEE 802.1ag standard and the ITU-T Y.1731 recommendation, together with state-of-the-art Optical Time-Domain Reflectometry (OTDR) provide new link-layer and physical tools for the effective troubleshooting of WDM-PONs. This article proposes an Integrated Troubleshooting Box (ITB) for the effectively combination of both physical and link-layer information into an effective and efficient set of management procedures for WDM-PONs. We show its applicability in a number of realistic troubleshooting scenarios, including failure situations involving either the feeder fibre, one of its branches and even Ethernet links after the ONT.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42180.html
notfound
=========================
What devices do data centers need
OFC 2014 Technical Digest, OSA
[u'Cedric F. Lam', u'Ryohei Urata', u'Hong Liu']
Networking
Abstract: We discuss the trend in fiber optic technology developments to fulfill the scaling requirements of datacenter networks.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A 10 us Hybrid Optical-Circuit/Electrical-Packet Network for Data Centers
Proceedings of OFC/NFOEC, UC San Diego, 9500 Gilman Dr., La Jolla CA 92093 (2013)
[u'Nathan Farrington', u'Alex Forencich', u'Pang-Chen Sun', u'Shaya Fainman', u'Joe Ford', u'Amin Vahdat', u'George Porter', u'George C. Papen']
Networking
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40757.html
found
=========================
Approximation Algorithms for the Directed k-Tour and k-Stroll Problems
Algorithmica, vol. 65 (2013), pp. 545-561
[u'Mohammadhossein Bateni', u'Julia Chuzhoy']
Networking
Abstract: We consider two natural generalizations of the Asymmetric Traveling Salesman problem: the k-Stroll and the k-Tour problems. The input to the k-Stroll problem is a directed n-vertex graph with nonnegative edge lengths, an integer k, as well as two special vertices s and t. The goal is to find a minimum-length s-t walk, containing at least k distinct vertices (including the endpoints s,t). The k-Tour problem can be viewed as a special case of k-Stroll, where s=t. That is, the walk is required to be a tour, containing some pre-specified vertex s. When k=n, the k-Stroll problem becomes equivalent to Asymmetric Traveling Salesman Path, and k-Tour to Asymmetric Traveling Salesman. Our main result is a polylogarithmic approximation algorithm for the k-Stroll problem. Prior to our work, only bicriteria (O(log2 k),3)-approximation algorithms have been known, producing walks whose length is bounded by 3OPT, while the number of vertices visited is ?(k/log2 k). We also show a simple O(log2 n/loglogn)-approximation algorithm for the k-Tour problem. The best previously known approximation algorithms achieved min(O(log3 k),O(log2 n?logk/loglogn)) approximation in polynomial time, and O(log2 k) approximation in quasipolynomial time.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
B4: Experience with a Globally Deployed Software Defined WAN
Proceedings of the ACM SIGCOMM Conference, Hong Kong, China (2013)
[u'Sushant Jain', u'Alok Kumar', u'Subhasree Mandal', u'Joon Ong', u'Leon Poutievski', u'Arjun Singh', u'Subbaiah Venkata', u'Jim Wanderer', u'Junlan Zhou', u'Min Zhu', u'Jonathan Zolla', u'Urs Hlzle', u'Stephen Stuart', u'Amin Vahdat']
Networking
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41862.html
notfound
=========================
CSRIC III WORKING GROUP 4 Network Security Best Practices FINAL Report BGP Security Best Practice
FCC (2013)
[u'Jason Schiller', u'Rodney Joffe', u'Rod Rasmussen', u'Mark Adams', u'Steve Bellovin', u'Donna Bethea-Murphy', u'Rodney Buie', u'Kevin Cox', u'John Crain', u'Michael Currie', u'Dale Drew', u'Chris Garner', u'Joseph Gersch', u'Jose A. Gonzalez', u'Kevin Graves', u'Chris Joul', u'Tom Haynes', u'Mazen Khaddam', u'Ron Mathis', u'Danny McPherson', u'Doug Montgomery', u'Heather Schiller', u'Tony Tauber', u'Marvin Simpson', u'Ron Roman', u'Elman Reyes', u'Victor Oppleman', u'Chris Oberg', u'Russ White', u'Paul Vixie', u'Bob Wright']
Networking
Abstract: Discussion of best current practices for securing intra-domain routing prior to the wide spread adoption of BGPsec.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41590.html
found
=========================
Capturing Mobile Experience in the Wild: A Tale of Two Apps
8th International Conference on emerging Networking EXperiments and Technologies (CoNEXT), ACM (Association for Computing Machinery) (2013), NA (to appear)
[u'Ashish Patro', u'Shravan Rayanchu', u'Michael Griepentrog']
Networking
Abstract: We present Insight, a framework that collects mobile application analytics with minimal overhead on the application and the developers. Insight offers information about application usage, device and platform statistics, application footprint, user behavior and retention properties and factors affecting application revenues. Further, Insight leverages the vast and diverse mobile user base of the applications to continuously crowd-source network measurements from across the world. This allows us to carry out interesting longitudinal studies about the long term trends in usage and performance characteristics of these networks. Further, by coupling network measurements along with application analytics, Insight also helps understand how network performance can impact application usage, performance and revenues. We deployed Insight on two applications in Apples AppStore and Googles Android Market. One of them, Parallel Kingdom (PK), is a popular Massively Multiplayer Online Role Playing Game (MMORPG) which has over 600,000 unique users distributed across 118 countries. The second application was more recently released and currently has a few thousand users. Our measurements span almost the entire life of the PK game starting from its inception on October 31, 2008 to Nov 10, 2011 (1104 days in total). Through deployment of Insight on this game, we also perform the rst study analyzing the characteristics of a mobile MMORPG.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Comparative study of classifiers to mitigate intersymbol interference in diffuse indoor optical wireless communication links
Optik - International Journal for Light and Electron Optics (2013)
[u'Sujan Rajbhandari', u'Joe Faith', u'Zabih Ghassemlooy']
Networking
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41404.html
notfound
=========================
Cross Platform Network Access Control
RVASec 2013, RVASec 2013, RIchmond, VA
[u'Paul (Tony) Watson']
Networking
Abstract: Discussion of Capirca, an open-sourced multi-platform Network ACL generation system. This talk will discuss the history of Capirca, originating as an internal Google project through its current form and use in the open-source community. Attendees will gain an understand of how to use the system to simplify and improve the efficiency and reliability of network security management. A significant portion of time will also be dedicated to an overview of how the software and libraries work internally, including how to develop new modules and contribute to the open source effort.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Demonstration of WDM OSNR performance monitoring and operating guidelines for pol-muxed 200Gbit/s 16-QAM and 100Gbit/s QPSK data channels
Optical Fiber Communication Conference (2013), OTh3B.6
[u'M. Chitgarha', u'S. Khaleghi', u'W. Daab', u'M. Ziyadi', u'A. Mohajerin-Ariaei', u'D.Rogawski', u'M. Tur', u'Vijay Vusirikala', u'Xiaoxue Zhao', u'Alan Willner']
Networking
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41848.html
notfound
=========================
Drilling Network Stacks with packetdrill
USENIX ;login:, vol. 38 (2013), pp. 48-52
[u'Neal Cardwell', u'Barath Raghavan']
Networking
Abstract: Testing and troubleshooting network protocols and stacks can be painstaking. To ease this process, our team built packetdrill, a tool that lets you write precise scripts to test entire network stacks, from the system call layer down to the NIC hardware. packetdrill scripts use a familiar syntax and run in seconds, making them easy to use during development, debugging, and regression testing, and for learning and investigation.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40812.html
found
=========================
Ensuring Connectivity via Data Plane Mechanisms
10th USENIX Symposium on Networked Systems Design and Implementation (2013)
[u'Junda Liu']
Networking
Abstract: We typically think of network architectures as having two basic components: a data plane responsible for forwarding packets at line-speed, and a control plane that instantiates the forwarding state the data plane needs. With this separation of concerns, ensuring connectivity is the responsibility of the control plane. However, the control plane typically operates at timescales several orders of magnitude slower than the data plane, which means that failure recovery will always be slow compared to dataplane forwarding rates. In this paper we propose moving the responsibility for connectivity to the data plane. Our design, called Data-Driven Connectivity (DDC) ensures routing connectivity via data plane mechanisms. We believe this new separation of concerns basic connectivity on the data plane, optimal paths on the control plane will allow networks to provide a much higher degree of availability, while still providing flexible routing control.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41611.html
found
=========================
Handling Packet Loss in WebRTC
International Conference on Image Processing (ICIP 2013), IEEE, pp. 1860-1864
[u'Stefan Holmer', u'Mikhal Shemer', u'Marco Paniconi']
Networking
Abstract: WebRTC is an open-source real-time interactive audio and video communication framework. This paper discusses some of the mechanisms utilized in WebRTC to handle packet losses in the video communication path. Various system details are discussed and an adaptive hybrid NACK/FEC method with temporal layers is presented. Results are shown to quantify how the method controls the quality trade-offs for real-time video communication.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41135.html
found
=========================
Improved Approximation Algorithms for (Budgeted) Node-weighted Steiner Problems
ICALP, Springer (2013)
[u'Mohammadhossein Bateni', u'MohammadTaghi Hajiaghayi', u'Vahid Liaghat']
Networking
Abstract: Moss and Rabani [12] study constrained node-weighted Steiner tree problems with two independent weight values associated with each node, namely, cost and prize (or penalty). They give an O(logn)-approximation algorithm for the prize-collecting node-weighted Steiner tree problem (PCST)
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41315.html
notfound
=========================
Network Utilization: The Flow View
IEEE INFOCOM 2013, IEEE, Turin, Italy
[u'Avinatan Hassidim', u'Danny Raz', u'Michal Segalov', u'Ariel Shaqed (Scolnicov)']
Networking
Abstract: Building and operating a large backbone network can take months or even years, and it requires a substantial investment. Therefore, there is an economical drive to increase the utilization of network resources (links, switches, etc.) in order to improve the cost efciency of the network. At the same time, the utilization of network components has a direct impact on the performance of the network and its resilience to failure, and thus operational considerations are a critical aspect of the decision regarding the desired network load and utilization. However, the actual utilization of the network resources is not easy to predict or control. It depends on many parameters like the trafc demand and the routing scheme (or Trafc Engineering if deployed), and it varies over time and space. As a result it is very difcult to actually dene real network utilization and to understand the reasons for this utilization. In this paper we introduce a novel way to look at the network utilization. Unlike traditional approaches that consider the average link utilization, we take the ow perspective and consider the network utilization in terms of the growth potential of the ows in the network. After dening this new Flow Utilization, and discussing how it differs from common denitions of network utilization, we study ways to efciently compute it over large networks. We then show, using real backbone data, that Flow Utilization is very useful in identifying network state and evaluating performance of TE algorithms.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41429.html
notfound
=========================
RFC 6937 - Proportional Rate Reduction for TCP
Internet Engineering Task Force (IETF) (2013)
[u'Matt Mathis', u'Nandita Dukkipati', u'Yuchung Cheng']
Networking
Abstract: This document describes an experimental Proportional Rate Reduction (PRR) algorithm as an alternative to the widely deployed Fast Recovery and Rate-Halving algorithms. These algorithms determine the amount of data sent by TCP during loss recovery. PRR minimizes excess window adjustments, and the actual window size at the end of recovery will be as close as possible to the ssthresh, as determined by the congestion control algorithm.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41330.html
notfound
=========================
RFC6928 - Increasing TCP's Initial Window
Internet Engineering Task Force (IETF) (2013)
[u'H.K. Jerry Chu', u'Nandita Dukkipati', u'Yuchung Cheng', u'Matt Mathis']
Networking
Abstract: This document proposes an experiment to increase the permitted TCP initial window (IW) from between 2 and 4 segments, as specified in RFC 3390, to 10 segments with a fallback to the existing recommendation when performance issues are detected. It discusses the motivation behind the increase, the advantages and disadvantages of the higher initial window, and presents results from several large-scale experiments showing that the higher initial window improves the overall performance of many web services without resulting in a congestion collapse. The document closes with a discussion of usage and deployment for further experimental purposes recommended by the IETF TCP Maintenance and Minor Extensions (TCPM) working group.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41400.html
found
=========================
Real-time communications for the web
Communications Magazine, IEEE, vol. 51 (2013), pp. 20-26
[u'Cullen Jenngins', u'Ted Hardie', u'Magnus Westerlund']
Networking
Abstract: This article provides an overview of the work that W3C and IETF are doing toward defining a framework, protocols, and application programming interfaces that will provide real-time interactive voice, video, and data in web browsers and other applications. The article explains how media and data will flow in a peer-to-peer style directly between two web browsers. This explains the protocols used to transport and secure the encrypted media, traverse NATs and firewalls, negotiate media capabilities, and provide identity for the media.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41217.html
notfound
=========================
Reducing Web Latency: the Virtue of Gentle Aggression
Proceedings of the ACM Conference of the Special Interest Group on Data Communication (SIGCOMM '13), ACM (2013)
[u'Tobias Flach', u'Nandita Dukkipati', u'Andreas Terzis', u'Barath Raghavan', u'Neal Cardwell', u'Yuchung Cheng', u'Ankur Jain', u'Shuai Hao', u'Ethan Katz-Bassett', u'Ramesh Govindan']
Networking
Abstract: To serve users quickly, Web service providers build infrastructure closer to clients and use multi-stage transport connections. Although these changes reduce client-perceived round-trip times, TCP's current mechanisms fundamentally limit latency improvements. We performed a measurement study of a large Web service provider and found that, while connections with no loss complete close to the ideal latency of one round-trip time, TCP's timeout-driven recovery causes transfers with loss to take five times longer on average. In this paper, we present the design of novel loss recovery mechanisms for TCP that judiciously use redundant transmissions to minimize timeout-driven recovery. Proactive, Reactive, and Corrective are three qualitatively different, easily-deployable mechanisms that (1) proactively recover from losses, (2) recover from them as quickly as possible, and (3) reconstruct packets to mask loss. Crucially, the mechanisms are compatible both with middleboxes and with TCP's existing congestion control and loss recovery. Our large-scale experiments on Google's production network that serves billions of flows demonstrate a 23% decrease in the mean and 47% in 99th percentile latency over today's TCP.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41331.html
notfound
=========================
Rogue Femtocell Owners: How Mallory Can Monitor My Devices
2013 Proceedings IEEE INFOCOM, IEEE, New Jersey, USA, pp. 3553-3558
[u'David Malone', u'Darren F Kavanagh', u'Niall Richard Murphy']
Networking
Abstract: Femtocells are small cellular telecommunication base stations that provide improved cellular coverage. These devices provide important improvements in coverage, battery life and throughput, they also present security challenges. We identify a problem which has not been identified in previous studies of femtocell security: rogue owners of femtocells can secretly monitor third-party mobile devices by using the femtocell's access control features. We present traffic analysis of real femtocell traces are presented and demonstrate the ability to monitor mobile devices through classification of the femtocell's encrypted backhaul traffic. We also consider the femtocell's power usage and status LEDs as other side channels that provide information on the femtocell's operation. We conclude by presenting suitable solutions to overcome this problem.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Scalability vs. Fault Tolerance in Aspen Trees
Microsoft Research technical report (2013)
[u'Meg Walraed-Sullivan', u'Keith Marzullo', u'Amin Vahdat']
Networking
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Shortest paths avoiding forbidden subpaths
Networks, vol. 61 (2013), pp. 322-334
[u'Mustaq Ahmed', u'Anna Lubiw']
Networking
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41414.html
notfound
=========================
The Prospect of Inter-Data-Center Optical Networks
IEEE Communication Magazine, vol. 51 (2013), pp. 32-38
[u'Xiaoxue Zhao', u'Vijay Vusirikala', u'Bikash Koley', u'Valey Kamalov', u'Tad Hofmeister']
Networking
Abstract: Mega data centers and their interconnection networks have drawn great attention in recent years because of the rapid public adoption of cloud-based services. The unprecedented amount of data that needs to be communicated between data centers imposes new requirements and challenges to inter-data-center optical networks. In this article, we discuss the traffic growth trends and capacity demands of Googles inter-data-center network, and how they drive the network architectures and technologies to scale capacities and operational ease on existing fiber plants. We extensively review recent research findings and emerging technologies, such as digital coherent detection and the flexgrid dense wavelength-division multiplexed channel plan, and propose practical implementations, such as C+L-band transmission, packet and optical layer integration, and a software-defined networking enabled network architecture for both capacity and operational scaling. In addition, we point out a few critical areas that require more attention and research to improve efficiency and flexibility of an inter-data-center optical network: optical regeneration, data rate mismatch between Ethernet and optical transport, and real-time optical performance monitoring.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42530.html
notfound
=========================
Using transparent WDM metro rings to provide an out-of-band control network for OpenFlow in MAN
ICTON 2013, 15th International Conference on Tranparent Optical Networks (ICTON'13),
[u'Rafael Sanchez', u'Jose Alberto Hernandez', u'David Larrabeiti']
Networking
Abstract: OpenFlow is a protocol that enables networks to evolve and change flexibly, by giving a remote controller the capability of modifying the behavior of network devices. In an OpenFlow network, each device needs to maintain a dedicated and separated connection with a remote controller. All these connections can be described as the OpenFlow control network, that is the data network which transports control plane information, and can be deployed together with the data infrastructure plane (in-band) or separated (out-of-band), with advantages and disadvantages in both cases. The control network is a critical subsystem since the communication with the controller must be reliable and ideally should be protected against failures. This paper proposes a novel ring architecture to efficiently transport both the data plane and an out-of-band control network.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41316.html
notfound
=========================
packetdrill: Scriptable Network Stack Testing, from Sockets to Packets
Proceedings of the USENIX Annual Technical Conference (USENIX ATC 2013), USENIX, 2560 Ninth Street, Suite 215, Berkeley, CA, 94710 USA, pp. 213-218
[u'Neal Cardwell', u'Yuchung Cheng', u'Lawrence Brakmo', u'Matt Mathis', u'Barath Raghavan', u'Nandita Dukkipati', u'Hsiao-keng Jerry Chu', u'Andreas Terzis', u'Tom Herbert']
Networking
Abstract: Testing todays increasingly complex network protocol implementations can be a painstaking process. To help meet this challenge, we developed packetdrill, a portable, open-source scripting tool that enables testing the correctness and performance of entire TCP/UDP/IP network stack implementations, from the system call layer to the hardware network interface, for both IPv4 and IPv6. We describe the design and implementation of the tool, and our experiences using it to execute 657 test cases. The tool was instrumental in our development of three new features for Linux TCPEarly Retransmit, Fast Open, and Loss Probesand allowed us to find and fix 10 bugs in Linux. Our team uses packetdrill in all phases of the development process for the kernel used in one of the worlds largest Linux installations.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40404.html
found
=========================
A Guided Tour of Datacenter Networking
Communications of the ACM - ACM Queue, vol. 55, number 6 (2012), pp. 44-51
[u'Dennis Abts', u'Bob Felderman']
Networking
Abstract: The magic of the cloud is that it is always on and always available from anywhere. Users have come to expect that services are there when they need them. A data center (or warehouse-scale computer) is the nexus from which all the services flow. It is often housed in a nondescript warehouse-sized building bearing no indication of what lies inside. Amidst the whirring fans and refrigerator-sized computer racks is a tapestry of electrical cables and fiber optics weaving everything togetherthe data-center network. This article provides a guided tour through the principles and central ideas surrounding the network at the heart of a data centerthe modern-day loom that weaves the digital fabric of the Internet.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub39962.html
found
=========================
Bridging communications and the physical world
IEEE Internet Computing, vol. 16 (2012), pp. 35-43
[u'Omer Boyaci', u'Victoria Beltran Martinez', u'Henning Schulzrinne']
Networking
Abstract: Sense Everything, Control Everything (SECE) is an event-driven system that lets nontechnical users create services that combine communication, location, social networks, presence, calendaring, and physical devices such as sensors and actuators. SECE combines information from multiple sources to personalize services and adapt them to changes in the user's context and preferences. Events trigger associated actions, which can control email delivery, change how phone calls are handled, update the user's social network status, and set the state of actuators such as lights, thermostats, and electrical appliances.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40592.html
notfound
=========================
Comparing In-Browser Methods of Measuring Resource Load Times
W3C Workshop on Web Performance 8, W3C, W3C/MIT 32 Vassar Street Room 32-G515 Cambridge, MA 02139 USA (2012)
[u'Eric Gavaletz', u'Dominic Hamon', u'Jasleen Kaur']
Networking
Abstract: When looking for an excellent platform for conducting end-to-end network performance measurement that is large-scale and representative, researchers should look no further than the browser -- after all, browsers are installed everywhere and are used multiple times per day by most Internet users. In this work, we investigate the use of the DOM, XHR and Navigation Timing API for measuring HTTP response times within browsers, with the goal of estimating path latency and throughput. The response times are measured using a set of popular browsers in a controlled environmentthis helps us isolate the differences between the browsers as well as study how closely the measurements match the ground truth. We show that, in general, the XHR method yields the most consistent measurements across browsers, but that the new Navigation Timing and the proposed Resource Timing APIs could change that. We also use the measurements from our controlled environment to study the impact of each of our investigated measurement methods on a hypothetical measurement study.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37678.html
notfound
=========================
Deadline-Aware Datacenter TCP (D2TCP)
Proceedings of the ACM SIGCOMM (2012)
[u'Balajee Vamanan', u'Jahangir Hasan', u'T. N. Vijaykumar']
Networking
Abstract: An important class of datacenter applications, called Online Data-Intensive (OLDI) applications, includes Web search, online retail, and advertisement. To achieve good user experience, OLDI applications operate under soft-real-time constraints (e.g., 300 ms latency) which imply deadlines for network communication within the applications. Further, OLDI applications typically employ tree-based algorithms which, in the common case, result in bursts of children-to-parent traffic with tight deadlines. Recent work on datacenter network protocols is either deadline-agnostic (DCTCP) or is deadline-aware (D3) but suffers under bursts due to race conditions. Further, D3 has the practical drawbacks of requiring changes to the switch hardware and not being able to coexist with legacy TCP. We propose Deadline-Aware Datacenter TCP (D2TCP), a novel transport protocol, which handles bursts, is deadline-aware, and is readily deployable. In designing D2TCP, we make two contributions: (1) D2TCP uses a distributed and reactive approach for bandwidth allocation which fundamentally enables D2TCPs properties. (2) D2TCP employs a novel congestion avoidance algorithm, which uses ECN feedback and deadlines to modulate the congestion window via a gamma-correction function. Using a small-scale implementation and at-scale simulations, we show that D2TCP reduces the fraction of missed deadlines compared to DCTCP and D3 by 75% and 50%, respectively.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Edge-preserving self-healing: keeping network backbones densely connected
NetSciCom (2012) (to appear)
[u'Atish Das Sarma', u'Amitabh Trehan']
Networking
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Efficient Computation of Distance Sketches in Distributed Networks
arXiv (2012)
[u'Atish Das Sarma', u'Michael Dinitz', u'Gopal Pandurangan']
Networking
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37516.html
found
=========================
End-to-end Verification of QoS Policies
The 13th IEEE/IFIP Network Operations and Management Symposium (NOMS 2012)
[u'Adel El-Atawy', u'Taghrid Samak']
Networking
Abstract: Conguring a large number of routers and network devices to achieve quality of service (QoS) goals is a challenging task. In a differentiated services (DiffServ) environment, trafc ows are assigned specic classes of service, and service level agreements (SLA) are enforced at routers within each domain. We present a model for QoS congurations that facilitates efcient property-based verication. Network conguration is given as a set of policies governing each device. The model efciently checks the required properties against the current conguration using computation tree logic (CTL) model checking. By symbolically modeling possible decision paths for different ows from source to destination, properties can be checked at each hop, and assessments can be made on how closely congurations adhere to the specied agreement. The model also covers conguration debugging given a specic QoS violation. Efciency and scalability of the model are analyzed for policy per-hop behavior (PHB) parameters over large network congurations.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37746.html
notfound
=========================
High Performance, Low Cost, Colorless ONU for WDM-PON
Optical Fiber Communication (OFC) Conference 2012, OSA, Washington DC
[u'Ryohei Urata', u'Cedric Lam', u'Hong Liu', u'Chris Johnson']
Networking
Abstract: We give an overview of key technologies for realizing WDM-PON. In particular, we highlight promising developments and directions in widely tunable laser technologies for achieving a high performance, colorless ONU at the cost points required for access networks.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
How to Split a Flow
INFOCOM (2012)
[u'Tzvika Hartman', u'Avinatan Hassidim', u'Haim Kaplan', u'Danny Raz', u'Michal Segalov']
Networking
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38239.html
notfound
=========================
LatLong: Diagnosing Wide-Area Latency Changes for CDNs
IEEE Transactions on Network and Service Management, vol. 9 (2012) (to appear)
[u'Yaping Zhu', u'Benjamin Helsley', u'Jennifer Rexford', u'Aspi Siganporia', u'Sridhar Srinivasan']
Networking
Abstract: Minimizing user-perceived latency is crucial for Content Distribution Networks (CDNs) hosting interactive services. Latency may increase for many reasons, such as interdomain routing changes and the CDN's own load-balancing policies. CDNs need greater visibility into the causes of latency increases, so they can adapt by directing traffic to different servers or paths. In this paper, we propose techniques for CDNs to diagnose large latency increases, based on passive measurements of performance, traffic, and routing. Separating the many causes from the effects is challenging. We propose a decision tree for classifying latency changes, and determine how to distinguish traffic shifts from increases in latency for existing servers, routers, and paths. Another challenge is that network operators group related clients to reduce measurement and control overhead, but the clients in a region may use multiple servers and paths during a measurement interval. We propose metrics that quantify the latency contributions across sets of servers and routers. Analyzing a month of data from Google's CDN, we find that nearly 1% of the daily latency changes increase delay by more than 100 msec. More than 40% of these increases coincide with interdomain routing changes, and more than one-third involve a shift in traffic to different servers. This is the first work to diagnose latency problems in a large, operational CDN from purely passive measurements. Through case studies of individual events, we identify research challenges for measuring and managing wide-area latency for CDNs.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Less is more: trading a little bandwidth for ultra-low latency in the data center
Proceedings of the 9th USENIX conference on Networked Systems Design and Implementation, USENIX Association, Berkeley, CA, USA (2012), pp. 19-19
[u'Mohammad Alizadeh', u'Abdul Kabbani', u'Tom Edsall', u'Balaji Prabhakar', u'Amin Vahdat', u'Masato Yasuda']
Networking
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Near-Optimal Random Walk Sampling in Distributed Networks
INFOCOM (2012) (to appear)
[u'Atish Das Sarma', u'Anisur Molla Rahman', u'Gopal Pandurangan']
Networking
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40282.html
notfound
=========================
Portable and Performant Userspace SCTP Stack
Computer Communications and Networks (ICCCN), 2012 21st International Conference on, IEEE
[u'Brad Penoff', u'Alan Wagner', u'Michael Tuexen', u'Irene Ruengeler']
Networking
Abstract: One of only two new transport protocols introduced in the last 30 years is the Stream Control Transmission Protocol (SCTP). SCTP enables capabilities like additional throughput and fault tolerance for multihomed hosts. An SCTP implementation is included with the Linux kernel and another implementation called sctplib functions successfully in userspace on several platforms but unfortunately neither of these implementations have all of the latest features nor do they perform as well as the FreeBSD kernel implementation of SCTP. We were motivated to produce a portable implementation of the FreeBSD kernel SCTP stack that operates in userspace of any system because of both our desires to obtain a higher performance SCTP stack for Linux as well as to exploit recent developments in hardware virtualization and transport protocol onloading. Unlike any other userspace transport implementation for TCP or SCTP, our userspace SCTP stack simultaneously achieves similar throughput and latency as the Linux kernel TCP stack, without compromising on any of the transport's features as well as maintaining true portability across multiple operating systems and devices. We create a callback API and implement a threshold to control its usage; our userspace SCTP stack with these optimizations obtains higher throughput than the Linux kernel implementation of SCTP. We describe our userspace SCTP stack's design and demonstrate how it gives similar throughput and latency on Linux as the kernel TCP implementation, with the benefits of the new features of SCTP.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38101.html
notfound
=========================
RFC6583 - Operational Neighbor Discovery Problems
IETF RFCs, Internet Engineering Task Force (2012)
[u'Warren Kumari', u'Igor Gashinsky', u'Yahoo!', u'Joel Jaeggli', u'Zynga']
Networking
Abstract: In IPv4, subnets are generally small, made just large enough to cover the actual number of machines on the subnet. In contrast, the default IPv6 subnet size is a /64, a number so large it covers trillions of addresses, the overwhelming number of which will be unassigned. Consequently, simplistic implementations of Neighbor Discovery (ND) can be vulnerable to deliberate or accidental denial of service (DoS), whereby they attempt to perform address resolution for large numbers of unassigned addresses. Such denial-of-service attacks can be launched intentionally (by an attacker) or result from legitimate operational tools or accident conditions. As a result of these vulnerabilities, new devices may not be able to "join" a network, it may be impossible to establish new IPv6 flows, and existing IPv6 transported flows may be interrupted. This document describes the potential for DoS in detail and suggests possible implementation improvements as well as operational mitigation techniques that can, in some cases, be used to protect against or at least alleviate the impact of such attacks.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41526.html
notfound
=========================
SPI-SNOOPER: a hardware-software approach for transparent network monitoring in wireless sensor networks
Proceedings of the eighth IEEE/ACM/IFIP international conference on Hardware/software codesign and system synthesis, ACM, New York, NY, USA (2012), pp. 53-62
[u'Mohammad Sajjad Hossain', u'Woo Suk Lee', u'Vijay Raghunathan']
Networking
Abstract: The lack of post-deployment visibility into system operation is one of the major challenges in ensuring reliable operation of remotely deployed embedded systems such as wireless sensor nodes. Over the years, many software-based solutions (in the form of debugging tools and protocols) have been proposed for in-situ system monitoring. However, all of them share the trait that the monitoring functionality is implemented as software executing on the same embedded processor that the main application executes on. This is a poor design choice from a reliability perspective. This paper makes the case for a joint hardware-software solution to this problem and advocates the use of a dedicated reliability co-processor that is tasked with monitoring the operation of the embedded system. As an embodiment of this design principle, this paper presents Spi-Snooper, a co-processor augmented hardware platform specifically designed for network monitoring. Spi-Snooper is completely cross-compatible with the Telos wireless sensor nodes from an operational standpoint and is based on a novel hardware architecture that enables transparent snooping of the communication bus between the main processor and the radio of the wireless embedded system. The accompanying software architecture provides a powerful tool for monitoring, logging, and even controlling all the communication that takes place between the main processor and the radio. We present a rigorous evaluation of our prototype and demonstrate its utility using a variety of usage scenarios.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub39960.html
notfound
=========================
Silicon Photonics for Optical Access Networks
Group IV Photonics, IEEE, Washington DC (2012), pp. 3
[u'Ryohei Urata', u'Hong Liu', u'Cedric Lam', u'Pedram Dashti', u'Chris Johnson']
Networking
Abstract: We highlight promising developments and directions in silicon photonics for realizing cost effective WDM-PON: photonic integration for integrated WDM transceivers at the OLT and widely tunable laser technologies for achieving a high performance, colorless ONU.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40606.html
found
=========================
Towards A Unified Modeling and Verification of Network and System Security Configuration
5th Symposium on Configuration Analytics and Automation (SafeConfig 2012)
[u'Mohammed Noraden Alsaleh', u'Ehab Al-Shaer', u'Adel El-Atawy']
Networking
Abstract: Systems and networks access control configuration are usually analyzed independently although they are logically combined to define the the end-to-end security property. While systems and applications security policies define access control based on user identity or group, request type and the requested resource, network security policies uses flow information such as host and service addresses for source and destination to define access control. Therefore, both network and systems access control have to be configured consistently in order enforce end-to-end security policies. Many previous research attempt to verify either side separately, but it does not provide a unified approach to automatically validate the logical consistency between both of them. Thus, using existing techniques requires error-prone manual and ad-hoc analysis to validate this link. In this paper, we introduce a cross-layer modeling and verification system that can analyzes the configurations and policies across both application and network components as a single unit. It combines policies from different devices as firewalls, NAT, routers and IPSec gateways as well as basic RBAC-based policies of higher service layers. This will allow analyzing, for example, firewall polices in the context of application access control and vice versa. Thus, by incorporating policies across the network and over multiple layers, we provide a true end-to-end configuration verification tool. Our model represents the system as a state machine where packet header, service request and location determine the state and transitions that conform with the configurations, device operations, and packet values are established. We encode the model as Boolean functions using binary decision diagrams (BDDs). We used an extended version of computational tree logic (CTL) to provide more useful operators and then use it with symbolic model checking to prove or find counter examples to needed properties. The tool is implemented and we gave special consideration to efficiency and scalability. Our extensive evaluation study shows acceptable computation and space requirements with large number of nodes and configuration sizes.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37739.html
notfound
=========================
Traffic Anomaly Detection Based on the IP Size Distribution
INFOCOM International Conference on Computer Communications, Joint Conference of the IEEE Computer and Communications Societies, IEEE (2012), pp. 2005-2013
[u'Fabio Soldo', u'Ahmed Metwally']
Networking
Abstract: In this paper we present a data-driven framework for detecting machine-generated traffic based on the IP size, i.e., the number of users sharing the same source IP. Our main observation is that diverse machine-generated traffic attacks share a common characteristic: they induce an anomalous deviation from the expected IP size distribution. We develop a principled framework that automatically detects and classifies these deviations using statistical tests and ensemble learning. We evaluate our approach on a massive dataset collected at Google for 90 consecutive days. We argue that our approach combines desirable characteristics: it can accurately detect fraudulent machine-generated traffic; it is based on a fundamental characteristic of these attacks and is thus robust (e.g., to DHCP re-assignment) and hard to evade; it has low complexity and is easy to parallelize, making it suitable for large-scale detection; and finally, it does not entail profiling users, but leverages only aggregate statistics of network traffic.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38103.html
found
=========================
Trickle: Rate Limiting YouTube Video Streaming
Proceedings of the USENIX Annual Technical Conference (2012), pp. 6
[u'Monia Ghobadi', u'Yuchung Cheng', u'Ankur Jain', u'Matt Mathis']
Networking
Abstract: YouTube traffic is bursty. These bursts trigger packet losses and stress router queues, causing TCPs congestion-control algorithm to kick in. In this paper, we introduce Trickle, a server-side mechanism that uses TCP to rate limit YouTube video streaming. Trickle paces the video stream by placing an upper bound on TCPs congestion window as a function of the streaming rate and the round-trip time. We evaluated Trickle on YouTube production data centers in Europe and India and analyzed its impact on losses, bandwidth, RTT, and video buffer under-run events. The results show that Trickle reduces the average TCP loss rate by up to 43% and the average RTT by up to 28% while maintaining the streaming rate requested by the application.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Upward Max Min Fairness
INFOCOM (2012)
[u'Emilie Danna', u'Avinatan Hassidim', u'Haim Kaplan', u'Alok Kumar', u'Yishay Mansour', u'Danny Raz', u'Michal Segalov']
Networking
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
100GbE and beyond for warehouse scale computing interconnects
Optical Fiber Technology, vol. 17 (2011), pp. 363-367
[u'Bikash Koley', u'Vijay Vusirikala']
Networking
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37177.html
notfound
=========================
Computing TCP's Retransmission Timer
IETF (2011)
[u'Vern Paxson', u'Mark Allman', u'H.K. Jerry Chu', u'Matt Sargent']
Networking
Abstract: This document defines the standard algorithm that Transmission Control Protocol (TCP) senders are required to use to compute and manage their retransmission timer. It expands on the discussion in Section 4.2.3.1 of RFC1122 and upgrades the requirement of supporting the algorithm from a SHOULD to a MUST. This document obsoletes RFC 2988. This is an Internet Standards Track document.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37363.html
notfound
=========================
DDoS Protections for SMTP Servers
International Journal of Computer Science and Security (IJCSS), vol. 4 (2011), pp. 497-610
[u'Michael Still', u'Eric McCreath']
Networking
Abstract: Many businesses rely on email of some form for their day to day operation. This is especially true for product support organizations, who are largely unable to perform their role in the company if their in boxes are flooded with malicious email, or if important email is delayed because of the processing of attack traffic. Simple Message Transfer Protocol (SMTP) is the Internet protocol for the transmission of these emails. Denial of Service (DoS) attacks are deliberate attempts by an attacker to disrupt the normal operation of a service with the goal of stopping legitimate requests for the service from being processed. This disruption normally takes the form of large delays in responding to requests, dropped requests, and other service interruptions. In this paper we explore the current state of research into Distributed Denial of Service (DDoS) attack detection, protection and mitigation for SMTP servers connected to the Internet. We find that whilst there has been significant research into DDoS protection and detection generally, much of it is not relevant to SMTP servers. During our survey we found only two papers directly addressing defending SMTP servers against such attacks.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub39984.html
notfound
=========================
Data-driven network connectivity
Proceedings of the 10th ACM Workshop on Hot Topics in Networks (2011)
[u'Junda Liu']
Networking
Abstract: Routing on the Internet combines data plane mechanisms for forwarding traffic with control plane protocols for guaranteeing connectivity and optimizing routes (e.g., shortest-paths and load distribution). We propose data-driven connectivity (DDC), a new routing approach that achieves the fundamental connectivity guarantees in the data plane rather than the control plane, while keeping the more complex requirements of route optimization in the control plane. DDC enables faster recovery from failures and easier implementation of control plane optimization.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36986.html
notfound
=========================
Diagnosing performance changes by comparing request ows
8th USENIX Symposium on Networked Systems Design and Implementation (NSDI) (2011)
[u'Raja R. Sambasivan', u'Alice X. Zheng', u'Michael De Rosa', u'Elie Krevat', u'Spencer Whitman', u'Michael Stroucken', u'William Wang', u'Lianghong Xu', u'Gregory R. Ganger']
Networking
Abstract: The causes of performance changes in a distributed system often elude even its developers. This paper develops a new technique for gaining insight into such changes: comparing system behaviours from two executions (e.g., of two system versions or time periods). Building on end-to-end request flow tracing within and across components, algorithms are described for identifying and ranking changes in the flow and/or timing of request processing. The implementation of these algorithms in a tool called Spectroscope is described and evaluated. Six case studies are presented of using Spectroscope to diagnose performance changes in a distributed storage system caused by code changes, configuration modifications, and component degradations, demonstrating the value and efficacy of comparing request flows. Preliminary experiences of using Spectroscope to diagnose performance changes within Google are also presented.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37208.html
notfound
=========================
Drivers and applications of optical technologies for Internet Data Center networks
Optical Fiber Communication Conference and Exposition (OFC/NFOEC), 2011 and the National Fiber Optic Engineers Conference, pp. 1-3
[u'Cedric F. Lam', u'Paul Schultz', u'Bikash Koley']
Networking
Abstract: The rise of large-scale Data Centers to power the Internet infrastructure is driving new architectural directions for optical networking. This paper highlights these architectural options and discusses technology building blocks for scaling inter-Datacenter connectivity.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36951.html
notfound
=========================
Energy-Efcient Protocol for Cooperative Networks
IEEE/ACM TRANSACTIONS ON NETWORKING, vol. 19 (2011), pp. 561-574
[u'Mohamed Elhawary', u'Zygmunt J. Haas']
Networking
Abstract: In cooperative networks, transmitting and receiving nodes recruit neighboring nodes to assist in communication. We model a cooperative transmission link in wireless networks as a transmitter cluster and a receiver cluster. We then propose a cooperative communication protocol for establishment of these clusters and for cooperative transmission of data. We derive the upper bound of the capacity of the protocol, and we analyze the end-to-end robustness of the protocol to data-packet loss, along with the tradeoff between energy consumption and error rate. The analysis results are used to compare the energy savings and the end-to-end robustness of our protocol to two non- cooperative schemes, as well as to another cooperative protocol published in the technical literature. The comparison results show that, when nodes are positioned on a grid, there is a reduction in the probability of packet delivery failure by two orders of magnitude for the values of parameters considered. Up to 80% in energy savings can be achieved for a grid topology, while for random node placement, our cooperative protocol can save up to 40% in energy consumption relative to the other protocols. The reduction in error rate and the energy savings translate into increased life time of cooperative sensor networks.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Evolutionary Models and Cyber-replicas of Large Small Worlds.
WIN2011
[u'Silvio Lattanzi', u'Alessandro Panconesi', u'D. Sivakumar']
Networking
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41349.html
notfound
=========================
Joint consideration of energy-efficiency and coverage-preservation in microsensor networks
Wireless Communications & Mobile Computing, vol. 11 (2011), pp. 707-722
[u'Navid Amini', u'Alireza Vahdatpour', u'Foad Dabiri', u'Hyduke Noshadi', u'Majid Sarrafzadeh']
Networking
Abstract: This paper presents an energy-efficient and coverage-preserving communication protocol which distributes a uniform energy load to the sensors in a wireless microsensor network. This protocol, called Distance-based Segmentation (DBS), is a cluster-based protocol that divides the entire network into equal-area segments and applies different clustering policies to each segment to (1) reduce total energy dissipation and (2) balance the energy load among the sensors. Therefore, it prolongs the lifetime of the network and improves the sensing coverage. Moreover, the proposed routing protocol does not need any centralized support from a certain node which is at odds with aiming to establish a scalable communication protocol. Results from extensive simulations on two different network configurations show that by lowering the number of wasteful transmissions in the network, the DBS can achieve as much as a 20% reduction in total dissipated energy as compared with current cluster-based protocols. In addition, this protocol is able to distribute energy load more evenly among the sensors in the network. Hence, it yields up to a 66% increase in the useful network lifetime. According to the simulation results, the sensing coverage degradation of the DBS is considerably slower than that of the other cluster-based protocols.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37486.html
notfound
=========================
Proportional Rate Reduction for TCP
Proceedings of the 11th ACM SIGCOMM Conference on Internet Measurement 2011, Berlin, Germany - November 2-4, 2011
[u'Nandita Dukkipati', u'Matt Mathis', u'Yuchung Cheng', u'Monia Ghobadi']
Networking
Abstract: Packet losses increase latency for Web users. Fast recovery is a key mechanism for TCP to recover from packet losses. In this paper, we explore some of the weaknesses of the standard algorithm described in RFC 3517 and the non-standard algorithms implemented in Linux. We nd that these algorithms deviate from their intended behavior in the real world due to the combined eect of short ows, application stalls, burst losses, acknowledgment (ACK) loss and reordering, and stretch ACKs. Linux suers from excessive congestion window reductions while RFC 3517 transmits large bursts under high losses, both of which harm the rest of the ow and increase Web latency. Our primary contribution is a new design to control transmission in fast recovery called proportional rate reduction (PRR). PRR recovers from losses quickly, smoothly and accurately by pacing out retransmissions across received ACKs. In addition to PRR, we evaluate the TCP early retransmit (ER) algorithm which lowers the duplicate acknowledgment threshold for short transfers, and show that delaying early retransmissions for a short interval is eective in avoiding spurious retransmissions in the presence of a small degree of reordering. PRR and ER reduce the TCP latency of connections experiencing losses by 3-10% depending on the response size. Based on our instrumentation on Google Web and YouTube servers in U.S. and India, we also present key statistics on the nature of TCP retransmissions.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
QoS Policy Verification for DiffServ Networks
19th International Workshop on Quality of Service, IWQoS'11 (2011), pp. 1-3
[u'Taghrid Samak', u'Adel El-Atawy']
Networking
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37645.html
notfound
=========================
RFC6472 - Recommendation for Not Using AS_SET and AS_CONFED_SET in BGP
IETF (2011)
[u'Warren Kumari', u'Kotikalapudi Sriram']
Networking
Abstract: This document recommends against the use of the AS_SET and AS_CONFED_SET types of the AS_PATH in BGPv4. This is done to simplify the design and implementation of BGP and to make the semantics of the originator of a route more clear. This will also simplify the design, implementation, and deployment of ongoing work in the Secure Inter-Domain Routing Working Group.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37517.html
notfound
=========================
TCP Fast Open
Proceedings of the 7th International Conference on emerging Networking EXperiments and Technologies (CoNEXT), ACM (2011)
[u'Sivasankar Radhakrishnan', u'Yuchung Cheng', u'Jerry Chu', u'Arvind Jain', u'Barath Raghavan']
Networking
Abstract: Todays web services are dominated by TCP flows so short that they terminate a few round trips after handshaking; this handshake is a significant source of latency for such flows. In this paper we describe the design, implementation, and deployment of the TCP Fast Open protocol, a new mechanism that enables data exchange during TCPs initial handshake. In doing so, TCP Fast Open decreases application network latency by one full round-trip time, decreasing the delay experienced by such short TCP transfers. We address the security issues inherent in allowing data exchange during the three-way handshake, which we mitigate using a security token that verifies IP address ownership. We detail other fall-back defense mechanisms and address issues we faced with middleboxes, backwards compatibility for existing network stacks, and incremental deployment. Based on traffic analysis and network emulation, we show that TCP Fast Open would decrease HTTP transaction network latency by 15%and whole-page load time over 10% on average, and in some cases up to 40%
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37121.html
notfound
=========================
Topology Discovery of Sparse Random Graphs With Few Participants
ACM International Conference on Measurement and Modeling of Computer Systems SIGMETRICS (2011), Best Paper Award
[u'Animashree Anandkumar', u'Avinatan Hassidim', u'Jonathan Kelner']
Networking
Abstract: We consider the task of topology discovery of sparse random graphs using end-to-end random measurements (e.g., delay) between a subset of nodes, referred to as the participants. The rest of the nodes are hidden, and do not provide any information for topology discovery. We consider topology discovery under two routing models: (a) the participants exchange messages along the shortest paths and obtain end-to-end measurements, and (b) additionally, the participants exchange messages along the second shortest path. For scenario (a), our proposed algorithm results in a sub-linear edit-distance guarantee using a sub-linear number of uniformly selected participants. For scenario (b), we obtain a much stronger result, and show that we can achieve consistent reconstruction when a sub-linear number of uniformly selected nodes participate. This implies that accurate discovery of sparse random graphs is tractable using an extremely small number of participants. Our algorithms are simple to implement, computationally efficient, and exploit the locally tree-like property of sparse random graphs. We finally obtain a lower bound on the number of participants required by any algorithm to reconstruct the original random graph up to a given edit distance. We also demonstrate that while consistent discovery is tractable for sparse random graphs using a small number of participants, in general, there are graphs which cannot be discovered by any algorithm even with a significant number of participants, and with the availability of end-to-end information along all the paths between the participants.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37010.html
notfound
=========================
Universal Gigabit Optical Access
OFC/NFOEC 2011 Technical Digest, Optical Society of America, 2010 Massachusetts Ave, NW Washington, DC 20036 USA
[u'James F.Kelly']
Networking
Abstract: We review the imperatives on the optical communication technology industry to realize universal ultra high speed access to the worlds information.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36863.html
notfound
=========================
100GbE and Beyond for Warehouse Scale Computing
OptoeElectronics and Communications Conference (OECC) Technical Digest (2010), pp. 106-107
[u'Bikash Koley', u'Vijay Vusirikala', u'Cedric Lam', u'Vijay Gill']
Networking
Abstract: As computation and storage continues to move from desktops to large internet services, computing platforms running such services are transforming into warehouse-scale computers. 100 Gigabit Ethernet and beyond will be instrumental in scaling the interconnection within and between these ubiquitous warehouse-scale computing infrastructures. In this paper, we describe the drivers for such interfaces and some methods of scaling Ethernet interfaces to speeds beyond 100GbE.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36910.html
notfound
=========================
Access and Analyze Broadband Measurements Collected using M-Lab
Summer 2010 ESCC/Internet2 Joint Techs
[u'Tiziana Refice']
Networking
Abstract: Measurement Lab (M-Lab) is an open, distributed server platform for researchers, to deploy Internet measurement tools. Everybody can use M-Lab's tools to measure their own broadband connection performance. The M-Lab servers collect logs of all the users' tests and make them publicly available. As of July 2010, users have run millions of tests that have generated many terabytes of measurement data. This talk will present the public repositories of M-Lab data and will explain how to analyze M-Lab data using Google's BigQuery. BigQuery stores M-Lab's measurements logs in a table with more than 60 billions of rows. It takes less than 1 minute to run a query against the whole dataset.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36640.html
notfound
=========================
An Argument for Increasing TCP's Initial Congestion Window
ACM SIGCOMM Computer Communications Review, vol. 40 (2010), pp. 27-33
[u'Nandita Dukkipati', u'Tiziana Refice', u'Yuchung Cheng', u'Jerry Chu', u'Tom Herbert', u'Amit Agarwal', u'Arvind Jain', u'Natalia Sutin']
Networking
Abstract: TCP flows start with an initial congestion window of at most four segments or approximately 4KB of data. Because most Web transactions are short-lived, the initial congestion window is a critical TCP parameter in determining how quickly flows can finish. While the global network access speeds increased dramatically on average in the past decade, the standard value of TCPs initial congestion window has remained unchanged. In this paper, we propose to increase TCPs initial congestion window to at least ten segments (about 15KB). Through large-scale Internet experiments, we quantify the latency benefits and costs of using a larger window, as functions of network bandwidth, round-trip time (RTT), bandwidthdelay product (BDP), and nature of applications. We show that the average latency of HTTP responses improved by approximately 10% with the largest benefits being demonstrated in high RTT and BDP networks. The latency of low bandwidth networks also improved by a significant amount in our experiments. The average retransmission rate increased by a modest 0.5%, with most of the increase coming from applications that effectively circumvent TCPs slow start algorithm by using multiple concurrent connections. Based on the results from our experiments, we believe the initial congestion window should be at least ten segments and the same be investigated for standardization by the IETF.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36240.html
notfound
=========================
Evaluating IPv6 adoption in the Internet
PAM 2010, Springer
[u'Lorenzo Colitti', u'Steinar H. Gunderson', u'Erik Kline', u'Tiziana Refice']
Networking
Abstract: As IPv4 address space approaches exhaustion, large networks are deploying IPv6 or preparing for deployment. However, there is little data available about the quantity and quality of IPv6 connectivity. We describe a methodology to measure IPv6 adoption from the perspective of a Web site operator and to evaluate the impact that adding IPv6 to a Web site will have on its users. We apply our methodology to the Google Web site and present results collected over the last year. Our data show that IPv6 adoption, while growing significantly, is still low, varies considerably by country, and is heavily influenced by a small number of large deployments. We find that native IPv6 latency is comparable to IPv4 and provide statistics on IPv6 transition mechanisms used.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36936.html
notfound
=========================
FTTH look ahead technologies & architectures
ECOC 2010, Turin, Italy
[u'Cedric F. Lam']
Networking
Abstract: We review the trade-offs, challenges and potentials of various FTTH architecture options.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36603.html
notfound
=========================
Fiber Optic Communication Technologies: Whats Needed for Datacenter Network Operations
IEEE Communications Magazine, vol. Vol.48 No.7 (2010)
[u'Cedric F. Lam', u'Hong Liu', u'Bikash Koley', u'Xiaoxue Zhao', u'Valey Kamalov', u'Vijay Gill']
Networking
Abstract: The authors review the growing trend of warehouse-scale mega-datacenter computing, the Internet transformation driven by mega-datacenter applications, and the opportunities and challenges for fiber optic communication technologies to support the growth of mega-datacenter computing in the next three to four years.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36935.html
notfound
=========================
Field verification of 40G DPSK upgrade in a legacy 10G network
Optical Fiber Communication, IEEE (2010), NTuC2
[u'Valey Kamalov', u'Bikash Koley', u'Xiaoxue Zhao', u'Cedric F. Lam']
Networking
Abstract: We report verification of 1,200 km field upgrade of 10 G NRZ wavelengths with 40 G DPSK channels. Non symmetric dispersion map results in pronounced intra-channel nonlinear effect, which could be significantly reduced by dispersion pre-compensation
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36840.html
notfound
=========================
Hardware Requirements for Optical Circuit Switched Data Center Networks
IEEE Communication Society, IEEE Photonic Society, Optical Society of America, OFC/NFOEC 2011, Los Angeles (2010), OTuH3
[u'Nathan Farrington', u'Yeshaiahu Fainman', u'Hong Liu', u'George Papen', u'Amin Vahdat']
Networking
Abstract: Based on measurements of a prototype, we identify hardware requirements for improving the performance of hybrid electrical-packet-switched/optical-circuit-switched data center networks.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35159.html
notfound
=========================
Optimizing the update packet stream for web applications
ICST International Conference on Broadband Communications, Networks, and Systems (BROADNETS) (2010)
[u'Muthuprasanna Muthusrinivasan', u'Manimaran Govindarasu']
Networking
Abstract: The Internet has evolved to an extent where users now expect any-where any-time and any-form access to their personalized data and applications of choice. However providing a coherent (seamless) user experience across multiple devices has been relatively hard to achieve. While the 'how to sync' problem has been well studied in literature, the complementary 'when to sync' problem has remained relatively unexplored. While frequent updates providing higher user satisfaction/retention are naturally more desirable than sparse updates, the steadily escalating resource costs are a significant bottleneck. We thus propose extensions to the traditional periodic refresh model based on an adaptive 'smart sync approach' that enables variable rate updates closely modeling expected user behavior over time. An experimental evaluation of the proposed mechanism on a sizeable subset of users of the GMAIL web interface indicates that the proposed refresh policy can achieve the best of both worlds - limited resource provisioning and minimal user-perceived delays.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36670.html
notfound
=========================
Scaling Optical Interconnects in Datacenter Networks Opportunities and Challenges for WDM
2010 18th IEEE Symposium on High Performance Interconnects, IEEE, pp. 113-116
[u'Hong Liu', u'Cedric F. Lam', u'Chris Johnson']
Networking
Abstract: We review the growing need for optical interconnect bandwidth in datacenter networks, and the opportunities and challenges for wavelength division multiplexing (WDM) to sustain the last 2km bandwidth growth inside datacenter networks.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36604.html
notfound
=========================
TCP Option to Denote Packet Mood
Internet Engineering Task Force, http://ietf.org (2010), pp. 8
[u'Richard Hay', u'Warren Turkal']
Networking
Abstract: In an attempt to anthropomorphize the bit streams on countless physical layer networks throughout the world, we propose a TCP option to express packet mood. This can be addressed by adding TCP Options [RFC793] to the TCP header, using ASCII characters that encode commonly used "emoticons" to convey packet mood.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub39965.html
found
=========================
Usage Patterns in an Urban WiFi Network
IEEE/ACM Transactions on Networking, vol. 18 , Issue: 5 (2010), 1359 - 1372
[u'Mikhail Afanasyev', u'Tsuwei Chen']
Networking
Abstract: While WiFi was initially designed as a local-area access network, mesh networking technologies have led to increasingly expansive deployments of WiFi networks. In urban environments, the WiFi mesh frequently supplements a number of existing access technologies, including wired broadband networks, 3G cellular, and commercial WiFi hotspots. It is an open question what role citywide WiFi deployments play in the increasingly diverse access network spectrum. We study the usage of the Google WiFi network deployed in Mountain View, CA, and find that usage naturally falls into three classes based almost entirely on client device type, which we divide into traditional laptop users, fixed-location access devices, and PDA-like smartphone devices. Moreover, each of these classes of use has significant geographic locality, following the distribution of residential, commercial, and transportation areas of the city. When comparing the network usage of each device class, we find a diverse set of mobility patterns that map well to the archetypal use cases for traditional access technologies. To help place our results in context, we also provide key performance measurements of the mesh backbone and, where possible, compare them to those of previously studied urban mesh networks.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35247.html
notfound
=========================
Characterizing End-to-End Packet Reordering with UDP Traffic
IEEE Symposium on Computers and Communications (ISCC) (2009), pp. 321-324
[u'Sandra Tinta', u'Alexander Mohr', u'Jennifer Wong']
Networking
Abstract: Packet reordering is an Internet event that degrades the performance of both TCP and UDP-based applications. In this paper, we present an end-to-end measurement study of packet reordering of UDP traffic. The goal of the measurement study, performed on PlanetLab, was to answer four main questions: how prevalent is reordering across end-to-end paths, what are the time scales of reordered packets, how correlated is reordering with traffic load, and does the size of a transmitted packet affect the likelihood of reordering? Overall, our analysis shows that current UDP traffic reordering is consistent to prior 1990's studies on TCP traffic, despite increased Internet load and technology advancements, and it adds to the previous results by identifying additional reordering characteristics. More specifically, we show that packet reordering is asymmetric as well as temporal and site-dependent, packet size does influence the likelihood of reordering, that there exists a time-of-the-day dependency, and reordering primarily exists at two time-scales (a few milliseconds or multiple tens of milliseconds.)
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Competitive Routing over Time
Workshop of Internet Economics (WINE) (2009), pp. 18-29
[u'Martin Hoefer', u'Vahab S. Mirrokni', u'Heiko Rglin', u'Shang-Hua Teng']
Networking
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35154.html
notfound
=========================
Cost-efficient Dragonfly Topology for Large-scale Systems
Optical Fiber Communication Conference (OFC 2009)
[u'John Kim', u'William J. Dally', u'Steve Scott', u'Dennis Abts']
Networking
Abstract: Evolving technology and increasing pin-bandwidth motivate the use of high-radix routers to reduce the diameter, latency, and cost of interconnection networks. This migration from low-radix to high-radix routers is demonstrated with the recent introduction of high-radix routers and they are expected to impact networks used in large-scale systems such as multicomputers and data centers. As a result, a scalable and a cost-efficient topology is needed to properly exploit high-radix routers. High-radix networks require longer cables than their low-radix counterparts. Because cables dominate network cost, the number of cables, and particularly the number of long, global cables should be minimized to realize an efficient network. In this paper, we introduce the dragonfly topology which uses a group of high-radix routers as a virtual router to increase the effective radix of the network. With this organization, each minimally routed packet traverses at most one global channel. By reducing global channels, a dragonfly reduces cost by 20% compared to a flattened butterfly and by 52% compared to a folded Clos network in configurations with at least 16K nodes. The paper also introduces two new variants of global adaptive routing that enable load-balanced routing in the dragonfly. Each router in a dragonfly must make an adaptive routing decision based on the state of a global channel connected to a different router. Because of the indirect nature of this routing decision, conventional adaptive routing algorithms give degraded performance. We introduce the use of selective virtual-channel discrimination and the use of credit round-trip latency to both sense and signal channel congestion. The combination of these two methods gives throughput and latency that approaches that of an ideal adaptive routing algorithm.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35590.html
notfound
=========================
Moving Beyond End-to-End Path Information to Optimize CDN Performance
Internet Measurement Conference (IMC), ACM, Chicago, IL (2009), pp. 190-201
[u'Rupa Krishnan', u'Harsha V. Madhyastha', u'Sushant Jain', u'Sridhar Srinivasan', u'Arvind Krishnamurthy', u'Thomas Anderson', u'Jie Gao']
Networking
Abstract: Replicating content across a geographically distributed set of servers and redirecting clients to the closest server in terms of latency has emerged as a common paradigm for improving client performance. In this paper, we analyze latencies measured from servers in Googles content distribution network (CDN) to clients all across the Internet to study the effectiveness of latency-based server selection. Our main result is that redirecting every client to the server with least latency does not suffice to optimize client latencies. First, even though most clients are served by a geographically nearby CDN node, a sizeable fraction of clients experience latencies several tens of milliseconds higher than other clients in the same region. Second, we find that queueing delays often override the benefits of a client interacting with a nearby server. To help the administrators of Googles CDN cope with these problems, we have built a system called WhyHigh. First, WhyHigh measures client latencies across all nodes in the CDN and correlates measurements to identify the prefixes affected by inflated latencies. Second, since clients in several thousand prefixes have poor latencies, WhyHigh prioritizes problems based on the impact that solving them would have, e.g., by identifying either an AS path common to several inflated prefixes or a CDN node where path inflation is widespread. Finally, WhyHigh diagnoses the causes for inflated latencies using active measurements such as traceroutes and pings, in combination with datasets such as BGP paths and flow records. Typical causes discovered include lack of peering, routing misconfigurations, and side-effects of traffic engineering. We have used WhyHigh to diagnose several instances of inflated latencies, and our efforts over the course of a year have significantly helped improve the performance offered to clients by Googles CDN. An anonymized data set is available for download.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Passive aggressive measurement with MGRP
SIGCOMM '09: Proceedings of the ACM SIGCOMM 2009 conference on Data communication, ACM, New York, NY, USA, pp. 279-290
[u'Pavlos Papageorge', u'Justin McCann', u'Michael Hicks']
Networking
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
RACNet: a high-fidelity data center sensing network
SenSys '09: Proceedings of the 7th ACM Conference on Embedded Networked Sensor Systems, ACM, New York, NY, USA (2009), pp. 15-28
[u'Chieh-Jan Mike Liang', u'Jie Liu', u'Liqian Luo', u'Andreas Terzis', u'Feng Zhao']
Networking
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35216.html
notfound
=========================
RFC5635 - Remote Triggered Black Hole filtering with uRPF
IETF, IETF (2009)
[u'Warren Kumari']
Networking
Abstract: Remote Triggered Black Hole (RTBH) filtering is a popular and effective technique for the mitigation of denial-of-service attacks. This document expands upon destination-based RTBH filtering by outlining a method to enable filtering by source address as well.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35476.html
notfound
=========================
Wireless Techniques in Optical Transport
Proceedings of the 14th Optoelectronics and Communications Conference (2009)
[u'Cedric F. Lam']
Networking
Abstract: Abstract The field of optical communications is undergoing a transformation from analog to digital. Advanced signal processing techniques which have been widely used in wireless communications and local access loops are now being applied to long haul optical transmission networks. In this paper, we discuss the implications of such transformations and postulate a new paradigm for optical transport in future high speed optical backbone networks.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34430.html
found
=========================
Analysis of a Mixed-Use Urban WiFi Network: When Metropolitan becomes Neapolitan
IMC '08 Proceedings of the 8th ACM SIGCOMM conference on Internet measurement, ACM, New York, NY, USA (2008), pp. 85-98
[u'Mikhail Afanasyev', u'Tsuwei Chen', u'Geoffrey M. Voelker', u'Alex C. Snoeren']
Networking
Abstract: In this paper, we study the usage of the Google WiFi network deployed in Mountain View, California. We find that usage naturally falls into three categories, based almost entirely on client device type. Moreover, each of these classes of use has significant geographical, and transportation areas of the city. Finally, we find a diverse set of mobility patterns that map well to the archetypal use cases for traditional access technologies.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Answering What-If Deployment and Configuration Questions with WISE
ACM SIGCOMM'08 (2008)
[u'Mukarram Tariq', u'Amgad Zeitoun', u'Vytautas Valancius', u'Nick Feamster', u'Mostafa Ammar']
Networking
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Performance Optimization of TCP/IP over 10 Gigabit Ethernet by Precise Instrumentation
Proceedings of the 2008 ACM/IEEE conference on Supercomputing (SC08)
[u'Takeshi Yoshino', u'Yutaka Sugawara', u'Katsushi Inagami', u'Junji Tamatsukuri', u'Mary Inaba', u'Kei Hiraki']
Networking
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36959.html
notfound
=========================
Practical Large-Scale Latency Estimation
Computer Networks, vol. 52 (2008), pp. 1343-1364
[u'Michal Szymaniak', u'David L. Presotto', u'Guillaume Pierre', u'Maarten van Steen']
Networking
Abstract: We present the implementation of a large-scale latency estimation system based on GNP and incorporated into the Google content delivery network. Our implementation does not rely on active participation of Web clients, and carefully controls the overhead incurred by latency measurements using a scalable centralized scheduler. It also requires only a small number of CDN modifications, which makes it attractive for any CDN interested in large-scale latency estimation. We investigate the issue of coordinate stability over time and show that coordinates drift away from their initial values with time, so that 25% of node coordinates become inaccurate by more than 33 milliseconds after one week. However, daily recomputations make 75% of the coordinates stay within 6 milliseconds of their initial values. Furthermore, we demonstrate that using coordinates to decide on client-to-replica redirection leads to selecting replicas closest in term of measured latency in 86% of all cases. In another 10% of all cases, clients are redirected to replicas offering latencies that are at most two times longer than optimal. Finally, collecting a huge volume of latency data and using clustering techniques enable us to estimate latencies between globally distributed Internet hosts that have not participated in our measurements at all. The results are sufficiently promising that Google may offer a public interface to the latency estimates in the future.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41370.html
notfound
=========================
Remote Medical Monitoring Through Vehicular Ad Hoc Network
IEEE 68th Vehicular Technology Conference (VTC), 2008., IEEE, pp. 1-5
[u'Hyduke Noshadi', u'Eugenio Giordano', u'Hagop Hagopian', u'Giovanni Pau', u'Mario Gerla', u'Majid Sarrafzadeh']
Networking
Abstract: Several diseases and medical conditions require constant monitoring of physiological signals and vital signs on daily bases, such as diabetics, hypertension and etc. In order to make these patients capable of living their daily life it is necessary to provide a platform and infrastructure that allows the constant collection of physiological data even when the patient is not inside of the coverage area. The data must be rapidly "transported" to care givers or to the designated medical enterprise. The problem is particularly severe in case of emergencies (e.g. natural disasters or hostile attacks) when the communications infrastructure (e.g. cellular telephony, WiFi public access, etc) has failed or is totally congested. In this paper we present an evaluation of of the vehicular ad-hoc networks (VANET) as an alternate method of collecting patient pre-recorded physiological data and at the same time reconfiguring patient medical wearable body vests to select the data specifically requested by the physicians. Another important use of vehicular collection of medical data from body vests is prompted by the need to correlate pedestrian reaction to vehicular traffic hazards such as chemical and noise pollution and traffic congestion. The vehicles collect noise, chemical and traffic samples and can directly correlate with the "stress level" of volunteers.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
The End of Eternity
Cisco Internet Protocol Journal (IPJ), vol. 11 (2008)
[u'Niall Murphy', u'David Wilson']
Networking
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub32887.html
notfound
=========================
An Active Approach to Measuring Routing Dynamics Induced by Autonomous Systems
Workshop of Experimental Computer Science (ExpCS), ACM (2007)
[u'Samantha Lo', u'Rocky K. C. Chang', u'Lorenzo Colitti']
Networking
Abstract: We present an active measurement study of the routing dynamics induced by AS-path prepending, a common method for controlling the inbound traffic of a multi-homed ISP. Unlike other inter-domain inbound traffic engineering methods, AS-path prepending not only provides network resilience but does not increase routing table size. Unfortunately, ISPs often perform prepending on a trail-and-error basis, which can lead to suboptimal results and to a large amount of network churn. We study these effects by actively injecting prepended routes into the Internet routing system using the RIPE NCC RIS route collectors and observing the resulting changes from almost 200 publicly-accessible sources of BGP information. Our results show that our prepending methods are simple and effective and that a small number of ASes is often responsible for large amounts of the route changes caused by prepending. Furthermore, we show that our methods are able to reveal hidden prepending policies to prepending and tie-breaking decisions made by ASes; this is useful for further predicting the behavior of prepending.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub32974.html
notfound
=========================
Investigating prefix propagation through active BGP probing
Microprocessors and Microsystems, vol. 31, no. 7 (2007), pp. 460-474
[u'Lorenzo Colitti', u'Giuseppe Di Battista', u'Maurizio Patrignani', u'Maurizio Pizzonia', u'Massimo Rimondini']
Networking
Abstract: To devise effective network engineering strategies and to assess the quality of upstream providers, network operators would greatly benefit from the knowledge of which Internet paths might be traversed by the traffic flows entering their networks in the case of network faults or when traffic engineering measures are used. However, current methodologies do not provide this information. This paper presents methodologies to discover alternate paths that might be selected in the presence of network faults or different routing policies and to deduce the routing policies of other operators. The techniques are validated through extensive experimentation on the Internet.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
On the Accuracy of Multi-hop Relative Location Estimation in Wireless Sensor Networks
Proc. 2007 International Conference on Wireless Communications and Mobile Computing, ACM, Honolulu, pp. 481-486
[u'Adel Youssef', u'Mohamed Younis', u'Moustafa Youssef', u'Ashok Agrawala']
Networking
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub32806.html
notfound
=========================
The Complete April Fools RFCs
Peer-to-Peer Communications LLC, PO Box 6970, Charlottesville, VA, US 22906-6970 (2007)
[u'Thomas A. Limoncelli', u'Peter H. Salus']
Networking
Abstract: Collection of the "April Fools" RFCs published by IETF from 1969 through 2005. Commentary and forewards by various Internet innovators.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Fast and memory-efficient regular expression matching for deep packet inspection
Proc. 2006 ACM/IEEE Symposium on Architecture for networking and communication systems, ACM, San Jose, CA, pp. 93-102
[u'Fang Yu', u'Zhifeng Chen', u'Yanlei Diao', u'T. V. Lakshman', u'Randy H. Katz']
Networking
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Growth Codes: Maximizing Sensor Network Data Persistence
Proceedings of the 2006 conference on Applications, technologies, architectures, and protocols for computer communications, ACM, Pisa, Italy, pp. 255-266
[u'Abhinav Kamra', u'Vishal Misra', u'Jon Feldman', u'Dan Rubenstein']
Networking
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Optimal Multicasting of Multiple Light-Trees of Different Bandwidth Granularities in a WDM Mesh Network With Sparse Splitting Capabilities
IEEE/ACM Transactions on Networking, vol. 14 (2006), pp. 1104-1117
[u'Narendra K. Singhal', u'Laxman H. Sahasrabuddhe', u'Biswanath Mukherjee']
Networking
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
The Effects of Faults on Network Expansion
Theory of Computing Systems, vol. 39, no. 6 (2006), pp. 903-928
[u'Amithaba Bagchi', u'Ankur Bhargava', u'Amitabh Chaudhary', u'David Eppstein', u'Christian Scheideler']
Networking
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Data Reduction for the Scalable Automated Analysis of Distributed Darknet Traffic
Proceedings of the 2005 Internet Measurement Conference
[u'Michael Bailey', u'Evan Cooke', u'Farnam Jahanian', u'Niels Provos', u'Karl Rosaen', u'David Watson']
Networking
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Trickle: A Userland Bandwidth Shaper for Unix-like Systems
USENIX Annual Technical Conference, FREENIX Track (2005), pp. 61-70
[u'Marius Eriksen']
Networking
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Monkey See, Monkey Do: A Tool for TCP Tracing and Replaying
USENIX Annual Technical Conference, General Track (2004)
[u'Yu-Chung Cheng', u'Urs Hlzle', u'Neal Cardwell', u'Stefan Savage', u'Geoffrey M. Voelker']
Networking
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Topology discovery in heterogeneous IP networks: the
IEEE/ACM Trans. Netw., vol. 12 (2004), pp. 401-414
[u'Yuri Breitbart', u'Minos N. Garofalakis', u'Ben Jai', u'Cliff Martin', u'Rajeev Rastogi', u'Avi Silberschatz']
Networking
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/SecurityPrivacyandAbusePrevention.html
found
http://research.google.com/pubs/pub43346.html
notfound
=========================
Ad Injection at Scale: Assessing Deceptive Advertisement Modifications
Proceedings of the IEEE Symposium on Security and Privacy (2015)
[u'Kurt Thomas', u'Elie Bursztein', u'Chris Grier', u'Grant Ho', u'Nav Jagpal', u'Alexandros Kapravelos', u'Damon McCoy', u'Antonio Nappa', u'Vern Paxson', u'Paul Pearce', u'Niels Provos', u'Moheeb Abu Rajab']
SecurityPrivacyandAbusePrevention
Abstract: Today, web injection manifests in many forms, but fundamentally occurs when malicious and unwanted actors tamper directly with browser sessions for their own profit. In this work we illuminate the scope and negative impact of one of these forms, ad injection, in which users have ads imposed on them in addition to, or different from, those that websites originally sent them. We develop a multi-staged pipeline that identifies ad injection in the wild and captures its distribution and revenue chains. We find that ad injection has entrenched itself as a cross-browser monetization platform impacting more than 5% of unique daily IP addresses accessing Googletens of millions of users around the globe. Injected ads arrive on a clients machine through multiple vectors: our measurements identify 50,870 Chrome extensions and 34,407 Windows binaries, 38% and 17% of which are explicitly malicious. A small number of software developers support the vast majority of these injectors who in turn syndicate from the larger ad ecosystem. We have contacted the Chrome Web Store and the advertisers targeted by ad injectors to alert each of the deceptive practices involved.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43975.html
found
=========================
Attitudes Toward Vehicle-Based Sensing and Recording
Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing, ACM, pp. 1017-1028
[u'Manya Sleeper', u'Sebastian Schnorf', u'Brian Kemler', u'Sunny Consolvo']
SecurityPrivacyandAbusePrevention
Abstract: Vehicles increasingly include features that rely on hi-tech sensors and recording; however, little is known of public attitudes toward such recording. We use two studies, an online survey (n=349) and an interview-based study (n=15), to examine perceptions of vehicle-based sensing and recording. We focus on: 1) how vehicle-based recording and sensing may differ from perceptions of current recording; 2) factors that impact comfort with vehicle-based recording for hypothetical drivers versus bystanders; and 3) perceptions of potential privacy-preserving techniques. We find that vehicle-based recording challenges current mental models of recording awareness. Comfort tends to depend on perceived bene- fits, which can vary by stakeholder type. Perceived privacy in spaces near cars can also impact comfort and reflect mental models of private spaces as well as the range of potentially sensitive activities people perform in and near cars. Privacy-preserving techniques may increase perceived comfort but may require addressing trust and usability issues.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43979.html
found
=========================
Distributed Authorization With Distributed Grammars
Programming Languages with Applications to Biology and Security, Springer International Publishing Switzerland, Gewerbestrasse 11 CH-6330 Cham (ZG) Switzerland (2015) (to appear)
[u'Martin Abadi', u'Mike Burrows', u'Himabindu Pucha', u'Adam Sadovsky', u'Asim Shankar', u'Ankur Taly']
SecurityPrivacyandAbusePrevention
Abstract: While groups are generally helpful for the definition of authorization policies, their use in distributed systems is not straightforward. This paper describes a design for authorization in distributed systems that treats groups as formal languages. The design supports forms of delegation and negative clauses in authorization policies. It also considers the wish for privacy and efficiency in group-membership checks, and the possibility that group definitions may not all be available and may contain cycles.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43888.html
notfound
=========================
Fast and Secure Three-party Computation: The Garbled Circuit Approach
The 22nd ACM Conference on Computer and Communications Security, ACM (2015)
[u'Payman Mohassel', u'Mike Rosulek', u'Ye Zhang']
SecurityPrivacyandAbusePrevention
Abstract: Many deployments of secure multi-party computation (MPC) in practice have used information-theoretic three-party protocols that tolerate a single, semi-honest corrupt party, since these protocols enjoy very high efficiency. We propose a new approach for secure three-party computation (3PC) that improves security while maintaining practical efficiency that is competitive with traditional information theoretic protocols. Our protocol is based on garbled circuits and provides security against a single, malicious corrupt party. Unlike information-theoretic 3PC protocols, ours uses a constant number of rounds. Our protocol only uses inexpensive symmetric-key cryptography: hash functions, block ciphers, pseudorandom generators (in particular, no oblivious transfers) and has performance that is comparable to that of Yaos (semi-honest) 2PC protocol. We demonstrate the practicality of our protocol with an implementation based on the JustGarble framework of Bellare et al. (S&P 2013). The implementation incorporates various optimizations including the most recent techniques for efficient circuit garbling. We perform experiments on several benchmarking circuits, in different setups. Our experiments confirm that, despite providing a more demanding security guarantee, our protocol has performance comparable to existing information-theoretic 3PC.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43798.html
notfound
=========================
Framing Dependencies Introduced by Underground Commoditization
Workshop on the Economics of Information Security (2015)
[u'Kurt Thomas', u'Danny Huang', u'David Wang', u'Elie Bursztein', u'Chris Grier', u'Thomas J. Holt', u'Christopher Kruegel', u'Damon McCoy', u'Stefan Savage', u'Giovanni Vigna']
SecurityPrivacyandAbusePrevention
Abstract: Internet crime has become increasingly dependent on the underground economy: a loose federation of specialists selling capabilities, services, and resources explicitly tailored to the abuse ecosystem. Through these emerging markets, modern criminal entrepreneurs piece together dozens of la carte components into entirely new criminal endeavors. From an abuse fighting perspective, criminal reliance on this black market introduces fragile dependencies that, if disrupted, undermine entire operations that as a composite appear intractable to protect against. However, without a clear framework for examining the costs and infrastructure behind Internet crime, it becomes impossible to evaluate the effectiveness of novel intervention strategies. In this paper, we survey a wealth of existing research in order to systematize the communitys understanding of the underground economy. In the process, we develop a taxonomy of profit centers and support centers for reasoning about the flow of capital (and thus dependencies) within the black market. Profit centers represent activities that transfer money from victims and institutions into the underground. These activities range from selling products to unwitting customers (in the case of spamvertised products) to outright theft from victims (in case of financial fraud). Support centers provide critical resources that other miscreants request to streamline abuse. These include exploit kits, compromised credentials, and even human services (e.g., manual CAPTCHA solvers) that have no credible non-criminal applications. We use this framework to contextualize the latest intervention strategies and their effectiveness. In the end, we champion a drastic departure from solely focusing on protecting users and systems (tantamount to a fire fight) and argue security practitioners must also strategically disrupt frail underground relationships that underpin the entire for-profit abuse ecosystem--including actors, infrastructure, and access to capital.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43470.html
notfound
=========================
GraphSC: Parallel Secure Computation Made Easy
IEEE Symposium on Security and Privacy, IEEE (2015)
[u'Kartik Nayak', u'Xiao S. Wang', u'Stratis Ioannidis', u'Udi Weinsberg', u'Nina Taft', u'Elaine Shi']
SecurityPrivacyandAbusePrevention
Abstract: We propose introducing modern parallel programming paradigms to secure computation, enabling their secure execution on large datasets. To address this challenge, we present GraphSC, a framework that (i) provides a programming paradigm that allows non-cryptography experts to write secure code; (ii) brings parallelism to such secure implementations; and (iii) meets the needs for obliviousness, thereby not leaking any private information. Using GraphSC, developers can efficiently implement an oblivious version of graph-based algorithms (including sophisticated data mining and machine learning algorithms) that execute in parallel with minimal communication overhead. Importantly, our secure version of graph-based algorithms incurs a small logarithmic overhead in comparison with the non-secure parallel version. We build GraphSC and demonstrate, using several algorithms as examples, that secure computation can be brought into the realm of practicality for big data analysis. Our secure matrix factorization implementation can process 1 million ratings in 13 hours, which is a multiple order-of-magnitude improvement over the only other existing attempt, which requires 3 hours to process 16K ratings.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43265.html
found
=========================
Improving SSL Warnings: Comprehension and Adherence
Proceedings of the Conference on Human Factors and Computing Systems, ACM (2015)
[u'Adrienne Porter Felt', u'Alex Ainslie', u'Robert W. Reeder', u'Sunny Consolvo', u'Somas Thyagaraja', u'Alan Bettes', u'Helen Harris', u'Jeff Grimes']
SecurityPrivacyandAbusePrevention
Abstract: Browsers warn users when the privacy of an SSL/TLS connection might be at risk. An ideal SSL warning would empower users to make informed decisions and, failing that, guide confused users to safety. Unfortunately, users struggle to understand and often disregard real SSL warnings. We report on the task of designing a new SSL warning, with the goal of improving comprehension and adherence. We designed a new SSL warning based on recommendations from warning literature and tested our proposal with microsurveys and a field experiment. We ultimately failed at our goal of a well-understood warning. However, nearly 30% more total users chose to remain safe after seeing our warning. We attribute this success to opinionated design, which promotes safety with visual cues. Subsequently, our proposal was released as the new Google Chrome SSL warning. We raise questions about warning comprehension advice and recommend that other warning designers use opinionated design.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43294.html
notfound
=========================
Internal Access Controls
Communications of the ACM, vol. 58 (2015), pp. 62-65
[u'Geetanjali Sampemane']
SecurityPrivacyandAbusePrevention
Abstract: Trust, but verify.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43962.html
notfound
=========================
Neither Snow Nor Rain Nor MITM ... An Empirical Analysis of Email Delivery Security
Proceedings of the Internet Measurement Conferene (2015)
[u'Zakir Durumeric', u'David Adrian', u'Ariana Mirian', u'James Kasten', u'Elie Bursztein', u'Nicolas Lidzborski', u'Kurt Thomas', u'Vijay Eranti', u'Michael Bailey', u'J. Alex Halderman']
SecurityPrivacyandAbusePrevention
Abstract: The SMTP protocol is responsible for carrying some of users most intimate communication, but like other Internet protocols, authentication and confidentiality were added only as an afterthought. In this work, we present the first report on global adoption rates of SMTP security extensions, including: STARTTLS, SPF, DKIM, and DMARC. We present data from two perspectives: SMTP server configurations for the Alexa Top Million domains, and over a year of SMTP connections to and from Gmail. We find that the top mail providers (e.g., Gmail, Yahoo, and Outlook) all proactively encrypt and authenticate messages. However, these best practices have yet to reach widespread adoption in a long tail of over 700,000 SMTP servers, of which only 35% successfully configure encryption, and 1.1% specify a DMARC authentication policy. This security patchwork -- paired with SMTP policies that favor failing open to allow gradual deployment -- exposes users to attackers who downgrade TLS connections in favor of cleartext and who falsify MX records to reroute messages. We present evidence of such attacks in the wild, highlighting seven countries where more than 20% of inbound Gmail messages arrive in cleartext due to network attackers.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44313.html
found
=========================
RFC 7646 -Definition and Use of DNSSEC Negative Trust Anchors
IETF RFCs, Internet Engineering Task Force (2015), pp. 15
[u'Warren Kumari', u'Jason Livingood', u'Chris Griffiths']
SecurityPrivacyandAbusePrevention
Abstract: DNS Security Extensions (DNSSEC) is now entering widespread deployment. However, domain signing tools and processes are not yet as mature and reliable as those for non-DNSSEC-related domain administration tools and processes. This document defines Negative Trust Anchors (NTAs), which can be used to mitigate DNSSEC validation failures by disabling DNSSEC validation at specified domains.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43973.html
found
=========================
RSSAC002 - RSSAC Advisory on Measurements of the Root Server System
ICANN Root Server System Advisory Committee ( RSSAC ) Reports and Advisories, Internet Corporation for Assigned Names and Numbers (ICANN) (2015), pp. 15
[u'Warren Kumari']
SecurityPrivacyandAbusePrevention
Abstract: RSSAC has begun work to determine a list of parameters that define the desired service trends for the root zone system. These parameters include the measured latency in the distribution of the root zone, the frequency of the updates, and their size. With knowledge of these parameters in hand, RSSAC can then seek to produce estimates of acceptable root zone size dynamics to ensure the overall system works within a set of parameters. The future work to define these parameters will involve RSSAC working closely with the root server operators to gather best practice estimates for the size and update frequency of the root zone. It must be well understood that the measurements described in this document are a response to the current awareness, experience, and understanding of the Root Zone System. As time progresses more, less, or entirely different metrics may be required to investigate new concerns or defined problem statements.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44272.html
notfound
=========================
Reasoning about Risk and Trust in an Open World
Victoria University of Wellington (2015)
[u'Sophia Drossopoulou', u'James Noble', u'Toby Murray', u'Mark S. Miller']
SecurityPrivacyandAbusePrevention
Abstract: Contemporary open systems use components developed by different parties, linked together dynamically in unforeseen constellations. Code needs to live up to strict security requirements, and ensure the correct functioning of its objects even when they collaborate with external, potentially malicious, objects. In this paper we propose special specification predicates that model risk and trust in open systems. We specify Miller, Van Cutsem, and Tullohs escrow exchange example, and discuss the meaning of such a specification. We propose a novel Hoare logic, based on four-tuples, including an invariant describing properties preserved by the execution of a statement as well as a post-condition describing the state after execution. We model specification and programing languages based on the Hoare logic, prove soundness, and prove the key steps of the Escrow protocol.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43821.html
found
=========================
SAC070 - SSAC Advisory on the Use of Static TLD / Suffix Lists
ICANN Security and Stability Advisory Committee (SSAC) Reports and Advisories, ICANN (2015), pp. 32
[u'Warren Kumari', u'Jaap Akkerhuis', u'Patrik Fltstrm']
SecurityPrivacyandAbusePrevention
Abstract: This advisory investigates the security and stability needs surrounding the growing use of public suffix lists on the Internet. For the purposes of this Advisory, a public suffix is defined as a domain under which multiple parties that are unaffiliated with the owner of the Public Suffix domain may register subdomains. Examples of Public Suffix domains include "org", "co.uk", "k12.wa.us" and "uk.com". There is no programmatic way to determine the boundary where a Domain Name System (DNS) label changes stewardship from a public suffix, yet tracking the boundary accurately is critically important for security, privacy, and usability issues in many modern systems and applications, such as web browsers. One method of determining this boundary is by use of public suffix lists (PSLs), which are static files listing the known public suffixes.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43783.html
found
=========================
Secrets, Lies, and Account Recovery: Lessons from the Use of Personal Knowledge Questions at Google
WWW'15 - Proceedings of the 22nd international conference on World Wide Web, ACM (2015)
[u'Joseph Bonneau', u'Elie Bursztein', u'Ilan Caron', u'Rob Jackson', u'Mike Williamson']
SecurityPrivacyandAbusePrevention
Abstract: We examine the first large real-world data set on personal knowledge question's security and memorability from their deployment at Google. Our analysis confirms that secret questions generally offer a security level that is far lower than user-chosen passwords. It turns out to be even lower than proxies such as the real distribution of surnames in the population would indicate. Surprisingly, we found that a significant cause of this insecurity is that users often don't answer truthfully. A user survey we conducted revealed that a significant fraction of users (37%) who admitted to providing fake answers did so in an attempt to make them "harder to guess" although on aggregate this behavior had the opposite effect as people "harden" their answers in a predictable way. On the usability side, we show that secret answers have surprisingly poor memorability despite the assumption that reliability motivates their continued deployment. From millions of account recovery attempts we observed a significant fraction of users (e.g 40\% of our English-speaking US users) were unable to recall their answers when needed. This is lower than the success rate of alternative recovery mechanisms such as SMS reset codes (over 80%). Comparing question strength and memorability reveals that the questions that are potentially the most secure (e.g what is your first phone number) are also the ones with the worst memorability. We conclude that it appears next to impossible to find secret questions that are both secure and memorable. Secret questions continue have some use when combined with other signals, but they should not be used alone and best practice should favor more reliable alternatives.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44195.html
found
=========================
Supporting Privacy-Conscious App Update Decisions with User Reviews
Proceedings of the 5th Annual ACM CCS Workshop on Security and Privacy in Smartphones and Mobile Devices, ACM, New York, NY, USA (2015), pp. 51-61
[u'Yuan Tian', u'Bin Liu', u'Weisi Dai', u'Blase Ur', u'Patrick Tague', u'Lorrie Faith Cranor']
SecurityPrivacyandAbusePrevention
Abstract: Smartphone app updates are critical to user security and privacy. New versions may fix important security bugs, which is why users should usually update their apps. However, occasionally apps turn malicious or radically change features in a way users dislike. Users should not necessarily always update in those circumstances, but current update processes are largely automatic. Therefore, it is important to understand user behaviors around updating apps and help them to make security-conscious choices. We conducted two related studies in this area. First, to understand users' current update decisions, we conducted an online survey of user attitudes toward updates. Based on the survey results, we then designed a notification scheme integrating user reviews, which we tested in a field study. Participants installed an Android app that simulated update notifications, enabling us to collect users' update decisions and reactions. We compared the effectiveness of our review-based update notifications with the permission-based notifications. Compared to notifications with permission descriptions only, we found our review-based update notification was more effective at alerting users of invasive or malicious app updates, especially for less trustworthy apps.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43808.html
notfound
=========================
Swapsies on the Internet: First Steps towards Reasoning about Risk and Trust in an Open World
Tenth Workshop on Programming Languages and Analysis for Security (PLAS 2015), ACM
[u'Sophia Drossopoulou', u'James Noble', u'Mark S. Miller']
SecurityPrivacyandAbusePrevention
Abstract: Contemporary open systems use components developed by many different parties, linked together dynamically in unforeseen constellations. Code needs to live up to strict security specifications: it has to ensure the correct functioning of its objects when they collaborate with external objects which may be malicious. In this paper we propose specifications that model risk and trust in such open systems. We specify Miller, Van Cutsem, and Tullohs escrow exchange example, and discuss the meaning of such a specification. We argue informally that the code satisfies its specification.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43856.html
notfound
=========================
The Correctness-Security Gap in Compiler Optimization
Security and Privacy Workshops (SPW), 2015 IEEE, IEEE, pp. 73-87
[u"Vijay D'Silva", u'Mathias Payer', u'Dawn Song']
SecurityPrivacyandAbusePrevention
Abstract: There is a significant body of work devoted to testing, verifying, and certifying the correctness of optimizing compilers. The focus of such work is to determine if source code and optimized code have the same functional semantics. In this paper, we introduce the correctness-security gap, which arises when a compiler optimization preserves the functionality of but violates a security guarantee made by source code. We show with concrete code examples that several standard optimizations, which have been formally proved correct, in-habit this correctness-security gap. We analyze this gap and conclude that it arises due to techniques that model the state of the program but not the state of the underlying machine. We propose a broad research programme whose goal is to identify, understand, and mitigate the impact of security errors introduced by compiler optimizations. Our proposal includes research in testing, program analysis, theorem proving, and the development of new, accurate machine models for reasoning about the impact of compiler optimizations on security.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43809.html
notfound
=========================
The Performance Cost of Shadow Stacks and Stack Canaries
Proceedings of the 10th ACM Symposium on Information, Computer and Communications Security (ASIACCS), ACM (2015), pp. 555-566
[u'Thurston H.Y. Dang', u'Petros Maniatis', u'David Wagner']
SecurityPrivacyandAbusePrevention
Abstract: Control flow defenses against ROP either use strict, expensive, but strong protection against redirected RET instructions with shadow stacks, or much faster but weaker protections without. In this work we study the inherent overheads of shadow stack schemes. We find that the overhead is roughly 10% for a traditional shadow stack. We then design a new scheme, the parallel shadow stack, and show that its performance cost is significantly less: 3.5%. Our measurements suggest it will not be easy to improve performance on current x86 processors further, due to inherent costs associated with RET and memory load/store instructions. We conclude with a discussion of the design decisions in our shadow stack instrumentation, and possible lighter-weight alternatives.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43862.html
found
=========================
Thwarting Fake OSN Accounts by Predicting their Victims
AI-Sec'2015, ACM (to appear)
[u'Yazan Boshmaf', u'Matei Ripeanu', u'Konstantin Beznosov', u'Elizeu Santos-Neto']
SecurityPrivacyandAbusePrevention
Abstract: Traditional defense mechanisms for fighting against automated fake accounts in online social networks are victim-agnostic. Even though victims of fake accounts play an important role in the viability of subsequent attacks, there is no work on utilizing this insight to improve the status quo. In this position paper, we take the first step and propose to incorporate predictions about victims of unknown fakes into the workflows of existing defense mechanisms. In particular, we investigated how such an integration could lead to more robust fake account defense mechanisms. We also used real world datasets from Facebook and Tuenti to evaluate the feasibility of predicting victims of fake accounts using supervised machine learning.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43824.html
notfound
=========================
Trends and Lessons from Three Years Fighting Malicious Extensions
USENIX Security Symposium (2015)
[u'Nav Jagpal', u'Eric Dingle', u'Jean-Philippe Gravel', u'Panayiotis Mavrommatis', u'Niels Provos', u'Moheeb Abu Rajab', u'Kurt Thomas']
SecurityPrivacyandAbusePrevention
Abstract: In this work we expose wide-spread efforts by criminals to abuse the Chrome Web Store as a platform for distributing malicious extensions. A central component of our study is the design and implementation of WebEval, the first system that broadly identifies malicious extensions with a concrete, measurable detection rate of 96.5%. Over the last three years we detected 9,523 malicious extensions: nearly 10% of every extension submitted to the store. Despite a short window of operation---we removed 50% of malware within 25 minutes of creation---a handful of under 100 extensions escaped immediate detection and infected over 50 million Chrome users. Our results highlight that the extension abuse ecosystem is drastically different from malicious binaries: miscreants profit from web traffic and user tracking rather than email spam or banking theft.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43426.html
notfound
=========================
Understanding Sensitivity by Analyzing Anonymity
IEEE Security & Privacy, vol. 13 (2015), pp. 14-21
[u'Sai Teja Peddinti', u'Aleksandra Korolova', u'Elie Bursztein', u'Geetanjali Sampemane']
SecurityPrivacyandAbusePrevention
Abstract: The range of topics that users of online services consider sensitive is often broader than what service providers or regulators deem sensitive. A data-driven approach can help providers improve products with features that let users exercise privacy preferences more effectively.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43963.html
found
=========================
...no one can hack my mind: Comparing Expert and Non-Expert Security Practices
Proceedings of the Eleventh Symposium On Usable Privacy and Security, USENIX (2015), pp. 327-346
[u'Iulia Ion', u'Rob Reeder', u'Sunny Consolvo']
SecurityPrivacyandAbusePrevention
Abstract: The state of advice given to people today on how to stay safe online has plenty of room for improvement. Too many things are asked of them, which may be unrealistic, time consuming, or not really worth the effort. To improve the security advice, our community must find out what practices people use and what recommendations, if messaged well, are likely to bring the highest benefit while being realistic to ask of people. In this paper, we present the results of a study which aims to identify which practices people do that they consider most important at protecting their security online. We compare self-reported security practices of non-experts to those of security experts (i.e., participants who reported having five or more years of experience working in computer security). We report on the results of two online surveysone with 231 security experts and one with 294 MTurk participantson what the practices and attitudes of each group are. Our findings show a discrepancy between the security practices that experts and non-experts report taking. For instance, while experts most frequently report installing software updates, using two-factor authentication and using a password manager to stay safe online, non-experts report using antivirus software, visiting only known websites, and changing passwords frequently.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42903.html
notfound
=========================
A Language-Based Approach to Secure Quorum Replication
Proceedings of the Ninth Workshop on Programming Languages and Analysis for Security (2014), pp. 27-39
[u'Lantian Zheng', u'Andrew C. Myers']
SecurityPrivacyandAbusePrevention
Abstract: Quorum replication is an important technique for building distributed systems because it can simultaneously improve both the integrity and availability of computation and storage. Information flow control is a well-known method for enforcing the confidentiality and integrity of information. This paper demonstrates that these two techniques can be integrated to simultaneously enforce all three major security properties: confidentiality, integrity and availability. It presents a security-typed language with explicit language constructs for supporting secure quorum replication. The dependency analysis performed by the type system of the language provides a way to formally verify the end-to-end security assurance of complex replication schemes. We also contribute a new multilevel timestamp mechanism for synchronizing code and data replicas while controlling the side channels such mechanisms introduce.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43231.html
notfound
=========================
BeyondCorp: A New Approach to Enterprise Security
;login:, vol. Vol. 39, No. 6 (2014), pp. 6-11
[u'Rory Ward', u'Betsy Beyer']
SecurityPrivacyandAbusePrevention
Abstract: Virtually every company today uses firewalls to enforce perimeter security. However, this security model is problematic because, when that perimeter is breached, an attacker has relatively easy access to a companys privileged intranet. As companies adopt mobile and cloud technologies, the perimeter is becoming increasingly difficult to enforce. Google is taking a different approach to network security. We are removing the requirement for a privileged intranet and moving our corporate applications to the Internet.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Cloak and Swagger: Understanding Data Sensitivity through the Lens of User Anonymity
2014 IEEE Symposium on Security and Privacy, SP 2014, Berkeley, CA, USA, May 18-21, 2014, IEEE Computer Society, pp. 493-508
[u'Sai Teja Peddinti', u'Aleksandra Korolova', u'Elie Bursztein', u'Geetanjali Sampemane']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Communities, Random Walks, and Social Sybil Defense.
Internet Mathematics (2014)
[u'Lorenzo Alvisi', u'Allen Clement', u'Alessandro Epasto', u'Silvio Lattanzi', u'Alessandro Panconesi']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43134.html
notfound
=========================
Dialing Back Abuse on Phone Verified Accounts
Proceedings of the 21st ACM Conference on Computer and Communications Security (2014)
[u'Kurt Thomas', u'Dmytro Iatskiv', u'Elie Bursztein', u'Tadek Pietraszek', u'Chris Grier', u'Damon McCoy']
SecurityPrivacyandAbusePrevention
Abstract: In the past decade the increase of for-profit cybercrime has given rise to an entire underground ecosystem supporting large-scale abuse, a facet of which encompasses the bulk registration of fraudulent accounts. In this paper, we present a 10 month longitudinal study of the underlying technical and financial capabilities of criminals who register phone verified accounts (PVA). To carry out our study, we purchase 4,695 Google PVA as well as acquire a random sample of 300,000 Google PVA through a collaboration with Google. We find that miscreants rampantly abuse free VOIP services to circumvent the intended cost of acquiring phone numbers, in effect undermining phone verification. Combined with short lived phone numbers from India and Indonesia that we suspect are tied to human verification farms, this confluence of factors correlates with a market-wide price drop of 30--40% for Google PVA until Google penalized verifications from frequently abused carriers. We distill our findings into a set of recommendations for any services performing phone verification as well as highlight open challenges related to PVA abuse moving forward.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42507.html
notfound
=========================
Dividing secrets to secure data outsourcing
Information Sciences, vol. 263 (2014), pp. 198-210
[u'Fatih Emekci', u'Ahmed Methwally', u'Divyakant Agrawal', u'Amr El Abbadi']
SecurityPrivacyandAbusePrevention
Abstract: Data outsourcing or database as a service is a new paradigm for data management. The third party service provider hosts databases as a service. These parties provide efficient and cheap data management by obviating the need to purchase expensive hardware and software, deal with software upgrades and hire professionals for administrative and maintenance tasks. However, due to recent governmental legislations, competition among companies and database thefts, companies cannot use database service providers directly. They need secure and privacy preserving data management techniques to be able to use them in practice. Since data is remotely stored in a privacy preserving manner, there are efficiency related problems such as poor query response time. We propose a new framework that provides efficient and scalable query response times by reducing the computation and communication costs. Furthermore, the proposed technique uses several service providers to guarantee the availability of the services while detecting the dishonest or faulty service providers without introducing additional overhead on the query response time. The evaluations demonstrate that our data outsourcing framework is scalable and practical.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42808.html
notfound
=========================
Enforcing Forward-Edge Control-Flow Integrity in GCC & LLVM
Proceedings of the 23rd Usenix Security Symposium, USENIX, San Diego, CA (2014)
[u'Caroline Tice', u'Tom Roeder', u'Peter Collingbourne', u'Stephen Checkoway', u'lfar Erlingsson', u'Luis Lozano', u'Geoff Pike']
SecurityPrivacyandAbusePrevention
Abstract: Constraining dynamic control transfers is a common technique for mitigating software vulnerabilities. This defense has been widely and successfully used to protect return addresses and stack data; hence, current attacks instead typically corrupt vtable and function pointers to subvert a forward edge (an indirect jump or call) in the control-flow graph. Forward edges can be protected using Control-Flow Integrity (CFI) but, to date, CFI implementations have been research prototypes, based on impractical assumptions or ad hoc, heuristic techniques. To be widely adoptable, CFI mechanisms must be integrated into production compilers and be compatible with software-engineering aspects such as incremental compilation and dynamic libraries. This paper presents implementations of fine-grained, forward-edge CFI enforcement and analysis for GCC and LLVM that meet the above requirements. An analysis and evaluation of the security, performance, and resource consumption of these mechanisms applied to the SPEC CPU2006 benchmarks and common benchmarks for the Chromium web browser show the practicality of our approach: these fine-grained CFI mechanisms have significantly lower overhead than recent academic CFI prototypes. Implementing CFI in industrial compiler frameworks has also led to insights into design tradeoffs and practical challenges, such as dynamic loading.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41927.html
found
=========================
Experimenting At Scale With Google Chrome's SSL Warning
ACM CHI Conference on Human Factors in Computing Systems (2014)
[u'Adrienne Porter Felt', u'Robert W. Reeder', u'Hazim Almuhimedi', u'Sunny Consolvo']
SecurityPrivacyandAbusePrevention
Abstract: Web browsers shown HTTPS authentication warnings (i.e., SSL warnings) when the integrity and confidentiality of users' interactions with websites are at risk. Our goal in this work is to decrease the number of users who click through the Google Chrome SSL warning. Prior research showed that the Mozilla Firefox SSL warning has a much lower click-through rate (CTR) than Chrome. We investigate several factors that could be responsible: the use of imagery, extra steps before the user can proceed, and style choices. To test these factors, we ran six experimental SSL warnings in Google Chrome 29 and measured 130,754 impressions.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43469.html
found
=========================
Handcrafted Fraud and Extortion: Manual Account Hijacking in the Wild
IMC '14 Proceedings of the 2014 Conference on Internet Measurement Conference, ACM, 1600 Amphitheatre Parkway, pp. 347-358
[u'Elie Bursztein', u'Borbala Benko', u'Daniel Margolis', u'Tadek Pietraszek', u'Andy Archer', u'Allan Aquino', u'Andreas Pitsillidis', u'Stefan Savage']
SecurityPrivacyandAbusePrevention
Abstract: Online accounts are inherently valuable resources---both for the data they contain and the reputation they accrue over time. Unsurprisingly, this value drives criminals to steal, or hijack, such accounts. In this paper we focus on manual account hijacking---account hijacking performed manually by humans instead of botnets. We describe the details of the hijacking workflow: the attack vectors, the exploitation phase, and post-hijacking remediation. Finally we share, as a large online company, which defense strategies we found effective to curb manual hijacking.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43406.html
found
=========================
Helping You Protect You
IEEE (2014), pp. 39-42
[u'M. Angela Sasse', u'Charles C. Palmer', u'Markus Jakobsson', u'Sunny Consolvo', u'Rick Wash', u'L. Jean Camp']
SecurityPrivacyandAbusePrevention
Abstract: Guest editors M. Angela Sasse and Charles C. Palmer speak with security practitioners (L. Jean Camp, Sunny Consolvo, Markus Jakobsson, and Rick Wash) about what companies are doing to keep customers secure, and what users can do to stay safe.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41892.html
found
=========================
Macaroons: Cookies with Contextual Caveats for Decentralized Authorization in the Cloud
Network and Distributed System Security Symposium, Internet Society (2014)
[u'Arnar Birgisson', u'Joe Gibbs Politz', u'lfar Erlingsson', u'Ankur Taly', u'Michael Vrable', u'Mark Lentczner']
SecurityPrivacyandAbusePrevention
Abstract: Controlled sharing is fundamental to distributed systems; yet, on the Web, and in the Cloud, sharing is still based on rudimentary mechanisms. More flexible, decentralized cryptographic authorization credentials have not been adopted, largely because their mechanisms have not been incrementally deployable, simple enough, or efficient enough to implement across the relevant systems and devices. This paper introduces macaroons: flexible authorization credentials for Cloud services that support decentralized delegation between principals. Macaroons are based on a construction that uses nested, chained MACs (e.g., HMACs) in a manner that is highly efficient, easy to deploy, and widely applicable. Although macaroons are bearer credentials, like Web cookies, macaroons embed caveats that attenuate and contextually confine when, where, by who, and for what purpose a target service should authorize requests. This paper describes macaroons and motivates their design, compares them to other credential systems, such as cookies and SPKI/SDSI, evaluates and measures a prototype implementation, and discusses practical security and application considerations. In particular, it is considered how macaroons can enable more fine-grained authorization in the Cloud, e.g., by strengthening mechanisms like OAuth2, and a formalization of macaroons is given in authorization logic.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
MiniBox: A Two-Way Sandbox for x86 Native Code
Proceedings of the Usenix Annual Technical Conference, Usenix (2014)
[u'Yanlin Li', u'Jonathan McCune', u'James Newsome', u'Adrian Perrig', u'Brandon Baker', u'Will Drewry']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43239.html
notfound
=========================
Moving Targets: Security and Rapid-Release in Firefox
Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security, ACM, New York, NY, pp. 1256-1266
[u'Sandy Clark', u'Michael Collis', u'Matt Blaze', u'Jonathan M. Smith']
SecurityPrivacyandAbusePrevention
Abstract: Software engineering practices strongly affect the security of the code produced. The increasingly popular Rapid Release Cycle (RRC) development methodology and easy network software distribution have enabled rapid feature introduction. RRC's defining characteristic of frequent software revisions would seem to conflict with traditional software engineering wisdom regarding code maturity, reliability and reuse, as well as security. Our investigation of the consequences of rapid release comprises a quantitative, data-driven study of the impact of rapid-release methodology on the security of the Mozilla Firefox browser. We correlate reported vulnerabilities in multiple rapid release versions of Firefox code against those in corresponding extended release versions of the same system; using a common software base with different release cycles eliminates many causes other than RRC for the observables. Surprisingly, the resulting data show that Firefox RRC does not result in higher vulnerability rates and, further, that it is exactly the unfamiliar, newly released software (the "moving targets") that requires time to exploit. These provocative results suggest that a rethinking of the consequences of software engineering practices for security may be warranted.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42852.html
found
=========================
RAPPOR: Randomized Aggregatable Privacy-Preserving Ordinal Response
Proceedings of the 21st ACM Conference on Computer and Communications Security, ACM, Scottsdale, Arizona (2014) (to appear)
[u'lfar Erlingsson', u'Vasyl Pihur', u'Aleksandra Korolova']
SecurityPrivacyandAbusePrevention
Abstract: Randomized Aggregatable Privacy-Preserving Ordinal Response, or RAPPOR, is a technology for crowdsourcing statistics from end-user client software, anonymously, with strong privacy guarantees. In short, RAPPORs allow the forest of client data to be studied, without permitting the possibility of looking at individual trees. By applying randomized response in a novel manner, RAPPOR provides the mechanisms for such collection as well as for efficient, high-utility analysis of the collected data. In particular, RAPPOR permits statistics to be collected on the population of client-side strings with strong privacy guarantees for each client, and without linkability of their reports. This paper describes and motivates RAPPOR, details its differential-privacy and utility guarantees, discusses its practical deployment and properties in the face of different attack models, and, finally, gives results of its application to both synthetic and real-world data.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42943.html
found
=========================
RFC7344 - Automating DNSSEC Delegation Trust Maintenance
IETF RFCs, Internet Engineering Task Force (2014)
[u'Warren Kumari']
SecurityPrivacyandAbusePrevention
Abstract: This document describes a method to allow DNS Operators to more easily update DNSSEC Key Signing Keys using the DNS as a communication channel. The technique described is aimed at delegations in which it is currently hard to move information from the Child to Parent.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42190.html
found
=========================
SSAC Advisory on Search List Processing
ICANN Security and Stability Advisory Committee (SSAC) Reports and Advisories, ICANN (2014), pp. 17
[u'Warren Kumari', u'Jaap Akkerhuis', u'Don Blumenthal']
SecurityPrivacyandAbusePrevention
Abstract: This advisory examines how current operating systems and applications process search lists. It outlines the issues related to the current search list behavior, and proposes both a strawman to improve search list processing in the long term and mitigation options for the Internet Corporation for Assigned Names and Numbers (ICANN) and the Internet community to consider in the short term. The purpose of these proposals is to help introduce new generic Top Level Domains (gTLDs) in a secure and stable manner with minimum disruptions to currently deployed systems.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42934.html
notfound
=========================
Securing the Tangled Web
Communications of the ACM, vol. 57, no. 9 (2014), pp. 38-47
[u'Christoph Kern']
SecurityPrivacyandAbusePrevention
Abstract: Preventing script injection vulnerabilities through software design. Script injection vulnerabilities are a bane of Web application development: deceptively simple in cause and remedy, they are nevertheless surprisingly difficult to prevent in large-scale Web development. Cross-site scripting (XSS) arises when insufficient data validation, sanitization, or escaping within a Web application allow an attacker to cause browser-side execution of malicious JavaScript in the application's context. This injected code can then do whatever the attacker wants, using the privileges of the victim. Exploitation of XSS bugs results in complete (though not necessarily persistent) compromise of the victim's session with the vulnerable application. This article provides an overview of how XSS vulnerabilities arise and why it is so difficult to avoid them in real-world Web application software development. Software design patterns developed at Google to address the problem are then described.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43464.html
found
=========================
The End is Nigh: Generic Solving of Text-based CAPTCHAs
WOOT'14 Proceedings of the 8th USENIX conference on Offensive Technologies, Usenix (2014)
[u'Elie Bursztein', u'Jonathan Aigrain', u'Angelika Moscicki', u'John C. Mitchell']
SecurityPrivacyandAbusePrevention
Abstract: Over the last decade, it has become well-established that a captchas ability to withstand automated solving lies in the difficulty of segmenting the image into individual characters. The standard approach to solving captchas automatically has been a sequential process wherein a segmentation algorithm splits the image into segments that contain individual characters, followed by a character recognition step that uses machine learning. While this approach has been effective against particular captcha schemes, its generality is limited by the segmentation step, which is hand-crafted to defeat the distortion at hand. No general algorithm is known for the character collapsing anti-segmentation technique used by most prominent real world captcha schemes. This paper introduces a novel approach to solving captchas in a single step that uses machine learning to attack the segmentation and the recognition problems simultaneously. Performing both operations jointly allows our algorithm to exploit information and context that is not available when they are done sequentially. At the same time, it removes the need for any hand-crafted component, making our approach generalize to new captcha schemes where the previous approach can not. We were able to solve all the real world captcha schemes we evaluated ac- curately enough to consider the scheme insecure in practice, including Yahoo (5.33%) and ReCaptcha (33.34%), without any adjustments to the algorithm or its parameters. Our success against the Baidu (38.68%) and CNN (51.09%) schemes that use occluding lines as well as character collapsing leads us to believe that our approach is able to defeat occluding lines in an equally general manner. The effectiveness and universality of our results suggests that combining segmentation and recognition is the next evolution of captcha solving, and that it supersedes the sequential approach used in earlier works. More generally, our approach raises questions about how to develop sufficiently secure captchas in the future.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Tick Tock: Building Browser Red Pills from Timing Side Channels
8th USENIX Workshop on Offensive Technologies (WOOT 14), USENIX Association (2014)
[u'Grant Ho', u'Dan Boneh', u'Lucas Ballard', u'Niels Provos']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42847.html
found
=========================
Would a Privacy Fundamentalist Sell Their DNA for $1000...If Nothing Bad Happened as a Result? The Westin Categories, Behavioral Intentions, and Consequences
Proceedings of the Symposium On Usable Privacy and Security: SOUPS '14, USENIX (2014)
[u'Allison Woodruff', u'Vasyl Pihur', u'Sunny Consolvo', u'Lauren Schmidt', u'Laura Brandimarte', u'Alessandro Acquisti']
SecurityPrivacyandAbusePrevention
Abstract: Westin's Privacy Segmentation Index has been widely used to measure privacy attitudes and categorize individuals into three privacy groups: fundamentalists, pragmatists, and unconcerned. Previous research has failed to establish a robust correlation between the Westin categories and actual or intended behaviors. Unexplored however is the connection between the Westin categories and individuals' responses to the consequences of privacy behaviors. We use a survey of 884 Amazon Mechanical Turk participants to investigate the relationship between the Westin Privacy Segmentation Index and attitudes and behavioral intentions for both privacy-sensitive scenarios and privacy-sensitive consequences. Our results indicate a lack of correlation between the Westin categories and consequences. We discuss potential implications of this attitude-consequence gap.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42546.html
found
=========================
Your Reputation Precedes You: History, Reputation, and the Chrome Malware Warning
Proceedings of the Symposium On Usable Privacy and Security: SOUPS '14, USENIX (2014)
[u'Hazim Almuhimedi', u'Adrienne Porter Felt', u'Robert W. Reeder', u'Sunny Consolvo']
SecurityPrivacyandAbusePrevention
Abstract: Several web browsers, including Google Chrome and Mozilla Firefox, use malware warnings to stop people from visiting infectious websites. However, users can choose to click through (i.e., ignore) these malware warnings. In Google Chrome, users click through a fifth of malware warnings on average. We investigate factors that may contribute to why people ignore such warnings. First, we examine field data to see how browsing history affects click-through rates. We find that users consistently heed warnings about websites that they have not visited before. However, users respond unpredictably to warnings about websites that they have previously visited. On some days, users ignore more than half of warnings about websites they've visited in the past. Next, we present results of an online, survey-based experiment that we ran to gain more insight into the effects of reputation on warning adherence. Participants said that they trusted high-reputation websites more than the warnings; however, their responses suggest that a notable minority of people could be swayed by providing more information. We provide recommendations for warning designers and pose open questions about the design of malware warnings.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43021.html
notfound
=========================
ZARATHUSTRA: Extracting WebInject Signatures from Banking Trojans
Twelfth Annual International Conference on Privacy, Security and Trust, IEEE (2014), pp. 139-148
[u'Claudio Criscione', u'Fabio Bosatelli', u'Stefano Zanero', u'Federico Maggi']
SecurityPrivacyandAbusePrevention
Abstract: Modern trojans are equipped with a functionality, called WebInject, that can be used to silently modify a web page on the infected end host. Given its flexibility, WebInject-based malware is becoming a popular information-stealing mechanism. In addition, the structured and well-organized malware-as-a-service model makes revenue out of customization kits, which in turns leads to high volumes of binary variants. Analysis approaches based on memory carving to extract the decrypted webinject.txt and config.bin files at runtime make the strong assumption that the malware will never change the way such files are handled internally, and therefore are not future proof by design. In addition, developers of sensitive web applications (e.g., online banking) have no tools that they can possibly use to even mitigate the effect of WebInjects. WebInject-based trojans insert client-side code (e.g., HTML, JavaScript) while the targeted web pages (e.g., online banking website, search engine) are rendered on the browser. This additional code will capture sensitive information entered by the victim (e.g., one-time passwords) or perform other nefarious actions (e.g., click fraud or search engine result poisoning). The visible effect of a WebInject is that a web page rendered on infected clients differs from the very same page rendered on clean machines. We leverage this key observation and propose an approach to automatically characterize the WebInject behavior. Ultimately, our system can be applied to analyze a sample automatically against a set of target websites, without requiring any manual action, or to generate fingerprints that are useful to determine whether a client is infected. Differently from the state of the art, our method works regardless of how the WebInject module is implemented and requires no reverse engineering. We implemented and evaluated our approach against live online websites and a dataset of distinct variants of WebInject-based financial trojans. The results show that our approach correctly recognize known variants of WebInject-based malware with negligible false positives. Throughout the paper, we describe some use cases that describe how our method can be applied in practice
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41941.html
found
=========================
My religious aunt asked why I was trying to sell her viagra: Experiences with account hijacking
Proceedings of the SIGCHI Conference on Human Factors in Computing Systems: CHI '14, ACM, New York, NY, USA (2014), pp. 2657-2666
[u'Richard Shay', u'Iulia Ion', u'Robert W. Reeder', u'Sunny Consolvo']
SecurityPrivacyandAbusePrevention
Abstract: With so much of our lives digital, online, and not entirely under our control, we risk losing access to our communications, reputation, and data. Recent years have brought a rash of high-profile account compromises, but account hijacking is not limited to high-profile accounts. In this paper, we report results of a survey about peoples experiences with and attitudes toward account hijacking. The problem is widespread; 30% of our 294 participants had an email or social networking account accessed by an unauthorized party. Five themes emerged from our results: (1) compromised accounts are often valuable to victims, (2) attackers are mostly unknown, but sometimes known, to victims, (3) users acknowledge some responsibility for keeping their accounts secure, (4) users understanding of important security measures is incomplete, and (5) harm from account hijacking is concrete and emotional. We discuss implications for designing security mechanisms to improve chances for user adoption.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41396.html
found
=========================
Advisory on Internal Name Certificates
ICANN SSAC Reports and Advisories, ICANN (Internet Corporation for Assigned Names and Numbers) (2013)
[u'Warren Kumari', u'Steve Crocker', u'Patrik Fltstrm', u'Ondrej Filip', u'James Galvin', u'Danny McPherson', u'Ram Mohan', u'Doron Shikmoni']
SecurityPrivacyandAbusePrevention
Abstract: The SSAC has identified a Certificate Authority (CA) practice that, if widely exploited, could pose a significant risk to the privacy and integrity of secure Internet communications. This CA practice could impact the new gTLD program. The SSAC thus advises ICANN take immediate steps to mitigate the risks.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41323.html
found
=========================
Alice in Warningland: A Large-Scale Field Study of Browser Security Warning Effectiveness
USENIX Security Symposium, USENIX (2013)
[u'Devdatta Akhawe', u'Adrienne Porter Felt']
SecurityPrivacyandAbusePrevention
Abstract: We empirically assess whether browser security warnings are as ineffective as suggested by popular opinion and previous literature. We used Mozilla Firefox and Google Chrome's in-browser telemetry to observe over 25 million warning impressions in situ. During our field study, users continued through a tenth of Mozilla Firefox's malware and phishing warnings, a quarter of Google Chrome's malware and phishing warnings, and a third of Mozilla Firefox's SSL warnings. This demonstrates that security warnings can be effective in practice; security experts and system architects should not dismiss the goal of communicating security information to end users. We also find that user behavior varies across warnings. In contrast to the other warnings, users continued through 70.2% of Google Chrome's SSL warnings. This indicates that the user experience of a warning can have a significant impact on user behavior. Based on our findings, we make recommendations for warning designers and researchers.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Anti-forensic resilient memory acquisition
Digital Investigation, vol. 10 (2013), S105-S115
[u'Johaness Stuerrgen', u'Michael Cohen']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40692.html
found
=========================
Authentication at Scale
IEEE Security and Privacy, vol. 11 (2013), pp. 15-22
[u'Eric Grosse', u'Mayank Upadhyay']
SecurityPrivacyandAbusePrevention
Abstract: In working to keep cloud computing users' data safe, we observe many threats---malware on the client, attacks on ssl, vulnerabilities in web applications, rogue insiders, espionage---but authentication related issues stand out amongst the biggest. When trying to help hundreds of millions of people from an unbelievable variety of endpoints, attitudes, and skill levels, what can possibly displace plain old passwords? No single thing, nothing overnight, and nothing perfect. A combination of risk-based checks, second-factor options, privacy-enhanced client certificates, and different forms of delegation is starting to find adoption towards making a discernible difference.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
CAMP: Content-Agnostic Malware Protection
Network and Distributed Systems Security Symposium (NDSS), Network and Distributed Systems Security Symposium (NDSS), USA (2013)
[u'Moheeb Abu Rajab', u'Lucas Ballard', u'Noe Lutz', u'Panayiotis Mavrommatis', u'Niels Provos']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41404.html
found
=========================
Cross Platform Network Access Control
RVASec 2013, RVASec 2013, RIchmond, VA
[u'Paul (Tony) Watson']
SecurityPrivacyandAbusePrevention
Abstract: Discussion of Capirca, an open-sourced multi-platform Network ACL generation system. This talk will discuss the history of Capirca, originating as an internal Google project through its current form and use in the open-source community. Attendees will gain an understand of how to use the system to simplify and improve the efficiency and reliability of network security management. A significant portion of time will also be dedicated to an overview of how the software and libraries work internally, including how to develop new modules and contribute to the open source effort.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41119.html
found
=========================
Crowd-Sourced Call Identification and Suppression
Federal Trade Commission Robocall Challenge (2013)
[u'Daniel V. Klein', u'Dean K. Jackson']
SecurityPrivacyandAbusePrevention
Abstract: We recommend the creation of a system that allows users to report, to an online database system, the originating telephone number of unwanted solicitations, advertisements or robotically placed calls (henceforth called 'spammers'). We also recommend that users' telephones or external hardware may automatically query the database about the telephone number of an incoming call (before the call is answered, or even before the telephone rings) to determine if the caller has been flagged as a spammer by other users, and optionally block the call or otherwise handle it differently from a non-spam call. The recommended system thereby would provide a means whereby users can make reports of spam calls as well as ask if others have reported a caller as a spammer. While the first few people called would get spammed, after a sufficient number of reports are made, further calls would be blocked. The recommended system would work on most types of telephonic platforms - smartphones, some feature phones, POTS lines, VoIP, PBX, and telephony providers - through the use of software and optional inline hardware. In addition to crowd-sourced blacklisting, we also recommend a means to whitelist specific numbers so that, for example, emergency calls will always go through.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40806.html
found
=========================
Design, Implementation and Verification of an eXtensible and Modular Hypervisor Framework
IEEE Symposium on Security and Privacy (2013) (to appear)
[u'Amit Vasudevan', u'Sagar Chaki', u'Limin Jia', u'Jonathan McCune', u'James Newsome', u'Anupam Datta']
SecurityPrivacyandAbusePrevention
Abstract: We present the design, implementation, and verification of XMHF - an eXtensible and Modular Hypervisor Framework. XMHF is designed to achieve three goals - modular extensibility, automated verification, and high performance. XMHF includes a core that provides functionality common to many hypervisor-based security architectures and supports extensions that augment the core with additional security or functional properties while preserving the fundamental hypervisor security property of memory integrity (i.e., ensuring that the hypervisor's memory is not modified by software running at a lower privilege level). We verify the memory integrity of the XMHF core - 6018 lines of code - using a combination of automated and manual techniques. The model checker CBMC automatically verifies 5208 lines of C code in about 80 seconds using less than 2GB of RAM. We manually audit the remaining 422 lines of C code and 388 lines of assembly language code that are stable and unlikely to change as development proceeds. Our experiments indicate that XMHF's performance is comparable to popular high-performance general-purpose hypervisors for the single guest that it supports.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40673.html
notfound
=========================
Distributed Electronic Rights in JavaScript
ESOP'13 22nd European Symposium on Programming, Springer (2013)
[u'Mark S. Miller', u'Tom Van Cutsem', u'Bill Tulloh']
SecurityPrivacyandAbusePrevention
Abstract: Contracts enable mutually suspicious parties to cooperate safely through the exchange of rights. Smart contracts are programs whose behavior enforces the terms of the contract. This paper shows how such contracts can be specified elegantly and executed safely, given an appropriate distributed, secure, persistent, and ubiquitous computational fabric. JavaScript provides the ubiquity but must be significantly extended to deal with the other aspects. The first part of this paper is a progress report on our efforts to turn JavaScript into this fabric. To demonstrate the suitability of this design, we describe an escrow exchange contract implemented in 42 lines of JavaScript code.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41215.html
notfound
=========================
Hunting in the Enterprise: Forensic Triage and Incident Response
Digital Investigation, vol. 10 (2013), pp. 89-98
[u'Andreas Moser', u'Michael Cohen']
SecurityPrivacyandAbusePrevention
Abstract: In enterprise environments, digital forensic analysis generates data volumes that traditional forensic methods are no longer prepared to handle. Triaging has been proposed as a solution to systematically prioritize the acquisition and analysis of digital evidence. We explore the application of automated triaging processes in such settings, where reliability and customizability are crucial for a successful deployment. We specifically examine the use of GRR Rapid Response (GRR) an advanced open source distributed enterprise forensics system in the triaging stage of common incident response investigations. We show how this system can be leveraged for automated prioritization of evidence across the whole enterprise fleet and describe the implementation details required to obtain sufficient robustness for large scale enterprise deployment. We analyze the performance of the system by simulating several realistic incidents and discuss some of the limitations of distributed agent based systems for enterprise triaging.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42189.html
notfound
=========================
Identifying and Exploiting Windows Kernel Race Conditions via Memory Access Patterns
Bochspwn: Exploiting Kernel Race Conditions Found via Memory Access Patterns, The Symposium on Security for Asia Network, 102F Pasir Panjang Road, #08-02, Singapore 118530 (2013), pp. 69
[u'Mateusz Jurczyk', u'Gynvael Coldwind']
SecurityPrivacyandAbusePrevention
Abstract: The overall security posture of operating systems kernels and specifically the Microsoft Windows NT kernel against both local and remote attacks has visibly improved throughout the last decade. In our opinion, this is primarily due to the increasing interest in kernel-mode vulnerabilities by both white and black-hat parties, as they ultimately allow attackers to subvert the currently widespread defense-in-depth technologies implemented on operating system level, such as sandboxing, or other features enabling better management of privileges within the execution environment (e.g. Mandatory Integrity Control ). As a direct outcome, Microsoft has invested considerable resources in both improving the development process with programs like Secure Development Lifecycle, and explicitly hardening the kernel against existing attacks; the latter was particularly characteristic to Windows 8, which introduced more kernel security improvements than any NT-family system thus far[11]. In this paper, we discuss the concept of employing CPU-level operating system instrumentation to identify potential instances of local race conditions in fetching user-mode input data within system call handlers and other user-facing ring-0 code, and how it was successfully implemented in the Bochspwn project. Further in the document, we present a number of generic techniques easing the exploitation of timing bound kernel vulnerabilities and show how these techniques can be employed in practical attacks against three exemplary vulnerabilities discovered by Bochspwn. In the last sections, we conclusively provide some suggestions on related research areas that havent been fully explored and require further development.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41460.html
notfound
=========================
Making programs forget: Enforcing Lifetime for Sensitive Data
Proceedings of the 13th USENIX conference on Hot topics in operating systems, USENIX Association, Berkeley, CA, USA (2013)
[u'Jayanthkumar Kannan', u'Gautam Altekar', u'Petros Maniatis', u'Byung-Gon Chun']
SecurityPrivacyandAbusePrevention
Abstract: This paper introduces guaranteed data lifetime, a novel system property ensuring that sensitive data cannot be retrieved from a system beyond a specified time. The trivial way to achieve this is to "reboot"; however, this is disruptive from the user's perspective, and may not even eliminate disk copies. We discuss an alternate approach based on state re-incarnation where data expiry is completely transparent to the user, and can be used even if the system is not designed a priori to provide the property.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41331.html
found
=========================
Rogue Femtocell Owners: How Mallory Can Monitor My Devices
2013 Proceedings IEEE INFOCOM, IEEE, New Jersey, USA, pp. 3553-3558
[u'David Malone', u'Darren F Kavanagh', u'Niall Richard Murphy']
SecurityPrivacyandAbusePrevention
Abstract: Femtocells are small cellular telecommunication base stations that provide improved cellular coverage. These devices provide important improvements in coverage, battery life and throughput, they also present security challenges. We identify a problem which has not been identified in previous studies of femtocell security: rogue owners of femtocells can secretly monitor third-party mobile devices by using the femtocell's access control features. We present traffic analysis of real femtocell traces are presented and demonstrate the ability to monitor mobile devices through classification of the femtocell's encrypted backhaul traffic. We also consider the femtocell's power usage and status LEDs as other side channels that provide information on the femtocell's operation. We conclude by presenting suitable solutions to overcome this problem.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41138.html
notfound
=========================
S-links: Why distributed security policy requires secure introduction
Web 2.0 Security & Privacy 2013, IEEE
[u'Joseph Bonneau']
SecurityPrivacyandAbusePrevention
Abstract: In this paper we argue that secure introduction via hyperlinks will be essential for distributing security policies on the web. The "strict transport security" policy, which makes HTTPS mandatory for a given domain, can already be expressed by links with an https URL. We propose s-links, a set of lightweight HTML extensions to express more complex security policies in links such as key pinning. This is the simplest and most efficient way to secure connections to new domains before persistent security policy can be negotiated directly, requiring no changes to the user experience and aligning trust decisions with the user's mental model. We show how s-links can benefit a variety of proposed protocols and discuss implications for the browser's same-origin policy.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42959.html
found
=========================
SAC062 - SSAC Advisory Concerning the Mitigation of Name Collision Risk
ICANN Security and Stability Advisory Committee (SSAC) Reports and Advisories, ICANN (2013)
[u'Warren Kumari']
SecurityPrivacyandAbusePrevention
Abstract: The term name collision refers to the situation in which a name that is properly defined in one operational domain or naming scope may appear in another domain (in which it is also syntactically valid), where users, software, or other functions in that domain may misinterpret it as if it correctly belonged there. The circumstances that may cause this can be accidental or malicious. In the context of Top Level Domains (TLDs), the conflicting namespaces are the DNS namespace defined in the root zone as published by the root management partners (ICANN, U.S. Dept. of Commerce National Telecommunications Information Administration (NTIA), and VeriSign) and any privately defined namespace, whether that namespace is defined only for the Domain Name System (DNS) or is also intended to work for other namespaces such as Active Directory
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Sok: The Evolution of Sybil Defense via Social Networks
2013 IEEE Symposium on Security and Privacy, SP 2013
[u'Lorenzo Alvisi', u'Allen Clement', u'Alessandro Epasto', u'Silvio Lattanzi', u'Alessandro Panconesi']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41882.html
notfound
=========================
Strato: A Retargetable Framework for Low-level Inlined Reference Monitors
Proceedings of the 22nd USENIX Conference on Security, USENIX Association, Berkeley, CA, USA (2013), pp. 369-382
[u'Bin Zeng', u'Gang Tan', u'lfar Erlingsson']
SecurityPrivacyandAbusePrevention
Abstract: Low-level Inlined Reference Monitors (IRM) such as control-flow integrity and software-based fault isolation can foil numerous software attacks. Conventionally, those IRMs are implemented through binary rewriting or transformation on equivalent low-level programs that are tightly coupled with a specific Instruction Set Architecture (ISA). Resulting implementations have poor retargetability to different ISAs. This paper introduces an IRM-implementation framework at a compiler intermediate-representation (IR) level. The IR-level framework enables easy retargetability to different ISAs, but raises the challenge of how to preserve security at the low level, as the compiler backend might invalidate the assumptions at the IR level. We propose a constraint language to encode the assumptions and check whether they still hold after the backend transformations and optimizations. Furthermore, an independent verifier is implemented to validate the security of low-level code. We have implemented the framework inside LLVM to enforce the policy of control-flow integrity and data sandboxing for both reads and writes. Experimental results demonstrate that it incurs modest runtime overhead of 19.90% and 25.34% on SPECint2000 programs for 86- 32 and 86-64, respectively.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub39961.html
notfound
=========================
The Dangers of Composing Anonymous Channels
Information Hiding - 14th International Conference, IH 2012, Revised Selected Papers, Springer, Lecture notes in Computer Science (2013), pp. 191-206
[u'Emilia Kasper', u'George Danezis']
SecurityPrivacyandAbusePrevention
Abstract: We present traffic analyses of two anonymous communications schemes that build on the classic Crowds/Hordes protocols. The AJSS10 [1] scheme combines multiple Crowds-like forward channels with a Hordes reply channel in an attempt to offer robustness in a mobile environment. We show that the resulting scheme fails to guarantee the claimed k-anonymity, and is in fact more vulnerable to malicious peers than Hordes, while suffering from higher latency. Similarly, the RWS11 [15] scheme invokes multiple instances of Crowds to provide receiver anonymity. We demonstrate that the sender anonymity of the scheme is susceptible to a variant of the predecessor attack [21], while receiver anonymity is fully compromised with an active attack. We conclude that the heuristic security claims of AJSS10 and RWS11 do not hold, and argue that composition of multiple anonymity channels can in fact weaken overall security. In contrast, we provide a rigorous security analysis of Hordes under the same threat model, and reflect on design principles for future anonymous channels to make them amenable to such security analysis.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40736.html
notfound
=========================
Trustworthy Proxies: Virtualizing Objects with Invariants
ECOOP 2013
[u'Tom Van Cutsem', u'Mark S. Miller']
SecurityPrivacyandAbusePrevention
Abstract: Proxies are a common technique to virtualize objects in object-oriented languages. A proxy is a placeholder object that emulates or wraps another target object. Both the proxy's representation and behavior may differ substantially from that of its target object. In many object-oriented languages, objects may have language-enforced invariants associated with them. For instance, an object may declare immutable fields, which are guaranteed to point to the same value throughout the execution of the program. Clients of an object can blindly rely on these invariants, as they are enforced by the language. In a language with both proxies and objects with invariants, these features interact. Can a proxy emulate or replace a target object purporting to uphold such invariants? If yes, does the client of the proxy need to trust the proxy to uphold these invariants, or are they still enforced by the language? This paper sheds light on these questions in the context of a Javascript-like language, and describes the design of a Proxy API that allows proxies to emulate objects with invariants, yet have these invariants continue to be language-enforced. This design forms the basis of proxies in ECMAScript 6.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42038.html
found
=========================
Verified Boot on Chrome OS and How to do it yourself
Embedded Linux Conference Europe, Linux Foundation, 660 York Street, Suite 102, San Francisco, CA 94110, USA (2013)
[u'Simon Glass']
SecurityPrivacyandAbusePrevention
Abstract: Chrome OS uses a first stage read-only firmware and second-stage updatable firmware. The updatable firmware is signed and contains kernel keys and a dm-verify hash, so that the firmware, Linux kernel and root filesystem are all protected against corruption and attack. This system is described and discussed. As part of Google's upstream efforts in U-Boot, a generalized secure boot system has been developed and released with U-Boot 2013.07. This implementation uses the FIT format, which collects together images, such as kernels, device tree, RAM disks. Support is provided for TPMs (Trust Platform Module), RSA-based signing and verificaiton, and hashing with hardware acceleration. This system is also described and discussed, along with the specific steps needed to implement it in your designs.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40816.html
found
=========================
Verifying Cloud Services: Present and Future
Operating Systems Review (2013)
[u'Sara Bouchenak', u'Gregory Chockler', u'Hana Chockler', u'Gabriela Gheorghe', u'Nuno Santos', u'Alexander Shraer']
SecurityPrivacyandAbusePrevention
Abstract: As cloud-based services gain popularity in both private and enterprise domains, cloud consumers are still lacking in tools to verify that these services work as expected. Such tools should consider properties such as functional correctness, service availability, reliability, performance and security guar- antees. In this paper we survey existing work in these ar- eas and identify gaps in existing cloud technology in terms of the verication tools provided to users. We also discuss challenges and new research directions that can help bridge these gaps.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41098.html
notfound
=========================
A taste of Capsicum: practical capabilities for UNIX
Communications of the ACM, vol. 55(3) (2012), pp. 97-104
[u'Robert N. M. Watson', u'Jonathan Anderson', u'Ben Laurie', u'Kris Kennaway']
SecurityPrivacyandAbusePrevention
Abstract: Capsicum is a lightweight operating system (OS) capability and sandbox framework planned for inclusion in FreeBSD 9. Capsicum extends, rather than replaces, UNIX APIs, providing new kernel primitives (sandboxed capability mode and capabilities) and a userspace sandbox API. These tools support decomposition of monolithic UNIX applications into compartmentalized logical applications, an increasingly common goal that is supported poorly by existing OS access control primitives. We demonstrate our approach by adapting core FreeBSD utilities and Google
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41397.html
found
=========================
Advisory on Impacts of Content Blocking via the Domain Name System
ICANN Security and Stability Advisory Committee (SSAC) Reports and Advisories, ICANN (Internet Corporation for Assigned Names and Numbers) (2012)
[u'Warren Kumari', u'Alain Aina', u'Jaap Akkerhuis', u'Don Blumenthal', u'KC Claffy', u'David Conrad', u'Patrik Fltstrm', u'James Galvin', u'Jason Livingood', u'Danny McPherson', u'Ram Mohan', u'Paul Vixie']
SecurityPrivacyandAbusePrevention
Abstract: The use of Domain Name System (DNS) blocking to limit access to resources on the Internet has become a topic of interest in numerousInternet governance venues. Several governments around the world, whether by law, treaty, court order, law enforcement action, or other actions or agreements, have either implemented DNS blocking or are actively considering doing so. However, due to the Internets architecture, blocking by domain name can be easily bypassed by end users and is thus likely to be largely ineffective in the long term and fraught with unanticipated consequences in the near term. In addition, DNS blocking can present conflicts with the adoption of DNS Security Extensions(DNSSEC) and could promote balkanization of the Internet into a country-by-country view of the Internets name space.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Browser Exploits as a Service: The Monetization of Driveby Downloads
Proceedings of 19th ACM Conference on Computer and Communications Security (2012)
[u'C. Grier', u'L. Ballard', u'J. Caballero', u'N. Chachra', u'C. Dietrich', u'K. Levchenko', u'P. Mavrommatis', u'D. McCoy', u'A. Nappa', u'A. Pitsillidis', u'N. Provos', u'Z. Rafique', u'M. Rajab', u'C. Rossow', u'K. Thomas', u'V. Paxson', u'S. Savage', u'G. Voelker']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37672.html
notfound
=========================
Cloud Data Protection for the Masses
Computer, vol. 45, no. 1 (2012), pp. 39-45
[u'Dawn Song', u'Elaine Shi', u'Ian Fischer', u'Umesh Shankar']
SecurityPrivacyandAbusePrevention
Abstract: Offering strong data protection to cloud users while enabling rich applications is a challenging task. Researchers explore a new cloud platform architecture called Data Protection as a Service, which dramatically reduces the per-application development effort required to offer data protection, while still allowing rapid development and maintenance.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Contextual OTP: Mitigating Emerging Man-in-the-Middle Attacks with Wireless Hardware Tokens
Applied Cryptography and Network Security - 10th International Conference, ACNS 2012, Springer, pp. 30-47
[u'Assaf Ben-David', u'Omer Berkman', u'Yossi Matias', u'Sarvar Patel', u'Cem Paya', u'Moti Yung']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Enhanced multi-factor authentication
Patent (2012)
[u'Lantian Zheng']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
How well can congestion pricing neutralize denial of service attacks?
Proceedings of the 12th ACM SIGMETRICS/PERFORMANCE joint international conference on Measurement and Modeling of Computer Systems, ACM, New York, NY, USA (2012), pp. 137-150
[u'Ashish Vulimiri', u'Gul A. Agha', u'Philip Brighten Godfrey', u'Karthik Lakshminarayanan']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38080.html
notfound
=========================
Let's Parse to Prevent Pwnage
USENIX workshop on Large-Scale Exploits and Emergent Threats, USENIX (2012)
[u'Mike Samuel', u'lfar Erlingsson']
SecurityPrivacyandAbusePrevention
Abstract: Software that processes rich content suffers from endemic security vulnerabilities. Frequently, these bugs are due to data confusion: discrepancies in how content data is parsed, composed, and otherwise processed by different applications, frameworks, and language runtimes. Data confusion often enables code injection attacks, such as cross-site scripting or SQL injection, by leading to incorrect assumptions about the encodings and checks applied to rich content of uncertain provenance. However, even for well-structured, value-only content, data confusion can critically impact security, e.g., as shown by XML signature vulnerabilities [12]. This paper advocates the position that data confusion can be effectively prevented through the use of simple mechanismsbased on parsingthat eliminate ambiguities by fully resolving content data to normalized, clearly-understood forms. Using code injection on the Web as our motivation, we make the case that automatic defense mechanisms should be integrated with programming languages, application frameworks, and runtime libraries, and applied with little, or no, developer intervention. We outline a scalable, sustainable approach for developing and maintaining those mechanisms. The resulting tools can offer comprehensive protection against data confusion, even when multiple types of rich content data are processed and composed in complex ways.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub39968.html
notfound
=========================
Lockdown: Towards a Safe and Practical Architecture for Security Applications on Commodity Platforms
TRUST 2012, Lecture Notes in Computer Science, pp. 21
[u'Amit Vasudevan', u'Bryan Parno', u'Ning Qu', u'Virgil D. Gligor', u'Adrian Perrig']
SecurityPrivacyandAbusePrevention
Abstract: We investigate a new point in the design space of red/green systems [19,30], which provide the user with a highly-protected, yet also highly-constrained trusted (green) environment for performing security-sensitive transactions, as well as a high-performance, general-purpose environment for all other (non-security-sensitive or red) applications. Through the design and implementation of the Lockdown architecture, we evaluate whether partitioning, rather than virtualizing, resources and devices can lead to better security or performance for red/green systems. We also design a simple external interface to allow the user to securely learn which environment is active and easily switch between them. We find that partitioning offers a new tradeoff between security, performance, and usability. On the one hand, partitioning can improve the security of the green environment and the performance of the red environment (as compared with a virtualized solution). On the other hand, with current systems, partitioning makes switching between environments quite slow (13-31 seconds), which may prove intolerable to users.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Manufacturing Compromise: The Emergence of Exploit-as-a-Service
Proceedings of 19th ACM Conference on Computer and Communications Security (2012)
[u'Chris Grier', u'Lucas Ballard', u'Juan Caballero', u'Neha Chachra', u'Christian J. Dietrich', u'Kirill Levchenko', u'Panayiotis Mavrommatis', u'Damon McCoy', u'Antonio Nappa', u'Andreas Pitsillidis', u'Niels Provos', u'M. Zubair Rafique', u'Moheeb Abu Rajab', u'Christian Rossow', u'Kurt Thomas', u'Vern Paxson', u'Stefan Savage', u'Geoffrey M. Voelker']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38224.html
notfound
=========================
Non-interactive CCA-Secure threshold cryptosystems with adaptive security: new framework and constructions
Proceedings of the 9th international conference on Theory of Cryptography, Springer-Verlag, Berlin, Heidelberg (2012), pp. 75-93
[u'Benoit Libert', u'Moti Yung']
SecurityPrivacyandAbusePrevention
Abstract: In threshold cryptography, private keys are divided into n shares, each one of which is given to a different server in order to avoid single points of failure. In the case of threshold public-key encryption, at least t n servers need to contribute to the decryption process. A threshold primitive is said robust if no coalition of t malicious servers can prevent remaining honest servers from successfully completing private key operations. So far, most practical non-interactive threshold cryptosystems, where no interactive conversation is required among decryption servers, were only proved secure against static corruptions. In the adaptive corruption scenario (where the adversary can corrupt servers at any time, based on its complete view), all existing robust threshold encryption schemes that also resist chosen-ciphertext attacks (CCA) till recently require interaction in the decryption phase. A specific method (in composite order groups) for getting rid of interaction was recently suggested, leaving the question of more generic frameworks and constructions with better security and better exibility (i.e., compatibility with distributed key generation). This paper describes a general construction of adaptively secure robust non-interactive threshold cryptosystems with chosen-ciphertext security. We dene the notion of all-but-one perfectly sound threshold hash proof systems that can be seen as (threshold) hash proof systems with publicly verifiable and simulation-sound proofs. We show that this notion generically implies threshold cryptosystems combining the aforementioned properties. Then, we provide ecient instantiations under well-studied assumptions in bilinear groups (e.g., in such groups of prime order). These instantiations have a tighter security proof and are indeed compatible with distributed key generation protocols.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38357.html
notfound
=========================
Origin-Bound Certificates: A Fresh Approach to Strong Client Authentication for the Web
21st USENIX Security Symposium, The USENIX Association (2012), pp. 317-332
[u'Michael Dietz', u'Alexei Czeskis', u'Dirk Balfanz', u'Dan Wallach']
SecurityPrivacyandAbusePrevention
Abstract: Client authentication on the web has remained in the internet-equivalent of the stone ages for the last two decades. Instead of adopting modern public-key-based authentication mechanisms, we seem to be stuck with passwords and cookies. In this paper, we propose to break this stalemate by presenting a fresh approach to public-key-based client authentication on the web. We describe a simple TLS extension that allows clients to establish strong authenti- cated channels with servers and to bind existing authen- tication tokens like HTTP cookies to such channels. This allows much of the existing infrastructure of the web to remain unchanged, while at the same time strengthening client authentication considerably against a wide range of attacks. We implemented our system in Google Chrome and Googles web serving infrastructure, and provide a per- formance evaluation of this implementation.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38101.html
found
=========================
RFC6583 - Operational Neighbor Discovery Problems
IETF RFCs, Internet Engineering Task Force (2012)
[u'Warren Kumari', u'Igor Gashinsky', u'Yahoo!', u'Joel Jaeggli', u'Zynga']
SecurityPrivacyandAbusePrevention
Abstract: In IPv4, subnets are generally small, made just large enough to cover the actual number of machines on the subnet. In contrast, the default IPv6 subnet size is a /64, a number so large it covers trillions of addresses, the overwhelming number of which will be unassigned. Consequently, simplistic implementations of Neighbor Discovery (ND) can be vulnerable to deliberate or accidental denial of service (DoS), whereby they attempt to perform address resolution for large numbers of unassigned addresses. Such denial-of-service attacks can be launched intentionally (by an attacker) or result from legitimate operational tools or accident conditions. As a result of these vulnerabilities, new devices may not be able to "join" a network, it may be impossible to establish new IPv6 flows, and existing IPv6 transported flows may be interrupted. This document describes the potential for DoS in detail and suggests possible implementation improvements as well as operational mitigation techniques that can, in some cases, be used to protect against or at least alleviate the impact of such attacks.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37733.html
notfound
=========================
Robust Trait Composition for JavaScript
Science of Computer Programming: Special Issue on Advances in Dynamic Languages (2012)
[u'Tom Van Cutsem', u'Mark S. Miller']
SecurityPrivacyandAbusePrevention
Abstract: We introduce traits.js, a small, portable trait composition library for Javascript. Traits are a more robust alternative to multiple inheritance and enable object composition and reuse. traits.js is motivated by two goals: first, it is an experiment in using and extending Javascript's recently added meta-level object description format. By reusing this standard description format, traits.js can be made more interoperable with similar libraries, and even with built-in primitives. Second, traits.js makes it convenient to create "high-integrity" objects whose integrity cannot be violated by clients, an important property in the context of mash-ups composed from mutually suspicious scripts. We describe the design of traits.js and provide an operational semantics for TRAITS-JS, a minimal calculus that models the core functionality of the library.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Scalable group signatures with revocation
Proceedings of the 31st Annual international conference on Theory and Applications of Cryptographic Techniques, Springer-Verlag, Berlin, Heidelberg (2012), pp. 609-627
[u'Benoit Libert', u'Thomas Peters', u'Moti Yung']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37399.html
notfound
=========================
Security and Testing
Introduction to Hardware Security and Trust, Springer (2012) (to appear)
[u'Kurt Rosenfeld']
SecurityPrivacyandAbusePrevention
Abstract: Test interfaces are present in nearly all digital hardware. In many cases, the security of the system depends on the security of the test interfaces. Systems have been hacked in the field using test interfaces as an avenue for attack. Researchers in industry and academia have developed defenses over the past 20 years. A diligent designer can significantly reduce the chance of system exploitation by understanding known threats and applying known defenses.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37673.html
found
=========================
Vanity or Privacy? Social Media as a Facilitator of Privacy and Trust
CSCW Workshop: Reconciling Privacy with Social Media (2012)
[u'Jessica Staddon']
SecurityPrivacyandAbusePrevention
Abstract: In this position paper, we argue that social media provides valuable support for the perception of ones self and others, and in doing so, supports privacy. In addition we suggest that engagement, which reflects a certain degree of trust, can be facilitated by social information. We support our arguments with results from a recent privacy survey and a study of social annotations in search.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37656.html
notfound
=========================
Address space randomization for mobile devices
WiSec '11 - Proceedings of the fourth ACM conference on wireless network security, ACM, New York, NY (2011)
[u'Hristo Bojinov', u'Dan Boneh', u'Rich Cannings', u'Iliyan Malchev']
SecurityPrivacyandAbusePrevention
Abstract: Address Space Layout Randomization (ASLR) is a defensive technique supported by many desktop and server operating systems. While smartphone vendors wish to make it available on their platforms, there are technical challenges in implementing ASLR on these devices. Pre-linking, limited processing power and restrictive update processes make it dicult to use existing ASLR implementation strategies even on the latest generation of smartphones. In this paper we introduce retouching, a mechanism for executable ASLR that requires no kernel modications and is suitable for mobile devices. We have implemented ASLR for the Android operating system and evaluated its eectiveness and performance. In addition, we introduce crash stack analysis, a technique that uses crash reports locally on the device, or in aggregate in the cloud to reliably detect attempts to brute-force ASLR protection. We expect that retouching and crash stack analysis will become standard techniques in mobile ASLR implementations.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37198.html
notfound
=========================
App Isolation: Get the Security of Multiple Browsers with Just One
18th ACM Conference on Computer and Communications Security, ACM (2011)
[u'Eric Y. Chen', u'Jason Bau', u'Charles Reis', u'Adam Barth', u'Collin Jackson']
SecurityPrivacyandAbusePrevention
Abstract: Many browser-based attacks can be prevented by using separate browsers for separate web sites. However, most users access the web with only one browser. We explain the security benefits that using multiple browsers provides in terms of two concepts: entry-point restriction and state isolation. We combine these concepts into a general app isolation mechanism that can provide the same security benefits in a single browser. While not appropriate for all types of web sites, many sites with high-value user data can opt in to app isolation to gain defenses against a wide variety of browser-based attacks. We implement app isolation in the Chromium browser and verify its security properties using finite-state model checking. We also measure the performance overhead of app isolation and conduct a large-scale study to evaluate its adoption complexity for various types of sites, demonstrating how the app isolation mechanisms are suitable for protecting a number of high-value Web applications, such as online banking.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37199.html
notfound
=========================
Automated Analysis of Security-Critical JavaScript APIs
IEEE Symposium on Security & Privacy (SP), IEEE (2011)
[u'Ankur Taly', u'lfar Erlingsson', u'John C. Mitchell', u'Mark S. Miller', u'Jasvir Nagra']
SecurityPrivacyandAbusePrevention
Abstract: JavaScript is widely used to provide client-side functionality in Web applications. To provide services ranging from maps to advertisements, Web applications may incorporate untrusted JavaScript code from third parties. The trusted portion of each application may then expose an API to untrusted code, interposing a reference monitor that mediates access to security-critical resources. However, a JavaScript reference monitor can only be effective if it cannot be circum- vented through programming tricks or programming language idiosyncracies. In order to verify complete mediation of critical resources for applications of interest, we dene the semantics of a restricted version of JavaScript devised by the ECMA Standards committee for isolation purposes, and develop and test an automated tool that can soundly establish that a given API cannot be circumvented or subverted. Our tool reveals a previously-undiscovered vulnerability in the widely-examined Yahoo! ADsafe lter and veries connement of the repaired lter and other examples from the Object-Capability literature.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41604.html
notfound
=========================
Digital Forensics with Open Source Tools
Syngress (2011)
[u'Cory Altheide', u'Harlan Carvey']
SecurityPrivacyandAbusePrevention
Abstract: Digital Forensics with Open Source Tools is the definitive book on investigating and analyzing computer systems and media using open source tools. The book is a technical procedural guide, and explains the use of these tools on Linux and Windows systems as a platform for performing computer forensics. Both well known and novel forensic methods are demonstrated using command-line and graphical open source computer forensic tools for examining a wide range of target systems and artifacts.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37237.html
notfound
=========================
Distributed forensics and incident response in the enterprise
Journal of Digital Investigation, vol. 8 (2011), S101-S110
[u'Michael Cohen', u'Darren Bilby', u'Germano Caronni']
SecurityPrivacyandAbusePrevention
Abstract: Remote live forensics has recently been increasingly used in order to facilitate rapid remote access to enterprise machines. We present the GRR Rapid Response Framework (GRR), a new multi-platform, open source tool for enterprise forensic investigations enabling remote raw disk and memory access. GRR is designed to be scalable, opening the door for continuous enterprise wide forensic analysis. This paper describes the architecture used by GRR and illustrates how it is used routinely to expedite enterprise forensic investigations.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37376.html
notfound
=========================
Fast Elliptic Curve Cryptography in OpenSSL
Financial Cryptography and Data Security: FC 2011 Workshops, RLCPS and WECSR, Springer
[u'Emilia Kasper']
SecurityPrivacyandAbusePrevention
Abstract: We present a 64-bit optimized implementation of the NIST and SECG-standardized elliptic curve P-224. Our implementation is fully integrated into OpenSSL 1.0.1: full TLS handshakes using a 1024-bit RSA certificate and ephemeral Elliptic Curve Diffie-Hellman key exchange over P-224 now run at twice the speed of standard OpenSSL, while atomic elliptic curve operations are up to 4 times faster. In addition, our implementation is immune to timing attacks - most notably, we show how to do small table look-ups in a cache-timing resistant way, allowing us to use precomputation. To put our results in context, we also discuss the various security performance trade-offs available to TLS applications.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37395.html
notfound
=========================
Hardware Trojan Detection Solutions and Design-for-Trust Challenges
IEEE Computer (2011), pp. 64-72
[u'Kurt Rosenfeld']
SecurityPrivacyandAbusePrevention
Abstract: Globalization of the semiconductor industry and evolving fabrication processes have made integrated circuits increasingly vulnerable to Trojans. Researchers must expand efforts to verify trust in intellectual property cores and ICs.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37128.html
notfound
=========================
Indirect Content Privacy Surveys: Measuring Privacy Without Asking About It
Symposium on Usable Privacy and Security (SOUPS), ACM SIGCHI (2011)
[u'Alex Braunstein', u'Laura Granka', u'Jessica Staddon']
SecurityPrivacyandAbusePrevention
Abstract: The strong emotional reaction elicited by privacy issues is well documented (e.g., [12, 8]). The emotional aspect of privacy makes it difficult to evaluate privacy concern, and directly asking about a privacy issue may result in an emo- tional reaction and a biased response. This effect may be partly responsible for the dramatic privacy concern ratings coming from recent surveys, ratings that often seem to be at odds with user behavior. In this paper we propose indirect techniques for measuring content privacy concerns through surveys, thus hopefully diminishing any emotional response. We present a design for indirect surveys and test the designs use as (1) a means to measure relative privacy concerns across content types, (2) a tool for predicting unwillingness to share content (a possible indicator of privacy concern), and (3) a gauge for two underlying dimensions of privacy content importance and the willingness to share content. Our evaluation consists of 3 surveys, taken by 200 users each, in which privacy is never asked about directly, but privacy warnings are issued with increasing escalation in the instruc- tions and individual question-wording. We demonstrate that this escalation results in statistically and practically signif- icant differences in responses to individual questions. In addition, we compare results against a direct privacy survey and show that rankings of privacy concerns are increasingly preserved as privacy language increases in the indirect sur- veys, thus indicating our mapping of the indirect questions to privacy ratings is accurately reflecting privacy concerns.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37150.html
notfound
=========================
Public vs. Publicized: Content Use Trends and Privacy Expectations
6th USENIX Workshop on Hot Topics in Security (HotSec '11), USENIX (2011)
[u'Jessica Staddon', u'Andrew Swerdlow']
SecurityPrivacyandAbusePrevention
Abstract: From a semantic standpoint, there is a clear differentia- tion between the meanings of public and publicized con- tent. The former includes any content that is accessible by anyone, while the latter emphasizes visibility publi- cized content is actively made available. As a users on- line experience becomes more personalized and data is increasingly pushed rather than pulled, the line between public and publicized content is inevitably blurred. In this position paper, we present quantitative evidence that despite this trend, in some settings users do not antici- pate the use of public content beyond the narrow context in which is was disclosed; they do not anticipate that the content may be publicized. While providing a publicized option for data is an important counterpart to the ability to limit access to data (e.g. through access con- trol lists), such an option must be accompanied by both greater user awareness of the ramifications of such an option and by transparency into data usage.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37661.html
notfound
=========================
Rootkits in your web application
28C3: Chaos Communications Congress, Berlin, Germany (2011)
[u'Artur Janc']
SecurityPrivacyandAbusePrevention
Abstract: In this work, I discuss practical approaches for exploiting cross-site scripting (XSS) and other client-side script injection vulnerabilities, and introduce novel techniques for maintaining and escalating access within the victim's browser. In particular, I introduce the concept of resident XSS where attacker-supplied code is running in the context of an affected user's main application window and describe its consequences. I also draw analogies between such persistent Web threats and traditional rootkits, including similarities in the areas of embedding malicious code, maintaining access, and the difficulty of detecting and removing attacker-supplied code. Details Despite a few high profile cases of XSS worms, the exploitation of script injection vulnerabilities has historically been mostly limited to cookie-stealing and executing simple malicious actions in the context of the affected Web application. However, as a consequence of inter-document interactions allowed by the same-origin policy and a combination of other browser mechanisms, a single XSS vulnerability can often lead to a long-term compromise all of a user's interactions with an affected webapp in the same browser profile, long after the original bug has been fixed. In particular, an attacker can maintain access across window/browser closures, survive cookie and cache deletions, and compromise other user accounts accessed from the same browser. Yet more troubling is the fact that Web application authors currently have no means to detect or mitigate such threats once an attack has taken place. In the talk I provide an overview of script injection attacks against Web clients, describe techniques to escalate an XSS into long-term account compromise, and introduce the concept of resident XSS where attacker-supplied code is injected into the user's main application window. Additionally, I explore the similarities between such Web bugs and traditional rootkits. In particular, I: Provide an overview of script injection vulnerabilities and describe real-world considerations for exploiting them against modern Web applications. Introduce the concept of resident XSS, where malicious JavaScript is executed in the context of the victim's main application window/tab. Contrary to the traditional methods of exploiting XSS via a hidden frame or malicious link which are opened in a separate, usually short-lived window, resident XSS gives an attacker full freedom to monitor and alter the user's interaction with the affected application. Describe several techniques to convert various Web bugs into a resident XSS. Such techniques include backdooring client-side persistent storage mechanisms (WebSQL, localStorage, Flash LSOs), opening poisoned application windows with injected malicious scripts, exploiting persistent (self-)XSS and others. Discuss the consequences of resident XSS, which usually allow the attacker to get permanent access to an affected user's account and/or obtain the user's application login credentials. On sensitive domains for which users have enabled access to additional browser or plugin features (geolocation, camera/microphone), it can enable persistent snooping on the exploited user. In a large number of cases it can also enable full compromise of the user's machine by exploiting the application-user trust relationship (e.g. by requiring the user to install attacker-supplied plugins to use the affected webapp, or by hijacking file download links within the vulnerable domain). Analyze the techniques for maintaining access to a once-compromised origin. In addition to backdooring persistent storage APIs, this can be achieved by exploiting self-XSS bugs, spawning same-origin pop-unders with references to the original window, and hiding in frames created by advertising networks on popular websites. In most cases, a combination of those techniques suffices to bypass a variety of the most common "cleanup" actions taken by users, and allows an on-going compromise of the affected origin. Present the difficulties faced by Web application authors when trying to clean up a compromised origin. Short of wiping/re-creating a browser profile, there are currently no fully reliable methods to restore a browser's state to a secure configuration once a malicious script has run in the context of an affected domain. A video of the presentation is below.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37396.html
notfound
=========================
Security Challenges During VLSI Test
Proceedings of 2011 IEEE NEWCAS Conference, IEEE
[u'Kurt Rosenfeld']
SecurityPrivacyandAbusePrevention
Abstract: VLSI testing is a practical requirement, but unless proper care is taken, features that enhance testability can reduce system security. Data confidentiality and intellectual property protection can be breached through testing security breaches. In this paper we review testing security problems, focusing on the scan technique. We then present some countermeasures which have recently been published and we discuss their characteristics.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37397.html
notfound
=========================
Security-Aware SoC Test Access Mechanisms
Proceedings of the 2011 IEEE VLSI Test Symposium
[u'Kurt Rosenfeld']
SecurityPrivacyandAbusePrevention
Abstract: Test access mechanisms are critical components in digital systems. They affect not only production and operational economics, but also system security. We propose a security enhancement for system-on-chip (SoC) test access that addresses the threat posed by untrustworthy cores. The scheme maintains the economy of shared wiring (bus or daisy-chain) while achieving most of the security benefits of star-topology test access wiring. Using the proposed scheme, the tester is able to establish distinct cryptographic session keys with each of the cores, significantly reducing the exposure in cases where one or more of the cores contains malicious or otherwise untrustworthy logic. The proposed scheme is out of the functional path and does not affect functional timing or power consumption.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38102.html
notfound
=========================
ShellOS: Enabling fast detection and forensic analysis of code injection attacks
USENIX Security Symposium (2011)
[u'Kevin Snow', u'Srinivas Krishnan', u'Fabian Monrose', u'Niels Provos']
SecurityPrivacyandAbusePrevention
Abstract: The availability of off-the-shelf exploitation toolkits for compromising hosts, coupled with the rapid rate of exploit discovery and disclosure, has made exploit or vulnerability-based detection far less effective than it once was. For instance, the increasing use of metamorphic and polymorphic techniques to deploy code injection attacks continues to confound signature-based detection techniques. The key to detecting these attacks lies in the ability to discover the presence of the injected code (or, shellcode). One promising technique for doing so is to examine data (be that from network streams or buffers of a process) and efciently execute its content to nd what lurks within. Unfortunately, current approaches for achieving this goal are not robust to evasion or scalable, primarily because of their reliance on software-based CPU emulators. In this paper, we argue that the use of software-based emulation techniques are not necessary, and instead propose a new framework that leverages hardware virtualization to better enable the detection of code injection attacks. We also report on our experience using this framework to analyze a corpus of malicious Portable Document Format (PDF) les and network-based attacks.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Third International Symposium on Engineering Secure Software and Systems, ESSoS 2011
Springer Verlag, Berlin / Heidelberg
[u'lfar Erlingsson', u'Roel Wieringa', u'Nicola Zannone', u'editors.']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37350.html
notfound
=========================
Transparency and Choice: Protecting Consumer Privacy in an Online World
W3C Workshop on Web Tracking and User Privacy, W3C (2011), pp. 3
[u'Alma Whitten', u'Sean Harvey', u'Ian Fette', u'Betsy Masiello', u'Jochen Eisinger', u'Jane Horvath']
SecurityPrivacyandAbusePrevention
Abstract: There have been concerns raised recently about online tracking. There are a variety of mechanisms by which data is collected online, and for which it is used, and it is unclear which of these are intended to be addressed by Do Not Track mechanisms. Tracking is often data collection that helps ensure the security and integrity of data, determines relevancy of served content and also helps create innovation opportunities. This value ought to be central in any Do Not Track discussions.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36642.html
notfound
=========================
Automata Evaluation and Text Search Protocols with Simulation Based Security
Google, Inc. (2010)
[u'Carmit Hazay', u'Rosario Gennaro', u'Jeffrey Sorensen']
SecurityPrivacyandAbusePrevention
Abstract: This paper presents an efficient protocol for securely computing the fundamental problem of pattern matching. This problem is defined in the two-party setting, where party P1 holds a pattern and party P2 holds a text. The goal of P1 is to learn where the pattern appears in the text, without revealing it to P2 or learning anything else about P2's text. Our protocol is the first to address this problem with full security in the face of malicious adversaries. The construction is based on a novel protocol for secure oblivious automata evaluation which is of independent interest. In this problem, party P1 holds an automaton and party P2 holds an input string, and they need to decide if the automaton accepts the input, without learning anything else.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37841.html
notfound
=========================
Dagstuhl Seminar 09141: Web Application Security (Abstracts collection)
Dagstuhl Seminar Proceedings, Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik, Germany, Dagstuhl, Germany (2010)
[u'Dan Boneh', u'lfar Erlingsson', u'Martin Johns', u'Benjamin Livshits']
SecurityPrivacyandAbusePrevention
Abstract: From 29th March to 3rd April 2009 the Dagstuhl Seminar 09141 Web Application Security was held in Schloss Dagstuhl -- Leibniz Center for Informatics. During the seminar, several participants presented their current research, and ongoing work and open problems were discussed. Abstracts of the presentations given during the seminar are put together in this paper. Links to full papers (if available) are provided in the corresponding seminar summary document.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Drac: An Architecture for Anonymous Low-Volume Communications
PETS 2010 (to appear)
[u'George Danezis', u'Claudia Diaz', u'Carmela Troncosco', u'Ben Laurie']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Engineering Privacy in an Age of Information Abundance
Intelligent Privacy Management Symposium (2010)
[u'Betsy Masiello', u'Alma Whitten']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Group Message Authentication
Security and Cryptography for Networks, SCN 2010, Springer Verlag, pp. 399-417
[u'Bartosz Przydatek', u'Douglas Wikstrm']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Improving users' security choices on home wireless networks
Proceedings of the Sixth Symposium on Usable Privacy and Security, ACM, New York, NY, USA (2010), 12:1-12:12
[u'Justin T. Ho', u'David Dearman', u'Khai N. Truong']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35580.html
notfound
=========================
Large-Scale Automatic Classification of Phishing Pages
NDSS '10 (2010)
[u'Colin Whittaker', u'Brian Ryner', u'Marria Nazif']
SecurityPrivacyandAbusePrevention
Abstract: Phishing websites, fraudulent sites that trick viewers into interacting with them, continue to cost Internet users over a billion dollars each year. In this paper, we describe the design and performance characteristics of a scalable machine learning classifier we developed to detect phishing web sites. We use this classifier to maintain Google's phishing blacklist automatically. Our classifier analyzes millions of pages a day, examining the URL and the contents of a page to determine whether or not a page is phishing. Unlike previous work in this field, we train the classifier on a noisy dataset consisting of millions of samples from previously collected live classification data. Despite the noise in the training data, our classifier learns a robust model for identifying phishing pages which correctly classifies more than 90% of phishing pages several weeks after training concludes.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36497.html
notfound
=========================
Making Privacy a Fundamental Component of Web Resources
W3C Workshop on Privacy for Advanced Web APIs, W3C (2010), pp. 5
[u'Thomas Duebendorfer', u'Christoph Renner', u'Tyrone Grandison', u'Michael Maximilien', u'Mark Weitzel']
SecurityPrivacyandAbusePrevention
Abstract: We present a social network inspired and access control list based sharing model for web resources. We have specified it as an extension for OpenSocial 1.0 and implemented a proof of concept in Orkut as well as a mobile social photo sharing application using it. The paper explains important design decisions and how the model can be leveraged to make privacy a core component and enabler for sharing resources on the web and beyond using capabilities of mobile devices.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36731.html
notfound
=========================
Practical Privacy Concerns in a Real World Browser
W3C Workshop on Privacy for Advanced Web APIs, W3C (2010), pp. 4
[u'Ian Fette', u'Jochen Eisinger']
SecurityPrivacyandAbusePrevention
Abstract: Google Chrome has implemented a number of HTML5 APIs, including the Geolocation API and various storage APIs. In this paper we discuss some of our experiences on the Google Chrome team in implementing these APIs, as well as our thoughts around privacy for new APIs we are considering implementing. Specifically, we discuss our ideas of how providing access to things such as speech, web cameras, and filesystems can be done in ways that are understandable and in the natural flow of users.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38394.html
notfound
=========================
Protecting Browsers from Extension Vulnerabilities
Network and Distributed System Security Symposium (2010)
[u'Adam Barth', u'Adrienne Porter Felt', u'Prateek Saxena', u'Aaron Boodman']
SecurityPrivacyandAbusePrevention
Abstract: Browser extensions are remarkably popular, with one in three Firefox users running at least one extension. Although well-intentioned, extension developers are often not security experts and write buggy code that can be exploited by malicious web site operators. In the Firefox extension system, these exploits are dangerous because extensions run with the user's full privileges and can read and write arbitrary files and launch new processes. In this paper, we analyze 25 popular Firefox extensions and find that 88% of these extensions need less than the full set of available privileges. Additionally, we find that 76% of these extensions use unnecessarily powerful APIs, making it difficult to reduce their privileges. We propose a new browser extension system that improves security by using least privilege, privilege separation, and strong isolation. Our system limits the misdeeds an attacker can perform through an extension vulnerability. Our design has been adopted as the Google Chrome extension system.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36553.html
notfound
=========================
PseudoID: Enhancing Privacy in Federated Login
Hot Topics in Privacy Enhancing Technologies (2010), pp. 95-107
[u'Arkajit Dey', u'Stephen Weis']
SecurityPrivacyandAbusePrevention
Abstract: PseudoID is a federated login system that protects users from disclosure of private login data held by identity providers. We offer a proof of concept implementation of PseudoID based on blind digital signatures that is backward-compatible with a popular federated login system named OpenID. We also propose several extensions and discuss some of the practical challenges that must be overcome to further protect user privacy in federated login systems.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36624.html
notfound
=========================
Public-Key Encryption in the Bounded-Retrieval Model
Advances in Cryptology - EUROCRYPT 2010, 29th Annual International Conference on the Theory and Applications of Cryptographic Techniques, French Riviera, May 30 - June 3, 2010. Proceedings, Springer, pp. 113-134
[u'Joel Alwen', u'Yevgeniy Dodis', u'Moni Naor', u'Gil Segev', u'Shabsi Walfish', u'Daniel Wichs']
SecurityPrivacyandAbusePrevention
Abstract: We construct the first public-key encryption scheme in the Bounded-Retrieval Model (BRM), providing security against various forms of adversarial "key leakage" attacks. In this model, the adversary is allowed to learn arbitrary information about the decryption key, subject only to the constraint that the overall amount of "leakage" is bounded by at most L bits. The goal of the BRM is to design cryptographic schemes that can flexibly tolerate arbitrarily leakage bounds L (few bits or many Gigabytes), by only increasing the size of secret key proportionally, but keeping all the other parameters -- including the size of the public key, ciphertext, encryption/decryption time, and the number of secret-key bits accessed during decryption - small and independent of L. As our main technical tool, we introduce the concept of an Identity-Based Hash Proof System (IB-HPS), which generalizes the notion of hash proof systems of Cramer and Shoup [CS02] to the identity-based setting. We give three different constructions of this primitive based on: (1) bilinear groups, (2) lattices, and (3) quadratic residuosity. As a result of independent interest, we show that an IB-HPS almost immediately yields an Identity-Based Encryption (IBE) scheme which is secure against (small) partial leakage of the target identitys decryption key. As our main result, we use IB-HPS to construct public-key encryption (and IBE) schemes in the Bounded-Retrieval Model.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36502.html
notfound
=========================
Technology Companies are Best Positioned to Offer Health Record Trusts
HealthSec '10 Position Paper (2010)
[u'Shirley Gaw', u'Umesh Shankar']
SecurityPrivacyandAbusePrevention
Abstract: The current health system lacks assurances to patients of data retention and privacy control. We argue that this is due to discrepancies in how health data is reported and consumed and contrast this with how financial credit data is reported and consumed. To address these health system gaps in protection of medical data, we would like to evangelize the implementation of health record trusts. Finally, we argue that Personal Health Records (PHRs) are the closest to offering the main features of health record trusts.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36346.html
notfound
=========================
The Nocebo Effect on the Web: An Analysis of Fake Anti-Virus Distribution
Large-Scale Exploits and Emergent Threats, USENIX (2010)
[u'Moheeb Abu Rajab', u'Lucas Ballard', u'Panayiotis Marvrommatis', u'Niels Provos', u'Xin Zhao']
SecurityPrivacyandAbusePrevention
Abstract: We present a study of Fake Anti-Virus attacks on the web. Fake AV software masquerades as a legitimate security product with the goal of deceiving victims into paying registration fees to seemingly remove malware from their computers. Our analysis of 240 million web pages collected by Google's malware detection infrastructure over a 13 month period discovered over 11,000 domains involved in Fake AV distribution. We show that the Fake AV threat is rising in prevalence, both absolutely, and relative to other forms of web-based malware. Fake AV currently accounts for 15% of all malware we detect on the web. Our investigation reveals several characteristics that distinguish Fake AVs from other forms of web-based malware and shows how these characteristics have changed over time. For instance, Fake AV attacks occur frequently via web sites likely to reach more users including spam web sites and on-line Ads. These attacks account for 60% of the malware discovered on domains that include trending keywords. As of this writing, Fake AV is responsible for 50% of all malware delivered via Ads, which represents a five-fold increase from just a year ago.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37398.html
notfound
=========================
Trustworthy Hardware: Identifying and Classifying Hardware Trojans
IEEE Design and Test of Computers (2010), pp. 39-46
[u'Kurt Rosenfeld']
SecurityPrivacyandAbusePrevention
Abstract: For reasons of economy, critical systems will inevitably depend on electronics made in untrusted factories. A proposed new hardware Trojan taxonomy provides a first step in better understanding existing and potential threats.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36584.html
notfound
=========================
Universally optimal privacy mechanisms for minimax agents
Proc. ACM SIGMOD, ACM, Indianapolis, Indiana (2010), pp. 135-146
[u'Mangesh Gupte', u'Mukund Sundararajan']
SecurityPrivacyandAbusePrevention
Abstract: A scheme that publishes aggregate information about sensitive data must resolve the trade-off between utility to information consumers and privacy of the database participants. Differential privacy is a well-established definition of privacy--this is a universal guarantee against all attackers, whatever their side-information or intent. Can we have a similar universal guarantee for utility? There are two standard models of utility considered in decision theory: Bayesian and minimax. Ghosh et. al. show that a certain "geometric mechanism" gives optimal utility to all Bayesian information consumers. In this paper, we prove a similar result for minimax information consumers. Our result also works for a wider class of information consumers which includes Bayesian information consumers and subsumes the result from [8]. We model information consumers as minimax (risk-averse) agents, each endowed with a loss-function which models their tolerance to inaccuracies and each possessing some side-information about the query. Further, information consumers are rational in the sense that they actively combine information from the mechanism with their side-information in a way that minimizes their loss. Under this assumption of rational behavior, we show that for every fixed count query, the geometric mechanism is universally optimal for all minimax information consumers. Additionally, our solution makes it possible to release query results, when information consumers are at different levels of privacy, in a collusion-resistant manner.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36501.html
notfound
=========================
Using the Wave Protocol to Represent Individuals Health Records
HealthSec '10 Position Paper (2010)
[u'Shirley Gaw', u'Umesh Shankar']
SecurityPrivacyandAbusePrevention
Abstract: There are several challenges in aggregating health records from multiple sources, including merging data, preserving proper attribution, and allowing corrections. unfortunately, standards for exchanging medical records data, such as CCR and CCD, tend to focus on representing particular clinical data as some subset of a patients complete record. This provides a snapshot of a patient record, but there is very little to describe how a sequence of changes to the record should be interpreted as a coherent whole.there is something available that gives us the data aggregation, conflict resolution, and audit trail that what we want: the Wave federation protocol.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38288.html
notfound
=========================
Web Application Obfuscation
Syngress (2010), pp. 282
[u'Eduardo Alberto Vela Nava']
SecurityPrivacyandAbusePrevention
Abstract: Web Application Obfuscation aims to instruct developers and security professionals about the different peculiarities in browsers that can be used to attack and hide an attack in web applications, as well as bypass web application firewalls, and intrusion detection systems.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A New Randomness Extraction Paradigm for Hybrid Encryption
EUROCRYPT '09: Proceedings of the 28th Annual International Conference on Advances in Cryptology, Springer-Verlag, Berlin, Heidelberg (2009), pp. 590-609
[u'Eike Kiltz', u'Krzysztof Pietrzak', u'Martijn Stam', u'Moti Yung']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Unified Framework for the Analysis of Side-Channel Key Recovery Attacks
EUROCRYPT '09: Proceedings of the 28th Annual International Conference on Advances in Cryptology, Springer-Verlag, Berlin, Heidelberg (2009), pp. 443-461
[u'Franois-Xavier Standaert', u'Tal G. Malkin', u'Moti Yung']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35116.html
notfound
=========================
Balancing Usability and Security in a Video CAPTCHA
Proceedings of the 5th Symposium on Usable Privacy and Security (SOUPS '09), ACM Press (2009)
[u'Kurt Alfred Kluever', u'Richard Zanibbi']
SecurityPrivacyandAbusePrevention
Abstract: We present a technique for using a content-based video labeling task as a CAPTCHA. Our video CAPTCHAs are generated from YouTube videos, which contain labels (tags) supplied by the person that uploaded the video. They are graded using a video's tags, as well as tags from related videos. In a user study involving 184 participants, we were able to increase the average human success rate on our video CAPTCHA from roughly 70% to 90%, while keeping the average success rate of a tag frequency-based attack fixed at around 13%. Through a different parameterization of the challenge generation and grading algorithms, we were able to reduce the success rate of the same attack to 2%, while still increasing the human success rate from 70% to 75%. The usability and security of our video CAPTCHA appears to be comparable to existing CAPTCHAs, and a majority of participants (60%) indicated that they found the video CAPTCHAs more enjoyable than traditional CAPTCHAs in which distorted text must be transcribed.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Browser Security: Lessons from Google Chrome
ACM Queue, vol. 7, no. 5 (2009), pp. 3
[u'Charles Reis', u'Adam Barth', u'Carlos Pizano']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35245.html
notfound
=========================
Capacity of Steganographic Channels
IEEE Transactions on Information Theory, vol. 55 (2009), pp. 1775-1792
[u'Jeremiah Harmsen', u'William Pearlman']
SecurityPrivacyandAbusePrevention
Abstract: This work investigates a central problem in steganography, that is: How much data can safely be hidden without being detected? To answer this question, a formal definition of steganographic capacity is presented. Once this has been defined, a general formula for the capacity is developed. The formula is applicable to a very broad spectrum of channels due to the use of an information-spectrum approach. This approach allows for the analysis of arbitrary steganalyzers as well as nonstationary, nonergodic encoder and attack channels. After the general formula is presented, various simplifications are applied to gain insight into example hiding and detection methodologies. Finally, the context and applications of the work are summarized in a general discussion.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Composability and On-Line Deniability of Authentication
Springer, pp. 146-162
[u'Yevgeniy Dodis', u'Jonathan Katz', u'Adam Smith', u'Shabsi Walfish']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Constructing Variable-Length PRPs and SPRPs from Fixed-Length PRPs
Information Security and Cryptology, Springer-Verlag, Berlin, Heidelberg (2009), pp. 157-180
[u'Debra L. Cook', u'Moti Yung', u'Angelos Keromytis']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40401.html
notfound
=========================
E Unum Pluribus - Google Network Filtering Management
LISA'09 23rd Large Installation System Administration Conference (2009)
[u'Paul (Tony) Watson', u'Peter Moody']
SecurityPrivacyandAbusePrevention
Abstract: Network filtering can be a very difficult challenge in large, complex and sprawling networks. Through the use of internally developed software, Google has automated and simplified many of the difficult tasks and provided the capability to easily audit and validate its filters. This talk will discuss our efforts in this area and release some of these tools to the community.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Efficient Robust Private Set Intersection
ACNS '09: Proceedings of the 7th International Conference on Applied Cryptography and Network Security, Springer-Verlag, Berlin, Heidelberg (2009), pp. 125-142
[u'Dana Dachman-Soled', u'Tal Malkin', u'Mariana Raykova', u'Moti Yung']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Efficient Traceable Signatures in the Standard Model
Pairing '09: Proceedings of the 3rd International Conference Palo Alto on Pairing-Based Cryptography, Springer-Verlag, Berlin, Heidelberg (2009), pp. 187-205
[u'Benot Libert', u'Moti Yung']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Efficient and secure authenticated key exchange using weak passwords
J. ACM, vol. 57 (2009), pp. 1-39
[u'Jonathan Katz', u'Rafail Ostrovsky', u'Moti Yung']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Elastic block ciphers: method, security and instantiations
Int. J. Inf. Secur., vol. 8 (2009), pp. 211-231
[u'Debra L. Cook', u'Moti Yung', u'Angelos D. Keromytis']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Expecting the Unexpected: Towards Robust Credential Infrastructure
Financial Cryptography and Data Security, Springer-Verlag, Berlin, Heidelberg (2009), pp. 201-221
[u'Shouhuai Xu', u'Moti Yung']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Firefox (In)Security Update Dynamics Exposed
ACM Sigcomm Comput. Commun. Rev., vol. 39 Issue 1 (2009), pp. 16-22
[u'Stefan Frei', u'Thomas Duebendorfer', u'Bernhard Plattner']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Generative usability: security and user centered design beyond the appliance
New Security Paradigms Workshop (2009)
[u'Luke Church', u'Alma Whitten']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Key Evolution Systems in Untrusted Update Environments
Information Security and Cryptology, Springer-Verlag, Berlin, Heidelberg (2009), pp. 12-21
[u'Benot Libert', u'Jean-Jacques Quisquater', u'Moti Yung']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36378.html
notfound
=========================
MAC Reforgeability
Fast Software Encryption, Springer (2009), pp. 345-362
[u'John Black', u'Martin Cochran']
SecurityPrivacyandAbusePrevention
Abstract: Message Authentication Codes (MACs) are core algorithms deployed in virtually every security protocol in common usage. In these protocols, the integrity and authenticity of messages rely entirely on the security of the MAC; we examine cases in which this security is lost. In this paper, we examine the notion of "reforgeability" for MACs, and motivate its utility in the context of {power, bandwidth, CPU}-constrained computing environments. We first give a definition for this new notion, then examine some of the most widely-used and well-known MACs under our definition in a variety of adversarial settings, finding in nearly all cases a failure to meet the new notion. We examine simple counter-measures to increase resistance to reforgeability, using state and truncating the tag length, but find that both are not simultaneously applicable to modern MACs. In response, we give a tight security reduction for a new MAC, WMAC, which we argue is the "best fit" for resource-limited devices.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
On the Portability of Generalized Schnorr Proofs
EUROCRYPT '09: Proceedings of the 28th Annual International Conference on Advances in Cryptology, Springer-Verlag, Berlin, Heidelberg (2009), pp. 425-442
[u'Jan Camenisch', u'Aggelos Kiayias', u'Moti Yung']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Plinko: polling with a physical implementation of a noisy channel
WPES '09: Proceedings of the 8th ACM workshop on Privacy in the electronic society, ACM, New York, NY, USA (2009), pp. 109-112
[u'Chris Alexander', u'Joel Reardon', u'Ian Goldberg']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Privacy-Preserving Information Markets for Computing Statistical Data
Financial Cryptography and Data Security, Springer-Verlag, Berlin, Heidelberg (2009), pp. 32-50
[u'Aggelos Kiayias', u'Blent Yener', u'Moti Yung']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Privacy-preserving indexing of documents on the network
The VLDB Journal, vol. 18 (2009), pp. 837-856
[u'Mayank Bawa', u'Roberto J. Bayardo', u'Rakesh Agrawal', u'Jaideep Vaidya']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Redirects to login pages are bad, or are they?
SOUPS '09: Proceedings of the 5th Symposium on Usable Privacy and Security, ACM, New York, NY, USA (2009), pp. 1-1
[u'Eric Sachs']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Secure EPC Gen2 Compliant Radio Frequency Identification
ADHOC-NOW '09: Proceedings of the 8th International Conference on Ad-Hoc, Mobile and Wireless Networks, Springer-Verlag, Berlin, Heidelberg (2009), pp. 227-240
[u'Mike Burmester', u'Breno Medeiros', u'Jorge Munilla', u'Alberto Peinado']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Secure Function Collection with Sublinear Storage
ICALP '09: Proceedings of the 36th Internatilonal Collogquium on Automata, Languages and Programming, Springer-Verlag, Berlin, Heidelberg (2009), pp. 534-545
[u'Maged H. Ibrahim', u'Aggelos Kiayias', u'Moti Yung', u'Hong-Sheng Zhou']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34836.html
notfound
=========================
The Goals and Challenges of Click Fraud Penetration Testing Systems
International Symposium on Software Reliability Engineering, International Symposium on Software Reliability Engineering (2009)
[u'Carmelo Kintana', u'David Turner', u'Jia-Yu Pan', u'Ahmed Metwally', u'Neil Daswani', u'Erika Chin', u'Andrew Bortz']
SecurityPrivacyandAbusePrevention
Abstract: It is important for search and pay-per-click engines to penetration test their click fraud detection systems, in order to find potential vulnerabilities and correct them before fraudsters can exploit them. In this paper, we describe: (1) some goals and desirable qualities of a click fraud penetration testing system, based on our experience, and (2) our experiences with the challenges of building and using a click fraud penetration testing system called Camelot that has been in use at Google.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
The Kurosawa-Desmedt key encapsulation is not chosen-ciphertext secure
Inf. Process. Lett., vol. 109 (2009), pp. 897-901
[u'Seung Geol Choi', u'Javier Herranz', u'Dennis Hofheinz', u'Jung Yeon Hwang', u'Eike Kiltz', u'Dong Hoon Lee', u'Moti Yung']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35246.html
notfound
=========================
Why Silent Updates Boost Security
ETH Zurich (2009), pp. 1-9
[u'Thomas Duebendorfer', u'Stefan Frei']
SecurityPrivacyandAbusePrevention
Abstract: Security fixes and feature improvements don't benefit the end user of software if the update mechanism and strategy is not effective. In this paper we analyze the effectiveness of different Web browsers update mechanisms; from Chrome's silent update mechanism to Opera's update requiring a full re-installation. We use anonymized logs from Google's world wide distributed Web servers. An analysis of the logged HTTP user-agent string that Web browsers report when requesting any Web page is used to measure the daily browser version shares in active use. To the best of our knowledge, this is the first global scale measurement of Web browser update effectiveness comparing four different Web browser update strategies. Our measurements prove that silent updates and little dependency on the underlying operating system are most effective to get users of Web browsers to surf the Web with the latest browser version. However, there is still room for improvement as we found. Chrome's advantageous silent update mechanism has been open sourced in April 2009. We recommend any software vendor to seriously consider deploying silent updates as this benefits both the vendor and the user, especially for widely used attack-exposed applications like Web browsers and browser plug-ins.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
xBook: Redesigning Privacy Control in Social Networking Platforms
18th Usenix Security Symposium, Usenix (2009)
[u'Kapil Singh', u'Sumeer Bhola', u'Wenke Lee']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
(Under)mining Privacy in Social Networks
W2SP 2008: Web 2.0 Security and Privacy 2008
[u'Monica Chew', u'Dirk Balfanz', u'Ben Laurie']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A block cipher based pseudo random number generator secure against side-channel key recovery
ASIACCS '08: Proceedings of the 2008 ACM symposium on Information, computer and communications security, ACM, New York, NY, USA, pp. 56-65
[u'Christophe Petit', u'Franois-Xavier Standaert', u'Olivier Pereira', u'Tal G. Malkin', u'Moti Yung']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Access Control
Google, Inc. (2008)
[u'Ben Laurie']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
All Your iFrames Point to Us
17th USENIX Security Symposium (2008)
[u'Niels Provos', u'Panayiotis Mavrommatis', u'Moheeb Rajab', u'Fabian Monrose']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Anonymous RFID authentication supporting constant cost key lookup against active adversaries
Int. J. Appl. Cryptol., vol. 1 (2008), pp. 79-90
[u'M. Burmester', u'B. De Medeiros', u'R. Motta']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Asynchronous Multi-Party Computation with Quadratic Communication
International Colloquium on Automata, Languages and Programming, ICALP 2008, Springer Verlag, pp. 473-485
[u'Martin Hirt', u'Jesper Buus Nielsen', u'Bartosz Przydatek']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Choose the Red Pill and the Blue Pill
New Security Paradigms Workshop 2008
[u'Ben Laurie', u'Abe Singer']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34324.html
notfound
=========================
Competition and Fraud in Online Advertising Markets
Financial Cryptography (2008)
[u'Bob Mungamuru', u'Stephen A. Weis']
SecurityPrivacyandAbusePrevention
Abstract: An economic model of the online advertising market is presented, focusing on the effect of ad fraud. In the model, the market is comprised of three classes of players: publishers, advertising networks, and advertisers. The central question is whether ad networks have an incentive to aggressively combat fraud. The main outcome of the model is to answer this question in the affirmative
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub33426.html
notfound
=========================
Corrupted DNS Resolution Paths: The Rise of a Malicious Resolution Authority
Proc. 15th Network and Distributed System Security Symposium (NDSS), Internet Society, San Diego, CA (2008)
[u'David Dagon', u'Chris Lee', u'Wenke Lee', u'Niels Provos']
SecurityPrivacyandAbusePrevention
Abstract: We study and document an important development in how attackers are using Internet resources: the creation of malicious DNS resolution paths. In this growing form of attack, victims are forced to use rogue DNS servers for all resolution. To document the rise of this "second secret authority" on the Internet, we studied instances of aberrant DNS resolution on a university campus. We found dozens of viruses that corrupt resolution paths, and noted that hundreds of URLs discovered per week performed drive-by alterations of host DNS settings.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34344.html
notfound
=========================
Distributed divide-and-conquer techniques for effective DDoS attack defenses
IEEE International Conference on Distributed Computing Systems (ICDCS) (2008)
[u'Muthuprasanna Muthusrinivasan', u'Manimaran Govindarasu']
SecurityPrivacyandAbusePrevention
Abstract: Distributed Denial-of-Service (DDoS) attacks have emerged as a popular means of causing mass targeted service disruptions, often for extended periods of time. The relative ease and low costs of launching such attacks, supplemented by the current woeful state of any viable defense mechanism, have made them one of the top threats to the Internet community today. While distributed packet logging and/or packet marking have been explored in the past for DDoS attack traceback/mitigation, we propose to advance the state of the art by using a novel distributed divide-and-conquer approach in designing a new data dissemination architecture that efficiently tracks attack sources. The main focus of our work is to tackle the three disjoint aspects of the problem, namely attack tree construction, attack path frequency detection, and packet to path association, independently and to use succinct recurrence relations to express their individual implementations. We also evaluate the network traffic and storage overhead induced by our proposed deployment on real-life Internet topologies, supporting hundreds of victims each subject to thousands of high-bandwidth flows simultaneously, and conclude that we can truly achieve single packet traceback guarantees with minimal overhead and high efficiency.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Does Physical Security of Cryptographic Devices Need a Formal Study? (Invited Talk)
ICITS '08: Proceedings of the 3rd international conference on Information Theoretic Security, Springer-Verlag, Berlin, Heidelberg (2008), pp. 70-70
[u'Franois-Xavier Standaert', u'Tal G. Malkin', u'Moti Yung']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Efficient Constructions of Composable Commitments and Zero-Knowledge Proofs
Proceedings of Advances in Cryptology - CRYPTO 2008, 28th Annual International Cryptology Conference, Santa Barbara, CA, USA, August 17-21, 2008, pp. 515-535
[u'Yevgeniy Dodis', u'Victor Shoup', u'Shabsi Walfish']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Error-Tolerant Combiners for Oblivious Primitives
International Colloquium on Automata, Languages and Programming, ICALP 2008, Springer Verlag, pp. 461-472
[u'Bartosz Przydatek', u'Jrg Wullschleger']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Fair Traceable Multi-Group Signatures
Financial Cryptography, Springer-Verlag, Berlin, Heidelberg (2008), pp. 231-246
[u'Vicente Benjumea', u'Seung Geol Choi', u'Javier Lopez', u'Moti Yung']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Ghost Turns Zombie: Exploring the Life Cycle of Web-based Malware
Proceedings of the 1st USENIX Workshop on Large-Scale Exploits and Emergent Threats (LEET) (2008)
[u'Michalis Polychronakis', u'Panayiotis Mavrommatis', u'Niels Provos']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Insecure Context Switching: Innoculating regular expressions for survivability
2nd USENIX Workshop on Offensive Technologies (WOOT '08) (2008)
[u'Will Drewry', u'Tavis Ormandy']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Methods for Linear and Differential Cryptanalysis of Elastic Block Ciphers
ACISP '08: Proceedings of the 13th Australasian conference on Information Security and Privacy, Springer-Verlag, Berlin, Heidelberg (2008), pp. 187-202
[u'Debra L. Cook', u'Moti Yung', u'Angelos D. Keromytis']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
On the Evolution of User Authentication: Non-bilateral Factors
Information Security and Cryptology, Third SKLOIS Conference, Inscrypt 2007, Springer-Verlag, Berlin, Heidelberg (2008), pp. 5-10
[u'Moti Yung']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Peeking Through the Cloud
6th Conference on Applied Cryptography and Network Security (2008)
[u'Moheeb Abu Rajab', u'Fabian Monrose', u'Andreas Terzis', u'Niels Provos']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Plan 9 Authentication in Linux
ACM SIGOPS OSR special issue on Research and Developments in the Linux Kernel, vol. 42, Issue 5 (July 2008) (2008)
[u'Ashwin Ganti']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35042.html
notfound
=========================
Please Permit Me: Stateless Delegated Authorization in Mashups
Proceedings of the Annual Computer Security Applications Conference, IEEE Press, Anaheim, CA (2008), pp. 173-182
[u'Ragib Hasan', u'Marianne Winslett', u'Richard Conlan', u'Brian Slesinsky', u'Nandakumar Ramani']
SecurityPrivacyandAbusePrevention
Abstract: Mashups have emerged as a Web 2.0 phenomenon, connecting disjoint applications together to provide unified services. However, scalable access control for mashups is difficult. To enable a mashup to gather data from legacy applications and services, users must give the mashup their login names and passwords for those services. This all-or-nothing approach violates the principle of least privilege (not to mention the terms of service) and leaves users vulnerable to misuse of their credentials by malicious mashups. In this paper, we introduce Permits - a stateless approach to access rights delegation in mashups - and describe our complete implementation of a permit-based authorization delegation service.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Privacy Preserving Data Mining within Anonymous Credential Systems
SCN '08: Proceedings of the 6th international conference on Security and Cryptography for Networks, Springer-Verlag, Berlin, Heidelberg (2008), pp. 57-76
[u'Aggelos Kiayias', u'Shouhuai Xu', u'Moti Yung']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Provably Secure Grouping-Proofs for RFID Tags
CARDIS '08: Proceedings of the 8th IFIP WG 8.8/11.2 international conference on Smart Card Research and Advanced Applications, Springer-Verlag, Berlin, Heidelberg (2008), pp. 176-190
[u'Mike Burmester', u'Breno Medeiros', u'Rossana Motta']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Public-key traitor tracing from efficient decoding and unbounded enrollment: extended abstract
DRM '08: Proceedings of the 8th ACM workshop on Digital rights management, ACM, New York, NY, USA (2008), pp. 9-18
[u'Aggelos Kiayias', u'Moti Yung']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Real Electronic Cash Versus Academic Electronic Cash Versus Paper Cash (Panel Report)
Financial Cryptography and Data Security, Springer-Verlag, Berlin, Heidelberg (2008), pp. 307-313
[u'Jon Callas', u'Yvo Desmedt', u'Daniel Nagy', u'Akira Otsuka', u'Jean-Jacques Quisquater', u'Moti Yung']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Securing Nonintrusive Web Encryption through Information Flow
Proceedings of the 2008 workshop on programming languages and analysis for security
[u'Lantian Zheng', u'Andrew C. Myers']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Security aspects of the Authentication used in Quantum Cryptography
IEEE Transactions on Information Theory, vol. 54 (2008), pp. 1735-1741
[u'Jrgen Cederlf', u'Jan-ke Larsson']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
To Catch a Predator: A Natural Language Approach for Eliciting Protocol Interaction
17th USENIX Security Symposium (2008)
[u'Sam Small', u'Joshua Mason', u'Fabian Monrose', u'Niels Provos', u'Adam Stubblefield']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Understanding the Web browser threat
ETH Zurich
[u'Stefan Frei', u'Thomas Duebendorfer', u'Gunter Ollmann', u'Martin May']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35117.html
notfound
=========================
Video CAPTCHAs: Usability vs. Security
Proceedings of the IEEE Western New York Image Processing Workshop (WNYIP '08), IEEE Press (2008)
[u'Kurt Alfred Kluever', u'Richard Zanibbi']
SecurityPrivacyandAbusePrevention
Abstract: A CAPTCHA is a variation of the Turing test, in which a challenge is used to distinguish humans from computers (bots) on the internet. They are commonly used to prevent the abuse of online services. CAPTCHAs discriminate using hard artificial intelligence problems: the most common type requires a user to transcribe distorted characters displayed within a noisy image. Unfortunately, many users find them frustrating and break rates as high as 60% have been reported (for Microsofts Hotmail). We present a new CAPTCHA in which users provide three words (tags) that describe a video. A challenge is passed if a users tag belongs to a set of automatically generated ground-truth tags. In an experiment, we were able to increase human pass rates for our video CAPTCHAs from 69.7% to 90.2% (184 participants over 20 videos). Under the same conditions, the pass rate for an attack submitting the three most frequent tags (estimated over 86,368 videos) remained nearly constant (5% over the 20 videos, roughly 12.9% over a separate sample of 5146 videos). Challenge videos were taken from YouTube.com. For each video, 90 tags were added from related videos to the ground-truth set; security was maintained by pruning all tags with a frequency 0.6%. Tag stemming and approximate matching were also used to increase human pass rates. Only 20.1% of participants preferred text-based CAPTCHAs, while 58.2% preferred our video-based alternative. Finally, we demonstrate how our technique for extending the ground truth tags allows for different usability/security trade-offs, and discuss how it can be applied to other types of CAPTCHAs.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Framework for Detection and Measurement of Phishing Attacks
WORM'07, ACM, Alexandria, VA (2007)
[u'Sujata Garera', u'Niels Provos', u'Monica Chew', u'Aviel D. Rubin']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
An Empirical Study into the Security Exposure to Hosts of Hostile Virtualized Environments
CanSecWest 2007
[u'Tavis Ormandy']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Byzantine Attacks on Anonymity Systems
Digital Privacy: Theory, Technologies, and Practices (2007)
[u'Nikita Borisov', u'George Danezis', u'Parisa Tabriz']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Cyberassault on Estonia
IEEE Security and Privacy, vol. 5, no. 4 (2007), pp. 4
[u'Marc Donner']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Defining Strong Privacy for RFID
Proc. 5th International Conf. on Pervasive Computing and Communications Workshops, IEEE (2007), pp. 342-347
[u'Ari Juels', u'Stephen A. Weis']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub33037.html
notfound
=========================
Delegating Responsibility in Digital Systems: Horton's
2nd USENIX Workshop on Hot Topics in Security, USENIX (2007), pp. 5
[u'Mark S. Miller', u'Jed Donnelley', u'Alan H. Karp']
SecurityPrivacyandAbusePrevention
Abstract: Programs do good things, but also do bad, making software security more than a fad. The authority of programs, we do need to tame. But bad things still happen. Who do we blame? From the very beginnings of access control: Should we be safe by construction, or should we patrol? Horton shows how, in an elegant way, we can simply do both, and so save the day. with apologies to Dr. Seuss
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Denial of Service or Denial of Security? How Attacks can Compromize Anonymity
Conference on Computer and Communications Security, ACM, Alexandria, VA (2007)
[u'Nikita Borisov', u'George Danezis', u'Prateek Mittal', u'Parisa Tabriz']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Dynamic Pharming Attacks and Locked Same-Origin Policies for Web Browsers
Conference on Computer and Communications Security, ACM, Alexandria, VA (2007)
[u'Chris Karlof', u'Umesh Shankar', u'J. D. Tygar', u'David Wagner']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Flayer: Exposing Application Internals
First USENIX Workshop on Offensive Technologies (WOOT '07), Online Proceedings, http://www.usenix.org/events/woot07/tech/ (2007)
[u'Will Drewry', u'Tavis Ormandy']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Foundations of Security: What Every Programmer Needs to Know
APress, New York (2007)
[u'Neil Daswani', u'Christoph Kern', u'Anita Kesavan']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Memsherlock: An Automated Debugger for Unknown Memory Corruption Vulnerabilities
Conference on Computer and Communication Security, ACM, Alexandria, VA (2007)
[u'Emre C. Sezer', u'Peng Ning', u'ChongKyung Kil', u'Jun Xu']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Provable Data Possession at Untrusted Stores
Conference on Computer and Communications Security, ACM, Alexandria, VA (2007)
[u'Giuseppe Ateniese', u'Randal Burns', u'Reza Curtmola', u'Joseph Herring', u'Lea Kissner', u'Zachary Peterson', u'Dawn Song']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub32874.html
notfound
=========================
Selective Disclosure
Ben Laurie (2007)
[u'Ben Laurie']
SecurityPrivacyandAbusePrevention
Abstract: Selective disclosure for the non-cryptographer.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
The Ghost In The Browser: Analysis of Web-based Malware
First Workshop on Hot Topics in Understanding Botnets (HotBots '07), Online Proceedings, http://www.usenix.org/events/hotbots07/tech/ (2007)
[u'Niels Provos', u'Dean McNamee', u'Panayiotis Mavrommatis', u'Ke Wang', u'Nagendra Modadugu']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Tradeoffs in Retrofitting Security: An Experience Report
Dynamic Languages Symposium, ACM (2007)
[u'Mark S. Miller']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Virtual Honeypots: From Botnet Tracking to Intrusion Detection
Addison Wesley (2007)
[u'Niels Provos', u'Thorsten Holz']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Method for Making Password-Based Key Exchange Resilient to Server Compromise
Advances in Cryptology - CRYPTO 2006, Springer, pp. 142-159
[u'Craig Gentry', u'Philip MacKenzie', u'Zulfikar Ramzan']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Cookies Along Trust-Boundaries (CAT): Accurate and Deployable Flood Protection
In Proceedings of Steps To Reduce Unwated Traffic From The Internet (2006)
[u'Martin Casado', u'Aditya Akella', u'Pei Cao', u'Niels Provos', u'Scott Shenker']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Flow-Cookies: Using Bandwidth Amplification to Defend Against DDoS Flooding Attacks
Proceedings of the IEEE Workshop on QoS (2006)
[u'Martin Casado', u'Pei Cao', u'Aditya Akella', u'Niels Provos']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Language Modeling and Encryption on Packet Switched Networks
Advances in Cryptology: Proc. Eurocrypt 2006, Springer, St. Petersburg, pp. 359-372
[u'Kevin S. McCurley']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Limits to Anti Phishing
Proceedings of the W3c Security and Usability Workshop (2006), pp. 5
[u'Jeff Nelson', u'David Jeske']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Packet vaccine: black-box exploit detection and signature generation
Proc. 13th ACM Conference on Computer and Communications Security, ACM, Alexandria, VA (2006), pp. 37-46
[u'XiaoFeng Wang', u'Zhuowei Li', u'Jun Xu', u'Michael K. Reiter', u'Chongkyung Kil', u'Jong Youl Choi']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Privacy-Enhancing Technologies
IEEE Security and Privacy, vol. 4 (2006), pp. 59
[u'Stephen A. Weis']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Resource Fairness and Composability of Cryptographic Protocols
Theory of Cryptography: Third Theory of Cryptography Conference, TCC 2006, Springer, pp. 404-428
[u'Juan Garay', u'Philip MacKenzie', u'Manoj Prabhakaran', u'Ke Yang']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub32617.html
notfound
=========================
Search Worms
WORM '06: Proceedings of the 4th ACM workshop on Recurring malcode, ACM Press, Alexandria, Virginia, USA (2006), pp. 1-8
[u'Niels Provos', u'Joe McClain', u'Ke Wang']
SecurityPrivacyandAbusePrevention
Abstract: Worms are becoming more virulent at the same time as operating system improvements try to contain them.Recent research demonstrates several effective methods to detect and prevent randomly scanning worms from spreading [2, 13]. As a result, worm authors are looking for new ways to acquire vulnerable targets without relying on randomly scanning for them. It is often possible to find vulnerable web servers by sending carefully crafted queries to search engines. Search worms1 automate this approach and spread by using popular search engines to find new attack vectors. These worms not only put significant load on search engines, they also evade detection mechanisms that assume random scanning. From the point of view of a search engine, signatures against search queries are only a temporary measure as many different search queries lead to the same results. In this paper, we present our experience with search worms and a framework that allows search engines to quickly detect new worms and take automatic countermeasures. We argue that signature-based filtering of search queries is ill-suited for protecting against search worms and show how we prevent worm propagation without relying on query signatures. We illustrate our approach with measurements and numeric simulations.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Virtual Honeypot Framework
USENIX Security Symposium (2004), pp. 1-14
[u'Niels Provos']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Cygnus - An Approach for Large Scale Network Security Monitoring
Syscan 2004, Singapore
[u'Paul (Tony) Watson']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Improving Host Security with System Call Policies
12th USENIX Security Symposium (2003)
[u'Niels Provos']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Preventing Privilege Escalation
12th USENIX Security Symposium (2003)
[u'Niels Provos', u'Markus Friedl', u'Peter Honeyman']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Defending Against Statistical Steganalysis
10th USENIX Security Symposium (2001)
[u'Niels Provos']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Encrypting Virtual Memory
9th USENIX Security Symposium (2000)
[u'Niels Provos']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Future-Adaptable Password Scheme
USENIX Annual Technical Conference, FREENIX Track (1999)
[u'Niels Provos', u'David Mazi{\\`e}res']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Cryptography in OpenBSD: An Overview
USENIX Annual Technical Conference, FREENIX Track (1999)
[u'Theo de Raadt', u'Niklas Hallqvist', u'Artur Grabowski', u'Angelos D. Keromytis', u'Niels Provos']
SecurityPrivacyandAbusePrevention
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/SoftwareEngineering.html
found
http://research.google.com/pubs/pub42249.html
notfound
=========================
Automated Decomposition of Build Targets
Proceedings of the 37th International Conference on Software Engineering, IEEE Computer Society (2015), pp. 123-133
[u'Mohsen Vakilian', u'Raluca Sauciuc', u'J. David Morgenthaler', u'Vahab Mirrokni']
SoftwareEngineering
Abstract: A (build) target specifies the information that is needed to automatically build a software artifact. This paper focuses on underutilized targetsan important dependency problem that we identified at Google. An underutilized target is one with files not needed by some of its dependents. Underutilized targets result in less modular code, overly large artifacts, slow builds, and unnecessary build and test triggers. To mitigate these problems, programmers decompose underutilized targets into smaller targets. However, manually decomposing a target is tedious and error-prone. Although we prove that finding the best target decomposition is NP-hard, we introduce a greedy algorithm that proposes a decomposition through iterative unification of the strongly connected components of the target. Our tool found that 19,994 of 40,000 Java library targets at Google can be decomposed to at least two targets. The results show that our tool is (1) efficient because it analyzes a target in two minutes on average and (2) effective because for each of 1,010 targets, it would save at least 50% of the total execution time of the tests triggered by the target.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43790.html
found
=========================
Continuous Pipelines at Google
SRECon Europe 2015, USENIX, Dublin, Ireland, pp. 12
[u'Dan Dennison']
SoftwareEngineering
Abstract: This article focuses on the real life challenges of managing data processing pipelines of depth and complexity. It considers the frequency continuum between periodic pipelines that run very infrequently through continuous pipelines that never stop running, and discusses the discontinuities that can produce significant operational problems. A fresh take on the masterslave model is presented as a more reliable and better scaling alternative to the periodic pipeline for processing Big Data.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Enhancing Android Accessibility for Users with Hand Tremor by Reducing Fine Pointing and Steady Tapping
Web4All, Florence, Italy (2015), pp. 10
[u'Yu Zhong', u'Astrid Weber', u'Casey Burkhardt', u'Phil Weaver', u'Jeffrey P. Bigham']
SoftwareEngineering
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43835.html
found
=========================
How Developers Search for Code: A Case Study
Joint Meeting of the European Software Engineering Conference and the Symposium on the Foundations of Software Engineering (ESEC/FSE ), 1600 Amphitheatre Parkway (2015) (to appear)
[u'Caitlin Sadowski', u'Kathryn T. Stolee', u'Sebastian Elbaum']
SoftwareEngineering
Abstract: With the advent of large code repositories and sophisticated search capabilities, code search is increasingly becoming a key software development activity. In this work we shed some light into how developers search for code through a case study performed at Google, using a combination of survey and log-analysis methodologies. Our study provides insights into what developers are doing and trying to learn when performing a search, search scope, query properties, and what a search session under different contexts usually entails. Our results indicate that programmers search for code very frequently, conducting an average of five search sessions with 12 total queries each workday. The search queries are often targeted at a particular code location and programmers are typically looking for code with which they are somewhat familiar. Further, programmers are generally seeking answers to questions about how to use an API, what code does, why something is failing, or where code is located.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43322.html
notfound
=========================
Tricorder: Building a Program Analysis Ecosystem
International Conference on Software Engineering (ICSE) (2015)
[u'Caitlin Sadowski', u'Jeffrey van Gogh', u'Ciera Jaspan', u'Emma Soederberg', u'Collin Winter']
SoftwareEngineering
Abstract: Static analysis tools help developers find bugs, improve code readability, and ensure consistent style across a project. However, these tools can be difficult to smoothly integrate with each other and into the developer workflow, particularly when scaling to large codebases. We present Tricorder, a program analysis platform aimed at building a data-driven ecosystem around program analysis. We present a set of guiding principles for our program analysis tools and a scalable architecture for an analysis platform implementing these principles. We include an empirical, in-situ evaluation of the tool as it is used by developers across
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43437.html
notfound
=========================
Using Actors to Implement Sequential Simulations
University of Saskatchewan, Saskatchewan, Canada (2015)
[u'Ryan Harrison']
SoftwareEngineering
Abstract: This thesis investigates using an approach based on the Actors paradigm for implementing a discrete event simulation system and comparing the results with more traditional approaches. The goal of this work is to determine if using Actors for sequential programming is viable. If Actors are viable for this type of programming, then it follows that they would be usable for general programming. One potential advantage of using Actors instead of traditional paradigms for general programming would be the elimination of a distinction between designing for a sequential environment and a concurrent/distributed one. Using Actors for general programming may also allow for a single implementation that can be deployed on both single core and multiple core systems. Most of the existing discussions about the Actors model focus on its strengths in distributed environments and its ability to scale with the amount of available computing resources. The chosen system for implementation is intentionally sequential to allow for examination of the behaviour of existing Actors implementations where managing concurrency complexity is not the primary task. Multiple implementations of the simulation system were built using different languages (C++, Erlang, and Java) and different paradigms, including traditional ones and Actors. These different implementations were compared quantitatively, based on their execution time, memory usage, and code complexity. The analysis of these comparisons indicates that for certain existing development environments, Erlang/OTP, following the Actors paradigm, produces a comparable or better implementation than traditional paradigms. Further research is suggested to solidify the validity of the results presented in this research and to extend their applicability.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A case of computational thinking: The subtle effect of hidden dependencies on the user experience of version control
Psychology of Programming Interest Group Annual Conference 2014, pp. 123-128
[u'Luke Church', u'Emma Soederberg', u'Elayabharath Elango']
SoftwareEngineering
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
ARC++: Effective Typestate and Lifetime Dependency Analysis
ISSTA, ACM (2014), pp. 116-126
[u'Xusheng Xiao', u'Gogul Balakrishnan', u'Franjo Ivancic', u'Naoto Maeda', u'Aarti Gupta', u'Deepak Chhetri']
SoftwareEngineering
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
An Adaptable Rule Placement for Software Defined Networks
DSN, IEEE (2014)
[u'Shuyuan Zhang', u'Franjo Ivancic', u'Cristian Lumezanu', u'Yifei Yuan', u'Aarti Gupta', u'Sharad Malik']
SoftwareEngineering
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41868.html
notfound
=========================
Bespoke infrastructures
IEEE Software, vol. 31 (2014), pp. 12-14
[u'Diomidis Spinellis']
SoftwareEngineering
Abstract: Infrastructure developed within an organization for its own internal use can take many forms. The obvious reason for creating a bespoke solution is that it can be tailored to fit the organization's unique needs. This can offer many advantages: better performance, increased flexibility, and tactical or strategic advantages over the competition. However, such solutions are associated with a steep learning curve for newcomers, maintenance and support costs, and the risk of hijacking by groups with vested interests. Given that investment in bespoke infrastructures is a sunk cost and that these polarize the types of employees that stay in the organization, rational approaches for building an organization's infrastructure include customizing a general-purpose solution or adopting an open-source tool and improving it to address the organization's requirements.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Generating Consistent Updates for Software-Defined Network Configurations
HotSDN, ACM (2014)
[u'Yifei Yuan', u'Franjo Ivancic', u'Cristian Lumezanu', u'Shuyuan Zhang', u'Aarti Gupta']
SoftwareEngineering
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43146.html
found
=========================
Machine Learning: The High Interest Credit Card of Technical Debt
SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop)
[u'D. Sculley', u'Gary Holt', u'Daniel Golovin', u'Eugene Davydov', u'Todd Phillips', u'Dietmar Ebner', u'Vinay Chaudhary', u'Michael Young']
SoftwareEngineering
Abstract: Machine learning offers a fantastically powerful toolkit for building complex systems quickly. This paper argues that it is dangerous to think of these quick wins as coming for free. Using the framework of technical debt, we note that it is remarkably easy to incur massive ongoing maintenance costs at the system level when applying machine learning. The goal of this paper is highlight several machine learning specific risk factors and design patterns to be avoided or refactored where possible. These include boundary erosion, entanglement, hidden feedback loops, undeclared consumers, data dependencies, changes in the external world, and a variety of system-level anti-patterns.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43239.html
found
=========================
Moving Targets: Security and Rapid-Release in Firefox
Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security, ACM, New York, NY, pp. 1256-1266
[u'Sandy Clark', u'Michael Collis', u'Matt Blaze', u'Jonathan M. Smith']
SoftwareEngineering
Abstract: Software engineering practices strongly affect the security of the code produced. The increasingly popular Rapid Release Cycle (RRC) development methodology and easy network software distribution have enabled rapid feature introduction. RRC's defining characteristic of frequent software revisions would seem to conflict with traditional software engineering wisdom regarding code maturity, reliability and reuse, as well as security. Our investigation of the consequences of rapid release comprises a quantitative, data-driven study of the impact of rapid-release methodology on the security of the Mozilla Firefox browser. We correlate reported vulnerabilities in multiple rapid release versions of Firefox code against those in corresponding extended release versions of the same system; using a common software base with different release cycles eliminates many causes other than RRC for the observables. Surprisingly, the resulting data show that Firefox RRC does not result in higher vulnerability rates and, further, that it is exactly the unfamiliar, newly released software (the "moving targets") that requires time to exploit. These provocative results suggest that a rethinking of the consequences of software engineering practices for security may be warranted.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43149.html
found
=========================
Norming to Performing: Failure Analysis and Deployment Automation of Big Data Software Developed by Highly Iterative Models
IEEE International Symposium on Software Reliability Engineering, IEEE International Symposium on Software Reliability Engineering (2014), pp. 144-155
[u'Keun Soo Yim']
SoftwareEngineering
Abstract: We observe many interesting failure characteristics from Big Data software developed and released using some kinds of highly iterative development models (e.g., agile). ~16% of failures occur due to faults in software deployments (e.g., packaging and pushing to production). Our analysis shows that many such production outages are at least partially due to some human errors rooted in the high frequency and complexity of software deployments. ~51% of the observed human errors (e.g., transcription, education, and communication error types) are avoidable through automation. We thus develop a fault-tolerant automation framework to make it efficient to automate end-to-end software deployment procedures. We apply the framework to two Big Data products. Our case studies show the complexity of the deployment procedures of multi-homed Big Data applications and help us to study the effectiveness of the validation and verification techniques for user-provided automation programs. We analyze the production failures of the two products again after the automation. Our experimental data shows how the automation and the associated procedure improvements reduce the deployment faults and overall failure rate, and improve the feature launch velocity. Automation facilitates more formal, procedure-driven software engineering practices which not only reduce the manual work and human-oriented, avoidable production outages but also help engineers to better understand overall software engineering procedures, making them more auditable, predictable, reliable, and efficient. We discuss two novel metrics to evaluate progress in mitigating human errors and the conditions indicating points to start such transition from owner-driven deployment practice.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42184.html
notfound
=========================
Programmers Build Errors: A Case Study (at Google)
International Conference on Software Engineering (ICSE) (2014) (to appear)
[u'Hyunmin Seo', u'Caitlin Sadowski', u'Sebastian Elbaum', u'Edward Aftandilian', u'Robert Bowdidge']
SoftwareEngineering
Abstract: Building is an integral part of the software development process. However, little is known about the errors occurring in this process. In this paper, we present an empirical study of 26.6 million builds produced during a period of nine months by thousands of developers. We describe the workflow through which those builds are generated, and we analyze failure frequency, error types, and resolution efforts to fix those errors. The results provide insights on how a large organization build process works, and pinpoints errors for which further developer support would be most effective.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42577.html
notfound
=========================
RLint: Reformatting R Code to Follow the Google Style Guide
R User Conference (2014)
[u'Alex Blocker', u'Andy Chen', u'Andy Chu', u'Tim Hesterberg', u'Jeffrey D. Oldham', u'Caitlin Sadowski', u'Tom Zhang']
SoftwareEngineering
Abstract: RLint (https://code.google.com/p/google-rlint/) both checks and reformats R code to the Google R Style Guide. It warns of violations and optionally produces compliant code. It considers proper spacing, line alignment inside brackets, and other style violations, but like all lint programs does not try to handle all syntax issues. Code that follows a uniform style eases maintenance, modification, and ensuring correctness, especially when multiple programmers are involved. Thus, RLint is automatically used within Google as part of the peer review process for R code. We encourage CRAN package authors and other R programmers to use this tool. A user can run the open-source Python-based program in a Linux, Unix, Mac or Windows machine via a command line.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42934.html
found
=========================
Securing the Tangled Web
Communications of the ACM, vol. 57, no. 9 (2014), pp. 38-47
[u'Christoph Kern']
SoftwareEngineering
Abstract: Preventing script injection vulnerabilities through software design. Script injection vulnerabilities are a bane of Web application development: deceptively simple in cause and remedy, they are nevertheless surprisingly difficult to prevent in large-scale Web development. Cross-site scripting (XSS) arises when insufficient data validation, sanitization, or escaping within a Web application allow an attacker to cause browser-side execution of malicious JavaScript in the application's context. This injected code can then do whatever the attacker wants, using the privileges of the victim. Exploitation of XSS bugs results in complete (though not necessarily persistent) compromise of the victim's session with the vulnerable application. This article provides an overview of how XSS vulnerabilities arise and why it is so difficult to avoid them in real-world Web application software development. Software design patterns developed at Google to address the problem are then described.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41461.html
found
=========================
2nd international workshop on user evaluations for software engineering researchers (USER)
International Conference on Software Engineering (ICSE) (2013)
[u'Andrew Begel', u'Caitlin Sadowski']
SoftwareEngineering
Abstract: We have met many software engineering researchers who would like to evaluate a tool or system they developed with real users, but do not know how to begin. In this second iteration of the USER workshop, attendees will collaboratively design, develop, and pilot plans for conducting user evaluations of their own tools and/or software engineering research projects. Attendees will gain practical experience with various user evaluation methods through scaffolded group exercises, panel discussions, and mentoring by a panel of user-focused software engineering researchers. Together, we will establish a community of likeminded researchers and developers to help one another improve our research and practice through user evaluation.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41441.html
notfound
=========================
Accuracy of Contemporary Parametric Software Estimation Models: A Comparative Analysis
Proceeding of the 39th Euromicro Conference Series on Software Engineering and Advanced Applications, IEEE, Santander, Spain (2013), pp. 313-316
[u'Derya Toka']
SoftwareEngineering
Abstract: Predicting the effort, duration and cost required to develop and maintain a software system is crucial in IT project management. Although an accurate estimation is invaluable for the success of an IT development project, it often proves difficult to attain. This paper presents an empirical evaluation of four parametric software estimation models, namely COCOMO II, SEER-SEM, SLIM, and TruePlanning, in terms of their project effort and duration prediction accuracy. Using real project data from 51 software development projects, we evaluated the capabilities of the models by comparing the predictions with the actual effort and duration values. The study showed that the estimation capabilities of the models investigated are on a par in accuracy, while there is still significant room for improvement in order to better address the prediction challenges faced in practice.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37040.html
found
=========================
Applications and Extensions of Alloy: Past, Present, and Future
Mathematical Structures in Computer Science, vol. 23 (2013), pp. 915-933
[u'Emina Torlak', u'Mana Taghdiri', u'Greg Dennis', u'Joseph Near']
SoftwareEngineering
Abstract: Alloy is a declarative language for lightweight modelling and analysis of software. The core of the language is based on first-order relational logic, which offers an attractive balance between analysability and expressiveness. The logic is expressive enough to capture the intricacies of real systems, but is also simple enough to support fully automated analysis with the Alloy Analyzer. The Analyzer is built on a SAT-based constraint solver and provides automated simulation, checking and debugging of Alloy specifications. Because of its automated analysis and expressive logic, Alloy has been applied in a wide variety of domains. These applications have motivated a number of extensions both to the Alloy language and to its SAT-based analysis. This paper provides an overview of Alloy in the context of its three largest application domains, lightweight modelling, bounded code verification and test-case generation, and three recent application-driven extensions, an imperative extension to the language, a compiler to executable code and a proof-capable analyser based on SMT.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41440.html
notfound
=========================
Combining compile-time and run-time instrumentation for testing tools
Programmnye produkty i sistemy, vol. 3 (2013), pp. 224-231
[u'Timur Iskhodzhanov', u'Reid Kleckner', u'Evgeniy Stepanov']
SoftwareEngineering
Abstract: Dynamic program analysis and testing tools typically require inserting extra instrumentation code into the program to test. The inserted instrumentation then gathers data about the program execution and hands it off to the analysis algorithm. Various analysis algorithms can be used to perform CPU profiling, processor cache simulation, memory error detection, data race detection, etc. Usually the instrumentation is done either at run time or atcompile time called dynamic instrumentation and compiler instrumentation, respectively. However, each of these methods has to make a compromise between performance and versatil-ity when used in industry software development. This paper presents a combined approach to instrumentationwhich takes the best of the two worlds the low run-time overhead and unique features of compile-time instrumentation and the flexibility of dynamic instrumentation. Wepresent modifications of two testing tools that benefit from thisapproach: AddressSanitizer and MemorySanitizer. We propose benchmarks to compare different instrumentation frameworks in conditions specific to hybrid instrumenta-tion. We discuss the changes we made to one of the state-of-the-art instrumentation frameworks to significantly improve the performance of hybrid tools.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41145.html
notfound
=========================
Does Bug Prediction Support Human Developers? Findings from a Google Case Study
International Conference on Software Engineering (ICSE) (2013)
[u'Chris Lewis', u'Zhongpeng Lin', u'Caitlin Sadowski', u'Xiaoyan Zhu', u'Rong Ou', u'E. James Whitehead Jr.']
SoftwareEngineering
Abstract: While many bug prediction algorithms have been developed by academia, they're often only tested and verified in the lab using automated means. We do not have a strong idea about whether such algorithms are useful to guide human developers. We deployed a bug prediction algorithm across Google, and found no identifiable change in developer behavior. Using our experience, we provide several characteristics that bug prediction algorithms need to meet in order to be accepted by human developers and truly change how developers evaluate their code.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40739.html
notfound
=========================
Generating Precise Dependencies for Large Software
Proceedings of the Forth International Workshop on Managing Technical Debt, IEEE (2013), pp. 47-50
[u'Pei Wang', u'Jinqiu Yang', u'Lin Tan', u'Robert Kroeger', u'J. David Morgenthaler']
SoftwareEngineering
Abstract: Intra- and inter-module dependencies can be a significant source of technical debt in the long-term software development, especially for large software with millions of lines of code. This paper designs and implements a precise and scalable tool that extracts code dependencies and their utilization for large C/C++ software projects. The tool extracts both symbol-level and module-level dependencies of a software system and identifies potential underutilized and inconsistent dependencies. Such information points to potential refactoring opportunities and help developers perform large-scale refactoring tasks.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41342.html
notfound
=========================
Large-Scale Automated Refactoring Using ClangMR
Proceedings of the 29th International Conference on Software Maintenance (2013)
[u'Hyrum Wright', u'Daniel Jasper', u'Manuel Klimek', u'Chandler Carruth', u'Zhanyong Wan']
SoftwareEngineering
Abstract: Maintaining large codebases can be a challenging endeavour. As new libraries, APIs and standards are introduced, old code is migrated to use them. To provide as clean and succinct an interface as possible for developers, old APIs are ideally removed as new ones are introduced. In practice, this becomes difficult as automatically finding and transforming code in a semantically correct way can be challenging, particularly as the size of a codebase increases. In this paper, we present a real-world implementation of a system to refactor large C++ codebases efficiently. A combination of the Clang compiler framework and the MapReduce parallel processor, ClangMR enables code maintainers to easily and correctly transform large collections of code. We describe the motivation behind such a tool, its implementation and then present our experiences using it in a recent API update with Googles C++ codebase.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41876.html
notfound
=========================
Scalable, Example-Based Refactorings with Refaster
Workshop on Refactoring Tools (2013)
[u'Louis Wasserman']
SoftwareEngineering
Abstract: We discuss Refaster, a tool that uses normal, compilable before-and-after examples of Java code to specify a Java refactoring. Refaster has been used successfully by the Java Core Libraries Team at Google to perform a wide variety of refactorings across Google's massive Java codebase. Our main contribution is that a large class of useful refactorings can be expressed in pure Java, without a specialized DSL, while keeping the tool easily accessible to average Java developers.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42109.html
notfound
=========================
Strategies for testing client-server interactions in mobile applications
MobileDeLi '13 Proceedings of the 2013 ACM workshop on Mobile development lifecycle, ACM, Indianapolis, Indiana, pp. 19-20
[u'Niranjan Tulpule']
SoftwareEngineering
Abstract: Modern smartphone ecosystems have their unique set of constraints which makes testing the contract between client and servers hard. In this paper we will describe the Google+ team's approaches to solving this problem. We will describe our testing philosophy followed by a couple of frameworks and test design patterns that we have found to be really useful in a client-server testing context.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41412.html
notfound
=========================
Testable JavaScript
O'Reilly Media, 1005 Gravenstein Highway North Sebastopol, CA 95472 (2013)
[u'Mark Ethan Trostler']
SoftwareEngineering
Abstract: One skill thats essential for any professional JavaScript developer is the ability to write testable code. This book shows you what writing and maintaining testable JavaScript for the client- or server-side actually entails, whether youre creating a new application or rewriting legacy code. From methods to reduce code complexity to unit testing, code coverage, debugging, and automation, youll learn a holistic approach for writing JavaScript code that you and your colleagues can easily fix and maintain going forward. Testing JavaScript code is complicated. This book helps you simply the process considerably. Get an overview of Agile, test-driven development, and behavior-driven development Use patterns from static languages and standards-based JavaScript to reduce code complexity Learn the advantages of event-based architectures, including modularity, loose coupling, and reusability Explore tools for writing and running unit tests at the functional and application level Generate code coverage to measure the scope and effectiveness of your tests Conduct integration, performance, and load testing, using Selenium or CasperJS Use tools for in-browser, Node.js, mobile, and production debugging Understand what, when, and how to automate your development processes
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43477.html
notfound
=========================
Why Don't Software Developers Use Static Analysis Tools to Find Bugs?
International Conference on Software Engineering (2013), pp. 672-681
[u'Brittany Johnson', u'Yoonki Song', u'Emerson Murphy-Hill', u'Robert Bowdidge']
SoftwareEngineering
Abstract: Using static analysis tools for automating code inspections can be beneficial for software engineers. Such tools can make finding bugs, or software defects, faster and cheaper than manual inspections. Despite the benefits of using static analysis tools to find bugs, research suggests that these tools are underused. In this paper, we investigate why developers are not widely using static analysis tools and how current tools could potentially be improved. We conducted interviews with 20 developers and found that although all of our participants felt that use is beneficial, false positives and the way in which the warnings are presented, among other things, are barriers to use. We discuss several implications of these results, such as the need for an interactive mechanism to help developers fix defects.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41098.html
found
=========================
A taste of Capsicum: practical capabilities for UNIX
Communications of the ACM, vol. 55(3) (2012), pp. 97-104
[u'Robert N. M. Watson', u'Jonathan Anderson', u'Ben Laurie', u'Kris Kennaway']
SoftwareEngineering
Abstract: Capsicum is a lightweight operating system (OS) capability and sandbox framework planned for inclusion in FreeBSD 9. Capsicum extends, rather than replaces, UNIX APIs, providing new kernel primitives (sandboxed capability mode and capabilities) and a userspace sandbox API. These tools support decomposition of monolithic UNIX applications into compartmentalized logical applications, an increasingly common goal that is supported poorly by existing OS access control primitives. We demonstrate our approach by adapting core FreeBSD utilities and Google
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37752.html
notfound
=========================
AddressSanitizer: A Fast Address Sanity Checker
USENIX ATC 2012
[u'Konstantin Serebryany', u'Derek Bruening', u'Alexander Potapenko', u'Dmitry Vyukov']
SoftwareEngineering
Abstract: Memory access bugs, including buffer overows and uses of freed heap memory, remain a serious problem for programming languages like C and C++. Many memory error detectors exist, but most of them are either slow or detect a limited set of bugs, or both. This paper presents AddressSanitizer, a new memory error detector. Our tool finds out-of-bounds accesses to heap, stack, and global objects, as well as use-after-free bugs. It employs a specialized memory allocator and code instrumentation that is simple enough to be implemented in any compiler, binary translation system, or even in hardware. AddressSanitizer achieves efficiency without sacricing comprehensiveness. Its average slowdown is just 73% yet it accurately detects bugs at the point of occurrence. It has found over 300 previously unknown bugs in the Chromium browser and many bugs in other software.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38275.html
notfound
=========================
Building Useful Program Analysis Tools Using an Extensible Java Compiler
International Working Conference on Source Code Analysis and Manipulation (SCAM), IEEE (2012), pp. 14-23
[u'Edward Aftandilian', u'Raluca Sauciuc', u'Siddharth Priya', u'Sundaresan Krishnan']
SoftwareEngineering
Abstract: Large software companies need customized tools to manage their source code. These tools are often built in an ad-hoc fashion, using brittle technologies such as regular expressions and home-grown parsers. Changes in the language cause the tools to break. More importantly, these ad-hoc tools often do not support uncommon-but-valid code code patterns. We report our experiences building source-code analysis tools at Google on top of a third-party, open-source, extensible compiler. We describe three tools in use on our Java codebase. The first, Strict Java Dependencies, enforces our dependency policy in order to reduce JAR file sizes and testing load. The second, error-prone, adds new error checks to the compilation process and automates repair of those errors at a whole-codebase scale. The third, Thindex, reduces the indexing burden for a Java IDE so that it can support Google-sized projects.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Measuring Enforcement Windows with Symbolic Trace Interpretation: What Well-Behaved Programs Say
Proceedings of the 2012 International Symposium on Software Testing and Analysis, ACM, pp. 276-286
[u'Devin Coughlin', u'Bor-Yuh Evan Chang', u'Amer Diwan', u'Jeremy Siek']
SoftwareEngineering
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37755.html
notfound
=========================
Searching for Build Debt: Experiences Managing Technical Debt at Google
Proceedings of the Third International Workshop on Managing Technical Debt, IEEE (2012), pp. 1-6
[u'J. David Morgenthaler', u'Misha Gridnev', u'Raluca Sauciuc', u'Sanjay Bhansali']
SoftwareEngineering
Abstract: With a large and rapidly changing codebase, Google software engineers are constantly paying interest on various forms of technical debt. Google engineers also make efforts to pay down that debt, whether through special Fixit days, or via dedicated teams, variously known as janitors, cultivators, or demolition experts. We describe several related efforts to measure and pay down technical debt found in Google's BUILD files and associated dead code. We address debt found in dependency specifications, unbuildable targets, and unnecessary command line flags. These efforts often expose other forms of technical debt that must first be managed.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40660.html
found
=========================
Systematic Software Testing: The Korat Approach
Foundations of Software Engineering (FSE), ACM (2012), pp. 1
[u'Chandrasekhar Boyapati', u'Sarfraz Khurshid', u'Darko Marinov']
SoftwareEngineering
Abstract: At ISSTA 2002, the three authors (then Ph.D. students) published the paper Korat: Automated Testing Based on Java Predicates", which won one of the first ACM SIGSOFT Distinguished paper awards. In 2012, the paper won the ACM SIGSOFT Impact Paper Award. The authors briefly recount the motivation behind the Korat research, the ideas presented in the original paper, and some work it inspired.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38144.html
found
=========================
Team Geek: A Software Developer's Guide to Working Well with Others
O'Reilly Media, 1005 Gravenstein Highway North, Sebastopol, CA 95472 (2012), pp. 180
[u'Brian W. Fitzpatrick', u'Ben Collins-Sussman']
SoftwareEngineering
Abstract: As a software engineer, youre great with computer languages, compilers, debuggers, and algorithms. And in a perfect world, those who produce the best code are the most successful. But in our perfectly messy world, success also depends on how you work with people to get your job done. In this highly entertaining book, Brian Fitzpatrick and Ben Collins-Sussman cover basic patterns and anti-patterns for working with other people, teams, and users while trying to develop software. Its valuable information from two respected software engineers whose popular video series, "Working with Poisonous People", has attracted hundreds of thousands of viewers. Youll learn how to deal with imperfect peoplethose irrational and unpredictable beingsin the course of your work. And youll discover why playing well with others is at least as important as having great technical skills. By internalizing the techniques in this book, youll get more software written, be more influential, be happier in your career.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37253.html
notfound
=========================
Building Web Apps for Google TV
o'Reilly Media, 1005 Gravenstein Hwy N Sebastopol, CA 95472 (2011), pp. 116
[u'Amanda Surya', u'Andres Ferrate', u'Daniels Lee', u'Maile Ohye', u'Paul Carff', u'Shawn Shen', u'Steven Hines']
SoftwareEngineering
Abstract: By integrating the Web with traditional TV, Google TV offers developers an important new channel for content. But creating apps for Google TV requires learning some new skillsin fact, what you may already know about mobile or desktop web apps isn't entirely applicable. Building Web Apps for Google TV will help you make the transition to Google TV as you learn the tools and techniques necessary to build sophisticated web apps for this platform.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Combined Static and Dynamic Automated Test Generation
Proc. 11th International Symposium on Software Testing and Analysis (ISSTA 2011), Toronto, Ontario, (to appear)
[u'Sai Zhang', u'David Saff', u'Yingyi Bu', u'Michael D. Ernst']
SoftwareEngineering
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37278.html
notfound
=========================
Dynamic Race Detection with LLVM Compiler
Google (2011)
[u'Konstantin Serebryany', u'Alexander Potapenko', u'Timur Iskhodzhanov', u'Dmitry Vyukov']
SoftwareEngineering
Abstract: Data races are among the most difficult to detect and costly bugs. Race detection has been studied widely, but none of the existing tools satisfies the requirements of high speed, detailed reports and wide availability at the same time. We describe our attempt to create a tool that works fast, has detailed and understandable reports and is available on a variety of platforms. The race detector is based on our previous work, ThreadSanitizer, and the instrumentation is done using the LLVM compiler. We show that applying compiler instrumentation and sampling reduces the slowdown to less than 1.5x, fast enough for interactive use.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41469.html
found
=========================
Entrepreneurial Innovation at Google
IEEE: Computer, vol. 0018-9162/11 (2011), pp. 7
[u'Patrick Copeland', u'Alberto Savoia']
SoftwareEngineering
Abstract: Large organizations have enormous innovation potential at their disposal. However, the innovation actually realized in successful products and services is usually only a small fraction of that potential. The amount and type of innovation a company achieves are directly related to the way it approaches, fosters, selects, and funds innovation efforts. To maximize innovation and avoid the dilemmas that mature companies face, Google complements the time-proven model of topdown innovation with its own brand of entrepreneurial innovation.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41143.html
found
=========================
HTAF: Hybrid Testing Automation Framework to Leverage Local and Global Computing Resources
Lecture Notes in Computer Science, vol. 6784 (2011), pp. 479-494
[u'Keun Soo Yim', u'David Hreczany', u'Ravishankar K. Iyer']
SoftwareEngineering
Abstract: In web application development, testing forms an increasingly large portion of software engineering costs due to the growing complexity and short time-to-market of these applications. This paper presents a hybrid testing automation framework (HTAF) that can automate routine works in testing and releasing web software. Using this framework, an individual software engineer can easily describe his routine software engineering tasks and schedule these described tasks by using both his local machine and global cloud computers in an efficient way. This framework is applied to commercial web software development processes. Our industry practice shows four example cases where the hybrid and decentralized architecture of HTAF is helpful at effectively managing both hardware resources and manpower required for testing and releasing web applications.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37274.html
notfound
=========================
Practical Memory Checking with Dr. Memory
Proceedings of the IEEE/ACM International Symposium on Code Generation and Optimization, IEEE Computer Society, Los Alamitos, CA, USA (2011), pp. 213-223
[u'Derek Bruening', u'Qin Zhao']
SoftwareEngineering
Abstract: Memory corruption, reading uninitialized memory, using freed memory, and other memory-related errors are among the most difficult programming bugs to identify and fix due to the delay and non-determinism linking the error to an observable symptom. Dedicated memory checking tools are invaluable for finding these errors. However, such tools are difficult to build, and because they must monitor all memory accesses by the application, they incur significant overhead. Accuracy is another challenge: memory errors are not always straightforward to identify, and numerous false positive error reports can make a tool unusable. A third obstacle to creating such a tool is that it depends on low-level operating system and architectural details, making it difficult to port to other platforms and difficult to target proprietary systems like Windows. This paper presents Dr. Memory, a memory checking tool that operates on both Windows and Linux applications. Dr. Memory handles the complex and not fully documented Windows environment, and avoids reporting false positive memory leaks that plague traditional leak locating algorithms. Dr. Memory employs efficient instrumentation techniques; a direct comparison with the state-of-the-art Valgrind Memcheck tool reveals that Dr. Memory is twice as fast as Memcheck on average and up to four times faster on individual benchmarks.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37123.html
notfound
=========================
RACEZ: A Lightweight and Non-Invasive Race Detection Tool for Production Applications
ICSE, ACM (2011), pp. 401-410
[u'Tianwei Sheng', u'Neil Vachharajani', u'Stephane Eranian', u'Robert Hundt']
SoftwareEngineering
Abstract: Concurrency bugs, particularly data races, are notoriously difficult to debug and are a significant source of unreliability in multithreaded applications. Many tools to catch data races rely on program instrumentation to obtain memory instruction traces. Unfortunately, this instrumentation introduces significant runtime overhead, is extremely invasive, or has a limited domain of applicability making these tools unsuitable for many production systems. Consequently, these tools are typically used during application testing where many data races go undetected. This paper proposes RACEZ, a novel race detection mechanism which uses a sampled memory trace collected by the hardware performance monitoring unit rather than invasive instrumentation. The approach introduces only a modest overhead making it usable in production environments. We validate RACEZ using two open source server applications and the PARSEC benchmarks. Our experiments show that RACEZ catches a set of known bugs with reasonable probability while introducing only 2.8% runtime slow down on average.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub39983.html
found
=========================
Still All On One Server: Perforce at Scale
2011 Perforce User Conference
[u'Dan Bloch']
SoftwareEngineering
Abstract: Google runs the busiest single Perforce server on the planet, and one of the largest repositories in any source control system. From that high-water mark this paper looks at server performance and other issues of scale, with digressions into where we are, how we got here, and how we continue to stay one step ahead of our users.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40496.html
found
=========================
The Future of Computing Performance: Game Over or Next Level?
The National Academies Press (2011), pp. 200
[u'Samuel H. Fuller', u'Luiz Andr Barroso', u'Robert P. Colwell', u'William J. Dally', u'Dan Dobberpuhl', u'Pradeep Dubey', u'Mark D. Hill', u'Mark Horowitz', u'David Kirk', u'Monica Lam', u'Kathryn S. McKinley', u'Charles Moore', u'Katherine Yelick']
SoftwareEngineering
Abstract: The end of dramatic exponential growth in single-processor performance marks the end of the dominance of the single microprocessor in computing. The era of sequential computing must give way to a new era in which parallelism is at the forefront. Although important scientific and engineering challenges lie ahead, this is an opportune time for innovation in programming systems and computing architectures. We have already begun to see diversity in computer designs to optimize for such considerations as power and throughput. The next generation of discoveries is likely to require advances at both the hardware and software levels of computing systems. There is no guarantee that we can make parallel computing as common and easy to use as yesterday's sequential single-processor computer systems, but unless we aggressively pursue efforts suggested by the recommendations in this book, it will be "game over" for growth in computing performance. If parallel programming and related software efforts fail to become widespread, the development of exciting new applications that drive the computer industry will stall; if such innovation stalls, many other parts of the economy will follow suit. The Future of Computing Performance describes the factors that have led to the future limitations on growth for single processors that are based on complementary metal oxide semiconductor (CMOS) technology. It explores challenges inherent in parallel computing and architecture, including ever-increasing power consumption and the escalated requirements for heat dissipation. The book delineates a research, practice, and education agenda to help overcome these challenges. The Future of Computing Performance will guide researchers, manufacturers, and information technology professionals in the right direction for sustainable growth in computer performance, so that we may all enjoy the next level of benefits to society.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Apprenticeship Patterns: Guidance for the Aspiring Software Craftsman
O'Reilly, Sebastopol, California (2010), pp. 144
[u'Dave Hoover', u'Ade Oshineye']
SoftwareEngineering
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40391.html
notfound
=========================
Evolving ASDF: More Cooperation, Less Coordination
Proceedings of the International Lisp Conference 2010
[u'Franois-Ren Rideau', u'Robert Goldman']
SoftwareEngineering
Abstract: We present ASDF 2, the current state of the art in CL build systems. From a technical standpoint, ASDF 2 improves upon ASDF by integrating previous common extensions, making conguration easy, and xing bugs. However the overriding concern driving these changes was social rather than technical: ASDF plays a central role in the CL community and we wanted to reduce the coordination costs that it imposed upon CL programmers. We outline ASDFs history and architecture, explain the link between the social issues we faced and the software features we added, and explore the technical challenges involved and lessons learned, notably involving inplace code upgrade of ASDF itself, backward compatibility, portability, testing and other coding best practices.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41672.html
found
=========================
Googles Innovation Factory: Testing, Culture, And Infrastructure
IEEE International Conference on Software Testing, Verification and Validation (2010), pp. 4
[u'Patrick Copeland']
SoftwareEngineering
Abstract: Google takes quality seriously and is reinventing how software is created, tested, released, and maintained.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36667.html
notfound
=========================
How Much Software Testing is Enough
Communications of the ACM, vol. 53. No 9 (2010), pp. 9
[u'Ruben Ortega']
SoftwareEngineering
Abstract: Software and Test-Driven Development
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36273.html
notfound
=========================
Object views: Fine-grained sharing in browsers
Proceedings of the International Conference on World Wide Web, World Wide Web Consortium (2010)
[u'Leo Meyerovich', u'Adrienne Felt', u'Mark S. Miller']
SoftwareEngineering
Abstract: Browsers do not currently support the secure sharing of JavaScript objects between principals. We present this problem as the need for object views, which are consistent and controllable versions of objects. Multiple views can be made for the same object and customized for the recipients. We implement object views with a JavaScript library that wraps shared objects and interposes on all access attempts. Developers can control the fine-grained behavior of objects with an aspect system that accepts programmatic policies. The security challenge is to fully mediate access to objects shared through a view and prevent privilege escalation. To facilitate simple document sharing, we build a policy system for declaratively defining policies for document object views. Notably, our document policy system makes it possible to hide elements without breaking document structure invariants. We discuss how object views can be deployed in two settings: same-origin sharing with rewriting-based JavaScript isolation systems like Google Caja, and inter-origin sharing between browser frames over a message-passing channel.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36675.html
notfound
=========================
Software development and crunch time; and more
Communications of the ACM, vol. 53 No. 7 (2010), pp. 10-11
[u'Ruben Ortega']
SoftwareEngineering
Abstract: Software Developers and Crunch Time
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36572.html
notfound
=========================
Performance Trade-offs Implementing Refactoring Support for Objective-C
Workshop on Refactoring Tools (2009)
[u'Robert Bowdidge']
SoftwareEngineering
Abstract: When we started implementing a refactoring tool for real-world C programs, we recognized that preprocessing and parsing in straightforward and accurate ways would result in unacceptably slow analysis times and an overly-complex parsing system. Instead, we traded some accuracy so we could parse, analyze, and change large, real programs while still making the refactoring experience feel interactive and fast. Our tradeoffs fell into three categories: using different levels of accuracy in different parts of the analysis, recognizing that the collected wisdom about C programs didn't hold for Objective-C programs, and finding ways to exploit delays in typical interaction with the tool.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36601.html
notfound
=========================
Programming Google App Engine
O'Reilly Media, Inc., 1005 Gravenstein Highway North, Sebastopol, CA, 95472 (2009), pp. 367
[u'Dan Sanderson']
SoftwareEngineering
Abstract: Google App Engine is a cloud computing service unlike any other: it provides a simple model for building applications that scale automatically to accommodate millions of users. With Programming Google App Engine, you'll get expert practical guidance that will help you make the best use of this powerful platform. Google engineer Dan Sanderson shows you how to design your applications for scalability, and how to perform common development tasks using App Engine's APIs and scalable services.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
ThreadSanitizer data race detection in practice.
Proceedings of the Workshop on Binary Instrumentation and Applications, WBIA'09 (http://www.dyninst.org/wbia09/cfp.html)., NYC, NY, U.S.A. (2009), pp. 62-71
[u'Konstantin Serebryany', u'Timur Iskhodzhanov']
SoftwareEngineering
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Code Coverage, Performance, Approximation and Automatic Recognition of Idioms in Scientific Applications
Proc. 17th International Symposium on High Performance Distributed Computing, ACM, Boston (2008), pp. 223-224
[u'Jiahua He', u'Allan E. Snavely', u'Rob F. Van der Wijngaart', u'Michael A. Frumkin']
SoftwareEngineering
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Dynamic Recognition of Synchronization Operations for Improved Data Race Detection
Proc. International Symposium on Software Testing and Analysis, ACM, Seattle (2008), pp. 143-154
[u'Chen Tian', u'Vijay Nagarajan', u'Rajiv Gupta', u'Sriraman Tallam']
SoftwareEngineering
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34339.html
notfound
=========================
Experiences Using Static Analysis to Find Bugs
IEEE Software, vol. 25 (2008), pp. 22-29
[u'Nathaniel Ayewah', u'David Hovemeyer', u'J. David Morgenthaler', u'John Penix', u'William Pugh']
SoftwareEngineering
Abstract: Static analysis examines code in the absence of input data and without running the code, and can detect potential security violations (e.g., SQL injection), runtime errors (e.g., dereferencing a null pointer) and logical inconsistencies (e.g., a conditional test that cannot possibly be true). While there is a rich body of literature on algorithms and analytical frameworks used by such tools, reports describing experiences with such tools in industry are much harder to come by. In this paper, we describe FindBugs, an open source static analysis tool for Java, and experience using it in production settings. FindBugs does not push the envelope in terms of the sophistication of its analysis techniques. Rather, it is designed to evaluate what kinds of defects can be effectively detected with relatively simple techniques and to help us understand how such tools can be incorporated into the software development process. FindBugs has become very popular, downloaded more than 500,000 times and used by many major companies and software projects. We report on experience running FindBugs against Suns JDK implementation, using Findbugs at Google where it has been used for more than a year and a half and incorporated into their standard development process, and preliminary results from a survey of FindBugs users.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
High Performance Web Sites
Communications of the ACM, vol. 51 (2008), pp. 36-41
[u'Steve Souders']
SoftwareEngineering
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub33330.html
notfound
=========================
Predicting Accurate and Actionable Static Analysis Warnings: An Experimental Approach
Proceedings of the International Conference on Software Engineering, ACM (2008), pp. 341-350
[u'Joseph Ruthruff', u'John Penix', u'J. David Morgenthaler', u'Sebastian Elbaum', u'Gregg Rothermel']
SoftwareEngineering
Abstract: Static analysis tools report software defects that may or may not be detected by other verification methods. Two challenges complicating the adoption of these tools are spurious false positive warnings and legitimate warnings that are not acted on. This paper reports automated support to help address these challenges using logistic regression models that predict the foregoing types of warnings from signals in the warnings and implicated code. Because examining many potential signaling factors in large software development settings can be expensive, we use a screening methodology to quickly discard factors with low predictive power and cost-effectively build predictive models. Our empirical evaluation indicates that these models can achieve high accuracy in predicting accurate and actionable static analysis warnings, and suggests that the models are competitive with alternative models built without screening.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34879.html
notfound
=========================
Version Control with Subversion, Second Edition
O'Reilly Media, 1003 Gravenstein Highway North Sebastopol, CA 95472 (2008), pp. 430
[u'Brian Fitzpatrick', u'Ben Collins-Sussman', u'C. Michael Pilato']
SoftwareEngineering
Abstract: The official guide and reference manual for the popular open source revision control technology.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub32791.html
notfound
=========================
Evaluating Static Analysis Defect Warnings on Production Software
Proceedings of the 7th ACM SIGPLAN-SIGSOFT workshop on Program analysis for software tools and engineering, ACM Press, New York, NY, USA (2007), pp. 1-8
[u'Nathaniel Ayewah', u'William Pugh', u'J. David Morgenthaler', u'John Penix', u'YuQian Zhou']
SoftwareEngineering
Abstract: Classification of static analysis warnings into false positive, trivial or serious bugs: Experience on Java JDK and Google codebase
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub32823.html
notfound
=========================
Keeping the Web in Web 2.0: An HCI Approach to Designing Web Applications
ACM CHI 2007
[u'J. Mittleman', u'Steffen Meschkat']
SoftwareEngineering
Abstract: We will discuss javascript programming and AJAX, the dominant tools for developing sophisticated applications on the web. You will come away with a general understanding of the building blocks and capabilities AJAX applications; and will have a headstart on learning to apply these tools to your own projects.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Parallel Test Generation and Execution with Korat
Proc. 6th Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on the Foundations of Software Engineering, ACM, Dubrovnik, Croatia (2007)
[u'Sasa Misailovic', u'Aleksandar Milicevic', u'Nemanja Petrovic', u'Sarfraz Khurshid', u'Darko Marinov']
SoftwareEngineering
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub33481.html
notfound
=========================
Project Intelligence
Pacific Northwest Software Quality Conference 2007 Proceedings, PNSQC, PO Box 10733, Portland, OR 97296-0733, pp. 267-274
[u'Rong Ou']
SoftwareEngineering
Abstract: Modern software development is mostly a cooperative team effort, generating large amount of data in disparate tools built around the development lifecycle. Making sense of this data to gain a clear understanding of the project status and direction has become a time-consuming, highoverhead and messy process. In this paper we show how we have applied Business Intelligence (BI) techniques to address some of these issues. We built a real-time data warehouse to host project-related data from different systems. The data is cleansed, transformed and sometimes rolled up to facilitate easier analytics operations. We built a web-based data visualization and dashboard system to give project stakeholders an accurate, real-time view of the project status. In practice, we saw participating teams gained better understanding of their corresponding projects and improved their project quality over time.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Using FindBugs on Production Software
Proc. OOPSLA'07, ACM, Montral (2007)
[u'Nathaniel Ayewah', u'J. David Morgenthaler', u'John Penix', u'William Pugh', u'YuQian Zhou']
SoftwareEngineering
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A Fishbowl with Piranhas: Coalescence, Convergence, or Divergence? The Future of Agile Software Development Practices: Some Assembly Required!
Proc. OOPSLA, ACM, Portland, Oregon (2006), pp. 937-939
[u'Steven Fraser', u'Linda Rising', u'Scott Ambler', u'Alistair Cockburn', u'Jutta Eckstein', u'David Hussman', u'Randy Miller', u'Mark Striebeck', u'Dave Thomas']
SoftwareEngineering
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
How to design a good API and why it matters
Proc. 21st ACM SIGPLAN Conference (OOPSLA), ACM, Portland, Oregon (2006), pp. 506-507
[u'Joshua Bloch']
SoftwareEngineering
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
LCSD: Library-Centric Software Design
Proc. OOPSLA, ACM, Portland, Oregon (2006), pp. 616-618
[u'Josh Bloch', u'Jaakko Jarvi', u'David Musser', u'Sibylle Schupp', u'Jeremy Siek']
SoftwareEngineering
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
LEVER: A Tool for Learning Based Verification (Tool Paper)
Springer (2006)
[u'Abhay Vardhan', u'Mahesh Viswanathan']
SoftwareEngineering
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Modular Software Upgrades for Distributed Systems
European Conference on Object-Oriented Programming (ECOOP) (2006)
[u'Sameer Ajmani', u'Barbara Liskov', u'Liuba Shrira']
SoftwareEngineering
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
binpac: A yacc for Writing Application Protocol Parsers
Proc. 6th ACM SIGCOMM on Internet Measurement, ACM, Rio de Janeriro (2006), pp. 289-300
[u'Ruoming Pang', u'Vern Paxson', u'Robin Sommer', u'Larry Peterson']
SoftwareEngineering
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Hancock: A language for analyzing transactional data streams
ACM Trans. Program. Lang. Syst., vol. 26 (2004), pp. 301-338
[u'Corinna Cortes', u'Kathleen Fisher', u'Daryl Pregibon', u'Anne Rogers', u'Frederick Smith']
SoftwareEngineering
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37377.html
notfound
=========================
How to Break Software
Addison-Wesley (2002)
[u'James A. Whittaker']
SoftwareEngineering
Abstract: How to Break Software is a departure from conventional testing in which testers prepare a written test plan and then use it as a script when testing the software. The testing techniques in this book are as flexible as conventional testing is rigid. And flexibility is needed in software projects in which requirements can change, bugs can become features and schedule pressures often force plans to be reassessed. Software testing is not such an exact science that one can determine what to test in advance and then execute the plan and be done with it. Instead of a plan, intelligence, insight, experience and a "nose for where the bugs are hiding" should guide testers. This book helps testers develop this insight. The techniques presented in this book not only allow testers to go off-script, they encourage them to do so. Don't blindly follow a document that may be out of date and that was written before the product was even testable. Instead, use your head! Open your eyes! Think a little, test a little and then think a little more. This book does teach planning, but in an "on- the-fly while you are testing" way. It also encourages automation with many repetitive and complex tasks that require good tools (one such tool is shipped with this book on the companion CD). However, tools are never used as a replacement for intelligence. Testers do the thinking and use tools to collect data and help them explore applications more efficiently and effectively.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Jscheme: A Dialect of Scheme for Scripting in Java,
Proceedings of the MIT Dynamic Languages Seminar (2001)
[u'Ken Anderson', u'Tim Hickey', u'Peter Norvig']
SoftwareEngineering
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/SoftwareSystems.html
found
http://research.google.com/pubs/pub43980.html
found
=========================
1ML - core and modules united (F-ing first-class modules)
International Conference on Functional Programming, ACM-SIGPLAN, Vancouver, Canada (2015)
[u'Andreas Rossberg']
SoftwareSystems
Abstract: ML is two languages in one: there is the core, with types and expressions, and there are modules, with signatures, structures and functors. Modules form a separate, higher-order functional language on top of the core. There are both practical and technical reasons for this stratification; yet, it creates substantial duplication in syntax and semantics, and it reduces expressiveness. For example, selecting a module cannot be made a dynamic decision. Language extensions allowing modules to be packaged up as first-class values have been proposed and implemented in different variations. However, they remedy expressiveness only to some extent, are syntactically cumbersome, and do not alleviate redundancy. We propose a redesign of ML in which modules are truly first-class values, and core and module layer are unified into one language. In this "1ML", functions, functors, and even type constructors are one and the same construct; likewise, no distinction is made between structures, records, or tuples. Or viewed the other way round, everything is just ("a mode of use of") modules. Yet, 1ML does not require dependent types, and its type structure is expressible in terms of plain System F, in a minor variation of our F-ing modules approach. We introduce both an explicitly typed version of 1ML, and an extension with Damas/Milner-style implicit quantification. Type inference for this language is not complete, but, we argue, not substantially worse than for Standard ML. An alternative view is that 1ML is a user-friendly surface syntax for System F that allows combining term and type abstraction in a more compositional manner than the bare calculus.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43854.html
found
=========================
Conflict-Driven Conditional Termination
Computer Aided Verification, Springer International Publishing (2015), pp. 271-286
[u"Vijay D'Silva", u'Caterina Urban']
SoftwareSystems
Abstract: Conflict-driven learning, which is essential to the performance of sat and smt solvers, consists of a procedure that searches for a model of a formula, and refutation procedure for proving that no model exists. This paper shows that conflict-driven learning can improve the precision of a termination analysis based on abstract interpretation. We encode non-termination as satisfiability in a monadic second-order logic and use abstract interpreters to reason about the satisfiability of this formula. Our search procedure combines decisions with reachability analysis to find potentially non-terminating executions and our refutation procedure uses a conditional termination analysis. Our implementation extends the set of conditional termination arguments discovered by an existing termination analyzer.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Declarative Rewriting Through Circular Nonterminal Attributes
Computer Languages, Systems & Structures (2015) (to appear)
[u'Emma Soederberg', u'Grel Hedin']
SoftwareSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43447.html
found
=========================
Flywheel: Google's Data Compression Proxy for the Mobile Web
Proceedings of the 12th USENIX Symposium on Networked Systems Design and Implementation (NSDI 2015)
[u'Victor Agababov', u'Michael Buettner', u'Victor Chudnovsky', u'Mark Cogan', u'Ben Greenstein', u'Shane McDaniel', u'Michael Piatek', u'Colin Scott', u'Matt Welsh', u'Bolian Yin']
SoftwareSystems
Abstract: Mobile devices are increasingly the dominant Internet access technology. Nevertheless, high costs, data caps, and throttling are a source of widespread frustration, and a significant barrier to adoption in emerging markets. This paper presents Flywheel, an HTTP proxy service that extends the life of mobile data plans by compressing responses in-flight between origin servers and client browsers. Flywheel is integrated with the Chrome web browser and reduces the size of proxied web pages by 50% for a median user. We report measurement results from millions of users as well as experience gained during three years of operating and evolving the production service at Google.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
In Defense of Soundiness: A Manifesto
Communications of the ACM, vol. 58 (2015), pp. 44-46
[u'Benjamin Livshits', u'Manu Sridharan', u'Yannis Smaragdakis', u'Ondrej Lhotak', u'J. Nelson Amaral', u'Bor-Yuh Evan Chang', u'Samuel Z. Guyer', u'Uday P. Khedker', u'Anders Mller', u'Dimitrios Vardoulakis']
SoftwareSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43867.html
found
=========================
Inferring the Network Latency Requirements of Cloud Tenants
15th Workshop on Hot Topics in Operating Systems (HotOS XV), USENIX Association (2015)
[u'Jeffrey C Mogul', u'Ramana Rao Kompella']
SoftwareSystems
Abstract: Cloud IaaS and PaaS tenants rely on cloud providers to provide network infrastructures that make the appropriate tradeoff between cost and performance. This can include mechanisms to help customers understand the performance requirements of their applications. Previous research (e.g., Proteus and Cicada) has shown how to do this for network-bandwidth demands, but cloud tenants may also need to meet latency objectives, which in turn may depend on reliable limits on network latency, and its variance, within the cloud providers infrastructure. On the other hand, if network latency is sufficient for an application, further decreases in latency might add cost without any benefit. Therefore, both tenant and provider have an interest in knowing what network latency is good enough for a given application. This paper explores several options for a cloud provider to infer a tenants network-latency demands, with varying tradeoffs between requirements for tenant participation, accuracy of inference, and instrumentation overhead. In particular, we explore the feasibility of a hypervisor-only mechanism, which would work without any modifications to tenant code, even in IaaS clouds.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43438.html
found
=========================
Large-scale cluster management at Google with Borg
Proceedings of the European Conference on Computer Systems (EuroSys), ACM, Bordeaux, France (2015)
[u'Abhishek Verma', u'Luis Pedrosa', u'Madhukar R. Korupolu', u'David Oppenheimer', u'Eric Tune', u'John Wilkes']
SoftwareSystems
Abstract: Google's Borg system is a cluster manager that runs hundreds of thousands of jobs, from many thousands of different applications, across a number of clusters each with up to tens of thousands of machines. It achieves high utilization by combining admission control, efficient task-packing, over-commitment, and machine sharing with process-level performance isolation. It supports high-availability applications with runtime features that minimize fault-recovery time, and scheduling policies that reduce the probability of correlated failures. Borg simplifies life for its users by offering a declarative job specification language, name service integration, real-time job monitoring, and tools to analyze and simulate system behavior. We present a summary of the Borg system architecture and features, important design decisions, a quantitative analysis of some of its policy decisions, and a qualitative examination of lessons learned from a decade of operational experience with it.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44311.html
found
=========================
Mantis: Efficient Predictions of Execution Time, Energy Usage, Memory Usage and Network Usage on Smart Mobile Devices
IEEE Transactions on Mobile Computing, vol. 14 (2015), pp. 2059-2072
[u'Yongin Kwon', u'Sangmin Lee', u'Hayoon Yi', u'Donghyun Kwon', u'Seungjun Yang', u'Byung-Gon Chun', u'Ling Huang', u'Petros Maniatis', u'Mayur Naik', u'Yunheung Paek']
SoftwareSystems
Abstract: We present Mantis, a framework for predicting the computational resource consumption (CRC) of Android applications on given inputs accurately, and efficiently. A key insight underlying Mantis is that program codes often contain features that correlate with performance and these features can be automatically computed efficiently. Mantis synergistically combines techniques from program analysis and machine learning. It constructs concise CRC models by choosing from many program execution features only a handful that are most correlated with the programs CRC metric yet can be evaluated efficiently from the programs input. We apply program slicing to reduce evaluation time of a feature and automatically generate executable code snippets for efficiently evaluating features. Our evaluation shows that Mantis predicts four CRC metrics of seven Android apps with estimation error in the range of 0-11.1 percent by executing predictor code spending at most 1.3 percent of their execution time on Galaxy Nexus.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43823.html
notfound
=========================
Memento Mori: Dynamic Allocation-site-based Optimizations
Proceedings of the 2015 ACM SIGPLAN International Symposium on Memory Management, ACM, New York, NY, USA, pp. 105-117
[u'Daniel Clifford', u'Hannes Payer', u'Michael Stanton', u'Ben L. Titzer']
SoftwareSystems
Abstract: Languages that lack static typing are ubiquitous in the world of mobile and web applications. The rapid rise of larger applications like interactive web GUIs, games, and cryptography presents a new range of implementation challenges for modern virtual machines to close the performance gap between typed and untyped languages. While all languages can benefit from efficient automatic memory management, languages like JavaScript present extra thrill with innocent-looking but difficult features like dynamically-sized arrays, deletable properties, and prototypes. Optimizing such languages requires complex dynamic techniques with more radical object layout strategies such as dynamically evolving representations for arrays. This paper presents a general approach for gathering temporal allocation site feedback that tackles both the general problem of object lifetime estimation and improves optimization of these problematic language features. We introduce a new implementation technique where allocation mementos processed by the garbage collector and runtime system efficiently tie objects back to allocation sites in the program and dynamically estimate object lifetime, representation, and size to inform three optimizations: pretenuring, pretransitioning, and presizing. Unlike previous work on pretenuring, our system utilizes allocation mementos to achieve fully dynamic allocation-site-based pretenuring in a production system. We implement all of our techniques in V8, a high performance virtual machine for JavaScript, and demonstrate solid performance improvements across a range of benchmarks.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43308.html
notfound
=========================
MemorySanitizer: fast detector of uninitialized memory use in C++
Proceedings of the 2015 IEEE/ACM International Symposium on Code Generation and Optimization (CGO), CGO 2015, San Francisco, CA, USA, pp. 46-55
[u'Evgeniy Stepanov', u'Konstantin Serebryany']
SoftwareSystems
Abstract: This paper presents MemorySanitizer, a dynamic tool that detects uses of uninitialized memory in C and C++. The tool is based on compile time instrumentation and relies on bit-precise shadow memory at run-time. Shadow propagation technique is used to avoid false positive reports on copying of uninitialized memory. MemorySanitizer finds bugs at a modest cost of 2.5x in execution time and 2x in memory usage; the tool has an optional origin tracking mode that provides better reports with moderate extra overhead. The reports with origins are more detailed compared to reports from other similar tools; such reports contain names of local variables and the entire history of the uninitialized memory including intermediate stores. In this paper we share our experience in deploying the tool at a large scale and demonstrate the benefits of compile time instrumentation over dynamic binary instrumentation.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43849.html
found
=========================
Pedestrian Detection with a Large-Field-Of-View Deep Network
Proceedings of ICRA 2015
[u'Anelia Angelova', u'Alex Krizhevsky', u'Vincent Vanhoucke']
SoftwareSystems
Abstract: Pedestrian detection is of crucial importance to autonomous driving applications. Methods based on deep learning have shown significant improvements in accuracy, which makes them particularly suitable for applications, such as pedestrian detection, where reducing miss rate is very important. Although they are accurate, their runtime has been at best in seconds per image, which makes them not practical for onboard applications. We present here a Large-Field-Of-View (LFOV) deep network for pedestrian detection, that can achieve high accuracy and is designed to make deep networks work faster for detection problems. The idea of the proposed Large-Field-of-View deep network is to learn to make classification decisions simultaneously and accurately at multiple locations. The LFOV network processes larger image areas at much faster speeds than typical deep networks have been able to do, and can intrinsically reuse computations. Our pedestrian detection solution, which is a combination of a LFOV network and a standard deep network, works at 280 ms per image on GPU and achieves 35.85 average miss rate on the Caltech Pedestrian Detection Benchmark.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44279.html
found
=========================
Precentile-Based Approach to Forecasting Workload Growth
IT Performance and Capacity by CMG 41st International Conference (CMG2015), Computer Measurement Group, 3501 Route 42 Suite 130 #121 Turnersville, NJ 08012-1734 USA
[u'Alex Gilgur', u'Stephen Gunn', u'Douglas Browning', u'Xiaojun Di', u'Wei Chen', u'Rajesh Krishnaswamy']
SoftwareSystems
Abstract: When forecasting resource workloads (traffic, CPU load, memory usage, etc.), we often extrapolate from the upper percentiles of data distributions. This works very well when the resource is far enough from its saturation point. However, when the resource utilization gets closer to the workload-carrying capacity of the resource, upper percentiles level off (the phenomenon is colloquially known as flat-topping or clipping), leading to underpredictions of future workload and potentially to undersized resources. This paper explains the phenomenon and proposes a new approach that can be used for making useful forecasts of workload when historical data for the forecast are collected from a resource approaching saturation.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43342.html
found
=========================
R for Marketing Research and Analytics
Springer, New York (2015)
[u'Chris Chapman', u'Elea McDonnell Feit']
SoftwareSystems
Abstract: This book is a complete introduction to the power of R for marketing research practitioners. The text describes statistical models from a conceptual point of view with a minimal amount of mathematics, presuming only an introductory knowledge of statistics. Hands-on chapters accelerate the learning curve by asking readers to interact with R from the beginning. Core topics include the R language, basic statistics, linear modeling, and data visualization, which is presented throughout as an integral part of analysis. Later chapters cover more advanced topics yet are intended to be approachable for all analysts. These sections examine logistic regression, customer segmentation, hierarchical linear modeling, market basket analysis, structural equation modeling, and conjoint analysis in R. The text uniquely presents Bayesian models with a minimally complex approach, demonstrating and explaining Bayesian methods alongside traditional analyses for analysis of variance, linear models, and metric and choice-based conjoint analysis. With its emphasis on data visualization, model assessment, and development of statistical intuition, this book provides guidance for any analyst looking to develop or improve skills in R for marketing applications.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43875.html
found
=========================
Real-Time Grasp Detection Using Convolutional Neural Networks
International Conference on Robotics and Automation (ICRA), IEEE (2015)
[u'Joseph Redmon', u'Anelia Angelova']
SoftwareSystems
Abstract: We present an accurate, real-time approach to robotic grasp detection based on convolutional neural networks. Our network performs single-stage regression to graspable bounding boxes without using standard sliding window or region proposal techniques. The model outperforms state-of- the-art approaches by 14 percentage points and runs at 13 frames per second on a GPU. Our network can simultaneously perform classification so that in a single step it recognizes the object and finds a good grasp rectangle. A modification to this model predicts multiple grasps per object by using a locally constrained prediction mechanism. The locally constrained model performs significantly better, especially on objects that can be grasped in a variety of ways.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43850.html
found
=========================
Real-Time Pedestrian Detection With Deep Network Cascades
Proceedings of BMVC 2015 (to appear)
[u'Anelia Angelova', u'Alex Krizhevsky', u'Vincent Vanhoucke', u'Abhijit Ogale', u'Dave Ferguson']
SoftwareSystems
Abstract: We present a new real-time approach to object detection that exploits the efficiency of cascade classifiers with the accuracy of deep neural networks. Deep networks have been shown to excel at classification tasks, and their ability to operate on raw pixel input without the need to design special features is very appealing. However, deep nets are notoriously slow at inference time. In this paper, we propose an approach that cascades deep nets and fast features, that is both extremely fast and extremely accurate. We apply it to the challenging task of pedestrian detection. Our algorithm runs in real-time at 15 frames per second. The resulting approach achieves a 26.2% average miss rate on the Caltech Pedestrian detection benchmark, which is competitive with the very best reported results. It is the first work we are aware of that achieves extremely high accuracy while running in real-time.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44272.html
found
=========================
Reasoning about Risk and Trust in an Open World
Victoria University of Wellington (2015)
[u'Sophia Drossopoulou', u'James Noble', u'Toby Murray', u'Mark S. Miller']
SoftwareSystems
Abstract: Contemporary open systems use components developed by different parties, linked together dynamically in unforeseen constellations. Code needs to live up to strict security requirements, and ensure the correct functioning of its objects even when they collaborate with external, potentially malicious, objects. In this paper we propose special specification predicates that model risk and trust in open systems. We specify Miller, Van Cutsem, and Tullohs escrow exchange example, and discuss the meaning of such a specification. We propose a novel Hoare logic, based on four-tuples, including an invariant describing properties preserved by the execution of a statement as well as a post-condition describing the state after execution. We model specification and programing languages based on the Hoare logic, prove soundness, and prove the key steps of the Escrow protocol.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43808.html
found
=========================
Swapsies on the Internet: First Steps towards Reasoning about Risk and Trust in an Open World
Tenth Workshop on Programming Languages and Analysis for Security (PLAS 2015), ACM
[u'Sophia Drossopoulou', u'James Noble', u'Mark S. Miller']
SoftwareSystems
Abstract: Contemporary open systems use components developed by many different parties, linked together dynamically in unforeseen constellations. Code needs to live up to strict security specifications: it has to ensure the correct functioning of its objects when they collaborate with external objects which may be malicious. In this paper we propose specifications that model risk and trust in such open systems. We specify Miller, Van Cutsem, and Tullohs escrow exchange example, and discuss the meaning of such a specification. We argue informally that the code satisfies its specification.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43856.html
found
=========================
The Correctness-Security Gap in Compiler Optimization
Security and Privacy Workshops (SPW), 2015 IEEE, IEEE, pp. 73-87
[u"Vijay D'Silva", u'Mathias Payer', u'Dawn Song']
SoftwareSystems
Abstract: There is a significant body of work devoted to testing, verifying, and certifying the correctness of optimizing compilers. The focus of such work is to determine if source code and optimized code have the same functional semantics. In this paper, we introduce the correctness-security gap, which arises when a compiler optimization preserves the functionality of but violates a security guarantee made by source code. We show with concrete code examples that several standard optimizations, which have been formally proved correct, in-habit this correctness-security gap. We analyze this gap and conclude that it arises due to techniques that model the state of the program but not the state of the underlying machine. We propose a broad research programme whose goal is to identify, understand, and mitigate the impact of security errors introduced by compiler optimizations. Our proposal includes research in testing, program analysis, theorem proving, and the development of new, accurate machine models for reasoning about the impact of compiler optimizations on security.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43809.html
found
=========================
The Performance Cost of Shadow Stacks and Stack Canaries
Proceedings of the 10th ACM Symposium on Information, Computer and Communications Security (ASIACCS), ACM (2015), pp. 555-566
[u'Thurston H.Y. Dang', u'Petros Maniatis', u'David Wagner']
SoftwareSystems
Abstract: Control flow defenses against ROP either use strict, expensive, but strong protection against redirected RET instructions with shadow stacks, or much faster but weaker protections without. In this work we study the inherent overheads of shadow stack schemes. We find that the overhead is roughly 10% for a traditional shadow stack. We then design a new scheme, the parallel shadow stack, and show that its performance cost is significantly less: 3.5%. Our measurements suggest it will not be easy to improve performance on current x86 processors further, due to inherent costs associated with RET and memory load/store instructions. We conclude with a discussion of the design decisions in our shadow stack instrumentation, and possible lighter-weight alternatives.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Towards Lifelong Feature-Based Mapping in Semi-Static Environments
RSS 2015 Workshop on the problem of mobile sensors
[u'David M Rosen', u'Julian Mason', u'John J Leonard']
SoftwareSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43322.html
found
=========================
Tricorder: Building a Program Analysis Ecosystem
International Conference on Software Engineering (ICSE) (2015)
[u'Caitlin Sadowski', u'Jeffrey van Gogh', u'Ciera Jaspan', u'Emma Soederberg', u'Collin Winter']
SoftwareSystems
Abstract: Static analysis tools help developers find bugs, improve code readability, and ensure consistent style across a project. However, these tools can be difficult to smoothly integrate with each other and into the developer workflow, particularly when scaling to large codebases. We present Tricorder, a program analysis platform aimed at building a data-driven ecosystem around program analysis. We present a set of guiding principles for our program analysis tools and a scalable architecture for an analysis platform implementing these principles. We include an empirical, in-situ evaluation of the tool as it is used by developers across
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44183.html
found
=========================
What you should know about R
Marketing Insights (2015), pp. 12-13
[u'Chris Chapman']
SoftwareSystems
Abstract: A primer on the industrys open-source statistical analysis language.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43462.html
found
=========================
Yedalog: Exploring Knowledge at Scale
1st Summit on Advances in Programming Languages (SNAPL 2015), Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik, Dagstuhl, Germany, pp. 63-78
[u'Brian Chin', u'Daniel von Dincklage', u'Vuk Ercegovac', u'Peter Hawkins', u'Mark S. Miller', u'Franz Och', u'Chris Olston', u'Fernando Pereira']
SoftwareSystems
Abstract: With huge progress on data processing frameworks, human programmers are frequently the bottleneck when analyzing large repositories of data. We introduce Yedalog, a declarative programming language that allows programmers to mix data-parallel pipelines and computation seamlessly in a single language. By contrast, most existing tools for data-parallel computation embed a sublanguage of data-parallel pipelines in a general-purpose language, or vice versa. Yedalog extends Datalog, incorporating not only computational features from logic programming, but also features for working with data structured as nested records. Yedalog programs can run both on a single machine, and distributed across a cluster in batch and interactive modes, allowing programmers to mix different modes of execution easily.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42903.html
found
=========================
A Language-Based Approach to Secure Quorum Replication
Proceedings of the Ninth Workshop on Programming Languages and Analysis for Security (2014), pp. 27-39
[u'Lantian Zheng', u'Andrew C. Myers']
SoftwareSystems
Abstract: Quorum replication is an important technique for building distributed systems because it can simultaneously improve both the integrity and availability of computation and storage. Information flow control is a well-known method for enforcing the confidentiality and integrity of information. This paper demonstrates that these two techniques can be integrated to simultaneously enforce all three major security properties: confidentiality, integrity and availability. It presents a security-typed language with explicit language constructs for supporting secure quorum replication. The dependency analysis performed by the type system of the language provides a way to formally verify the end-to-end security assurance of complex replication schemes. We also contribute a new multilevel timestamp mechanism for synchronizing code and data replicas while controlling the side channels such mechanisms introduce.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43216.html
notfound
=========================
ACDC-JS: explorative benchmarking of javascript memory management
Proceedings of the 10th ACM Symposium on Dynamic Languages, ACM, New York, NY, USA (2014), pp. 67-78
[u'Martin Aigner', u'Thomas Huetter', u'Christoph M. Kirsch', u'Alexander Miller', u'Hannes Payer', u'Mario Preishuber']
SoftwareSystems
Abstract: We present ACDC-JS, an open-source JavaScript memory management benchmarking tool. ACDC-JS incorporates a heap model based on real web applications and may be configured to expose virtually any relevant performance characteristics of JavaScript memory management systems. ACDC-JS is based on ACDC, a benchmarking tool for C/C++ that models periodic allocation and deallocation behavior (AC) as well as persistent memory (DC). We identify important characteristics of JavaScript mutator behavior and propose a configurable heap model based on typical distributions of these characteristics as foundation for ACDC-JS. We describe heap analyses of 13 real web applications extending existing work on JavaScript behavior analysis. Our experimental results show that ACDC-JS enables performance benchmarking and debugging of state-of-the-art JavaScript virtual machines such as V8 and SpiderMonkey by exposing key aspects of their memory management performance.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42478.html
notfound
=========================
Allocation Folding Based on Dominance
Proceedings of the 2014 International Symposium on Memory Management, ACM, New York, NY, USA
[u'Daniel Clifford', u'Hannes Payer', u'Michael Starzinger', u'Ben L. Titzer']
SoftwareSystems
Abstract: Memory management system performance is of increasing importance in today's managed languages. Two lingering sources of overhead are the direct costs of memory allocations and write barriers. This paper introduces allocation folding, an optimization technique where the virtual machine automatically folds multiple memory allocation operations in optimized code together into a single, larger allocation group. An allocation group comprises multiple objects and requires just a single bounds check in a bump-pointer style allocation, rather than a check for each individual object. More importantly, all objects allocated in a single allocation group are guaranteed to be contiguous after allocation and thus exist in the same generation, which makes it possible to statically remove write barriers for reference stores involving objects in the same allocation group. Unlike object inlining, object fusing, and object colocation, allocation folding requires no special connectivity or ownership relation between the objects in an allocation group. We present our analysis algorithm to determine when it is safe to fold allocations together and discuss our implementation in V8, an open-source, production JavaScript virtual machine. We present performance results for the Octane and Kraken benchmark suites and show that allocation folding is a strong performance improvement, even in the presence of some heap fragmentation. Additionally, we use four hand-selected benchmarks JPEGEncoder, NBody, Soft3D, and Textwriter where allocation folding has a large impact.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41868.html
found
=========================
Bespoke infrastructures
IEEE Software, vol. 31 (2014), pp. 12-14
[u'Diomidis Spinellis']
SoftwareSystems
Abstract: Infrastructure developed within an organization for its own internal use can take many forms. The obvious reason for creating a bespoke solution is that it can be tailored to fit the organization's unique needs. This can offer many advantages: better performance, increased flexibility, and tactical or strategic advantages over the competition. However, such solutions are associated with a steep learning curve for newcomers, maintenance and support costs, and the risk of hijacking by groups with vested interests. Given that investment in bespoke infrastructures is a sunk cost and that these polarize the types of employees that stay in the organization, rational approaches for building an organization's infrastructure include customizing a general-purpose solution or adopting an open-source tool and improving it to address the organization's requirements.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42958.html
found
=========================
C/C++ Thread Safety Analysis
2014 IEEE 14th International Working Conference on Source Code Analysis and Manipulation, IEEE
[u'DeLesley Hutchins', u'Aaron Ballman', u'Dean Sutherland']
SoftwareSystems
Abstract: Writing multithreaded programs is hard. Static analysis tools can help developers by allowing threading policies to be formally specified and mechanically checked. They essentially provide a static type system for threads, and can detect potential race conditions and deadlocks. This paper describes Clang Thread Safety Analysis, a tool which uses annotations to declare and enforce thread safety policies in C and C++ programs. Clang is a production-quality C++ compiler which is available on most platforms, and the analysis can be enabled for any build with a simple warning flag: Wthreadsafety. The analysis is deployed on a large scale at Google, where it has provided sufficient value in practice to drive widespread voluntary adoption. Contrary to popular belief, the need for annotations has not been a liability, and even confers some benefits with respect to software evolution and maintenance.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42808.html
found
=========================
Enforcing Forward-Edge Control-Flow Integrity in GCC & LLVM
Proceedings of the 23rd Usenix Security Symposium, USENIX, San Diego, CA (2014)
[u'Caroline Tice', u'Tom Roeder', u'Peter Collingbourne', u'Stephen Checkoway', u'lfar Erlingsson', u'Luis Lozano', u'Geoff Pike']
SoftwareSystems
Abstract: Constraining dynamic control transfers is a common technique for mitigating software vulnerabilities. This defense has been widely and successfully used to protect return addresses and stack data; hence, current attacks instead typically corrupt vtable and function pointers to subvert a forward edge (an indirect jump or call) in the control-flow graph. Forward edges can be protected using Control-Flow Integrity (CFI) but, to date, CFI implementations have been research prototypes, based on impractical assumptions or ad hoc, heuristic techniques. To be widely adoptable, CFI mechanisms must be integrated into production compilers and be compatible with software-engineering aspects such as incremental compilation and dynamic libraries. This paper presents implementations of fine-grained, forward-edge CFI enforcement and analysis for GCC and LLVM that meet the above requirements. An analysis and evaluation of the security, performance, and resource consumption of these mechanisms applied to the SPEC CPU2006 benchmarks and common benchmarks for the Chromium web browser show the practicality of our approach: these fine-grained CFI mechanisms have significantly lower overhead than recent academic CFI prototypes. Implementing CFI in industrial compiler frameworks has also led to insights into design tradeoffs and practical challenges, such as dynamic loading.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43103.html
found
=========================
Evaluating job packing in warehouse-scale computing
IEEE Cluster, Madrid, Spain (2014)
[u'Abhishek Verma', u'Madhukar Korupolu', u'John Wilkes']
SoftwareSystems
Abstract: One of the key factors in selecting a good scheduling algorithm is using an appropriate metric for comparing schedulers. But which metric should be used when evaluating schedulers for warehouse-scale (cloud) clusters, which have machines of different types and sizes, heterogeneous workloads with dependencies and constraints on task placement, and long-running services that consume a large fraction of the total resources? Traditional scheduler evaluations that focus on metrics such as queuing delay, makespan, and running time fail to capture important behaviors and ones that rely on workload synthesis and scaling often ignore important factors such as constraints. This paper explains some of the complexities and issues in evaluating warehouse scale schedulers, focusing on what we find to be the single most important aspect in practice: how well they pack long-running services into a cluster. We describe and compare four metrics for evaluating the packing efficiency of schedulers in increasing order of sophistication: aggregate utilization, hole filling, workload inflation and cluster compaction.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43981.html
found
=========================
F-ing modules
Journal of Functional Programming, vol. 24 (5) (2014)
[u'Andreas Rossberg', u'Claudio Russo', u'Derek Dreyer']
SoftwareSystems
Abstract: ML modules are a powerful language mechanism for decomposing programs into reusable components. Unfortunately, they also have a reputation for being "complex" and requiring fancy type theory that is mostly opaque to non-experts. While this reputation is certainly understandable, given the many non-standard methodologies that have been developed in the process of studying modules, we aim here to demonstrate that it is undeserved. To do so, we give a very simple elaboration semantics for a full-featured, higher-order ML-like module language. Our elaboration defines the meaning of module expressions by a straightforward, compositional translation into vanilla System F (the higher-order polymorphic -calculus), under plain F typing environments. We thereby show that ML modules are merely a particular mode of use of System F. We start out with a module language that supports the usual second-class modules with Standard ML-style generative functors, and includes local module definitions. To demonstrate the versatility of our approach, we further extend the language with the ability to package modules as first-class values a very simple extension, as it turns out and a novel treatment of OCaml-style applicative functors. Unlike previous work combining both generative and applicative functors, we do not require two distinct forms of functor or sealing expressions. Instead, whether a functor is applicative or not depends only on the computational purity of its body in fact, we argue that applicative/generative is rather incidental terminology for what is best understood as pure vs. impure functors. This approach results in a semantics that we feel is simpler and more natural, and moreover prohibits breaches of data abstraction that are possible under earlier semantics for applicative functors. We also revive (in refined form) the long-lost notion of structure sharing from SML'90. Although previous work on module type systems has disparaged structure sharing as type-theoretically questionable, we observe that (1) some variant of it is in fact necessary in order to provide a proper treatment of abstraction in the presence of applicative functors, and (2) it is straightforward to account for using ``phantom types''. Based on this, we can even justify the (previously poorly understood) "where module" operator for signatures and the related notion of manifest module specifications. Altogether, we describe a comprehensive, unified, and yet simple semantics of a full-blown module language that with the main exception of cross-module recursion covers almost all interesting features that can be found in either the literature or in practical implementations of ML modules. We prove the language sound and its type checking decidable.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42299.html
notfound
=========================
Google hostload prediction based on Bayesian model with optimized feature combination
Journal Parallel and Distributed Computing (2014)
[u'Sheng Dia', u'Derrick Kondo', u'Walfredo Cirne']
SoftwareSystems
Abstract: We design a novel prediction method with Bayes model to predict a load fluctuation pattern over a long-term interval, in the context of Google data centers. We exploit a set of features that capture the expectation, trend, stability and patterns of recent host loads. We also investigate the correlations among these features and explore the most effective combinations of features with various training periods. All of the prediction methods are evaluated using Google trace with 10,000+heterogeneous hosts. Experiments show that our Bayes method improves the long-term load prediction accuracy by 5.6%50%, compared to other state-of-the-art methods based on moving average, auto-regression, and/or noise filters. Mean squared error of pattern prediction with Bayes method can be approximately limited in [108 ,105 ]. Through a load balancing scenario, we confirm the precision of pattern prediction in finding a set of idlest/busiest hosts from among 10,000+ hosts can be improved by about 7% on average.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43217.html
found
=========================
How Developers Use Data Race Detection Tools
Evaluation and Usability of Programming Languages and Tools (PLATEAU), ACM (2014)
[u'Caitlin Sadowski', u'Jaeheon Yi']
SoftwareSystems
Abstract: Developers need help with multithreaded programming. We investigate how two program analysis tools are used by developers at Google: ThreadSafety, an annotation-based static data race analysis, and TSan, a dynamic data race detector. The data was collected by interviewing seven veteran industry developers at Google, and provides unique insight into how four different teams use tooling in different ways to help with multithreaded programming. The result is a collection of perceived pros and cons of using ThreadSafety and TSan, as well as general issues with multithreading.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43017.html
found
=========================
Long-term SLOs for reclaimed cloud computing resources
ACM Symposium on Cloud Computing (SoCC), ACM, Seattle, WA, USA (2014), 20:1-20:13
[u'Marcus Carvalho', u'Walfredo Cirne', u'Franciso Brasileiro', u'John Wilkes']
SoftwareSystems
Abstract: The elasticity promised by cloud computing does not come for free. Providers need to reserve resources to allow users to scale on demand, and cope with workload variations, which results in low utilization. The current response to this low utilization is to re-sell unused resources with no Service Level Objectives (SLOs) for availability. In this paper, we show how to make some of these reclaimable resources more valuable by providing strong, long-term availability SLOs for them. These SLOs are based on forecasts of how many resources will remain unused during multi-month periods, so users can do capacity planning for their long-running services. By using confidence levels for the predictions, we give service providers control over the risk of violating the availability SLOs, and allow them trade increased risk for more resources to make available. We evaluated our approach using 45 months of workload data from 6 production clusters at Google, and show that 6--17% of the resources can be re-offered with a long-term availability of 98.9% or better. A conservative analysis shows that doing so may increase the profitability of selling reclaimed resources by 22--60%.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42576.html
notfound
=========================
Making Push On Green a Reality: Issues & Actions Involved in Maintaining a Production Service
;login:, vol. 39, number 5 (2014), pp. 26-32
[u'Daniel V. Klein', u'Dina M. Betser', u'Mathew G. Monroe']
SoftwareSystems
Abstract: Updating production software is a process that may require dozens, if not hundreds, of steps. These include creating and testing the new code, building new binaries and packages, associating the packages with a versioned release, updating the jobs in production datacenters, possibly modifying database schemata, and testing and verifying the results. There are boxes to check and approvals to seek, and the more automated the process, the easier it becomes. When releases can be made faster, it is possible to release more often, and organizationally, one becomes less afraid to release early, release often. This is the fundamental driving force behind the work described in this paper making rollouts as easy and as automated as possible, so that when a green condition (defined below) is detected, we can more quickly perform a new rollout. Humans may still be needed somewhere in the loop, but we strive to reduce the purely mechanical toil they need to perform. This paper describes how we, as Site Reliability Engineers working on several different Ads and Commerce services at Google, do this, and shares information on how to enable other organizations to do the same. We define Push On Green and describe the development and deployment of best practices that serve as a foundation for this kind of undertaking. Using a sample service at Google as an example, we look at the historical development of the mechanization of the rollout process, and discuss the steps taken to further automate it. We then examine the steps remaining, both near and long-term, as we continue to gain experience and advance the process towards full automation. We conclude with a set of concrete recommendations for other groups wishing to implement a Push On Green system that keeps production systems not only up-and-running, but also updated with as little engineer-involvement and user-visible downtime as possible.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Outlawing ghosts: avoiding out-of-thin-air results
Workshop on Memory Systems Performance and Correctness (MSPC), ACM, New York, NY (2014)
[u'Hans-J. Boehm', u'Brian Demsky']
SoftwareSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43246.html
found
=========================
Perfect Reconstructability of Control Flow from Demand Dependence Graphs
Transactions on Architecture and Code Optimization (2014) (to appear)
[u'Helge Bahmann', u'Nico Reissmann', u'Magnus Jahre', u'Jan Christian Meyer']
SoftwareSystems
Abstract: Functional demand-based dependence graphs, such as the Regionalized Value State Dependence Graph, are intermediate representations that only model the flow of data and state with implicit and severely restricted control flow. While suitable for formulation of program transformations, they require algorithms for conversion from and to representations with explicit control flow such as CFG. Existing solutions exhibit structural constraints limiting quality of generated control flow, but we show that this is not intrinsic to RVSDGs. We provide algorithms capable of perfect round-trip conversions, prove their correctness and empirically evaluate their run-time performance and representation overhead.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43153.html
found
=========================
Physical Telepresence: Shape Capture and Display for Embodied, Computer-mediated Remote Collaboration
ACM Symposium on User Interface Software and Technology, ACM (2014), pp. 461-470
[u'Daniel Leithinger', u'Sean Follmer', u'Alex Olwal', u'Hiroshi Ishii']
SoftwareSystems
Abstract: We propose a new approach to Physical Telepresence, based on shared workspaces with the ability to capture and remotely render the shapes of people and objects. In this paper, we describe the concept of shape transmission, and propose interaction techniques to manipulate remote physical objects and physical renderings of shared digital content. We investigate how the representation of user's body parts can be altered to amplify their capabilities for teleoperation. We also describe the details of building and testing prototype Physical Telepresence workspaces based on shape displays. A preliminary evaluation shows how users are able to manipulate remote objects, and we report on our observations of several different manipulation techniques that highlight the expressive nature of our system.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44271.html
found
=========================
Profiling a warehouse-scale computer
ISCA '15 Proceedings of the 42nd Annual International Symposium on Computer Architecture, ACM (2014), pp. 158-169
[u'Svilen Kanev', u'Juan Darago', u'Kim Hazelwood', u'Parthasarathy Ranganathan', u'Tipp Moseley', u'Gu-Yeon Wei', u'David Brooks']
SoftwareSystems
Abstract: With the increasing prevalence of warehouse-scale (WSC) and cloud computing, understanding the interactions of server applications with the underlying microarchitecture becomes ever more important in order to extract maximum performance out of server hardware. To aid such understanding, this paper presents a detailed microarchitectural analysis of live datacenter jobs, measured on more than 20,000 Google machines over a three year period, and comprising thousands of different applications. We first find that WSC workloads are extremely diverse, breeding the need for architectures that can tolerate application variability without performance loss. However, some patterns emerge, offering opportunities for co-optimization of hardware and software. For example, we identify common building blocks in the lower levels of the software stack. This "datacenter tax" can comprise nearly 30% of cycles across jobs running in the fleet, which makes its constituents prime candidates for hardware specialization in future server systems-on-chips. We also uncover opportunities for classic microarchitectural optimizations for server processors, especially in the cache hierarchy. Typical workloads place significant stress on instruction caches and prefer memory latency over bandwidth. They also stall cores often, but compute heavily in bursts. These observations motivate several interesting directions for future warehouse-scale computers.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42577.html
found
=========================
RLint: Reformatting R Code to Follow the Google Style Guide
R User Conference (2014)
[u'Alex Blocker', u'Andy Chen', u'Andy Chu', u'Tim Hesterberg', u'Jeffrey D. Oldham', u'Caitlin Sadowski', u'Tom Zhang']
SoftwareSystems
Abstract: RLint (https://code.google.com/p/google-rlint/) both checks and reformats R code to the Google R Style Guide. It warns of violations and optionally produces compliant code. It considers proper spacing, line alignment inside brackets, and other style violations, but like all lint programs does not try to handle all syntax issues. Code that follows a uniform style eases maintenance, modification, and ensuring correctness, especially when multiple programmers are involved. Thus, RLint is automatically used within Google as part of the peer review process for R code. We encourage CRAN package authors and other R programmers to use this tool. A user can run the open-source Python-based program in a Linux, Unix, Mac or Windows machine via a command line.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42179.html
notfound
=========================
Residential Power Load Forecasting
Conference on Systems Engineering Research (CSER 2014), Elisevier B.V., Elsevier Inc/1600 John F Kennedy Boulevard Suite 1800 Philadelphia PA 19103-2879 USA (to appear)
[u'Jeffrey Stevenson', u'Patrick Day', u'George Ruwisch', u'Michael Fabian', u'Ryan Spencer', u'Rajeshbabu Thoppay', u'Donald Noble']
SoftwareSystems
Abstract: Abstract The prepaid electric power metering market is being driven in large part by advancements in and the adoption of Smart Grid technology. Advanced smart meters facilitate the deployment of prepaid systems with smart prepaid meters. A successful program hinges on the ability to accurately predict the amount of energy consumed on a daily basis for each end user. This method of forecasting is called Residential Power Load Forecasting (RPLF). This paper describes the systems engineering (SE) processes and tools that were used to develop a recommended load prediction model for the project sponsor, SmartGridCIS. The basic concept is that power is treated similar to a prepaid telephone in a pay as you go fashion. Modeling techniques explored in the analysis of alternatives (AoA) include Fuzzy Logic, Time Series Moving Average, and Artificial Neural Networks (ANN). SE tools such as prioritization and Pugh matrices were used to choose the best-fit model, which ended up being the ANN. Cognitive systems engineering was used in conjunction with the task analysis. Requirements were developed using the commercial tool IBM Rational DOORS.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Unsupervised Discovery of Object Classes with a Mobile Robot
ICRA 2014
[u'Julian Mason', u'Bhaskara Marthi', u'Ronald Parr']
SoftwareSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40678.html
found
=========================
A new approach to the semantics of model diagrams
18th International Workshop on Types for Proofs and Programs (TYPES 2011), LIPICS (2013), pp. 28-40
[u'Johan G. Granstrom']
SoftwareSystems
Abstract: Sometimes, a diagram can say more than a thousand lines of code. But, sadly, most of the time, software engineers give up on diagrams after the design phase, and all real work is done in code. The supremacy of code over diagrams would be leveled if diagrams were code. This paper suggests that model and instance diagrams, or, which amounts to the same, class and object diagrams, become first level entities in a suitably expressive programming language, viz., type theory. The proposed semantics of diagrams is compositional and self-describing, i.e., reflexive, or metacircular. Moreover, it is well suited for metamodelling and model driven engineering, as it is possible to prove model transformations correct in type theory. The encoding into type theory has the additional benefit of making diagrams immediately useful, given an implementation of type theory.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41685.html
found
=========================
AGILE: elastic distributed resource scaling for Infrastructure-as-a-Service
10th International Conference on Autonomic Computing (ICAC), USENIX, San Jose, CA, USA (2013), pp. 69-82
[u'Hiep Nguyen', u'Zhiming Shen', u'Xiaohui Gu', u'Sethuraman Subbiah', u'John Wilkes']
SoftwareSystems
Abstract: Dynamically adjusting the number of virtual machines (VMs) assigned to a cloud application to keep up with load changes and interference from other uses typically requires detailed application knowledge and an ability to know the future, neither of which are readily available to infrastructure service providers or application owners. The result is that systems need to be over-provisioned (costly), or risk missing their performance Service Level Objectives (SLOs) and have to pay penalties (also costly). AGILE deals with both issues: it uses wavelets to provide a medium-term resource demand prediction with enough lead time to start up new application server instances before performance falls short, and it uses dynamic VM cloning to reduce application startup times. Tests using RUBiS and Google cluster traces show that AGILE can predict varying resource demands over the medium-term with up to 3.42 better true positive rate and 0.34 the false positive rate than existing schemes. Given a target SLO violation rate, AGILE can efciently handle dynamic application workloads, reducing both penalties and user dissatisfaction.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40737.html
found
=========================
CPI2: CPU performance isolation for shared compute clusters
SIGOPS European Conference on Computer Systems (EuroSys), ACM, Prague, Czech Republic (2013), pp. 379-391
[u'Xiao Zhang', u'Eric Tune', u'Robert Hagmann', u'Rohit Jnagal', u'Vrigo Gokhale', u'John Wilkes']
SoftwareSystems
Abstract: Performance isolation is a key challenge in cloud computing. Unfortunately, Linux has few defenses against performance interference in shared resources such as processor caches and memory buses, so applications in a cloud can experience unpredictable performance caused by other program's behavior. Our solution, CPI2, uses cycles-per-instruction (CPI) data obtained by hardware performance counters to identify problems, select the likely perpetrators, and then optionally throttle them so that the victims can return to their expected behavior. It automatically learns normal and anomalous behaviors by aggregating data from multiple tasks in the same job. We have rolled out CPI2 to all of Google's shared compute clusters. The paper presents the analysis that lead us to that outcome, including both case studies and a large-scale evaluation of its ability to solve real production issues.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41434.html
notfound
=========================
Cloud-based robot grasping with the google object recognition engine
IEEE Intl Conf. on Robotics and Automation (2013), pp. 8
[u'Ben Kehoe', u'Akihiro Matsukawa', u'Sal Candido', u'James Kuffner', u'Ken Goldberg']
SoftwareSystems
Abstract: Rapidly expanding internet resources and wireless networking have potential to liberate robots and automation systems from limited onboard computation, memory, and software. "Cloud Robotics" describes an approach that recognizes the wide availability of networking and incorporates opensource elements to greatly extend earlier concepts of "Online Robots" and "Networked Robots". In this paper we consider how cloud-based data and computation can facilitate 3D robot grasping. We present a system architecture, implemented prototype, and initial experimental data for a cloud-based robot grasping system that incorporates a Willow Garage PR2 robot with onboard color and depth cameras, Googles proprietary object recognition engine, the Point Cloud Library (PCL) for pose estimation, Columbia Universitys GraspIt! toolkit and OpenRAVE for 3D grasping and our prior approach to sampling-based grasp analysis to address uncertainty in pose. We report data from experiments in recognition (a recall rate of 80% for the objects in our test set), pose estimation (failure rate under 14%), and grasping (failure rate under 23%) and initial results on recall and false positives in larger data sets using condence measures.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41415.html
found
=========================
Concurrency-aware compiler optimizations for hardware description languages
ACM Transactions on Design Automation of Electronic Systems (TODAES), vol. Volume 18, Issue 1 (2013), 10:1-10:16
[u'Harikumar Somakumar']
SoftwareSystems
Abstract: In this article, we discuss the application of compiler technology for eliminating redundant computation in hardware simulation. We discuss how concurrency in hardware description languages (HDLs) presents opportunities for expression reuse across different threads. While accounting for discrete event simulation semantics, we extend the data flow analysis framework to concurrent threads. In this process, we introduce a rewriting scheme named VF and a graph representation to model sensitivity relationships among threads. An algorithm for identifying common sub-expressions as applied to HDLs is presented. Related issues, such as scheduling correctness, are also considered.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Conjoint Analysis in R Now with Individual-Level Utilities and Survey Mockups
American Marketing Association Advanced Research Techniques Forum (2013), Poster
[u'Chris Chapman', u'Steven Ellis']
SoftwareSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40673.html
found
=========================
Distributed Electronic Rights in JavaScript
ESOP'13 22nd European Symposium on Programming, Springer (2013)
[u'Mark S. Miller', u'Tom Van Cutsem', u'Bill Tulloh']
SoftwareSystems
Abstract: Contracts enable mutually suspicious parties to cooperate safely through the exchange of rights. Smart contracts are programs whose behavior enforces the terms of the contract. This paper shows how such contracts can be specified elegantly and executed safely, given an appropriate distributed, secure, persistent, and ubiquitous computational fabric. JavaScript provides the ubiquity but must be significantly extended to deal with the other aspects. The first part of this paper is a progress report on our efforts to turn JavaScript into this fabric. To demonstrate the suitability of this design, we describe an escrow exchange contract implemented in 42 lines of JavaScript code.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41848.html
found
=========================
Drilling Network Stacks with packetdrill
USENIX ;login:, vol. 38 (2013), pp. 48-52
[u'Neal Cardwell', u'Barath Raghavan']
SoftwareSystems
Abstract: Testing and troubleshooting network protocols and stacks can be painstaking. To ease this process, our team built packetdrill, a tool that lets you write precise scripts to test entire network stacks, from the system call layer down to the NIC hardware. packetdrill scripts use a familiar syntax and run in seconds, making them easy to use during development, debugging, and regression testing, and for learning and investigation.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41446.html
notfound
=========================
Harmonizing classes, functions, tuples, and type parameters in Virgil III
Proceedings of the 34th ACM SIGPLAN conference on Programming language design and implementation, ACM, New York, New York (2013), pp. 85-94
[u'Ben L. Titzer']
SoftwareSystems
Abstract: Languages are becoming increasingly multi-paradigm. Subtype polymorphism in statically-typed object-oriented languages is being supplemented with parametric polymorphism in the form of generics. Features like first-class functions and lambdas are appearing everywhere. Yet existing languages like Java, C#, C++, D, and Scala seem to accrete ever more complexity when they reach beyond their original paradigm into another; inevitably older features have some rough edges that lead to nonuniformity and pitfalls. Given a fresh start, a new language designer is faced with a daunting array of potential features. Where to start? What is important to get right first, and what can be added later? What features must work together, and what features are orthogonal? We report on our experience with Virgil III, a practical language with a careful balance of classes, functions, tuples and type parameters. Virgil intentionally lacks many advanced features, yet we find its core feature set enables new species of design patterns that bridge multiple paradigms and emulate features not directly supported such as interfaces, abstract data types, ad hoc polymorphism, and variant types. Surprisingly, we find variance for function types and tuple types often replaces the need for other kinds of type variance when libraries are designed in a more functional style.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Instant Proling: Instrumentation Sampling for Proling Datacenter Applications
Proceedings of the 2013 IEEE/ACM International Symposium on Code Generation and Optimization (CGO), IEEE Computer Society, Washington, DC, USA
[u'Hyoun Kyu Cho', u'Tipp Moseley', u'Rick Hank', u'Derek Bruening', u'Scott A. Mahlke']
SoftwareSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40738.html
notfound
=========================
JSWhiz - Static Analysis for JavaScript Memory Leaks
Proceedings of the 10th annual IEEE/ACM international symposium on Code generation and optimization, IEEE (2013)
[u'Jacques Pienaar', u'Robert Hundt']
SoftwareSystems
Abstract: JavaScript is the dominant language for implementing dynamic web pages in browsers. Even though it is standardized, many browsers implement language and browser bindings in different and incompatible ways. As a result, a plethora of web development frameworks were developed to hide cross-browser issues and to ease development of large web applications. An unwelcome side-effect of these frameworks is that they can introduce memory leaks, despite the fact that JavaScript is garbage collected. Memory bloat is a major issue for web applications, as it affects user perceived latency and may even prevent large web applications from running on devices with limited resources. In this paper we present JSWhiz, an extension to the open-source Closure JavaScript compiler. Based on experiences analyzing memory leaks in Gmail, JSWhiz detects five identified common problem patterns. JSWhiz found a total of 89 memory leaks across Google's Gmail, Docs, Spreadsheets, Books, and Closure itself. It contributed significantly in a recent effort to reduce Gmail memory footprint, which resulted in bloat reduction of 75% at the 99th percentile, and by roughly 50% at the median.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41179.html
notfound
=========================
Janus: Optimal Flash Provisioning for Cloud Storage Workloads
Proceedings of the USENIX Annual Technical Conference, USENIX, Advanced Computing System Association, 2560 Ninth Street, Suite 215, Berkeley, CA 94710, USA (2013), pp. 91-102
[u'Christoph Albrecht', u'Arif Merchant', u'Murray Stokely', u'Muhammad Waliji', u'Francois Labelle', u'Nathan Coehlo', u'Xudong Shi', u'Eric Schrock']
SoftwareSystems
Abstract: Janus is a system for partitioning the ash storage tier between workloads in a cloud-scale distributed le system with two tiers, ash storage and disk. The le system stores newly created les in the ash tier and moves them to the disk tier using either a First-In-First-Out (FIFO) policy or a Least-Recently-Used (LRU) policy, subject to per-workload allocations. Janus constructs compact metrics of the cacheability of the different workloads, using sampled distributed traces because of the large scale of the system. From these metrics, we formulate and solve an optimization problem to determine the ash allocation to workloads that maximizes the total reads sent to the ash tier, subject to operator-set priorities and bounds on ash write rates. Using measurements from production workloads in multiple data centers using these recommendations, as well as traces of other production workloads, we show that the resulting allocation improves the ash hit rate by 4776% compared to a unied tier shared by all workloads. Based on these results and an analysis of several thousand production workloads, we conclude that ash storage is a cost-effective complement to disks in data centers.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Linux System Programming
O'Reilly (2013)
[u'Robert Love']
SoftwareSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43982.html
found
=========================
Mixin' up the ML module system
Transactions on Programming Languages and Systems, vol. 35 (1) (2013)
[u'Andreas Rossberg', u'Derek Dreyer']
SoftwareSystems
Abstract: ML modules provide hierarchical namespace management, as well as fine-grained control over the propagation of type information, but they do not allow modules to be broken up into mutually recursive, separately compilable components. Mixin modules facilitate recursive linking of separately compiled components, but they are not hierarchically composable and typically do not support type abstraction. We synthesize the complementary advantages of these two mechanisms in a novel module system design we call MixML. A MixML module is like an ML structure in which some of the components are specified but not defined. In other words, it unifies the ML structure and signature languages into one. MixML seamlessly integrates hierarchical composition, translucent ML-style data abstraction, and mixin-style recursive linking. Moreover, the design of MixML is clean and minimalist; it emphasizes how all the salient, semantically interesting features of the ML module system (and several proposed extensions to it) can be understood simply as stylized uses of a small set of orthogonal underlying constructs, with mixin composition playing a central role. We provide a declarative type system for MixML, including two important extensions: higher-order modules, and modules as first-class values. We also present a sound and complete, three-pass type checking algorithm for this system. The operational semantics of MixML is defined by an elaboration translation into an internal core language called LTG namely, a polymorphic lambda calculus with single-assignment references and recursive type generativity which employs a linear type and kind system to track definedness of term and type imports.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40750.html
found
=========================
Multi-Armed Recommendation Bandits for Selecting State Machine Policies for Robotic Systems
Proceedings of International Conference on Robotics and Automation (ICRA 2013)
[u'Pyry Matikainen', u'P. Michael Furlong', u'Rahul Sukthankar', u'Martial Hebert']
SoftwareSystems
Abstract: We investigate the problem of selecting a state-machine from a library to control a robot. We are particularly interested in this problem when evaluating such state machines on a particular robotics task is expensive. As a motivating example, we consider a problem where a simulated vacuuming robot must select a driving state machine well-suited for a particular (unknown) room layout. By borrowing concepts from collaborative filtering (recommender systems such as Netflix and Amazon.com), we present a multi-armed bandit formulation that incorporates recommendation techniques to efficiently select state machines for individual room layouts. We show that this formulation outperforms the individual approaches (recommendation, multi-armed bandits) as well as the baseline of selecting the `average best' state machine across all rooms.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41684.html
found
=========================
Omega: flexible, scalable schedulers for large compute clusters
SIGOPS European Conference on Computer Systems (EuroSys), ACM, Prague, Czech Republic (2013), pp. 351-364
[u'Malte Schwarzkopf', u'Andy Konwinski', u'Michael Abd-El-Malek', u'John Wilkes']
SoftwareSystems
Abstract: Increasing scale and the need for rapid response to changing requirements are hard to meet with current monolithic cluster scheduler architectures. This restricts the rate at which new features can be deployed, decreases efficiency and utilization, and will eventually limit cluster growth. We present a novel approach to address these needs using parallelism, shared state, and lock-free optimistic concurrency control. We compare this approach to existing cluster scheduler designs, evaluate how much interference between schedulers occurs and how much it matters in practice, present some techniques to alleviate it, and finally discuss a use case highlighting the advantages of our approach -- all driven by real-life Google production workloads.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41587.html
found
=========================
Physically-based Grasp Quality Evaluation under Pose Uncertainty
IEEE Transactions on Robotics (2013)
[u'Junggon Kim', u'Kunihiro Iwamoto', u'James J.Kuffner', u'Yasuhiro Ota', u'Nancy S. Pollard']
SoftwareSystems
Abstract: Although there has been great progress in robot grasp planning, automatically generated grasp sets using a quality metric are not as robust as human generated grasp sets when applied to real problems. Most previous research on grasp quality metrics has focused on measuring the quality of established grasp contacts after grasping, but it is difcult to reproduce the same planned nal grasp conguration with a real robot hand, which makes the quality evaluation less useful in practice. In this study we focus more on the grasping process which usually involves changes in contact and object location, and explore the efcacy of using dynamic simulation in estimating the likely success or failure of a grasp in the real environment. Among many factors that can possibly affect the result of grasping, we particularly investigated the effect of considering object dynamics and pose uncertainty on the performance in estimating the actual grasp success rates measured from experiments. We observed that considering both dynamics and uncertainty improved the performance signicantly and, when applied to automatic grasp set generation, this method generated more stable and natural grasp sets compared to a commonly used method based on kinematic simulation and force-closure analysis.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41099.html
notfound
=========================
Reducing Lookups for Invariant Checking
Proceedings of ECOOP 2013 (to appear)
[u'Jakob G. Thomsen', u'Christian Clausen', u'Kristoffer J. Andersen', u'Erik Ernst', u'John Danaher']
SoftwareSystems
Abstract: This paper helps reducing the cost of invariant checking in cases where access to data is expensive. Assume that a set of variables satisfy a given invariant and a request is received to update a subset of them. We reduce the set of variables to inspect, in order to verify that the invariant is still satised. We present a formal model of this scenario, based on a simple query language for the expression of invariants that covers the core of a realistic query language. We present an algorithm which simplies a representation of the invariant, along with a mechan- ically veried proof of correctness. We also investigate the underlying invariant checking problem in general and show that it is co-NP hard, i.e., that solutions must be approximations to remain tractable. We have seen more than an order of magnitude performance improvement using these techniques in a case study
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42949.html
found
=========================
SAC063: SSAC Advisory on DNSSEC Key Rollover in the Root Zone
ICANN Security and Stability Advisory Committee (SSAC) Reports and Advisories, ICANN (2013)
[u'Warren Kumari', u'Russ Mundy', u'Matt Larson', u'Jaap Akkerhuis']
SoftwareSystems
Abstract: There is consensus in the security and domain name system (DNS) communities that the root zone DNS Security Extensions (DNSSEC) system poses unique challenges for standard DNSSEC practices. While there is agreement that an eventual root zone Key-Signing Key (KSK) rollover is inevitable regardless of whether that rollover is caused by a key compromise or other factors, there is no solid consensus in the technical community regarding the frequency of routine, scheduled KSK rollovers. In this Advisory the SSAC addresses the following topics: * Terminology and definitions relating to DNSSEC key rollover in the root zone; * Key management in the root zone; * Motivations for root zone KSK rollover; * Risks associated with root zone KSK rollover; * Available mechanisms for root zone KSK rollover; * DNS response size considerations; * Quantifying the risk of failed trust anchor update; and * DNS response size considerations
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41882.html
found
=========================
Strato: A Retargetable Framework for Low-level Inlined Reference Monitors
Proceedings of the 22nd USENIX Conference on Security, USENIX Association, Berkeley, CA, USA (2013), pp. 369-382
[u'Bin Zeng', u'Gang Tan', u'lfar Erlingsson']
SoftwareSystems
Abstract: Low-level Inlined Reference Monitors (IRM) such as control-flow integrity and software-based fault isolation can foil numerous software attacks. Conventionally, those IRMs are implemented through binary rewriting or transformation on equivalent low-level programs that are tightly coupled with a specific Instruction Set Architecture (ISA). Resulting implementations have poor retargetability to different ISAs. This paper introduces an IRM-implementation framework at a compiler intermediate-representation (IR) level. The IR-level framework enables easy retargetability to different ISAs, but raises the challenge of how to preserve security at the low level, as the compiler backend might invalidate the assumptions at the IR level. We propose a constraint language to encode the assumptions and check whether they still hold after the backend transformations and optimizations. Furthermore, an independent verifier is implemented to validate the security of low-level code. We have implemented the framework inside LLVM to enforce the policy of control-flow integrity and data sandboxing for both reads and writes. Experimental results demonstrate that it incurs modest runtime overhead of 19.90% and 25.34% on SPECint2000 programs for 86- 32 and 86-64, respectively.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40736.html
found
=========================
Trustworthy Proxies: Virtualizing Objects with Invariants
ECOOP 2013
[u'Tom Van Cutsem', u'Mark S. Miller']
SoftwareSystems
Abstract: Proxies are a common technique to virtualize objects in object-oriented languages. A proxy is a placeholder object that emulates or wraps another target object. Both the proxy's representation and behavior may differ substantially from that of its target object. In many object-oriented languages, objects may have language-enforced invariants associated with them. For instance, an object may declare immutable fields, which are guaranteed to point to the same value throughout the execution of the program. Clients of an object can blindly rely on these invariants, as they are enforced by the language. In a language with both proxies and objects with invariants, these features interact. Can a proxy emulate or replace a target object purporting to uphold such invariants? If yes, does the client of the proxy need to trust the proxy to uphold these invariants, or are they still enforced by the language? This paper sheds light on these questions in the context of a Javascript-like language, and describes the design of a Proxy API that allows proxies to emulate objects with invariants, yet have these invariants continue to be language-enforced. This design forms the basis of proxies in ECMAScript 6.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Understanding Latency of Black-Box Service Workloads
WWW 2013 (to appear)
[u'Darja Krushevskaja']
SoftwareSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42551.html
found
=========================
Web-Scale Job Scheduling
Lecture Notes in Computer Science, vol. 7698 (2013)
[u'Walfredo Cirne', u'Eitan Frachtenberg']
SoftwareSystems
Abstract: Web datacenters and clusters can be larger than the worlds largest supercomputers, and run workloads that are at least as heteroge- neous and complex as their high-performance computing counterparts. And yet little is known about the unique job scheduling challenges of these environments. This article aims to ameliorate this situation. It dis- cusses the challenges of running web infrastructure and describes several techniques to address them. It also presents some of the problems that remain open in the field.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41187.html
found
=========================
Whare-Map: Heterogeneity in Homogeneous Warehouse-Scale Computers
Proceedings of the 2013 ACM/IEEE International Symposium on Computer Architecture (ISCA), IEEE (to appear)
[u'Jason Mars', u'Lingjia Tang', u'Robert Hundt']
SoftwareSystems
Abstract: Modern warehouse scale computers (WSCs) continue to be embraced as homogeneous computing platforms. However, due to frequent machine replacements and upgrades, modern WSCs are in fact composed of diverse commodity microarchitectures and machine congurations. Yet, current WSCs are architected with the assumption of homogeneity, leaving a potentially signicant performance opportunity unexplored. In this paper, we expose and quantify the performance impact of the homogeneity assumption for modern production WSCs using industry-strength large-scale web-service workloads. In addition, we argue for, and evaluate the benets of, a heterogeneity-aware WSC using commercial web-service production workloads including Googles websearch. We also identify key factors impacting the available performance opportunity when exploiting heterogeneity and introduce a new metric, opportunity factor, to quantify an applications sensitivity to the heterogeneity in a given WSC. To exploit heterogeneity in homogeneous WSCs, we propose Whare-Map, the WSC Heterogeneity Aware Mapper that leverages already in-place continuous proling subsystems found in production environments. When employing Whare-Map, we observe a cluster-wide performance improvement of 15% on average over heterogeneityoblivious job placement and up to an 80% improvement forweb-service applications that are particularly sensitive to heterogeneity
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43477.html
found
=========================
Why Don't Software Developers Use Static Analysis Tools to Find Bugs?
International Conference on Software Engineering (2013), pp. 672-681
[u'Brittany Johnson', u'Yoonki Song', u'Emerson Murphy-Hill', u'Robert Bowdidge']
SoftwareSystems
Abstract: Using static analysis tools for automating code inspections can be beneficial for software engineers. Such tools can make finding bugs, or software defects, faster and cheaper than manual inspections. Despite the benefits of using static analysis tools to find bugs, research suggests that these tools are underused. In this paper, we investigate why developers are not widely using static analysis tools and how current tools could potentially be improved. We conducted interviews with 20 developers and found that although all of our participants felt that use is beneficial, false positives and the way in which the warnings are presented, among other things, are barriers to use. We discuss several implications of these results, such as the need for an interactive mechanism to help developers fix defects.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Why you should care about quantile regression
Architectural Support for Programming Languages and Operating Systems, ASPLOS '13, ACM (2013), pp. 207-218
[u'Augusto Born De Oliveira', u'Sebastian Fischmeister', u'Amer Diwan', u'Matthias Hauswirth', u'Peter Sweeney']
SoftwareSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41316.html
found
=========================
packetdrill: Scriptable Network Stack Testing, from Sockets to Packets
Proceedings of the USENIX Annual Technical Conference (USENIX ATC 2013), USENIX, 2560 Ninth Street, Suite 215, Berkeley, CA, 94710 USA, pp. 213-218
[u'Neal Cardwell', u'Yuchung Cheng', u'Lawrence Brakmo', u'Matt Mathis', u'Barath Raghavan', u'Nandita Dukkipati', u'Hsiao-keng Jerry Chu', u'Andreas Terzis', u'Tom Herbert']
SoftwareSystems
Abstract: Testing todays increasingly complex network protocol implementations can be a painstaking process. To help meet this challenge, we developed packetdrill, a portable, open-source scripting tool that enables testing the correctness and performance of entire TCP/UDP/IP network stack implementations, from the system call layer to the hardware network interface, for both IPv4 and IPv6. We describe the design and implementation of the tool, and our experiences using it to execute 657 test cases. The tool was instrumental in our development of three new features for Linux TCPEarly Retransmit, Fast Open, and Loss Probesand allowed us to find and fix 10 bugs in Linux. Our team uses packetdrill in all phases of the development process for the kernel used in one of the worlds largest Linux installations.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37752.html
found
=========================
AddressSanitizer: A Fast Address Sanity Checker
USENIX ATC 2012
[u'Konstantin Serebryany', u'Derek Bruening', u'Alexander Potapenko', u'Dmitry Vyukov']
SoftwareSystems
Abstract: Memory access bugs, including buffer overows and uses of freed heap memory, remain a serious problem for programming languages like C and C++. Many memory error detectors exist, but most of them are either slow or detect a limited set of bugs, or both. This paper presents AddressSanitizer, a new memory error detector. Our tool finds out-of-bounds accesses to heap, stack, and global objects, as well as use-after-free bugs. It employs a specialized memory allocator and code instrumentation that is simple enough to be implemented in any compiler, binary translation system, or even in hardware. AddressSanitizer achieves efficiency without sacricing comprehensiveness. Its average slowdown is just 73% yet it accurately detects bugs at the point of occurrence. It has found over 300 previously unknown bugs in the Chromium browser and many bugs in other software.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38275.html
found
=========================
Building Useful Program Analysis Tools Using an Extensible Java Compiler
International Working Conference on Source Code Analysis and Manipulation (SCAM), IEEE (2012), pp. 14-23
[u'Edward Aftandilian', u'Raluca Sauciuc', u'Siddharth Priya', u'Sundaresan Krishnan']
SoftwareSystems
Abstract: Large software companies need customized tools to manage their source code. These tools are often built in an ad-hoc fashion, using brittle technologies such as regular expressions and home-grown parsers. Changes in the language cause the tools to break. More importantly, these ad-hoc tools often do not support uncommon-but-valid code code patterns. We report our experiences building source-code analysis tools at Google on top of a third-party, open-source, extensible compiler. We describe three tools in use on our Java codebase. The first, Strict Java Dependencies, enforces our dependency policy in order to reduce JAR file sizes and testing load. The second, error-prone, adds new error checks to the compilation process and automates repair of those errors at a whole-codebase scale. The third, Thindex, reduces the indexing burden for a Java IDE so that it can support Google-sized projects.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38290.html
notfound
=========================
CDE: A Tool For Creating Portable Experimental Software Packages
Computing in Science & Engineering, vol. 14 (2012), pp. 32-35
[u'Philip Guo']
SoftwareSystems
Abstract: One technical barrier to reproducible computational science is that it's hard to distribute scientific code in a form that other researchers can easily execute on their own computers. To help eliminate this barrier, the CDE tool packages all software dependencies required to rerun Linux-based computational experiments on other computers.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42552.html
found
=========================
Characterization and Comparison of Cloud versus Grid Workloads
IEEE Cluster 2012
[u'Sheng Di', u'Derrick Kondo', u'Walfredo Cirne']
SoftwareSystems
Abstract: A new era of Cloud Computing has emerged, but the characteristics of Cloud load in data centers is not perfectly clear. Yet this characterization is critical for the design of novel Cloud job and resource management systems. In this paper, we comprehensively characterize the job/task load and host load in a real-world production data center at Google Inc. We use a detailed trace of over 25 million tasks across over 12,500 hosts. We study the differences between a Google data center and other Grid/HPC systems, from the perspective of both work load (w.r.t. jobs and tasks) and host load (w.r.t. machines). In particular, we study the job length, job submission frequency, and the resource utilization of jobs in the different systems, and also investigate valuable statistics of machines maximum load, queue state and relative usage levels, with different job priorities and resource attributes. We find that the Google data center exhibits finer resource allocation with respect to CPU and memory than that of Grid/HPC systems. Google jobs are always submitted with much higher frequency and they are much shorter than Grid jobs. As such, Google host load exhibits higher variance and noise.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40592.html
found
=========================
Comparing In-Browser Methods of Measuring Resource Load Times
W3C Workshop on Web Performance 8, W3C, W3C/MIT 32 Vassar Street Room 32-G515 Cambridge, MA 02139 USA (2012)
[u'Eric Gavaletz', u'Dominic Hamon', u'Jasleen Kaur']
SoftwareSystems
Abstract: When looking for an excellent platform for conducting end-to-end network performance measurement that is large-scale and representative, researchers should look no further than the browser -- after all, browsers are installed everywhere and are used multiple times per day by most Internet users. In this work, we investigate the use of the DOM, XHR and Navigation Timing API for measuring HTTP response times within browsers, with the goal of estimating path latency and throughput. The response times are measured using a set of popular browsers in a controlled environmentthis helps us isolate the differences between the browsers as well as study how closely the measurements match the ground truth. We show that, in general, the XHR method yields the most consistent measurements across browsers, but that the new Navigation Timing and the proposed Resource Timing APIs could change that. We also use the measurements from our controlled environment to study the impact of each of our investigated measurement methods on a hypothetical measurement study.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Dart: Up and Running
O'Reilly Media, 1005 Gravenstein Highway North Sebastopol, CA 95472 USA (2012)
[u'Kathleen Walrath', u'Seth Ladd']
SoftwareSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40355.html
found
=========================
Google's C/C++ toolchain for smart handheld devices
VLSI Design, Automation, and Test (VLSI-DAT), 2012 International Symposium on, IEEE
[u'Doug Kwan', u'Jing Yu', u'Bhaskar Janakiraman']
SoftwareSystems
Abstract: Smart handheld devices are ubiquitous today and software plays an important role on them. Therefore a compiler and related tools can improve devices by generating efficient, compact and secure code. In this paper, we share our experience of applying various compilation techniques at Google to improve software running on smart handheld devices, using our mobile platforms as examples. At Google we use the GNU toolchain for generating code on different platforms and for conducting compiler research and development. We have developed new techniques, added features and functionality in the GNU tools. Some of these results are now used for smart handheld devices.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42553.html
found
=========================
Hostload prediction in a Google compute cloud with a Bayesian model
Supercomputing 2012
[u'Sheng Di', u'Derrick Kondo', u'Walfredo Cirne']
SoftwareSystems
Abstract: Prediction of host load in Cloud systems is crit- ical for achieving service-level agreements. However, accurate prediction of host load in Clouds is extremely challenging because it fluctuates drastically at small timescales. We design a prediction method based on Bayes model to predict the mean load over a long-term time interval, as well as the mean load in consecutive future time intervals. We identify novel predictive features of host load that capture the expectation, predictabil- ity, trends and patterns of host load. We also determine the most effective combinations of these features for prediction. We evaluate our method using a detailed one-month trace of a Google data center with thousands of machines. Experiments show that the Bayes method achieves high accuracy with a mean squared error of 0.0014. Moreover, the Bayes method improves the load prediction accuracy by 5.6-50% compared to other state-of-the-art methods based on moving averages, auto-regression, and/or noise filters.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Implementing language-based virtual machines
Proceedings of the 11th annual international conference on Aspect-oriented Software Development Companion, ACM, New York, NY, USA (2012), pp. 7-8
[u'Lars Bak']
SoftwareSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
JANUS: exploiting parallelism via hindsight
Proceedings of the 33rd ACM SIGPLAN conference on Programming Language Design and Implementation, ACM, New York, NY, USA (2012), pp. 145-156
[u'Omer Tripp', u'Roman Manevich', u'John Field', u'Mooly Sagiv']
SoftwareSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40390.html
found
=========================
LIL: CLOS reaches higher-order, sheds identity, and has a transformative experience
Proceedings of the International Lisp Conference 2012 (to appear)
[u'Franois-Ren Rideau']
SoftwareSystems
Abstract: LIL, the Lisp Interface Library, is a data structure library based on Interface-Passing Style. This programming style was designed to allow for parametric polymorphism (abstracting over types, classes, functions, data) as well as ad-hoc polymorphism (incremental development with inheritance and mixins). It consists in isolating algorithmic information into first-class interfaces, explicitly passed around as arguments dispatched upon by generic functions. As compared to traditional objects, these interfaces typically lack identity and state, while they manipulate data structures without intrinsic behavior. This style makes it just as easy to use pure functional persistent data structures without identity or state as to use stateful imperative ephemeral data structures. Judicious Lisp macros allow developers to avoid boilerplate and to abstract away interface objects to expose classic-looking Lisp APIs. Using on a very simple linear type system to model the side-effects of methods, it is even possible to transform pure interfaces into stateful interfaces or the other way around, or to transform a stateful interface into a traditional object-oriented API.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37626.html
notfound
=========================
LaDeDa: Languages for Debuggable Distributed Algorithms
Lada 2012: Workshop on Languages for Distributed Algorithms (to appear)
[u'Mark S. Miller', u'Tom Van Cutsem']
SoftwareSystems
Abstract: When programming language designs are presented, the examples are almost exclusively of correct programs. Most attention of programming language designers is indeed on the beauty and elegance of correct programs. For incorrect programs, great design attention is paid to catching errors early---such as fancy static type systems---so that many incorrect programs are never run. Due to the success of these efforts, many programs are either correct or inadmissible, conserving on the need for programmer attention. As a result, most of the attention working programmers spend looking at code is spent debugging incorrect running code. Often this is code written by others and only partially understood. What properties should such code have? How can programming language design encourage incorrect programs to have those properties that facilitate debugging? Distributed programs introduce additional difficult bugs of a different character. How should distributed language design facilitate the debugging of distributed programs? We explain how these considerations have affected four distributed language designs (E, AmbientTalk, Joe-E/Waterken, Dr. SES) and one distributed debugging tool (Causeway).
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub39968.html
found
=========================
Lockdown: Towards a Safe and Practical Architecture for Security Applications on Commodity Platforms
TRUST 2012, Lecture Notes in Computer Science, pp. 21
[u'Amit Vasudevan', u'Bryan Parno', u'Ning Qu', u'Virgil D. Gligor', u'Adrian Perrig']
SoftwareSystems
Abstract: We investigate a new point in the design space of red/green systems [19,30], which provide the user with a highly-protected, yet also highly-constrained trusted (green) environment for performing security-sensitive transactions, as well as a high-performance, general-purpose environment for all other (non-security-sensitive or red) applications. Through the design and implementation of the Lockdown architecture, we evaluate whether partitioning, rather than virtualizing, resources and devices can lead to better security or performance for red/green systems. We also design a simple external interface to allow the user to securely learn which environment is active and easily switch between them. We find that partitioning offers a new tradeoff between security, performance, and usability. On the one hand, partitioning can improve the security of the green environment and the performance of the red environment (as compared with a virtualized solution). On the other hand, with current systems, partitioning makes switching between environments quite slow (13-31 seconds), which may prove intolerable to users.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40595.html
notfound
=========================
Magda: A New Language for Modularity
Lecture Notes in Computer Science, Springer (2012), pp. 560-588
[u'Jarek Kusmierek', u'Viviana Bono', u'Mauro Mulatero']
SoftwareSystems
Abstract: We introduce Magda, a modularity-oriented programming language. The language features lightweight mixins as units of code reuse, modular initial- ization protocols, and a hygienic approach to identiers. In particular, Magda's modularity guarantees that client code of a library written in Magda will never break as a consequence of any addition of members to the library's mixins.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Measuring Interference Between Live Datacenter Applications
Supercomputing, ACM (2012)
[u'Melanie Kambadur', u'Tipp Moseley', u'Rick Hank', u'Martha A. Kim']
SoftwareSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41686.html
found
=========================
Obfuscatory obscanturism: making workload traces of commercially-sensitive systems safe to release
CloudMAN, IEEE, Maui, HI, USA (2012)
[u'Charles Reiss', u'John Wilkes', u'Joseph L. Hellerstein']
SoftwareSystems
Abstract: Cloud providers such as Google are interested in fostering research on the daunting technical challenges they face in supporting planetary-scale distributed systems, but no academic organizations have similar scale systems on which to experiment. Fortunately, good research can still be done using traces of real-life production workloads, but there are risks in releasing such data, including inadvertently disclosing condential or proprietary information, as happened with the Netix Prize data. This paper discusses these risks, and our approach to them, which we call {\em systematic obfuscation}. It protects proprietary and personal data while leaving it possible to answer some interesting research questions. We explain and motivate some of the risks and concerns and propose how they can best be mitigated, using as an example our recent publication of a month-long trace of a production system workload on a 11k-machine cluster.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40357.html
notfound
=========================
On inter-deriving small-step and big-step semantics: A case study for storeless call-by-need evaluation
Theoretical Computer Science, vol. 435 (2012), pp. 21-42
[u'Olivier Danvy', u'Kevin Millikin', u'Johan Munk', u'Ian Zerny']
SoftwareSystems
Abstract: Starting from the standard call-by-need reduction for the -calculus that is common to Ariola, Felleisen, Maraist, Odersky, and Wadler, we inter-derive a series of hygienic semantic artifacts: a reduction-free storeless abstract machine, a continuation-passing evaluation function, and what appears to be the first heapless natural semantics for call-by-need evaluation. Furthermore we observe that the evaluation function implementing this natural semantics is in defunctionalized form. The refunctionalized counterpart of this evaluation function implements an extended direct semantics in the sense of Cartwright and Felleisen. Overall, the semantic artifacts presented here are simpler than many other such artifacts that have been independently worked out, and which require ingenuity, skill, and independent soundness proofs on a case-by-case basis. They are also simpler to inter-derive because the inter-derivational tools (e.g., refocusing and defunctionalization) already exist.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37741.html
notfound
=========================
On the design of the ECMAScript Reflection API
TOPLAS (Transactions on Programming Languages and Systems) (2012)
[u'Tom Van Cutsem', u'Mark S. Miller']
SoftwareSystems
Abstract: We describe in detail the new reflection API of the upcoming Javascript standard. The most prominent feature of this new API is its support for creating proxies: virtual objects that behave as regular objects, but whose entire meta-object protocol is implemented in Javascript itself. Next to a detailed description of the API, we describe a more general set of design principles that helped steer the APIs design, and which should be applicable to similar APIs for other languages. We also describe access control abstractions implemented in the new API, and provide an operational semantics of an extension of the untyped lambda-calculus featuring proxies.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Proceedings of the ACM 4th annual workshop on Evaluation and usability of programming languages and tools (PLATEAU)
Conference on Systems, Programming, and Applications: Software for Humanity (SPLASH) (2012)
[u'Emerson Murphy-Hill', u'Caitlin Sadowski', u'Shane Markstrum']
SoftwareSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Programming Perl
O'Reilly, 1005 Gravenstein Highway North Sebastopol, CA 95472 (2012)
[u'Tom Christiansen', u'brian d foy', u'Larry Wall', u'Jon Orwant']
SoftwareSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37733.html
found
=========================
Robust Trait Composition for JavaScript
Science of Computer Programming: Special Issue on Advances in Dynamic Languages (2012)
[u'Tom Van Cutsem', u'Mark S. Miller']
SoftwareSystems
Abstract: We introduce traits.js, a small, portable trait composition library for Javascript. Traits are a more robust alternative to multiple inheritance and enable object composition and reuse. traits.js is motivated by two goals: first, it is an experiment in using and extending Javascript's recently added meta-level object description format. By reusing this standard description format, traits.js can be made more interoperable with similar libraries, and even with built-in primitives. Second, traits.js makes it convenient to create "high-integrity" objects whose integrity cannot be violated by clients, an important property in the context of mash-ups composed from mutually suspicious scripts. We describe the design of traits.js and provide an operational semantics for TRAITS-JS, a minimal calculus that models the core functionality of the library.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38226.html
found
=========================
Runtime adaptation: a case for reactive code alignment
Proceedings of the 2nd International Workshop on Adaptive Self-Tuning Computing Systems for the Exaflop Era, ACM, New York, NY, USA (2012), pp. 1-11
[u'Michelle McDaniel', u'Kim Hazelwood']
SoftwareSystems
Abstract: Static alignment techniques are well studied and have been incorporated into compilers in order to optimize code locality for the instruction fetch unit in modern processors. However, current static alignment techniques have several limitations that cannot be overcome. In the exascale era, it becomes even more important to break from static techniques and develop adaptive algorithms in order to maximize the utilization of every processor cycle. In this paper, we explore those limitations and show that reactive realignment, a method where we dynamically monitor running applications, react to symptoms of poor alignment, and adapt alignment to the current execution environment and program input, is more scalable than static alignment. We present fetches-per-instruction as a runtime indicator of poor alignment. Additionally, we discuss three main opportunities that static alignment techniques cannot leverage, but which are increasingly important in large scale computing systems: microarchitectural differences of cores, dynamic program inputs that exercise different and sometimes alternating code paths, and dynamic branch behavior, including indirect branch behavior and phase changes. Finally, we will present several instances where our trigger for reactive realignment may be incorporated in practice, and discuss the limitations of dynamic alignment.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Simbeeotic: a simulation-emulation platform for large scale micro-aerial swarms
Proceedings of the 11th international conference on Information Processing in Sensor Networks, ACM, New York, NY, USA (2012), pp. 139-140
[u'Jason Waterman', u'Bryan Kate', u'Karthik Dantu', u'Matt Welsh']
SoftwareSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Simbeeotic: a simulator and testbed for micro-aerial vehicle swarm experiments
Proceedings of the 11th international conference on Information Processing in Sensor Networks, ACM, New York, NY, USA (2012), pp. 49-60
[u'Bryan Kate', u'Jason Waterman', u'Karthik Dantu', u'Matt Welsh']
SoftwareSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Transparent dynamic instrumentation
Proceedings of the 8th ACM SIGPLAN/SIGOPS conference on Virtual Execution Environments, ACM, New York, NY, USA (2012), pp. 133-144
[u'Derek Bruening', u'Qin Zhao', u'Saman Amarasinghe']
SoftwareSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
An Equivalence-Preserving CPS Translation via Multi-Language Semantics
Proceedings of the 16th ACM SIGPLAN International Conference on Functional Programming (ICFP 2011) (to appear)
[u'Amal Ahmed', u'Matthias Blume']
SoftwareSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Automated locality optimization based on the reuse distance of string operations
CGO '11 Proceedings of the 9th Annual IEEE/ACM International Symposium on Code Generation and Optimization, IEEE Computer Society, Washington, DC, USA (2011), pp. 181-190
[u'Silvius Rus', u'Raksit Ashok', u'Xinliang David Li']
SoftwareSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41836.html
notfound
=========================
Capirca
Blackhat USA (2011) (to appear)
[u'Paul (Tony) Watson']
SoftwareSystems
Abstract: Capirca is an open-sourced cross-platform network security policy compiler developed at Google. It allows the creation and deployment of ACL filters across multiple target platforms based on a single security policy and shared network and service definitions. The software is ideal for both small and large organizations to eliminate common errors while greatly simplifying security policy maintenance.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
CloudScale: elastic resource scaling for multi-tenant cloud systems
Symposium on Cloud Computing (SoCC), ACM, Cascais, Portugal (2011)
[u'Zhiming Shen', u'Sethuraman Subbiah', u'Xiaohui Gu', u'John Wilkes']
SoftwareSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37352.html
notfound
=========================
Custom AST transformations with Project Lombok
IBM developerWorks (2011)
[u'Alex Ruiz']
SoftwareSystems
Abstract: Alex Ruiz introduces Project Lombok in this article, discussing some of the programming sugar that makes it unique, including annotation-driven code generation and clean, compact, and readable code. He then draws your attention to one of the more rewarding uses of Lombok: extending it with custom AST (Abstract Syntax Tree) transformations. Extending Lombok will enable you to generate your own project- or domain-specific boilerplate code, but it does require a fair amount of work. Alex concludes with his tips for easing through key stages of the process, along with a freely usable custom extension for JavaBeans.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36727.html
notfound
=========================
Cython: The Best of Both Worlds
Computing in Science and Engineering, vol. 13.2 (2011), pp. 31-39
[u'Stefan Behnel', u'Robert Bradshaw', u'Craig Citro', u'Lisandro Dalcin', u'Dag Sverre Seljebotn', u'Kurt Smith']
SoftwareSystems
Abstract: Cython is an extension to the Python language that allows explicit type declarations and is compiled directly to C. This addresses Python's large overhead for numerical loops and the difficulty of efficiently making use of existing C and Fortran code, which Cython code can interact with natively. The Cython language combines the speed of C with the power and simplicity of the Python language.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37061.html
notfound
=========================
Experiences Scaling Use of Google's Sawzall
DIMACS Workshop on Parallelism: A 2020 Vision, http://dimacs.rutgers.edu/Workshops/Parallel/ (2011)
[u'Jeffrey D. Oldham']
SoftwareSystems
Abstract: Sawzall is a procedural language developed at Google for parallel analysis of very large data sets. Given a log sharded into many separate files, its companion tool named saw runs Sawzall interpreters to perform an analysis. Hundreds of Googlers have written thousands of saw+Sawzall programs, which form a significant minority of Google's daily data processing. Short programs grew to become longer programs, which were not easily shared nor tested. In other words, scaling naively written Sawzall led to unmaintainable programs. The simple idea of writing programs functionally, not iteratively, yielded shareable, testable programs. The functions reflect fundamental map reduction concepts: mapping, reducing, and iterating. Each can be easily tested. This case study demonstrates that developers of parallel processing systems should also simultaneously develop ways for users to decompose code into sharable pieces that reflect fundamental underlying concepts. As importantly, they must develop ways for users to easily write tests of their code.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Fay: Extensible Distributed Tracing from Kernels to Clusters
Proceedings of the 23rd ACM Symposium on Operating Systems Principles (SOSP'11), ACM, New York, NY, USA (2011)
[u'lfar Erlingsson', u'Marcus Peinado', u'Simon Peter', u'Mihai Budiu']
SoftwareSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Language-Independent Sandboxing of Just-In-Time Compilation and Self-Modifying Code
ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI), ACM SIGPLAN, New York, NY, USA. (2011)
[u'Jason Ansel', u'Petr Marchenko', u'lfar Erlingsson', u'Elijah Taylor', u'Brad Chen', u'Derek Schuff', u'David Sehr', u'Cliff L. Biffle', u'Bennet S. Yee']
SoftwareSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37512.html
notfound
=========================
Logical Attestation: An Authorization Architecture for Trustworthy Computing
Proceedings of the 23rd ACM Symposium on Operating System Principles, ACM, New York, NY, USA (2011)
[u'Emin Gn Sirer', u'Willem de Bruijn', u'Patrick Reynolds', u'Alan Shieh', u'Kevin Walsh', u'Dan Williams', u'Fred B. Schneider']
SoftwareSystems
Abstract: This paper describes the design and implementation of a new operating system authorization architecture to support trustworthy computing. Called logical attestation, this architecture provides a sound framework for reasoning about run time behavior of applications. Logical attestation is based on attributable, unforgeable statements about program properties, expressed in a logic. These statements are suitable for mechanical processing, proof construction, and verification; they can serve as credentials, support authorization based on expressive authorization policies, and enable remote principals to trust software components without restricting the local users choice of binary implementations. We have implemented logical attestation in a new operating system called the Nexus. The Nexus executes natively on x86 platforms equipped with secure coprocessors. It supports both native Linux applications and uses logical attestation to support new trustworthy-computing applications. When deployed on a trustworthy cloud-computing stack, logical attestation is efficient, achieves high-performance, and can run applications that provide qualitative guarantees not possible with existing modes of attestation.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37122.html
notfound
=========================
Loop Recognition in C++/Java/Go/Scala
Proceedings of Scala Days 2011
[u'Robert Hundt']
SoftwareSystems
Abstract: In this experience report we encode a well specied, compact benchmark in four programming languages, namely C++, Java, Go, and Scala. The implementations each use the languages idiomatic container classes, looping constructs, and memory/object allocation schemes. It does not attempt to exploit specic language and runtime features to achieve maximum performance. This approach allows an almost fair comparison of language features, code complexity, compilers and compile time, binary sizes, runtimes, and memory footprint. While the benchmark itself is simple and compact, it employs many language features, in particular, higher-level data structures (lists, maps, lists and arrays of sets and lists), a few algorithms (union/nd, dfs / deep recursion, and loop recognition based on Tarjan), iterations over collection types, some object oriented features, and interesting memory allocation patterns. We do not explore any aspects of multi-threading, or higher level type mechanisms, which vary greatly between the languages. The benchmark points to very large differences in all examined dimensions of the language implementations. After publication of the benchmark internally at Google, several engineers produced highly optimized versions of the benchmark. While this whole effort is an anectodal comparison only, the benchmark and subsequent tuning effort might be indicatie of typical performance pain points in the respective languages.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37077.html
notfound
=========================
MAO - an Extensible Micro-Architectural Optimizer
Proceedings of the 8th annual IEEE/ACM international symposium on Code generation and optimization, ACM (2011)
[u'Robert Hundt', u'Easwaran Raman', u'Martin Thuresson', u'Neil Vachharajani']
SoftwareSystems
Abstract: Performance matters, and so does repeatability and predictability. Today's processors' micro-architectures have become so complex as to now contain many undocumented, not understood, and even puzzling performance cliffs. Small changes in the instruction stream, such as the insertion of a single NOP instruction, can lead to significant performance deltas, with the effect of exposing compiler and performance optimization efforts to perceived unwanted randomness. This paper presents MAO, an extensible micro-architectural assembly to assembly optimizer, which seeks to address this problem for x86/64 processors. In essence, MAO is a thin wrapper around a common open source assembler infrastructure. It offers basic operations, such as creation or modification of instructions, simple data-flow analysis, and advanced infra-structure, such as loop recognition, and a repeated relaxation algorithm to compute instruction addresses and lengths. This infrastructure enables a plethora of passes for pattern matching, alignment specific optimizations, peep-holes, experiments (such as random insertion of NOPs), and fast prototyping of more sophisticated optimizations. MAO can be integrated into any compiler that emits assembly code, or can be used standalone. MAO can be used to discover micro-architectural details semi-automatically. Initial performance results are encouraging.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43983.html
found
=========================
Non-Parametric Parametricity
Journal of Funcitonal Programming, vol. 21 (4 & 5) (2011)
[u'Georg Neis', u'Derek Dreyer', u'Andreas Rossberg']
SoftwareSystems
Abstract: Type abstraction and intensional type analysis are features seemingly at oddstype abstraction is intended to guarantee parametricity and representation independence, while type analysis is inherently non-parametric. Recently, however, several researchers have proposed and implemented dynamic type generation as a way to reconcile these features. The idea is that, when one defines an abstract type, one should also be able to generate at run time a fresh type name, which may be used as a dynamic representative of the abstract type for purposes of type analysis. The question remains: in a language with non-parametric polymorphism, does dynamic type generation provide us with the same kinds of abstraction guarantees that we get from parametric polymorphism? Our goal is to provide a rigorous answer to this question. We define a step-indexed Kripke logical relation for a language with both non-parametric polymorphism (in the form of type-safe cast) and dynamic type generation. Our logical relation enables us to establish parametricity and representation independence results, even in a non-parametric setting, by attaching arbitrary relational interpretations to dynamically-generated type names. In addition, we explore how programs that are provably equivalent in a more traditional parametric logical relation may be wrapped systematically to produce terms that are related by our non-parametric relation, and vice versa. This leads us to develop a polarized variant of our logical relation, which enables us to distinguish formally between positive and negative notions of parametricity.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42554.html
found
=========================
Perspectives on cloud computing: interviews with five leading scientists from the cloud community
Journal of Internet Services and Applications (2011)
[u'Gordon Blair', u'Fabio Kon', u'Walfredo Cirne', u'Dejan Milojicic', u'Raghu Ramakrishnan', u'Dan Reed', u'Dilma Silva']
SoftwareSystems
Abstract: Cloud computing is currently one of the major topics in dis- tributed systems, with large numbers of papers being writ- ten on the topic, with major players in the industry releasing a range of software platforms offering novel Internet-based services and, most importantly, evidence of real impact on end user communities in terms of approaches to provision- ing software services. Cloud computing though is at a for- mative stage, with a lot of hype surrounding the area, and this makes it difficult to see the true contribution and impact of the topic. Cloud computing is a central topic for the Journal of In- ternet Services and Applications (JISA) and indeed the most downloaded paper from the first year of JISA is concerned with the state-of-the-art and research challenges related to cloud computing [1]. The Editors-in-Chief, Fabio Kon and Gordon Blair, therefore felt it was timely to seek clarifica- tion on the key issues around cloud computing and hence invited five leading scientists from industrial organizations central to cloud computing to answer a series of questions on the topic. The five scientists taking part are: Walfredo Cirne, from Googles infrastructure group in California, USA Dejan Milojicic, Senior Researcher and Director of the Open Cirrus Cloud Computing testbed at HP Labs Raghu Ramakrishnan, Chief Scientist for Search and Cloud Platforms at Yahoo! Dan Reed, Microsofts Corporate Vice President for Tech- nology Strategy and Policy and Extreme Computing Dilma Silva, researcher at the IBM T.J. Watson Research Center, in New York
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36605.html
notfound
=========================
Scala In Depth
Manning Publications Co., Sound View Ct. #3B Greenwich, CT 06830 (2011), pp. 250
[u'Josh Suereth']
SoftwareSystems
Abstract: Scala is a unique and powerful new programming language for the JVM. Blending the strengths of the Functional and Imperative programming models, Scala is a great tool for building highly concurrent applications without sacrificing the benefits of an OO approach. While information about the Scala language is abundant, skilled practitioners, great examples, and insight into the best practices of the community are harder to find. Scala in Depth bridges that gap, preparing you to adopt Scala successfully for real world projects. Scala in Depth is a unique new book designed to help you integrate Scala effectively into your development process. By presenting the emerging best practices and designs from the Scala community, it guides you though dozens of powerful techniques example by example. There's no heavy-handed theory here-just lots of crisp, practical guides for coding in Scala. For example: * Discover the "sweet spots" where object-oriented and functional programming intersect. * Master advanced OO features of Scala, including type member inheritance, multiple inheritance and composition. * Employ functional programming concepts like tail recursion, immutability, and monadic operations. * Learn good Scala style to keep your code concise, expressive and readable. As you dig into the book, you'll start to appreciate what makes Scala really shine. For instance, the Scala type system is very, very powerful; this book provides use case approaches to manipulating the type system and covers how to use type constraints to enforce design constraints. Java developers love Scala's deep integration with Java and the JVM Ecosystem, and this book shows you how to leverage it effectively and work around the rough spots.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37485.html
notfound
=========================
traits.js: Robust Object Composition and High-integrity Objects for ECMAScript 5
Plastic 2011: International Workshop on Programming Language And Systems Technologies for Internet Clients, ACM
[u'Tom Van Cutsem', u'Mark S. Miller']
SoftwareSystems
Abstract: This paper introduces traits.js, a small, portable trait composition library for Javascript. Traits are a more robust alternative to multiple inheritance and enable object composition and reuse. traits.js is motivated by two goals: rst, it is an experiment in using and extending Javascripts recently added meta-level object description format. By reusing this standard description format, traits.js can be made more interoperable with similar libraries, and even with built-in primitives. Second, traits.js makes it convenient to create high-integrity objects whose integrity cannot be violated by clients, an important property in the context of interaction between mutually suspicious scripts
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35649.html
notfound
=========================
Adapting Software Fault Isolation to Contemporary CPU Architectures
19th USENIX Security Symposium, USENIX (2010), pp. 1-11
[u'David Sehr', u'Robert Muth', u'Cliff L. Biffle', u'Victor Khimenko', u'Egor Pasko', u'Bennet Yee', u'Karl Schimpf', u'Brad Chen']
SoftwareSystems
Abstract: Software Fault Isolation (SFI) is an effective approach to sandboxing binary code of questionable provenance, an interesting use case for native plugins in a Web browser. We present software fault isolation schemes for ARM and x86-64 that provide control-flow and memory integrity with average performance overhead of under 5% on ARM and 7% on x86-64. We believe these are the best known SFI implementations for these architectures, with significantly lower overhead than previous systems for similar architectures. Our experience suggests that these SFI implementations benefit from instruction-level parallelism, and have particularly small impact for workloads that are data memory-bound, both properties that tend to reduce the impact of our SFI systems for future CPU implementations.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37264.html
notfound
=========================
C# in Depth
Manning, 20 Baldwin Road PO Box 261 Shelter Island, NY 11964 (2010), pp. 584
[u'Jon Skeet']
SoftwareSystems
Abstract: C# has changed significantly since it was first introduced. With the many upgraded features, C# is more expressive than ever. However, an in depth understanding is required to get the most out of the language. C# in Depth, Second Edition is a thoroughly revised, up-to-date book that covers the new features of C# 4 as well as Code Contracts. In it, youll see the subtleties of C# programming in action, learning how to work with high-value features that youll be glad to have in your toolkit. The book helps readers avoid hidden pitfalls of C# programming by understanding "behind the scenes" issues.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36669.html
notfound
=========================
CPU bandwidth control for CFS
Proceedings of the Linux Symposium, Linux Symposium (2010), pp. 245-254
[u'Paul Turner', u'Bharata B Rao', u'Nikhil Rao']
SoftwareSystems
Abstract: Over the past few years there has been an increasing focus on the development of features which deliver resource management within the Linux kernel. The addition of the fair group scheduler has enabled the provisioning of proportional CPU time through the specification of group weights. As the scheduler is inherently work-conserving in nature, a task or a group may consume excess CPU share in an otherwise idle system. There are many scenarios where this unbounded CPU share may lead to unacceptable utilization or latency variation. CPU bandwidth control approaches this problem by allowing an explicit upper bound for allowable CPU bandwidth to be defined in addition to the lower bound already provided by shares. There are many enterprise scenarios where this functionality is useful. In particular are the cases of pay-per-use environments, and user facing services where provisioning is latency bounded. In this paper we detail the motivations behind this feature, the challenges involved in incorporating into CFS (Completely Fair Scheduler), and the future development road map.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36736.html
notfound
=========================
Capsicum: practical capabilities for UNIX
Proceedings of the 19th USENIX Security Symposium (2010)
[u'Robert N. M. Watson', u'Jonathan Anderson', u'Ben Laurie', u'Kris Kennaway']
SoftwareSystems
Abstract: Capsicum is a lightweight operating system capabil- ity and sandbox framework planned for inclusion in FreeBSD 9. Capsicum extends, rather than replaces, UNIX APIs, providing new kernel primitives (sandboxed capability mode and capabilities) and a userspace sand- box API. These tools support compartmentalisation of monolithic UNIX applications into logical applications, an increasingly common goal supported poorly by dis- cretionary and mandatory access control. We demon- strate our approach by adapting core FreeBSD utilities and Googles Chromium web browser to use Capsicum primitives, and compare the complexity and robustness of Capsicum with other sandboxing techniques.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Contention Aware Execution: Online Contention Detection and Response
Proceedings of International Symposium on Code Generation and Optimization (CGO), IEEE (2010)
[u'Jason Mars', u'Neil Vachharajani', u'Robert Hundt', u'Mary Lou Souffa']
SoftwareSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Defunctionalized Interpreters for Call-by-Need Evaluation
Functional and Logic Programming, 10th International Symposium, FLOPS 2010, Springer, pp. 240-256
[u'Olivier Danvy', u'Kevin Millikin', u'Johan Munk', u'Ian Zerny']
SoftwareSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40670.html
notfound
=========================
Effective Perl Programming, 2nd Edition
Addison-Wesley Professional (2010), pp. 445
[u'Joshua McAdams', u'brian d foy', u'Joseph Hall']
SoftwareSystems
Abstract: The Classic Guide to Solving Real-World Problems with Perl - Now Fully Updated for Today;s Best Idioms! For years, experienced programmers have relied on Effective Perl Programming to discover better ways to solve problems with Perl. Now, in this long-awaited second edition, three renowned Perl programmers bring together today's best idioms, techniques, and examples: everything you need to write more powerful, fluent, expressive, and succinct code with Perl. Nearly twice the size of the first edition, Effective Perl Programming, Second Edition, offers everything from rules of thumb to avoid common pitfalls to the latest wisdom for using Perl modules. You won't just learn the right ways to use Perl: You'll learn why these approaches work so well. New coverage in this edition includes - Reorganized and expanded material spanning twelve years of Perl evolution - Eight new chapters on CPAN, databases, distributions, files and filehandles, production Perl, testing, Unicode, and warnings - Updates for Perl 5.12, the latest version of Perl Systematically updated examples reflecting today's best idioms You'll learn how to work with strings, numbers, lists, arrays, strictures, namespaces, regular expressions, subroutines, references, distributions, inline code, warnings, Perl::Tidy, data munging, Perl one-liners, and a whole lot more. Every technique is organized in the same Items format that helped make the first edition so convenient and popular.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40391.html
found
=========================
Evolving ASDF: More Cooperation, Less Coordination
Proceedings of the International Lisp Conference 2010
[u'Franois-Ren Rideau', u'Robert Goldman']
SoftwareSystems
Abstract: We present ASDF 2, the current state of the art in CL build systems. From a technical standpoint, ASDF 2 improves upon ASDF by integrating previous common extensions, making conguration easy, and xing bugs. However the overriding concern driving these changes was social rather than technical: ASDF plays a central role in the CL community and we wanted to reduce the coordination costs that it imposed upon CL programmers. We outline ASDFs history and architecture, explain the link between the social issues we faced and the software features we added, and explore the technical challenges involved and lessons learned, notably involving inplace code upgrade of ASDF itself, backward compatibility, portability, testing and other coding best practices.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36970.html
notfound
=========================
Experience report: Haskell as a reagent: results and observations on the use of Haskell in a python project
Proceedings of the 15th ACM SIGPLAN international conference on Functional programming, ACM, New York, NY, USA (2010), pp. 369-374
[u'Iustin Pop']
SoftwareSystems
Abstract: In system administration, the languages of choice for solving automation tasks are scripting languages, owing to their flexibility, extensive library support and quick development cycle. Functional programming is more likely to be found in software development teams and the academic world. This separation means that system administrators cannot use the most effective tool for a given problem; in an ideal world, we should be able to mix and match different languages, based on the problem at hand. This experience report details our initial introduction and use of Haskell in a mature, medium size project implemented in Python. We also analyse the interaction between the two languages, and show how Haskell has excelled at solving a particular type of real-world problems.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35650.html
found
=========================
FlumeJava: Easy, Efficient Data-Parallel Pipelines
ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI), ACM New York, NY 2010, 2 Penn Plaza, Suite 701 New York, NY 10121-0701 (2010), pp. 363-375
[u'Craig Chambers', u'Ashish Raniwala', u'Frances Perry', u'Stephen Adams', u'Robert Henry', u'Robert Bradshaw', u'Nathan']
SoftwareSystems
Abstract: MapReduce and similar systems significantly ease the task of writing data-parallel code. However, many real-world computations require a pipeline of MapReduces, and programming and managing such pipelines can be difficult. We present FlumeJava, a Java library that makes it easy to develop, test, and run efficient dataparallel pipelines. At the core of the FlumeJava library are a couple of classes that represent immutable parallel collections, each supporting a modest number of operations for processing them in parallel. Parallel collections and their operations present a simple, high-level, uniform abstraction over different data representations and execution strategies. To enable parallel operations to run effi- ciently, FlumeJava defers their evaluation, instead internally constructing an execution plan dataflow graph. When the final results of the parallel operations are eventually needed, FlumeJava first optimizes the execution plan, and then executes the optimized operations on appropriate underlying primitives (e.g., MapReduces). The combination of high-level abstractions for parallel data and computation, deferred evaluation and optimization, and efficient parallel primitives yields an easy-to-use system that approaches the effi- ciency of hand-optimized pipelines. FlumeJava is in active use by hundreds of pipeline developers within Google. Categories and Subject Descriptors D.1.3 [Concurrent Programming]: Parallel Programming General Terms Algorithms, Languages, Performance Keywords data-parallel programming, MapReduce, Java
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36663.html
notfound
=========================
Functional and Logic Programming
Springer, LNCS (2010)
[u'Matthias Blume', u'Naoki Kobayashi', u'Germn Vidal']
SoftwareSystems
Abstract: Functional and Logic Programming, 10th International Symposium, FLOPS 2010, Sendai, Japan, April 19-21, 2010, Proceedings
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36575.html
notfound
=========================
Google-Wide Profiling: A Continuous Profiling Infrastructure for Data Centers
IEEE Micro (2010), pp. 65-79
[u'Gang Ren', u'Eric Tune', u'Tipp Moseley', u'Yixin Shi', u'Silvius Rus', u'Robert Hundt']
SoftwareSystems
Abstract: Google-Wide Profiling (GWP), a continuous profiling infrastructure for data centers, provides performance insights for cloud applications. With negligible overhead, GWP provides stable, accurate profiles and a datacenter-scale tool for traditional performance analyses. Furthermore, GWP introduces novel applications of its profiles, such as application- platform affinity measurements and identification of platform-specific, microarchitectural peculiarities.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36355.html
notfound
=========================
Lightweight Feedback-Directed Cross-Module Optimization
Proceedings of International Symposium on Code Generation and Optimization (CGO), IEEE (2010)
[u'Xinliang David Li', u'Raksit Ashok', u'Robert Hundt']
SoftwareSystems
Abstract: Cross-module inter-procedural compiler optimization (IPO) and Feedback-Directed Optimization (FDO) are two important compiler techniques delivering solid performance gains. The combination of IPO and FDO delivers peak performance, but also multiplies both techniques' usability problems. In this paper, we present LIPO, a novel static IPO framework, which integrates IPO and FDO. Compared to existing approaches, LIPO no longer requires writing of the compiler's intermediate representation, eliminates the link-time inter-procedural optimization phase entirely, and minimizes code re-generation overhead, thus improving scalability by an order of magnitude. Compared to an FDO baseline, and without further specific tuning, LIPO improves performance of SPEC2006 INT by 2.5%, and of SPEC2000 INT by 4.4%, with up to 23% for one benchmarks. We confirm our scalability results on a set of large industrial applications, demonstrating 2.9% performance improvements on average. Compile time overhead for full builds is less than 30%, incremental builds take a few seconds on average, and storage requirements increase by only 24%, all compared to the FDO baseline.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Linux Kernel Development
Addison-Wesley (2010)
[u'Robert Love']
SoftwareSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41688.html
found
=========================
PRESS: PRedictive Elastic ReSource Scaling for cloud systems
6th IEEE/IFIP International Conference on Network and Service Management (CNSM 2010), Niagara Falls, Canada
[u'Zhenhuan Gong', u'Xiaohui Gu', u'John Wilkes']
SoftwareSystems
Abstract: Cloud systems require elastic resource allocation to minimize resource provisioning costs while meeting service level objectives (SLOs). In this paper, we present a novel {\em PRedictive Elastic reSource Scaling} (PRESS) scheme for cloud systems. PRESS unobtrusively extracts ne-grained dynamic patterns in application resource demands and adjust their resource allocations automatically. Our approach leverages light-weight signal processing and statistical learning algorithms to achieve online predictions of dynamic application resource requirements. We have implemented the PRESS system on Xen and tested it using RUBiS and an application load trace from Google. Our experiments show that we can achieve good resource prediction accuracy with less than 5\% over-estimation error and near zero under-estimation error, and elastic resource scaling can both signicantly reduce resource waste and SLO violations.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36574.html
notfound
=========================
Proxies: Design Principles for Robust Object-oriented Intercession APIs
Dynamic Languages Symposium, ACM (2010)
[u'Tom Van Cutsem', u'Mark S. Miller']
SoftwareSystems
Abstract: Proxies are a powerful approach to implement meta-objects in object-oriented languages without having to resort to metacircular interpretation. We introduce such a meta-level API based on proxies for Javascript. We simultaneously introduce a set of design principles that characterize such APIs in general, and compare similar APIs of other languages in terms of these principles. We highlight how principled proxy-based APIs improve code robustness by avoiding interference between base and meta-level code that occur in more common reective intercession mechanisms.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37266.html
notfound
=========================
Real World Functional Programming
Manning, 20 Baldwin Road PO Box 261 Shelter Island, NY 11964 (2010), pp. 500
[u'Tomas Petricek', u'Jon Skeet']
SoftwareSystems
Abstract: Functional programming languages like F#, Erlang, and Scala are attracting attention as an efficient way to handle the new requirements for programming multi-processor and high-availability applications. Microsoft's new F# is a true functional language and C# uses functional language features for LINQ and other recent advances. Real World Functional Programming is a unique tutorial that explores the functional programming model through the F# and C# languages. The clearly presented ideas and examples teach readers how functional programming differs from other approaches. It explains how ideas look in F#-a functional language-as well as how they can be successfully used to solve programming problems in C#. Readers build on what they know about .NET and learn where a functional approach makes the most sense and how to apply it effectively in those cases.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36912.html
notfound
=========================
Safe ICF: Pointer Safe and Unwinding Aware Identical Code Folding in Gold
GCC Developers Summit (2010)
[u'Sriraman Tallam', u'Cary Coutant', u'Ian Lance Taylor', u'Xinliang David Li', u'Chris Demetriou']
SoftwareSystems
Abstract: We have found that large C++ applications and shared libraries tend to have many functions whose code is identical with another function. As much as 10% of the code could theoretically be eliminated by merging such identical functions into a single copy. This optimization, Identical Code Folding (ICF), has been implemented in the gold linker. At link time, ICF detects functions with identical object code and merges them into a single copy. ICF can be unsafe, however, as it can change the run-time behaviour of code that relies on each function having a unique address. To address this, ICF can be used in a safe mode where it identifies and folds functions whose addresses are guaranteed not to have been used in comparison operations. Further, profiling and debugging binaries with merged functions can be confusing, as the PC values of merged functions cannot be always disambiguated to point to the correct function. To address this, we propose a new call table format for the DWARF debugging information to allow tools like the debugger and profiler to disambiguate PC values of merged functions correctly by examining the call chain. Detailed experiments on the x86 platform show that ICF can reduce the text size of a selection of Google binaries, whose average text size is 64 MB, by about 6%. Also, the code size savings of ICF with the safe option is almost as good as the code savings obtained without the safe option. Further, experiments also show that the run-time performance of the optimized binaries on the x86 platform does not change.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36841.html
notfound
=========================
Scalable I/O Event Handling for GHC
Proceedings of the 2010 ACM SIGPLAN Haskell Symposium (Haskell'10), pp. 103-108
[u'Bryan OSullivan', u'Johan Tibell']
SoftwareSystems
Abstract: We have developed a new, portable I/O event manager for the Glasgow Haskell Compiler (GHC) that scales to the needs of modern server applications. Our new code is transparently available to existing Haskell applications. Performance at lower concurrency levels is comparable with the existing implementation. We support millions of concurrent network connections, with millions of active timeouts, from a single multithreaded program, levels far beyond those achievable with the current I/O manager. In addition, we provide a public API to developers who need to create event-driven network applications.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36358.html
notfound
=========================
Taming Hardware Event Samples for FDO Compilation
Proceedings of International Symposium on Code Generation and Optimization (CGO) (2010)
[u'Dehao Chen', u'Neil Vachharajani', u'Robert Hundt', u'Shih-wei Liao', u'Vinodha Ramasamy', u'Paul Yuan', u'Wenguang Chen', u'Weiming Zheng']
SoftwareSystems
Abstract: Feedback-directed optimization (FDO) is effective in improving application runtime performance, but has not been widely adopted due to the tedious dual-compilation model, the difficulties in generating representative training data sets, and the high runtime overhead of profile collection. The use of hardware-event sampling to generate estimated edge profiles overcomes these drawbacks. Yet, hardware event samples are typically not precise at the instruction or basic-block granularity. These inaccuracies lead to missed performance when compared to instrumentation-based FDO. In this paper, we use multiple hardware event profiles and supervised learning techniques to generate heuristics for improved precision of basic-block-level sample profiles, and to further improve the smoothing algorithms used to construct edge profiles. We demonstrate that sampling-based FDO can achieve an average of 78% of the performance gains obtained using instrumentation-based exact edge profiles for SPEC2000 benchmarks, matching or beating instrumentation-based FDO in many cases. The overhead of collection is only 0.74% on average, while compiler based instrumentation incurs 6.8%53.5% overhead (and 10x overhead on an industrial web search application), and dynamic instrumentation incurs 28.6%1639.2% overhead.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36902.html
notfound
=========================
The Go Frontend for GCC
GCC Summit 2010 (to appear)
[u'Ian Lance Taylor']
SoftwareSystems
Abstract: A description of the Go language frontend for gcc. This is a new frontend which is a complete implementation of the new Go programming language. The frontend is currently some 50,000 lines of C++ code, and uses its own IR which is then converted to GENERIC. I describe the structure of the frontend and the IR, issues that arise when compiling the Go language, and issues with hooking up any frontend to the gcc middle-end.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36244.html
notfound
=========================
Why Feedback Implementations Fail: The Importance of Systematic Testing
Workshop on Feedback Control Implementation and Design (at EuroSys), ACM (2010)
[u'Joseph L. Hellerstein']
SoftwareSystems
Abstract: Over the last decade, there has been great progress in using formal methods from control theory to design closed loops in software systems. Despite this progress, formal methods are rarely used by software practitioners. One reason is the substantial risk of making changes to closed loops in software products, code that is typically complex and performance sensitive. We argue that broad adoption of formal methods for controller design require addressing how to reduce the risk of making changes in controller implementations. To this end, we propose a framework for testing controller implementations that focuses on scenario coverage, scenario evaluation, and runtime efficiencies. We give examples of applying this framework to the Microsoft .NET Thread Pool, the Google Cluster Manager, and a Google stream processing system.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35161.html
notfound
=========================
An Unexceptional Implementation of First-Class Continuations
Proceedings of the 2009 International Lisp Conference, Association of Lisp Users, 1938 East Beech Road, Sterling, Virginia 20164, pp. 36-40
[u'Joseph Marshall']
SoftwareSystems
Abstract: Describes how to implement first-class continuations on a virtual machine that does not support stack inspection. Unlike previous work, use of the exception handler is avoided. Measurements demonstrate acceptable performance.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35085.html
notfound
=========================
Applying Control Theory in the Real World: Experience With Building a Controller for the .NET Thread Pool
Sigmetrics Performance Evaluation Review (2009), pp. 38-42
[u'Joseph L. Hellerstein', u'Vance Morrison', u'Eric Eilebrecht']
SoftwareSystems
Abstract: While much has been published about the value of using formal techniques from control engineering to build software systems, little has been reported on software engineering considerations for building closed loop systems, especially widely deployed resource managers. This paper discusses the design, testing, and tuning of a controller that optimizes concurrency levels in the .NET thread pool, a feature that is present in approximately 1 billion computers that run the Windows Operating System. Some of the issues we encountered are: (a) designing an extensible controller that easily incorporates a diverse set of techniques; (b) creating a scalable test infrastructure to address running a large number of test cases; (c) providing test cases for which the optimal concurrency level is known a priori; and (d) choosing settings of tuning parameters that result in good controller performance for multiple evaluation criteria.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Are We Ready for a Safer Construction Environment?
European Conference on Object Oriented Languages, Springer Verlag (2009), pp. 495-519
[u'Yossi Gil']
SoftwareSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Blame for all
STOP '09: Proceedings for the 1st workshop on Script to Program Evolution, ACM, New York, NY, USA (2009), pp. 1-13
[u'Amal Ahmed', u'Robert Bruce Findler', u'Jacob Matthews', u'Philip Wadler']
SoftwareSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40401.html
found
=========================
E Unum Pluribus - Google Network Filtering Management
LISA'09 23rd Large Installation System Administration Conference (2009)
[u'Paul (Tony) Watson', u'Peter Moody']
SoftwareSystems
Abstract: Network filtering can be a very difficult challenge in large, complex and sprawling networks. Through the use of internally developed software, Google has automated and simplified many of the difficult tasks and provided the capability to easily audit and validate its filters. This talk will discuss our efforts in this area and release some of these tools to the community.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36600.html
notfound
=========================
ESOFTCHECK: REMOVAL OF NON-VITAL CHECKS FOR FAULT TOLERANCE
Proceedings of the CGO 2009, The Seventh International Symposium on Code Generation and Optimization, IEEE Computer Society, pp. 35-46
[u'Jing Yu', u'Maria Jesus Garzaran', u'Marc Snir']
SoftwareSystems
Abstract: As semiconductor technology scales into the deep submicron regime the occurrence of transient or soft errors will increase. This will require new approaches to error detection. Software checking approaches are attractive because they require little hardware modification and can be easily adjusted to fit different reliability and performance requirements. Unfortunately, software checking adds a significant performance overhead.In this paper we present ESoftCheck, a set of compiler optimization techniques to determine which are the vital checks, that is, the minimum number of checks that are necessary to detect an error and roll back to a correct program state. ESoftCheck identifies the vital checks on platforms where registers are hardware-protected with parity or ECC, when there are redundant checks and when checks appear in loops. ESoftCheck also provides knobs to trade reliability for performance based on the support for recovery and the degree of trustiness of the operations. Our experimental results on a Pentium 4 show that ESoftCheck can obtain 27.1% performance improvement without losing fault coverage.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35168.html
notfound
=========================
Erlang for Concurrent Programming
Communications of the ACM, vol. 52 (2009), pp. 48-56
[u'Jim Larson']
SoftwareSystems
Abstract: Designed for concurrency from the ground up, the Erlang language can be a valuable too to help solve concurrent problems.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Flapjax: a programming language for Ajax applications
OOPSLA '09: Proceeding of the 24th ACM SIGPLAN conference on Object oriented programming systems languages and applications, ACM, New York, NY, USA (2009), pp. 1-20
[u'Leo A. Meyerovich', u'Arjun Guha', u'Jacob Baskin', u'Gregory H. Cooper', u'Michael Greenberg', u'Aleks Bromfield', u'Shriram Krishnamurthi']
SoftwareSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34924.html
notfound
=========================
Isolating Web Programs in Modern Browser Architectures
Eurosys, Nuremburg (2009)
[u'Charles Reis', u'Steven D. Gribble']
SoftwareSystems
Abstract: Many of today's web sites contain substantial amounts of client-side code, and consequently, they act more like programs than simple documents. This creates robustness and performance challenges for web browsers. To give users a robust and responsive platform, the browser must identify program boundaries and provide isolation between them. We provide three contributions in this paper. First, we present abstractions of web programs and program instances, and we show that these abstractions clarify how browser components interact and how appropriate program boundaries can be identified. Second, we identify backwards compatibility tradeoffs that constrain how web content can be divided into programs without disrupting existing web sites. Third, we present a multi-process browser architecture that isolates these web program instances from each other, improving fault tolerance, resource management, and performance. We discuss how this architecture is implemented in Google Chrome, and we provide a quantitative performance evaluation examining its benefits and costs.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Linux in a Nutshell
O'Reilly (2009)
[u'Robert Love']
SoftwareSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34913.html
notfound
=========================
Native Client: A Sandbox for Portable, Untrusted x86 Native Code
IEEE Symposium on Security and Privacy (Oakland'09), IEEE, IEEE, 3 Park Avenue, 17th Floor, New York, NY 10016 (2009)
[u'Bennet Yee', u'David Sehr', u'Greg Dardyk', u'Brad Chen', u'Robert Muth', u'Tavis Ormandy', u'Shiki Okasaka', u'Neha Narula', u'Nicholas Fullagar']
SoftwareSystems
Abstract: Native Client is an open-source research technology for running x86 native code in web applications, with the goal of maintaining the browser neutrality, OS portability, and safety that people expect from web apps. We released this project in December 2008 to get feedback from the security and broader open-source communities. We believe that Native Client technology will someday help web developers to create richer and more dynamic browser-based applications.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub35475.html
notfound
=========================
Optimizing Programs with Intended Semantics
Proceedings of OOPSLA, ACM Press (2009) (to appear)
[u'Daniel von Dincklage', u'Amer Diwan']
SoftwareSystems
Abstract: Modern object-oriented languages have complex features that cause programmers to overspecify their programs. This overspecification hinders automatic optimizers, since they must preserve the overspecified semantics. If an optimizer knew which semantics the programmer intended, it could do a better job. Making a programmer clarify his intentions by placing assumptions into the program is rarely practical. This is because the programmer does not know which parts of the programs' overspecified semantics hinder the optimizer. Therefore, the programmer has to guess which assumption to add. Since the programmer can add many different assumptions to a large program, he will need to place many such assumptions before he guesses right and helps the optimizer. We present IOpt, a practical optimizer that uses a specification of the programmers' intended semantics to enable additional optimizations. That way, our optimizer can significantly improve the performance of a program. We present case studies in which we use IOpt to speed up two programs by over 50%. To make specifying the intended semantics practical, IOpt communicates with the programmer. IOpt identifies which assumptions the programmer textit{should} place, and where he should place them. IOpt ranks each assumption by (i) the likelyhood that the assumption conforms to the programmers' intended semantics and (ii) how much the assumption will help IOpt improve the programs' performance. IOpt proposes ranked assumptions to the programmer, who just picks those that conform to his intended semantics. With this approach, IOpt keeps the programmers' specification burden low. Our case studies show that the programmer just needs to add a few assumptions to realize the 50% speedup.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36599.html
notfound
=========================
Perflint: A Context Sensitive Performance Advisor for C++ Programs
Proceedings of the 7th annual IEEE/ACM International Symposium on Code Generation and Optimization, IEEE Computer Society, Washington, DC, USA (2009), pp. 265-274
[u'Lixia Liu', u'Silvius Rus']
SoftwareSystems
Abstract: We present perflint, a new industrial strength open source analysis tool that identifies suboptimal use patterns of the C++ standard library. Simply by recompiling and running on a representative input set, programmers receive context sensitive performance advice on their use of standard library data structures and algorithms. Our solution consists of collecting traces of relevant library operations and state during program execution, and then recognizing patterns for which there is a faster alternative, based on a model made of performance guarantees in the C++ language standard and machine knowledge. perflint has already found hundreds of suboptimal patterns in a set of large C++ benchmarks. In one case, following the advice and changing one line of code resulted in 17% program run time reduction.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Revised6 report on the algorithmic language scheme
J. Funct. Program., vol. 19 (2009), pp. 1-301
[u'Michael Sperber', u'R. kent Dybvig', u'Matthew Flatt', u'Anton Van straaten', u'Robby Findler', u'Jacob Matthews']
SoftwareSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Scenario Based Optimization: A Framework for Statically Enabling Online Optimizations
Proceedings of the 2009 Symposium on Code Generation and Optimization (CGO), IEEE Computer Society, 10662 Los Vaqueros Circle, P.O. Box 3014, Los Alamitos, CA, 90720, pp. 169-170
[u'Jason Mars', u'Robert Hundt']
SoftwareSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Towards Characterizing Cloud Backend Workloads: Insights from Google Compute Clusters
Sigmetrics Performance Evaluation Review, ACM (2009)
[u'Asit Mishra', u'Joseph L Hellerstein', u'Walfredo Cirne']
SoftwareSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Why we're able to Google
Proceeding CRASS '09 Computing Research that Changed the World: Reflections and Perspectives, Computing Research Association, Washington, D.C. (2009)
[u'Alfred Z. Spector']
SoftwareSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34417.html
notfound
=========================
A New ELF Linker
Proceedings of the GCC Developers' Summit (2008)
[u'Ian Lance Taylor']
SoftwareSystems
Abstract: gold is a new ELF linker recently added to the GNU binutils. I discuss why it made sense to write a new linker rather than extend the existing one. I describe the architecture of the linker, and new features. I present performance measurements. I discuss future plans for the linker. I discuss the use of C++ in writing system tools.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40335.html
notfound
=========================
A rational deconstruction of Landin's SECD machine with the J operator
Logical Methods in Computer Science, vol. 4 (2008), pp. 1-67
[u'Olivier Danvy', u'Kevin Millikin']
SoftwareSystems
Abstract: Landin's SECD machine was the first abstract machine for applicative expressions, ie, functional programs. Landin's J operator was the first control operator for functional languages, and was specified by an extension of the SECD machine. We present a family of evaluation functions corresponding to this extension of the SECD machine, using a series of elementary transformations (transformation into continu-ation-passing style (CPS) and defunctionalization, chiefly) and their left inverses (transformation into direct style and refunctionalization). To this end, we modernize the SECD machine into a bisimilar one that operates in lockstep with the original one but that (1) does not use a data stack and (2) uses the caller-save rather than the callee-save convention for environments. We also identify that the dump component of the SECD machine is managed in a callee-save way. The caller-save counterpart of the modernized SECD machine precisely corresponds to Thielecke's double-barrelled continuations and to Felleisen's encoding of J in terms of call/cc. We then variously characterize the J operator in terms of CPS and in terms of delimited-control operators in the CPS hierarchy. As a byproduct, we also present several reduction semantics for applicative expressions with the J operator, based on Curien's original calculus of explicit substitutions. These reduction semantics mechanically correspond to the modernized versions of the SECD machine and to the best of our knowledge, they provide the first syntactic theories of applicative expressions with the J operator. The present work is concluded by a motivated wish to see Landin's name added to the list of co-discoverers of continuations. Methodologically, however, it mainly illustrates the value of Reynolds's defunctionalization and of refunctionalization as well as the expressive power of the CPS hierarchy (1) to account for the first control operator and the first abstract machine for functional languages and (2) to connect them to their successors. Our work also illustrates the value of Danvy and Nielsen's refocusing technique to connect environment-based abstract machines and syntactic theories in the form of reduction semantics for calculi of explicit substitutions.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
C++ Dynamic Arrays
ISO/IEC JTC1 SC22 WG21 (2008)
[u'Matt Austern', u'Lawrence Crowl']
SoftwareSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36452.html
notfound
=========================
Effective Java, Second Edition
Addison-Wesley, Boston, MA (2008)
[u'Joshua Bloch']
SoftwareSystems
Abstract: Second edition of the best-selling, Jolt Award winning Java best practices guide. Covers Java SE 6, including all of the language features introduced in Java 5.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Fault-Safe Code Motion for Type-Safe Languages
Proc. Sixth Annual IEEE/ACM International Symposium on Code Generation and Optimization, ACM, Boston (2008), pp. 144-154
[u'Brian R Murphy', u'Vijay Menon', u'Florian T. Schneider', u'Tatiana Shpeisman', u'Ali-Reza Adi-Tabatabai']
SoftwareSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36576.html
notfound
=========================
Feedback-Directed Optimizations in GCC with Estimated Edge Profiles from Hardware Event Sampling
Proceedings of GCC Summit 2008, pp. 87-102
[u'Vinodha Ramasamy', u'Paul Yuan', u'Dehao Chen', u'Robert Hundt']
SoftwareSystems
Abstract: Traditional feedback-directed optimization (FDO) in GCC uses static instrumentation to collect edge and value profiles. This method has shown good application performance gains, but is not commonly used in practice due to the high runtime overhead of profile collection, the tedious dual-compile usage model, and difficulties in generating representative training data sets. In this paper, we show that edge frequency estimates can be successfully constructed with heuristics using profile data collected by sampling of hardware events, incurring low runtime overhead (e.g., less then 2%), and requiring no instrumentation, yet achieving competitive performance gains. We describe the motivation, design, and implementation of FDO using sample profiles in GCC and also present our initial experimental results with SPEC2000int C benchmarks that show approximately 70% to 90% of the performance gains obtained using traditional FDO with exact edge profiles.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34438.html
notfound
=========================
Guarded Program Transformations Using JTL
TOOLS EUROPE 2008 (LNBIP 11), Springer-Verlag, Berlin, pp. 100-120
[u'Tal Cohen', u'Joseph (Yossi) Gil', u'Itay Maman']
SoftwareSystems
Abstract: There is a growing research interest in employing the logic paradigm for making queries on software in general, and OOP software in particular. We describes a side-effect-free technique of using the paradigm for the general task of program transformation. Our technique offers a variety of applications, such as implementing generic structures (without erasure) in JAVA, a Lint-like program checker, and more. By allowing the transformation target to be a different language than the source (program translation), we show how the language can be employed for tasks like the generation of database schemas or XML DTDs that match JAVA classes. The technique is an extension of JTL (Java Tools Language), which is a high-level abstraction over DATALOG. We discuss the JTL-to-DATALOG compilation process, and how the program transformation extension can be added to JTL without deviating from the logic paradigm, and specifically without introducing side-effects to logic programs.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Lightweight, High-Resolution Monitoring for Troubleshooting Production Systems
OSDI '08 (2008)
[u'Sapan Bhatia', u'Abhishek Kumar', u'Marc E. Fiuczynski', u'Larry Peterson']
SoftwareSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Linux capabilities: making them work
Linux Symposium 2008, 2008 Linux Symposium Inc., http://www.linuxsymposium.org/2008/cfp.php, pp. 10
[u'Serge E. Hallyn', u'Andrew G. Morgan']
SoftwareSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Selective Versioning in a Secure Disk System
Usenix Security Symposium 2008
[u'Swaminathan Sundararaman', u'Gopalan Sivathanu', u'Erez Zadok']
SoftwareSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub33526.html
notfound
=========================
What can performance counters do for memory subsystem analysis?
ACM SIGPLAN Workshop on Memory Systems Performance & Correctness (MSPC'08), ACM, Seattle (2008), pp. 26-30
[u'Stephane Eranian']
SoftwareSystems
Abstract: Nowadays, all major processors provide a set of performance counters which capture micro-architectural level information, such as the number of elapsed cycles, cache misses, or instructions executed. Counters can be found in processor cores, processor die, chipsets, or in I/O cards. They can provide a wealth of information as to how the hardware is being used by software. Many processors now support events to measure precisely and with very limited overhead, the traffic between a core and the memory subsystem. It is possible to compute average load latency and bus bandwidth utilization. This valuable information can be used to improve code quality and placement of threads to maximize hardware utilization.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Automatic Inference of Optimizer Flow Functions from Semantic Meanings
Proc. PLDI 07, ACM Press (2007), pp. 135-145
[u'Erika Rice Scherpelz', u'Sorin Lerner', u'Craig Chambers']
SoftwareSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
CRF-filters: Conditional Particle Filters for Sequential State Estimation
Proceedings of the International Conference on Robotics and Automation (2007)
[u'Bensen Limketkai', u'Dieter Fox', u'Lin Liao']
SoftwareSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Generalized File System Dependencies
Proc. SOSP'07, ACM, Stevenson, Washington (2007)
[u'Christopher Frost', u'Mike Mammarella', u'Eddie Kohler', u'Andrew de los Reyes', u'Shant Hovsepian', u'Andrew Matsuoka', u'Lei Zhang']
SoftwareSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Linux System Programming
O'Reilly (2007)
[u'Robert Love']
SoftwareSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Independently Extensible Solutions to the Expression Problem
FOOL (2005)
[u'Matthias Zenger', u'Martin Odersky']
SoftwareSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Java Puzzlers: Traps, Pitfalls, and Corner Cases
Addison-Wesley (2005)
[u'Joshua Bloch', u'Neal Gafter']
SoftwareSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Scalable Component Abstractions
OOPSLA (2005), pp. 41-57
[u'Martin Odersky', u'Matthias Zenger']
SoftwareSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Systems Support for Preemptive Disk Scheduling
IEEE Trans. Computers, vol. 54 (2005), pp. 1314-1326
[u'Zoran Dimitrijevi', u'Raju Rangaswami', u'Edward Y. Chang']
SoftwareSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Thwarting Virtual Bottlenecks in Multi-Bitrate Streaming Servers
IEEE RTSS, IEEE RTSS (2005)
[u'Bin Liu', u'Raju Rangaswami', u'Zoran Dimitrijevi']
SoftwareSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
The Google File System
Proceedings of the 19th ACM Symposium on Operating Systems Principles, ACM, Bolton Landing, NY (2003), pp. 20-43
[u'Sanjay Ghemawat', u'Howard Gobioff', u'Shun-Tak Leung']
SoftwareSystems
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/SpeechProcessing.html
found
http://research.google.com/pubs/pub43989.html
found
=========================
Robust Estimation of Reverberation Time Using Polynomial Roots
AES 60th Conference on Dereverberation and Reverberation of Audio, Music, and Speech, Google Ireland Ltd. (2016) (to appear)
[u'Ian Kelly', u'Francis Boland', u'Jan Skoglund']
SpeechProcessing
Abstract: This paper further investigates previous findings that coefficients of acoustic responses can be modelled as random polynomials with certain constraints applied. In the case of room impulse responses, the median value of their clustered roots has been shown to be directly related to the reverberation time of the room. In this paper we examine the frequency dependency of reverberation time and we also demonstrate the methods robustness to truncation of impulse responses.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43280.html
found
=========================
A 6 W per Channel Analog Biomimetic Cochlear Implant Processor Filterbank Architecture With Across Channels AGC
IEEE Transactions on Biomedical Circuits and Systems, vol. 9 (2015), pp. 72-86
[u'Guang Wang', u'Richard F. Lyon', u'Emmanuel M. Drakakis']
SpeechProcessing
Abstract: A new analog cochlear implant processor filterbank architecture of increased biofidelity, enhanced across-channel contrast and very low power consumption has been designed and prototyped. Each channel implements a biomimetic, asymmetric bandpass-like One-Zero-Gammatone-Filter (OZGF) transfer function, using class-AB log-domain techniques. Each channel's quality factor and suppression are controlled by means of a new low power Automatic Gain Control (AGC) scheme which is coupled across the neighboring channels and emulates lateral inhibition (LI) phenomena in the auditory system. Detailed measurements from a five-channel silicon IC prototype fabricated in a 0.35 m AMS technology confirm the operation of the coupled AGC scheme and its ability to enhance contrast among channel outputs. The prototype is characterized by an input dynamic range of 92 dB while consuming only 28 W of power in total ~6 W per channel) under a 1.8 V power supply. The architecture is well-suited for fully-implantable cochlear implants.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43912.html
found
=========================
A Gaussian Mixture Model Layer Jointly Optimized with Discriminative Features within A Deep Neural Network Architecture
ICASSP, IEEE (2015)
[u'Ehsan Variani', u'Erik McDermott', u'Georg Heigold']
SpeechProcessing
Abstract: This article proposes and evaluates a Gaussian Mixture Model (GMM) represented as the last layer of a Deep Neural Network (DNN) architecture and jointly optimized with all previous layers using Asynchronous Stochastic Gradient Descent (ASGD). The resulting Deep GMM architecture was investigated with special attention to the following issues: (1) The extent to which joint optimization improves over separate optimization of the DNN-based feature extraction layers and the GMM layer; (2) The extent to which depth (measured in number of layers, for a matched total number of parameters) helps a deep generative model based on the GMM layer, compared to a vanilla DNN model; (3) Head-to-head performance of Deep GMM architectures vs. equivalent DNN architectures of comparable depth, using the same optimization criterion (frame-level Cross Entropy (CE)) and optimization method (ASGD); (4) Expanded possibilities for modeling offered by the Deep GMM generative model. The proposed Deep GMMs were found to yield Word Error Rates (WERs) competitive with state-of-the-art DNN systems, at the cost of pre-training using standard DNNs to initialize the Deep GMM feature extraction layers. An extension to Deep Subspace GMMs is described, resulting in additional gains.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43893.html
notfound
=========================
Acoustic Modeling in Statistical Parametric Speech Synthesis - From HMM to LSTM-RNN
Proc. MLSLP (2015)
[u'Heiga Zen']
SpeechProcessing
Abstract: Statistical parametric speech synthesis (SPSS) combines an acoustic model and a vocoder to render speech given a text. Typically decision tree-clustered context-dependent hidden Markov models (HMMs) are employed as the acoustic model, which represent a relationship between linguistic and acoustic features. Recently, artificial neural network-based acoustic models, such as deep neural networks, mixture density networks, and long short-term memory recurrent neural networks (LSTM-RNNs), showed significant improvements over the HMM-based approach. This paper reviews the progress of acoustic modeling in SPSS from the HMM to the LSTM-RNN.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44269.html
notfound
=========================
Acoustic Modelling with CD-CTC-SMBR LSTM RNNS
ASRU (2015) (to appear)
[u'Andrew Senior', u'Hasim Sak', u'Felix de Chaumont Quitry', u'Tara N. Sainath', u'Kanishka Rao']
SpeechProcessing
Abstract: This paper describes a series of experiments to extend the application of Context-Dependent (CD) long short-term memory (LSTM) recurrent neural networks (RNNs) trained with Connectionist Temporal Classification (CTC) and sMBR loss. Our experiments, on a noisy, reverberant voice search task, include training with alternative pronunciations and the application to child speech recognition; combination of multiple models, and convolutional input layers. We also investigate the latency of CTC models and show that constraining forward-backward alignment in training can reduce the delay for a real-time streaming speech recognition system. Finally we investigate transferring knowledge from one network to another through alignments
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43289.html
found
=========================
Automatic Gain Control and Multi-style Training for Robust Small-Footprint Keyword Spotting with Deep Neural Networks
Proceedings of International Conference on Acoustics, Speech and Signal Processing (ICASSP), IEEE (2015), pp. 4704-4708
[u'Rohit Prabhavalkar', u'Raziel Alvarez', u'Carolina Parada', u'Preetum Nakkiran', u'Tara Sainath']
SpeechProcessing
Abstract: We explore techniques to improve the robustness of small-footprint keyword spotting models based on deep neural networks (DNNs) in the presence of background noise and in far-field conditions. We find that system performance can be improved significantly, with relative improvements up to 75% in far-field conditions, by employing a combination of multi-style training and a proposed novel formulation of automatic gain control (AGC) that estimates the levels of both speech and background noise. Further, we find that these techniques allow us to achieve competitive performance, even when applied to DNNs with an order of magnitude fewer parameters than our baseline.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Automatic Pronunciation Verification for Speech Recognition
ICASSP (2015)
[u'Kanishka Rao', u'Fuchun Peng', u'Franoise Beaufays']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Bringing Contextual Information to Google Speech Recognition
Interspeech 2015, International Speech Communications Association
[u'Petar Aleksic', u'Mohammadreza Ghodsi', u'Assaf Michaely', u'Cyril Allauzen', u'Keith Hall', u'Brian Roark', u'David Rybach', u'Pedro Moreno']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Composition-based on-the-fly rescoring for salient n-gram biasing
Interspeech 2015, International Speech Communications Association
[u'Keith Hall', u'Eunjoon Cho', u'Cyril Allauzen', u'Francoise Beaufays', u'Noah Coccaro', u'Kaisuke Nakajima', u'Michael Riley', u'Brian Roark', u'David Rybach', u'Linda Zhang']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43813.html
notfound
=========================
Compressing Deep Neural Networks using a Rank-Constrained Topology
Proceedings of Annual Conference of the International Speech Communication Association (Interspeech), ISCA (2015), pp. 1473-1477
[u'Preetum Nakkiran', u'Raziel Alvarez', u'Rohit Prabhavalkar', u'Carolina Parada']
SpeechProcessing
Abstract: We present a general approach to reduce the size of feed-forward deep neural networks (DNNs). We propose a rank-constrained topology, which factors the weights in the input layer of the DNN in terms of a low-rank representation: unlike previous work, our technique is applied at the level of the filters learned at individual hidden layer nodes, and exploits the natural two-dimensional time-frequency structure in the input. These techniques are applied on a small-footprint DNN-based keyword spotting task, where we find that we can reduce model size by 75% relative to the baseline, without any loss in performance. Furthermore, we find that the proposed approach is more effective at improving model performance compared to other popular dimensionality reduction techniques, when evaluated with a comparable number of parameters.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Context dependent phone models for LSTM RNN acoustic modelling
ICASSP (2015), pp. 4585-4589
[u'Andrew W. Senior', u'Hasim Sak', u'Izhak Shafran']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Convolutional Neural Networks for Small-Footprint Keyword Spotting
Interspeech (2015)
[u'Tara Sainath', u'Carolina Parada']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Convolutional, Long Short-Term Memory, Fully Connected Deep Neural Networks
ICASSP (2015)
[u'Tara Sainath', u'Oriol Vinyals', u'Andrew Senior', u'Hasim Sak']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
DETECTION AND SUPPRESSION OF KEYBOARD TRANSIENT NOISE IN AUDIO STREAMS WITH AUXILIARY KEYBED MICROPHONE
ICASSP 2015, IEEE
[u'Simon Godsill', u'Herbert Buchner', u'Jan Skoglund']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
DIRECT-TO-REVERBERANT RATIO ESTIMATION USING A NULL-STEERED BEAMFORMER
ICASSP 2015, IEEE
[u'James Eaton', u'Alastair Moore', u'Patrick Naylor', u'Jan Skoglund']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43434.html
notfound
=========================
Deep Learning for Acoustic Modeling in Parametric Speech Generation: A systematic review of existing techniques and future trends
IEEE Signal Processing Magazine, vol. 32 (2015), pp. 35-52
[u'Zhen-Hua Ling', u'Shiyin Kang', u'Heiga Zen', u'Andrew Senior', u'Mike Schuster', u'Xiao-Jun Qian', u'Helen Meng', u'Li Deng']
SpeechProcessing
Abstract: Hidden Markov models (HMMs) and Gaussian mixture models (GMMs) are the two most common types of acoustic models used in statistical parametric approaches for generating low-level speech waveforms from high-level symbolic inputs via intermediate acoustic feature sequences. However, these models have their limitations in representing complex, nonlinear relationships between the speech generation inputs and the acoustic features. Inspired by the intrinsically hierarchical process of human speech production and by the successful application of deep neural networks (DNNs) to automatic speech recognition (ASR), deep learning techniques have also been applied successfully to speech generation, as reported in recent literature.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43267.html
notfound
=========================
Directly Modeling Speech Waveforms by Neural Networks for Statistical Parametric Speech Synthesis
Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), IEEE (2015), pp. 4215-4219
[u'Keiichi Tokuda', u'Heiga Zen']
SpeechProcessing
Abstract: This paper proposes a novel approach for directly-modeling speech at the waveform level using a neural network. This approach uses the neural network-based statistical parametric speech synthesis framework with a specially designed output layer. As acoustic feature extraction is integrated to acoustic model training, it can overcome the limitations of conventional approaches, such as two-step (feature extraction and acoustic modeling) optimization, use of spectra rather than waveforms as targets, use of overlapping and shifting frames as unit, and fixed decision tree structure. Experimental results show that the proposed approach can directly maximize the likelihood defined at the waveform domain.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Fast and Accurate Recurrent Neural Network Acoustic Models for Speech Recognition
CoRR, vol. abs/1507.06947 (2015)
[u'Hasim Sak', u'Andrew W. Senior', u'Kanishka Rao', u'Franoise Beaufays']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Fix It Where It Fails: Pronunciation Learning by Mining Error Corrections from Speech Logs
ICASSP (2015)
[u'Zhenzhen Kou', u'Daisy Stanton', u'Fuchun Peng', u'Franoise Beaufays', u'Trevor Strohman']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Garbage Modeling for On-device Speech Recognition
Interspeech 2015, International Speech Communications Association (to appear)
[u'Christophe Van Gysel', u'Leonid Velikovich', u'Ian McGraw', u'Franoise Beaufays']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Geo-location for Voice Search Language Modeling
Interspeech 2015, International Speech Communications Association, pp. 1438-1442
[u'Ciprian Chelba', u'Xuedong Zhang', u'Keith Hall']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Grapheme-to-Phoneme Conversion Using Long Short-Term Memory Recurrent Neural Networks
ICASSP (2015)
[u'Kanishka Rao', u'Fuchun Peng', u'Hasim Sak', u'Franoise Beaufays']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Improved recognition of contact names in voice commands
ICASSP 2015
[u'Petar Aleksic', u'Cyril Allauzen', u'David Elson', u'Aleks Kracun', u'Diego Melendo Casado', u'Pedro J. Moreno']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43258.html
found
=========================
Language Modeling in the Era of Abundant Data
Stanford Information Theory Forum (2015)
[u'Ciprian Chelba']
SpeechProcessing
Abstract: The talk presents an overview of statistical language modeling as applied to real-word problems: speech recognition, machine translation, spelling correction, soft keyboards to name a few prominent ones. We summarize the most successful estimation techniques, and examine how they fare for applications with abundant data, e.g. voice search. We conclude by highlighting a few open problems: getting an accurate estimate for the entropy of text produced by a very specific source, e.g. query stream); optimally leveraging data that is of different degrees of relevance to a given "domain"; does a bound on the size of a "good" model for a given source exist?
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44268.html
notfound
=========================
Large Vocabulary Automatic Speech Recognition for Children
Interspeech (2015)
[u'Hank Liao', u'Golan Pundak', u'Olivier Siohan', u'Melissa Carroll', u'Noah Coccaro', u'Qi-Ming Jiang', u'Tara N. Sainath', u'Andrew Senior', u'Franoise Beaufays', u'Michiel Bacchiani']
SpeechProcessing
Abstract: Recently, Google launched YouTube Kids, a mobile application for children, that uses a speech recognizer built specifically for recognizing childrens speech. In this paper we present techniques we explored to build such a system. We describe the use of a neural network classifier to identify matched acoustic training data, filtering data for language modeling to reduce the chance of producing offensive results. We also compare long short-term memory (LSTM) recurrent networks to convolutional, LSTM, deep neural networks (CLDNN). We found that a CLDNN acoustic model outperforms an LSTM across a variety of different conditions, but does not specifically model child speech relatively better than adult. Overall, these findings allow us to build a successful, state-of-the-art large vocabulary speech recognizer for both children and adults.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44019.html
found
=========================
Large-scale, sequence-discriminative, joint adaptive training for masking-based robust ASR
INTERSPEECH-2015, ISCA, pp. 3571-3575
[u'Arun Narayanan', u'Ananya Misra', u'Kean Chin']
SpeechProcessing
Abstract: Recently, it was shown that the performance of supervised time-frequency masking based robust automatic speech recognition techniques can be improved by training them jointly with the acoustic model [1]. The system in [1], termed deep neural network based joint adaptive training, used fully-connected feed-forward deep neural networks for estimating time-frequency masks and for acoustic modeling; stacked log mel spectra was used as features and training minimized cross entropy loss. In this work, we extend such jointly trained systems in several ways. First, we use recurrent neural networks based on long short-term memory (LSTM) units this allows the use of unstacked features, simplifying joint optimization. Next, we use a sequence discriminative training criterion for optimizing parameters. Finally, we conduct experiments on large scale data and show that joint adaptive training can provide gains over a strong baseline. Systematic evaluations on noisy voice-search data show relative improvements ranging from 2% at 15 dB to 5.4% at -5 dB over a sequence discriminative, multi-condition trained LSTM acoustic model.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Learning acoustic frame labeling for speech recognition with recurrent neural networks
ICASSP (2015), pp. 4280-4284
[u'Hasim Sak', u'Andrew W. Senior', u'Kanishka Rao', u'Ozan Irsoy', u'Alex Graves', u'Franoise Beaufays', u'Johan Schalkwyk']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Learning the Speech Front-end with Raw Waveform CLDNNs
Interspeech (2015)
[u'Tara Sainath', u'Ron J. Weiss', u'Kevin Wilson', u'Andrew W. Senior', u'Oriol Vinyals']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Long Short-Term Memory Language Models with Additive Morphological Features for Automatic Speech Recognition
IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP) (2015)
[u'Daniel Renshaw', u'Keith B. Hall']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43830.html
found
=========================
Pruning Sparse Non-negative Matrix N-gram Language Models
Proceedings of Interspeech 2015, ISCA, pp. 1433-1437
[u'Joris Pelemans', u'Noam M. Shazeer', u'Ciprian Chelba']
SpeechProcessing
Abstract: In this paper we present a pruning algorithm and experimental results for our recently proposed Sparse Non-negative Matrix (SNM) family of language models (LMs). We show that when trained with only n-gram features SNMLM pruning based on a mutual information criterion yields the best known pruned model on the One Billion Word Language Model Benchmark, reducing perplexity with 18% and 57% over Katz and Kneser-Ney LMs, respectively. We also illustrate a method for converting an SNMLM to ARPA back-off format which can be readily used in a single-pass decoder for Automatic Speech Recognition.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Query-by-Example Keyword Spotting Using Long Short-Term Memory Networks
ICASSP (2015)
[u'Guoguo Chen', u'Carolina Parada', u'Tara N. Sainath']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Rapid Vocabulary Addition to Context-Dependent Decoder Graphs
Interspeech 2015
[u'Cyril Allauzen', u'Michael Riley']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Sequence-based Class Tagging for Robust Transcription in ASR
Interspeech 2015, International Speech Communications Association (to appear)
[u'Lucy Vasserman', u'Vlad Schogol', u'Keith Hall']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43964.html
found
=========================
Sparse Non-negative Matrix Language Modeling for Geo-annotated Query Session Data
Automatic Speech Recognition and Understanding Workshop (ASRU 2015) Proceedings, IEEE, to appear (to appear)
[u'Ciprian Chelba', u'Noam M. Shazeer']
SpeechProcessing
Abstract: The paper investigates the impact on query language modeling when using skip-grams within query as well as across queries in a given search session, in conjunction with the geo-annotation available for the query stream data. As modeling tool we use the recently proposed sparse non-negative matrix estimation technique, since it offers the same expressive power as the well-established maximum entropy approach in combining arbitrary context features. Experiments on the google.com query stream show that using session-level and geo-location context we can expect reductions in perplexity of 34% relative over the Kneser Ney N-gram baseline; when evaluating on the `''local'' subset of the query stream, the relative reduction in PPL is 51%---more than a bit. Both sources of context information (geo-location, and previous queries in session) are about equally valuable in building a language model for the query stream.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Speaker Location and Microphone Spacing Invariant Acoustic Modeling from Raw Multichannel Waveforms
ASRU (2015) (to appear)
[u'Tara N. Sainath', u'Ron J. Weiss', u'Kevin Wilson', u'Arun Narayanan', u'Michiel Bacchiani', u'Andrew Senior']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43290.html
found
=========================
Speech Acoustic Modeling from Raw Multichannel Waveforms
International Conference on Acoustics, Speech, and Signal Processing, IEEE (2015)
[u'Yedid Hoshen', u'Ron Weiss', u'Kevin W Wilson']
SpeechProcessing
Abstract: Standard deep neural network-based acoustic models for automatic speech recognition (ASR) rely on hand-engineered input features, typically log-mel filterbank magnitudes. In this paper, we describe a convolutional neural network - deep neural network (CNN-DNN) acoustic model which takes raw multichannel waveforms as input, i.e. without any preceding feature extraction, and learns a similar feature representation through supervised training. By operating directly in the time domain, the network is able to take advantage of the signal's fine time structure that is discarded when computing filterbank magnitude features. This structure is especially useful when analyzing multichannel inputs, where timing differences between input channels can be used to localize a signal in space. The first convolutional layer of the proposed model naturally learns a filterbank that is selective in both frequency and direction of arrival, i.e. a bank of bandpass beamformers with an auditory-like frequency scale. When trained on data corrupted with noise coming from different spatial locations, the network learns to filter them out by steering nulls in the directions corresponding to the noise sources. Experiments on a simulated multichannel dataset show that the proposed acoustic model outperforms a DNN that uses log-mel filterbank magnitude features under noisy and reverberant conditions.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub44312.html
found
=========================
Statistical parametric speech synthesis: from HMM to LSTM-RNN
N/A (2015)
[u'Heiga Zen']
SpeechProcessing
Abstract: This talk will present progress of acoustic modeling in statistical parametric speech synthesis from the conventional hidden Markov model HMM to the state-of-the-art long short-term memory recurrent neural network. The details of implementation and applications of statistical parametric speech synthesis are also included.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43266.html
found
=========================
Unidirectional Long Short-Term Memory Recurrent Neural Network with Recurrent Output Layer for Low-Latency Speech Synthesis
Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), IEEE (2015), pp. 4470-4474
[u'Heiga Zen', u'Hasim Sak']
SpeechProcessing
Abstract: Long short-term memory recurrent neural networks (LSTM-RNNs) have been applied to various speech applications including acoustic modeling for statistical parametric speech synthesis. One of the concerns for applying them to text-to-speech applications is its effect on latency. To address this concern, this paper proposes a low-latency, streaming speech synthesis architecture using unidirectional LSTM-RNNs with a recurrent output layer. The use of unidirectional RNN architecture allows frame-synchronous streaming inference of output acoustic features given input linguistic features. The recurrent output layer further encourages smooth transition between acoustic features at consecutive frames. Experimental results in subjective listening tests show that the proposed architecture can synthesize natural sounding speech without requiring utterance-level batch processing.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43990.html
notfound
=========================
ViSQOL: an objective speech quality model
EURASIP Journal on Audio, Speech, and Music Processing, vol. 2015 (13) (2015), pp. 1-18
[u'Andrew Hines', u'Jan Skoglund', u'Anil Kokaram', u'Naomi Harte']
SpeechProcessing
Abstract: This paper presents an objective speech quality model, ViSQOL, the Virtual Speech Quality Objective Listener. It is a signal-based, full-reference, intrusive metric that models human speech quality perception using a spectro-temporal measure of similarity between a reference and a test speech signal. The metric has been particularly designed to be robust for quality issues associated with Voice over IP (VoIP) transmission. This paper describes the algorithm and compares the quality predictions with the ITU-T standard metrics PESQ and POLQA for common problems in VoIP: clock drift, associated time warping, and playout delays. The results indicate that ViSQOL and POLQA significantly outperform PESQ, with ViSQOL competing well with POLQA. An extensive benchmarking against PESQ, POLQA, and simpler distance metrics using three speech corpora (NOIZEUS and E4 and the ITU-T P.Sup. 23 database) is also presented. These experiments benchmark the performance for a wide range of quality impairments, including VoIP degradations, a variety of background noise types, speech enhancement methods, and SNR levels. The results and subsequent analysis show that both ViSQOL and POLQA have some performance weaknesses and under-predict perceived quality in certain VoIP conditions. Both have a wider application and robustness to conditions than PESQ or more trivial distance metrics. ViSQOL is shown to offer a useful alternative to POLQA in predicting speech quality in VoIP scenarios.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43336.html
notfound
=========================
Vocaine the Vocoder and Applications in Speech Synthesis
ICASSP, IEEE (2015) (to appear)
[u'Yannis Agiomyrgiannakis']
SpeechProcessing
Abstract: Vocoders received renewed attention recently as basic components in speech synthesis applications such as voice transformation, voice conversion and statistical parametric speech synthesis. This paper presents a new vocoder synthesizer, referred to as Vocaine, that features a novel Amplitude Modulated-Frequency Modulated (AM-FM) speech model, a new way to synthesize non-stationary sinusoids using quadratic phase splines and a super fast cosine generator. Extensive evaluations are made against several state-ofthe-art methods in Copy-Synthesis and Text-To-Speech synthesis experiments. Vocaine matches or outperforms STRAIGHT in CopySynthesis experiments and outperforms our baseline real-time optimized Mixed-Excitation vocoder with the same computational cost. We report that Vocaine considerably improves our statistical TTS synthesizers and that our new statistical parametric synthesizer [1] matched the quality of our mature production Unit-Selection system with uncompressed waveforms.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43230.html
notfound
=========================
A big data approach to acoustic model training corpus selection
Conference of the International Speech Communication Association (Interspeech) (2014)
[u'Olga Kapralova', u'John Alex', u'Eugene Weinstein', u'Pedro Moreno', u'Olivier Siohan']
SpeechProcessing
Abstract: Deep neural networks (DNNs) have recently become the state of the art technology in speech recognition systems. In this paper we propose a new approach to constructing large high quality unsupervised sets to train DNN models for large vocabulary speech recognition. The core of our technique consists of two steps. We first redecode speech logged by our production recognizer with a very accurate (and hence too slow for real-time usage) set of speech models to improve the quality of ground truth transcripts used for training alignments. Using confidence scores, transcript length and transcript flattening heuristics designed to cull salient utterances from three decades of speech per language, we then carefully select training data sets consisting of up to 15K hours of speech to be used to train acoustic models without any reliance on manual transcription. We show that this approach yields models with approximately 18K context dependent states that achieve 10% relative improvement in large vocabulary dictation and voice-search systems for Brazilian Portuguese, French, Italian and Russian languages.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
An Analysis of the Effect of Larynx-Synchronous Averaging on Dereverberation of Voiced Speech
Proceedings of European Signal Processing Conference (EUSIPCO) 2014
[u'Alastair H Moore', u'Patrick A Naylor', u'Jan Skoglund']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42248.html
found
=========================
Asynchronous Stochastic Optimization for Sequence Training of Deep Neural Networks
Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), IEEE, Firenze, Italy (2014)
[u'Georg Heigold', u'Erik McDermott', u'Vincent Vanhoucke', u'Andrew Senior', u'Michiel Bacchiani']
SpeechProcessing
Abstract: This paper explores asynchronous stochastic optimization for sequence training of deep neural networks. Sequence training requires more computation than frame-level training using pre-computed frame data. This leads to several complications for stochastic optimization, arising from signicant asynchrony in model updates under massive parallelization, and limited data shufing due to utterance-chunked processing. We analyze the impact of these two issues on the efciency and performance of sequence training. In particular, we suggest a framework to formalize the reasoning about the asynchrony and present experimental results on both small and large scale Voice Search tasks to validate the effectiveness and efciency of asynchronous stochastic optimization.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Asynchronous Stochastic Optimization for Sequence Training of Deep Neural Networks: Towards Big Data
Interspeeech, ISCA (2014)
[u'Erik McDermott', u'Georg Heigold', u'Pedro Moreno', u'Andrew Senior', u'Michiel Bacchiani']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Asynchronous, Online, GMM-free Training of a Context Dependent Acoustic Model for Speech Recognition
Proceedings of the European Conference on Speech Communication and Technology (2014) (to appear)
[u'M. Bacchiani', u'A. Senior', u'G. Heigold']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42538.html
notfound
=========================
Automatic Language Identification Using Deep Neural Networks
Proc. ICASSP, IEEE (2014)
[u'Ignacio Lopez-Moreno', u'Javier Gonzalez-Dominguez', u'Oldrich Plchot']
SpeechProcessing
Abstract: This work studies the use of deep neural networks (DNNs) to address automatic language identification (LID). Motivated by their recent success in acoustic modelling, we adapt DNNs to the problem of identifying the language of a given spoken utterance from short-term acoustic features. The proposed approach is compared to state-of-the-art i-vector based acoustic systems on two different datasets: Google 5M LID corpus and NIST LRE 2009. Results show how LID can largely benefit from using DNNs, especially when a large amount of training data is available. We found relative improvements up to 70%, in Cavg, over the baseline system.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Automatic Language Identification using Long Short-Term Memory Recurrent Neural Networks
Interspeech (2014)
[u'Javier Gonzalez-Dominguez', u'Ignacio Lopez-Moreno', u'Hasim Sak']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42947.html
found
=========================
Autoregressive Product of Multi-frame Predictions Can Improve the Accuracy of Hybrid Models
Proceedings of Interspeech 2014
[u'Navdeep Jaitly', u'Vincent Vanhoucke', u'Geoffrey Hinton']
SpeechProcessing
Abstract: We describe a simple but effective way of using multi-frame targets to improve the accuracy of Artificial Neural Network- Hidden Markov Model (ANN-HMM) hybrid systems. In this approach a Deep Neural Network (DNN) is trained to predict the forced-alignment state of multiple frames using a separate softmax unit for each of the frames. This is in contrast to the usual method of training a DNN to predict only the state of the central frame. By itself this is not sufficient to improve accuracy of the system significantly. However, if we average the predic- tions for each frame - from the different contexts it is associated with - we achieve state of the art results on TIMIT using a fully connected Deep Neural Network without convolutional archi- tectures or dropout training. On a 14 hour subset of Wall Street Journal (WSJ) using a context dependent DNN-HMM system it leads to a relative improvement of 6.4% on the dev set (test- dev93) and 9.3% on test set (test-eval92).
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub43114.html
found
=========================
Backoff Inspired Features for Maximum Entropy Language Models
Proceedings of Interspeech, ISCA (2014)
[u'Fadi Biadsy', u'Keith Hall', u'Pedro Moreno', u'Brian Roark']
SpeechProcessing
Abstract: Maximum Entropy (MaxEnt) language models are linear models that are typically regularized via well-known L1 or L2 terms in the likelihood objective, hence avoiding the need for the kinds of backoff or mixture weights used in smoothed n-gram language models using Katz backoff and similar techniques. Even though backoff cost is not required to regularize the model, we investigate the use of backoff features in MaxEnt models, as well as some backoff-inspired variants. These features are shown to improve model quality substantially, as shown in perplexity and word-error rate reductions, even in very large scale training scenarios of tens or hundreds of billions of words and hundreds of millions of features.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42502.html
found
=========================
Computer-aided quality assurance of an Icelandic pronunciation dictionary
LREC 2014, Reykjavik
[u'Martin Jansche']
SpeechProcessing
Abstract: We propose a model-driven method for ensuring the quality of pronunciation dictionaries. The key ingredient is computing an alignment between letter strings and phoneme strings, a standard technique in pronunciation modeling. The novel aspect of our method is the use of informative, parametric alignment models which are refined iteratively as they are tested against the data. We discuss the use of alignment failures as a signal for detecting and correcting problematic dictionary entries. We illustrate this method using an existing pronunciation dictionary for Icelandic. Our method is completely general and has been applied in the construction of pronunciation dictionaries for commercially deployed speech recognition systems in several languages.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Context Dependent State Tying for Speech Recognition using Deep Neural Network Acoustic Models
Proceedings of the International Conference on Acoustics,Speech and Signal Processing (2014)
[u'M. Bacchiani', u'D. Rybach']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42020.html
notfound
=========================
Deep Mixture Density Networks for Acoustic Modeling in Statistical Parametric Speech Synthesis
Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), IEEE (2014), pp. 3872-3876
[u'Heiga Zen', u'Andrew Senior']
SpeechProcessing
Abstract: Statistical parametric speech synthesis (SPSS) using deep neural networks (DNNs) has shown its potential to produce naturally-sounding synthesized speech. However, there are limitations in the current implementation of DNN-based acoustic modeling for speech synthesis, such as the unimodal nature of its objective function and its lack of ability to predict variances. To address these limitations, this paper investigates the use of a mixture density output layer. It can estimate full probability density functions over real-valued output features conditioned on the corresponding input features. Experimental results in objective and subjective evaluations show that the use of the mixture density output layer improves the prediction accuracy of acoustic features and the naturalness of the synthesized speech.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Deep Neural Networks for Small Footprint Text-dependent Speaker Verification
Proc. ICASSP, IEEE (2014)
[u'Ehsan Variani', u'Xin Lei', u'Erik McDermott', u'Ignacio Lopez Moreno', u'Javier Gonzalez-Dominguez']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42900.html
found
=========================
Discriminative pronunciation modeling for dialectal speech recognition
Proc. Interspeech (2014) (to appear)
[u'Maider Lehr', u'Kyle Gorman', u'Izhak Shafran']
SpeechProcessing
Abstract: Speech recognizers are typically trained with data from a standard dialect and do not generalize to non-standard dialects. Mismatch mainly occurs in the acoustic realization of words, which is represented by acoustic models and pronunciation lexicon. Standard techniques for addressing this mismatch are generative in nature and include acoustic model adaptation and expansion of lexicon with pronunciation variants, both of which have limited effectiveness. We present a discriminative pronunciation model whose parameters are learned jointly with parameters from the language models. We tease apart the gains from modeling the transitions of canonical phones, the transduction from surface to canonical phones, and the language model. We report experiments on African American Vernacular English (AAVE) using NPR's StoryCorps corpus. Our models improve the performance over the baseline by about 2.1% on AAVE, of which 0.6% can be attributed to the pronunciation model. The model learns the most relevant phonetic transformations for AAVE speech.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Encoding Linear Models As Weighted Finite-State Transducers
Interspeech 2014, ISCA, pp. 1258-1262
[u'Ke Wu', u'Cyril Allauzen', u'Keith Hall', u'Michael Riley', u'Brian Roark']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Fine Context, Low-rank, Softplus Deep Neural Networks for Mobile Speech Recognition
Proc. ICASSP (2014) (to appear)
[u'Andrew Senior', u'Xin Lei']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42929.html
found
=========================
Frame by Frame Language Identification in Short Utterances using Deep Neural Networks
Neural Networks Special Issue: Neural Network Learning in Big Data (2014)
[u'Javier Gonzalez-Dominguez', u'Ignacio Lopez-Moreno', u'Pedro J. Moreno', u'Joaquin Gonzalez-Rodriguez']
SpeechProcessing
Abstract: This work addresses the use of deep neural networks (DNNs) in automatic language identification (LID) focused on short test utterances. Motivated by their recent success in acoustic modelling for speech recognition, we adapt DNNs to the problem of identifying the language in a given utterance from the short-term acoustic features. We show how DNNs are particularly suitable to perform LID in real-time applications, due to their capacity to emit a language identification posterior at each new frame of the test utterance. We then analyse different aspects of the system, such as the amount of required training data, the number of hidden layers, the relevance of contextual information and the effect of the test utterance duration. Finally, we propose several methods to combine frame-by-frame posteriors. Experiments are conducted on two different datasets: the public NIST Language Recognition Evaluation 2009 (3 seconds task) and a much larger corpus (of 5 million utterances) known as Google 5M LID, obtained from different Google Services. Reported results show relative improvements of DNNs versus the i-vector system of 40% in LRE09 3 second task and 76% in Google 5M LID.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
GMM-Free DNN Training
Proceedings of the International Conference on Acoustics,Speech and Signal Processing (2014)
[u'A. Senior', u'G. Heigold', u'M. Bacchiani', u'H. Liao']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42536.html
notfound
=========================
Improving DNN Speaker Independence with I-vector Inputs
Proc. ICASSP, IEEE (2014)
[u'Andrew Senior', u'Ignacio Lopez-Moreno']
SpeechProcessing
Abstract: We propose providing additional utterance-level features as inputs to a deep neural network (DNN) to facilitate speaker, channel and background normalization. Modifications of the basic algorithm are developed which result in significant reductions in word error rates (WERs). The algorithms are shown to combine well with speaker adaptation by backpropagation, resulting in a 9\% relative WER reduction. We address implementation of the algorithm for a streaming task.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41924.html
found
=========================
JustSpeak: Enabling Universal Voice Control on Android
W4A 2014
[u'Yu Zhong', u'T. V. Raman', u'Casey Burkhardt', u'Fadi Biadsy', u'Jeffrey P. Bigham']
SpeechProcessing
Abstract: In this paper we introduce JustSpeak, a universal voice control solution for non-visual access to the Android operating system. JustSpeak offers two contributions as compared to existing systems. First, it enables system wide voice control on Android that can accommodate any application. JustSpeak constructs the set of available voice commands based on application context; these commands are directly synthesized from on-screen labels and accessibility metadata, and require no further intervention from the application developer. Second, it provides more efficient and natural interaction with support of multiple voice commands in the same utterance. We present the system design of JustSpeak and describe its utility in various use cases. We then discuss the system level supports required by a service like JustSpeak on other platforms. By eliminating the target locating and pointing tasks, JustSpeak can significantly improve experience of graphic interface interaction for blind and motion-impaired users.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42535.html
notfound
=========================
Large-Scale Speaker Identification
Proc. ICASSP, IEEE (2014)
[u'Ludwig Schmidt', u'Matthew Sharifi', u'Ignacio Lopez-Moreno']
SpeechProcessing
Abstract: Speaker identification is one of the main tasks in speech processing. In addition to identification accuracy, large-scale applications of speaker identification give rise to another challenge: fast search in the database of speakers. In this paper, we propose a system based on i-vectors, a current approach for speaker identification, and locality sensitive hashing, an algorithm for fast nearest-neighbor search in high dimensions. The connection between the two techniques is the cosine distance: one the one hand, we use the cosine distance to compare i-vectors, on the other hand, locality sensitive hashing allows us to quickly approximate the cosine distance in our retrieval procedure. We evaluate our approach on a realistic data set from YouTube with about 1000 speakers. The results show that our algorithm is approximately one to two orders of magnitude faster than a linear search while maintaining the identification accuracy of an i-vector-based system.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Long Short-Term Memory Based Recurrent Neural Network Architectures for Large Vocabulary Speech Recognition
CoRR, vol. abs/1402.1128 (2014)
[u'Hasim Sak', u'Andrew W. Senior', u'Franoise Beaufays']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Long short-term memory recurrent neural network architectures for large scale acoustic modeling
INTERSPEECH (2014), pp. 338-342
[u'Hasim Sak', u'Andrew W. Senior', u'Franoise Beaufays']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Pronunciation Learning for Named-Entities through Crowd-Sourcing
Proceedings of Interspeech (2014)
[u'Attapol Rutherford', u'Fuchun Peng', u'Franoise Beaufays']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42547.html
found
=========================
Sequence Discriminative Distributed Training of Long Short-Term Memory Recurrent Neural Networks
Interspeech (2014)
[u'Hasim Sak', u'Oriol Vinyals', u'Georg Heigold', u'Andrew Senior', u'Erik McDermott', u'Rajat Monga', u'Mark Mao']
SpeechProcessing
Abstract: We recently showed that Long Short-Term Memory (LSTM) recurrent neural networks (RNNs) outperform state-of-the-art deep neural networks (DNNs) for large scale acoustic modeling where the models were trained with the cross-entropy (CE) criterion. It has also been shown that sequence discriminative training of DNNs initially trained with the CE criterion gives significant improvements. In this paper, we investigate sequence discriminative training of LSTM RNNs in a large scale acoustic modeling task. We train the models in a distributed manner using asynchronous stochastic gradient descent optimization technique. We compare two sequence discriminative criteria -- maximum mutual information and state-level minimum Bayes risk, and we investigate a number of variations of the basic training strategy to better understand issues raised by both the sequential model, and the objective function. We obtain significant gains over the CE trained LSTM RNN model using sequence discriminative training techniques.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Sinusoidal Interpolation Across Missing Data
International Workshop on Acoustic Signal Enhancement 2014 (IWAENC 2014), pp. 71-75
[u'W. Bastiaan Kleijn', u'Turaj Zakizadeh Shabestary', u'Jan Skoglund']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Small-Footprint Keyword Spotting using Deep Neural Networks
ICASSP, IEEE (2014)
[u'Guoguo Chen', u'Carolina Parada', u'Georg Heigold']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42624.html
found
=========================
Statistical Parametric Speech Synthesis
UKSpeech Conference, Edinburgh, UK (2014)
[u'Heiga Zen']
SpeechProcessing
Abstract: Statistical parametric speech synthesis has grown in popularity over the last years. In this tutorial, its system architecture is outlined, and then basic techniques used in the system, including algorithms for speech parameter generation, are described with simple examples.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42037.html
notfound
=========================
Training Data Selection Based On Context-Dependent State Matching
Proceedings of ICASSP 2014 (to appear)
[u'Olivier Siohan']
SpeechProcessing
Abstract: In this paper we construct a data set for semi-supervised acoustic model training by selecting spoken utterances from a massive collection of anonymized Google Voice Search utterances. Semi-supervised training usually retains high-confidence utterances which are presumed to have an accurate hypothesized transcript, a necessary condition for successful training. Selecting high confidence utterances can however restrict the diversity of the resulting data set. We propose to introduce a constraint enforcing that the distribution of the context-dependent state symbols obtained by running forced alignment of the hypothesized transcript matches a reference distribution estimated from a curated development set. The quality of the obtained training set is illustrated on large scale Voice Search recognition experiments and outperforms random selection of high-confidence utterances.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub42543.html
found
=========================
Word Embeddings for Speech Recognition
Proceedings of the 15th Conference of the International Speech Communication Association, Interspeech (2014)
[u'Samy Bengio', u'Georg Heigold']
SpeechProcessing
Abstract: Speech recognition systems have used the concept of states as a way to decompose words into sub-word units for decades. As the number of such states now reaches the number of words used to train acoustic models, it is interesting to consider approaches that relax the assumption that words are made of states. We present here an alternative construction, where words are projected into a continuous embedding space where words that sound alike are nearby in the Euclidean sense. We show how embeddings can still allow to score words that were not in the training dictionary. Initial experiments using a lattice rescoring approach and model combination on a large realistic dataset show improvements in word error rate.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Accurate and Compact Large Vocabulary Speech Recognition on Mobile Devices
Interspeech (2013)
[u'Xin Lei', u'Andrew Senior', u'Alexander Gruenstein', u'Jeffrey Sorensen']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
An Empirical study of learning rates in deep neural networks for speech recognition
Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), IEEE, Vancouver, CA (2013) (to appear)
[u'Andrew Senior', u'Georg Heigold', u"Marc'aurelio Ranzato", u'Ke Yang']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41539.html
found
=========================
Deep Learning in Speech Synthesis
8th ISCA Speech Synthesis Workshop, Barcelona, Spain (2013)
[u'Heiga Zen']
SpeechProcessing
Abstract: Deep learning has been a hot research topic in various machine learning related areas including general object recognition and automatic speech recognition. This talk will present recent applications of deep learning to statistical parametric speech synthesis and contrast the deep learning-based approaches to the existing hidden Markov model-based one.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Deep Neural Networks with Auxiliary Gaussian Mixture Models for Real-Time Speech Recognition
Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), IEEE, Vancouver, CA (2013)
[u'Xin Lei', u'Hui Lin', u'Georg Heigold']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41450.html
notfound
=========================
Direct construction of compact context-dependency transducers from data
Computer Speech & Language (2013) (to appear)
[u'David Rybach', u'Michael Riley', u'Chris Alberti']
SpeechProcessing
Abstract: This paper describes a new method for building compact context-dependency transducers for finite-state transducer-based ASR decoders. Instead of the conventional phonetic decision tree growing followed by FST compilation, this approach incorporates the phonetic context splitting directly into the transducer construction. The objective function of the split optimization is augmented with a regularization term that measures the number of transducer states introduced by a split. We give results on a large spoken-query task for various n-phone orders and other phonetic features that show this method can greatly reduce the size of the resulting context-dependency transducer with no significant impact on recognition accuracy. This permits using context sizes and features that might otherwise be unmanageable.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41096.html
found
=========================
Empirical Exploration of Language Modeling for the google.com Query Stream as Applied to Mobile Voice Search
Mobile Speech and Advanced Natural Language Solutions, Springer Science+Business Media, New York (2013), pp. 197-229
[u'Ciprian Chelba', u'Johan Schalkwyk']
SpeechProcessing
Abstract: Mobile is poised to become the predominant platform over which people are accessing the World Wide Web. Recent developments in speech recognition and understanding, backed by high bandwidth coverage and high quality speech signal acquisition on smartphones and tablets are presenting the users with the choice of speaking their web search queries instead of typing them. A critical component of a speech recognition system targeting web search is the language model. The chapter presents an empirical exploration of the google.com query stream with the end goal of high quality statistical language modeling for mobile voice search. Our experiments show that after text normalization the query stream is not as ``wild'' as it seems at first sight. One can achieve out-of-vocabulary rates below 1% using a one million word vocabulary, and excellent n-gram hit ratios of 77/88% even at high orders such as n=5/4, respectively. A more careful analysis shows that a significantly larger vocabulary (approx. 10 million words) may be required to guarantee at most 1% out-of-vocabulary rate for a large percentage (95%) of users. Using large scale, distributed language models can improve performance significantly---up to 10% relative reductions in word-error-rate over conventional models used in speech recognition. We also find that the query stream is non-stationary, which means that adding more past training data beyond a certain point provides diminishing returns, and may even degrade performance slightly. Perhaps less surprisingly, we have shown that locale matters significantly for English query data across USA, Great Britain and Australia. In an attempt to leverage the speech data in voice search logs, we successfully build large-scale discriminative N-gram language models and derive small but significant gains in recognition performance.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Language Model Verbalization for Automatic Speech Recognition
Proc ICASSP, IEEE (2013)
[u'Hasim Sak', u'Franoise Beaufays', u'Kaisuke Nakajima', u'Cyril Allauzen']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Language Modeling Capitalization
Proc ICASSP, IEEE (2013) (to appear)
[u'Franoise Beaufays', u'Brian Strope']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41133.html
found
=========================
Large Scale Distributed Acoustic Modeling With Back-off N-grams
ICSI, Berkeley, California (2013)
[u'Ciprian Chelba', u'Peng Xu', u'Fernando Pereira', u'Thomas Richardson']
SpeechProcessing
Abstract: Google Voice Search is an application that provides a data-rich setup for both language and acoustic modeling research. The approach we take revives an older approach to acoustic modeling that borrows from n-gram language modeling in an attempt to scale up both the amount of training data, and the model size (as measured by the number of parameters in the model), to approximately 100 times larger than current sizes used in automatic speech recognition. Speech recognition experiments are carried out in an N-best list rescoring framework for Google Voice Search. We use 87,000 hours of training data (speech along with transcription) obtained by filtering utterances in Voice Search logs on automatic speech recognition confidence. Models ranging in size between 20--40 million Gaussians are estimated using maximum likelihood training. They achieve relative reductions in word-error-rate of 11% and 6% when combined with first-pass models trained using maximum likelihood, and boosted maximum mutual information, respectively. Increasing the context size beyond five phones (quinphones) does not help.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Large scale deep neural network acoustic modeling with semi-supervised training data for YouTube video transcription
ASRU (2013)
[u'Hank Liao', u'Erik McDermott', u'Andrew Senior']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Mixture of mixture n-gram language models
ASRU (2013), pp. 31-36
[u'Hasim Sak', u'Cyril Allauzen', u'Kaisuke Nakajima', u'Franoise Beaufays']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Monitoring the Effects of Temporal Clipping on VoIP Speech Quality
Interspeech 2013, pp. 1188-1192
[u'Andrew Hines', u'Jan Skoglund', u'Anil Kokaram', u'Naomi Harte']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Multiframe Deep Neural Networks for Acoustic Modeling
Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), IEEE, Vancouver, CA (2013)
[u'Vincent Vanhoucke', u'Matthieu Devin', u'Georg Heigold']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Multilingual acoustic models using distributed deep neural networks
Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), IEEE, Vancouver, CA (2013)
[u'Georg Heigold', u'Vincent Vanhoucke', u'Andrew Senior', u'Patrick Nguyen', u"Marc'aurelio Ranzato", u'Matthieu Devin', u'Jeff Dean']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40811.html
found
=========================
On Rectified Linear Units For Speech Processing
38th International Conference on Acoustics, Speech and Signal Processing (ICASSP), Vancouver (2013)
[u'M.D. Zeiler', u'M. Ranzato', u'R. Monga', u'M. Mao', u'K. Yang', u'Q.V. Le', u'P. Nguyen', u'A. Senior', u'V. Vanhoucke', u'J. Dean', u'G.E. Hinton']
SpeechProcessing
Abstract: Deep neural networks have recently become the gold standard for acoustic modeling in speech recognition systems. The key computational unit of a deep network is a linear projection followed by a point-wise non-linearity, which is typically a logistic function. In this work, we show that we can improve generalization and make training of deep networks faster and simpler by substituting the logistic units with rectified linear units. These units are linear when their input is positive and zero otherwise. In a supervised setting, we can successfully train very deep nets from random initialization on a large vocabulary speech recognition task achieving lower word error rates than using a logistic network with the same topology. Similarly in an unsupervised setting, we show how we can learn sparse features that can be useful for discriminative tasks. All our experiments are executed in a distributed environment using several hundred machines and several hundred hours of speech data.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Pre-Initialized Composition for Large-Vocabulary Speech Recognition
Interspeech 2013, 666 670
[u'Cyril Allauzen', u'Michael Riley']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
RAPID ADAPTATION FOR MOBILE SPEECH APPLICATIONS
Proceedings of the International Conference on Acoustics,Speech and Signal Processing (2013)
[u'M. Bacchiani']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41648.html
found
=========================
Rate-Distortion Optimization for Multichannel Audio Compression
2013 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)
[u'Minyue Li', u'Jan Skoglund', u'W. Bastiaan Kleijn']
SpeechProcessing
Abstract: Multichannel audio coding is studied from a rate-distortion theoret- ical viewpoint. Two practical coding techniques, both of which are based on rate-distortion optimization, are also proposed. The first technique decorrelates a multichannel signal hierarchically using el- ementary unitary transforms. The second method rearranges a mul- tichannel signal into sub-signals and compresses them at optimized bit rates using a conventional codec. Both objective and subjective tests were conducted to illustrate the efficiency of the methods.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41186.html
found
=========================
Recurrent Neural Networks for Voice Activity Detection
ICASSP, IEEE (2013), pp. 7378-7382
[u'Thad Hughes', u'Keir Mierle']
SpeechProcessing
Abstract: We present a novel recurrent neural network (RNN) model for voice activity detection. Our multi-layer RNN model, in which nodes compute quadratic polynomials, outperforms a much larger baseline system composed of Gaussian mixture models (GMMs) and a hand-tuned state machine (SM) for temporal smoothing. All parameters of our RNN model are optimized together, so that it properly weights its preference for temporal continuity against the acoustic features in each frame. Our RNN uses one tenth the parameters and outperforms the GMM+SM baseline system by 26% reduction in false alarms, reducing overall speech recognition computation time by 17% while reducing word error rate by 1% relative.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Robustness of Speech Quality Metrics to Background Noise and Network Degradations: Comparing VISQOL, PESQ and POLQA
IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), IEEE (2013), pp. 3697-3701
[u'Andrew Hines', u'Jan Skoglund', u'Anil Kokaram', u'Naomi Harte']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Search Results Based N-Best Hypothesis Rescoring With Maximum Entropy Classification
Proceedings of ASRU (2013)
[u'Fuchun Peng', u'Scott Roy', u'Ben Shahshahani', u'Franoise Beaufays']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41345.html
found
=========================
Smoothed marginal distribution constraints for language modeling
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL) (2013), pp. 43-52
[u'Brian Roark', u'Cyril Allauzen', u'Michael Riley']
SpeechProcessing
Abstract: We present an algorithm for re-estimating parameters of backoff n-gram language models so as to preserve given marginal distributions, along the lines of well-known Kneser-Ney smoothing. Unlike Kneser-Ney, our approach is designed to be applied to any given smoothed backoff model, including models that have already been heavily pruned. As a result, the algorithm avoids issues observed when pruning Kneser-Ney models (Siivola et al., 2007; Chelba et al., 2010), while retaining the benefits of such marginal distribution constraints. We present experimental results for heavily pruned backoff n-gram models, and demonstrate perplexity and word error rate reductions when used with various baseline smoothing methods. An open-source version of the algorithm has been released as part of the OpenGrm ngram library.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Speaker Adaptation of Context Dependent Deep Neural Networks
International Conference of Acoustics, Speech, and Signal Processing. (2013)
[u'Hank Liao']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41117.html
found
=========================
Speech and Natural Language: Where Are We Now And Where Are We Headed?
Mobile Voice Conference, San Francisco (2013)
[u'Ciprian Chelba']
SpeechProcessing
Abstract: Slides from a presentation on invited panel at the Mobile Voice Conference 2013, San Francisco.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40837.html
notfound
=========================
Statistical Parametric Speech Synthesis Using Deep Neural Networks
Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), IEEE (2013), pp. 7962-7966
[u'Heiga Zen', u'Andrew Senior', u'Mike Schuster']
SpeechProcessing
Abstract: Conventional approaches to statistical parametric speech synthesis typically use decision tree-clustered context-dependent hidden Markov models (HMMs) to represent probability densities of speech parameters given texts. Speech parameters are generated from the probability densities to maximize their output probabilities, then a speech waveform is reconstructed from the generated parameters. This approach is reasonably effective but has a couple of limitations, e.g. decision trees are inef?cient to model complex context dependencies. This paper examines an alternative scheme that is based on a deep neural network (DNN). The relationship between input texts and their acoustic realizations is modeled by a DNN. The use of the DNN can address some limitations of the conventional approach. Experimental results show that the DNN-based systems outperformed the HMM-based systems with similar numbers of parameters.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Written-Domain Language Modeling for Automatic Speech Recognition
Interspeech (2013)
[u'Hasim Sak', u'Yun-hsuan Sung', u'Franoise Beaufays', u'Cyril Allauzen']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
iVector-based Acoustic Data Selection
Proceedings of Interspeech (2013)
[u'Olivier Siohan', u'Michiel Bacchiani']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38130.html
found
=========================
Application Of Pretrained Deep Neural Networks To Large Vocabulary Speech Recognition
Proceedings of Interspeech 2012
[u'Navdeep Jaitly', u'Patrick Nguyen', u'Andrew Senior', u'Vincent Vanhoucke']
SpeechProcessing
Abstract: The use of Deep Belief Networks (DBN) to pretrain Neural Networks has recently led to a resurgence in the use of Articial Neural Network - Hidden Markov Model (ANN/HMM) hybrid systems for Automatic Speech Recognition (ASR). In this paper we report results of a DBN-pretrained context-dependent ANN/HMM system trained on two datasets that are much larger than any reported previously with DBN-pretrained ANN/HMM systems - 5870 hours of Voice Search and 1400 hours of YouTube data. On the rst dataset, the pretrained ANN/HMM system outperforms the best Gaussian Mixture Model - Hidden Markov Model (GMM/HMM) baseline, built with a much larger dataset by 3.7% absolute WER, while on the second dataset, it outperforms the GMM/HMM baseline by 4.7% absolute. Maximum Mutual Information (MMI) ne tuning and model combination using Segmental Conditional Random Fields (SCARF) give additional gains of 0.1% and 0.4% on the rst dataset and 0.5% and 0.9% absolute on the second dataset.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40680.html
found
=========================
Buildling adaptive dialogue systems via Bayes-adaptive POMDP
IEEE Journal of Selected Topics in Signal Processing, vol. vol.6(8). 2012. (2012), pp. 917-927
[u'Shaowei Png', u'Joelle Pineau', u'B. Chaib-draa']
SpeechProcessing
Abstract: Recent research has shown that effective dialogue management can be achieved through the Partially Observable Markov Decision Process (POMDP) framework. However past research on POMDP-based dialogue systems usually assumed the parameters of the decision process were known a priori. The main contribution of this paper is to present a Bayesian reinforcement learning framework for learning the POMDP parameters online from data, in a decision-theoretic manner. We discuss various approximations and assumptions which can be leveraged to ensure computational tractability, and apply these techniques to learning observation models for several simulated spoken dialogue domains.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Chapter 17: Uncertainty Decoding, In Virtanen, Singh, & Raj (Eds.) Techniques for Noise Robustness in Automatic Speech Recognition.
Wiley (2012), pp. 463-485
[u'Hank Liao']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Continuous Space Discriminative Language Modeling
ICASSP 2012
[u'Puyang Xu', u'Sanjeev Khudanpur', u'Maider Lehr', u'Emily Prudhommeaux', u'Nathan Glenn', u'Damianos Karakos', u'Brian Roark', u'Kenji Sagae', u'Murat Saraclar', u'Izhak Shafran', u'Dan Bikel', u'Chris Callison-Burch', u'Yuan Cao', u'Keith Hall', u'Eva Hasler', u'Philipp Koehn', u'Adam Lopez', u'Matt Post', u'Darcey Riley']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38131.html
found
=========================
Deep Neural Networks for Acoustic Modeling in Speech Recognition
Signal Processing Magazine (2012)
[u'Geoffrey Hinton', u'Li Deng', u'Dong Yu', u'George Dahl', u'Abdel-rahman Mohamed', u'Navdeep Jaitly', u'Andrew Senior', u'Vincent Vanhoucke', u'Patrick Nguyen', u'Tara Sainath', u'Brian Kingsbury']
SpeechProcessing
Abstract: Most current speech recognition systems use hidden Markov models (HMMs) to deal with the temporal variability of speech and Gaussian mixture models to determine how well each state of each HMM ts a frame or a short window of frames of coefcients that represents the acoustic input. An alternative way to evaluate the t is to use a feedforward neural network that takes several frames of coefcients as input and produces posterior probabilities over HMM states as output. Deep neural networks with many hidden layers, that are trained using new methods have been shown to outperform Gaussian mixture models on a variety of speech recognition benchmarks, sometimes by a large margin. This paper provides an overview of this progress and represents the shared views of four research groups who have had recent successes in using deep neural networks for acoustic modeling in speech recognition.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37681.html
notfound
=========================
Distributed Acoustic Modeling with Back-off N-grams
Proceedings of ICASSP 2012, IEEE, pp. 4129-4132
[u'Ciprian Chelba', u'Peng Xu', u'Fernando Pereira', u'Thomas Richardson']
SpeechProcessing
Abstract: The paper proposes an approach to acoustic modeling that borrows from n-gram language modeling in an attempt to scale up both the amount of training data and model size (as measured by the number of parameters in the model) to approximately 100 times larger than current sizes used in ASR. Dealing with unseen phonetic contexts is accomplished using the familiar back-off technique used in language modeling due to implementation simplicity. The new acoustic model is estimated and stored using the MapReduce distributed computing infrastructure. Speech recognition experiments are carried out in an Nbest rescoring framework for Google Voice Search. 87,000 hours of training data is obtained in an unsupervised fashion by ltering utterances in Voice Search logs on ASR condence. The resulting models are trained using maximum likelihood and contain 20-40 million Gaussians. They achieve relative reductions in WER of 11% and 6% over first-pass models trained using maximum likelihood, and boosted MMI, respectively.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37682.html
notfound
=========================
Distributed Discriminative Language Models for Google Voice Search
Proceedings of ICASSP 2012, IEEE, pp. 5017-5021
[u'Preethi Jyothi', u'Leif Johnson', u'Ciprian Chelba', u'Brian Strope']
SpeechProcessing
Abstract: This paper considers large-scale linear discriminative language models trained using a distributed perceptron algorithm. The algorithm is implemented efficiently using a MapReduce/SSTable framework. This work also introduces the use of large amounts of unsupervised data (confidence filtered Google voice-search logs) in conjunction with a novel training procedure that regenerates word lattices for the given data with a weaker acoustic model than the one used to generate the unsupervised transcriptions for the logged data. We observe small but statistically significant improvements in recognition performance after reranking N-best lists of a standard Google voice-search data set.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Estimating Word-Stability During Incremental Speech Recognition
Interspeech (2012)
[u'Ian McGraw', u'Alexander Gruenstein']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38079.html
notfound
=========================
Google's Cross-Dialect Arabic Voice Search
IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2012), pp. 4441-4444
[u'Fadi Biadsy', u'Pedro J. Moreno', u'Martin Jansche']
SpeechProcessing
Abstract: We present a large scale effort to build a commercial Automatic Speech Recognition (ASR) product for Arabic. Our goal is to support voice search, dictation, and voice control for the general Arabic-speaking public, including support for multiple Arabic dialects. We describe our ASR system design and compare recognizers for five Arabic dialects, with the potential to reach more than 125 million people in Egypt, Jordan, Lebanon, Saudi Arabia, and the United Arab Emirates (UAE). We compare systems built on diacritized vs. non-diacritized text. We also conduct cross-dialect experiments, where we train on one dialect and test on the others. Our average word error rate (WER) is 24.8% for voice search.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Hallucinated N-Best Lists for Discriminative Language Modeling
Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP) (2012)
[u'Kenji Sagae', u'Maider Lehr', u'Emily Tucker Prudhommeaux', u'Puyang Xu', u'Nathan Glenn', u'Damianos Karakos', u'Sanjeev Khudanpur', u'Brian Roark', u'Murat Saralar', u'Izhak Shafran', u'Daniel M. Bikel', u'Chris Callison-Burch', u'Yuan Cao', u'Keith Hall', u'Eva Hassler', u'Philipp Koehn', u'Adam Lopez', u'Matt Post', u'Darcey Riley']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Haptic Voice Recognition Grand Challenge
14th ACM International Conference on Multimodal Interaction. (2012)
[u'K. Sim', u'S. Zhao', u'K. Yu', u'H. Liao']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
IMPROVED PREDICTION OF NEARLY-PERIODIC SIGNALS
International Workshop on Acoustic Signal Enhancement 2012 (IWAENC2012)
[u'Bastiaan Kleijn', u'Jan Skoglund']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37825.html
notfound
=========================
Investigations on Exemplar-Based Features for Speech Recognition Towards Thousands of Hours of Unsupervised, Noisy Data
Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), IEEE, Kyoto, Japan (2012), pp. 4437-4440
[u'Georg Heigold', u'Patrick Nguyen', u'Mitchel Weintraub', u'Vincent Vanhoucke']
SpeechProcessing
Abstract: The acoustic models in state-of-the-art speech recognition systems are based on phones in context that are represented by hidden Markov models. This modeling approach may be limited in that it is hard to incorporate long-span acoustic context. Exemplar-based approaches are an attractive alternative, in particular if massive data and computational power are available. Yet, most of the data at Google are unsupervised and noisy. This paper investigates an exemplar-based approach under this yet not well understood data regime. A log-linear rescoring framework is used to combine the exemplar-based features on the word level with the first-pass model. This approach guarantees at least baseline performance and focuses on the refined modeling of words with sufficient data. Experimental results for the Voice Search and the YouTube tasks are presented.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Japanese and Korean Voice Search
International Conference on Acoustics, Speech and Signal Processing, IEEE (2012), pp. 5149-5152
[u'Mike Schuster', u'Kaisuke Nakajima']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40380.html
found
=========================
Language Modeling for Automatic Speech Recognition Meets the Web: Google Search by Voice
University of Toronto (2012)
[u'Ciprian Chelba', u'Johan Schalkwyk', u'Boulos Harb', u'Carolina Parada', u'Cyril Allauzen', u'Leif Johnson', u'Michael Riley', u'Peng Xu', u'Preethi Jyothi', u'Thorsten Brants', u'Vida Ha', u'Will Neveitt']
SpeechProcessing
Abstract: A critical component of a speech recognition system targeting web search is the language model. The talk presents an empirical exploration of the google.com query stream with the end goal of high quality statistical language modeling for mobile voice search. Our experiments show that after text normalization the query stream is not as ``wild'' as it seems at first sight. One can achieve out-of-vocabulary rates below 1% using a one million word vocabulary, and excellent n-gram hit ratios of 77/88% even at high orders such as n=5/4, respectively. Using large scale, distributed language models can improve performance significantly---up to 10\% relative reductions in word-error-rate over conventional models used in speech recognition. We also find that the query stream is non-stationary, which means that adding more past training data beyond a certain point provides diminishing returns, and may even degrade performance slightly. Perhaps less surprisingly, we have shown that locale matters significantly for English query data across USA, Great Britain and Australia. In an attempt to leverage the speech data in voice search logs, we successfully build large-scale discriminative N-gram language models and derive small but significant gains in recognition performance.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40491.html
found
=========================
Large Scale Language Modeling in Automatic Speech Recognition
Google (2012)
[u'Ciprian Chelba', u'Dan Bikel', u'Maria Shugrina', u'Patrick Nguyen', u'Shankar Kumar']
SpeechProcessing
Abstract: Large language models have been proven quite beneficial for a variety of automatic speech recognition tasks in Google. We summarize results on Voice Search and a few YouTube speech transcription tasks to highlight the impact that one can expect from increasing both the amount of training data, and the size of the language model estimated from such data. Depending on the task, availability and amount of training data used, language model size and amount of work and care put into integrating them in the lattice rescoring step we observe reductions in word error rate between 6% and 10% relative, for systems on a wide range of operating points between 17% and 52% word error rate.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38145.html
found
=========================
Large-scale Discriminative Language Model Reranking for Voice Search
Proceedings of the NAACL-HLT 2012 Workshop: Will We Ever Really Replace the N-gram Model? On the Future of Language Modeling for HLT, Association for Computational Linguistics, pp. 41-49
[u'Preethi Jyothi', u'Leif Johnson', u'Ciprian Chelba', u'Brian Strope']
SpeechProcessing
Abstract: We present a distributed framework for large-scale discriminative language models that can be integrated within a large vocabulary continuous speech recognition (LVCSR) system using lattice rescoring. We intentionally use a weakened acoustic model in a baseline LVCSR system to generate candidate hypotheses for voice-search data; this allows us to utilize large amounts of unsupervised data to train our models. We propose an efficient and scalable MapReduce framework that uses a perceptron-style distributed training strategy to handle these large amounts of data. We report small but significant improvements in recognition accuracies on a standard voice-search data set using our discriminative reranking model. We also provide an analysis of the various parameters of our models including model size, types of features, size of partitions in the MapReduce framework with the help of supporting experiments.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36901.html
notfound
=========================
Learning improved linear transforms for speech recognition
ICASSP, IEEE (2012)
[u'Andrew Senior', u'Youngmin Cho', u'Jason Weston']
SpeechProcessing
Abstract: This paper explores a large margin approach to learning a linear transform for dimensionality reduction. The method assumes a trained Gaussian mixture model for the each class to be discriminated and trains a linear transform with respect to the model using stochastic gradient descent. Results are presented showing improvements in state classification for individual frames and reduced word error rate in a large vocabulary speech recognition problem after maximum likelihood training and boosted maximum mutual information training.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Music Models for Music-Speech Separation
ICASSP, IEEE (2012), pp. 4917-4920
[u'Thad Hughes', u'Trausti Kristjansson']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40492.html
found
=========================
Optimal Size, Freshness and Time-frame for Voice Search Vocabulary
Google (2012)
[u'Maryam Kamvar', u'Ciprian Chelba']
SpeechProcessing
Abstract: In this paper, we investigate how to optimize the vocabulary for a voice search language model. The metric we optimize over is the out-of-vocabulary (OoV) rate since it is a strong indicator of user experience. In a departure from the usual way of measuring OoV rates, web search logs allow us to compute the per-session OoV rate and thus estimate the percentage of users that experience a given OoV rate. Under very conservative text normalization, we nd that a voice search vocabulary consisting of 2 to 2.5M words extracted from 1 week of search query data will result in an aggregate OoV rate of 0.01; at that size, the same OoV rate will also be experienced by 90% of users. The number of words included in the vocabulary is a stable indicator of the OoV rate. Altering the freshness of the vocabulary or the duration of the time window over which the training data is gathered does not signicantly change the OoV rate. Surprisingly, a signicantly larger vocabulary (approx. 10 million words) is required to guarantee OoV rates below 0.01 (1%) for 95% of the users.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37830.html
notfound
=========================
Recognition of Multilingual Speech in Mobile Applications
ICASSP (2012)
[u'Hui Lin', u'Jui-Ting Huang', u'Francoise Beaufays', u'Brian Strope', u'Yun-hsuan Sung']
SpeechProcessing
Abstract: We evaluate different architectures to recognize multilingual speech for real-time mobile applications. In particular, we show that combining the results of several recognizers greatly outperforms other solutions such as training a single large multilingual system or using an explicit language identification system to select the appropriate recognizer. Experiments are conducted on a trilingual English-French-Mandarin mobile speech task. The data set includes Google searches, Maps queries, as well as more general inputs such as email and short message dictation. Without pre-specifying the input language, the combined system achieves comparable accu- racy to that of the monolingual systems when the input language is known. The combined system is also roughly 5% absolute better than an explicit language identification approach, and 10% better than a single large multilingual system.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Semi-supervised Discriminative Language Modeling for Turkish ASR
2012 IEEE International Conference on Acoustics, Speech, and Signal Processing Proceedings, IEEE, Kyoto, Japan
[u'Murat Saralar', u'Daniel M. Bikel', u'Keith Hall', u'Kenji Sagae']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub39988.html
found
=========================
Spectral Intersections for Non-Stationary Signal Separation
Proceedings of InterSpeech 2012, Portland, OR
[u'Trausti Kristjansson', u'Thad Hughes']
SpeechProcessing
Abstract: We describe a new method for non-stationary noise suppression that is simple to implement yet has performance rivaling far more complex algorithms. Spectral Intersections is a model based MMSE signal separation method that uses a new simple approximation to the observation likelihood. Furthermore, Spectral Intersections uses an efficient approximation to the expectation integral of the MMSE estimate that could be described as unscented importance sampling. We apply the new method to the task of separating speech mixed with music. We report results on the Google Voice Search task where the new method provides a 7% relative reduction in WER at 10dB SNR. Interestingly, the new method provides considerably greater reduction in average WER than the MAX method and approaches the performance of the more complex Algonquin algorithm.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub40362.html
notfound
=========================
Speech/Nonspeech Segmentation in Web Videos
Proceedings of InterSpeech 2012
[u'Ananya Misra']
SpeechProcessing
Abstract: Speech transcription of web videos requires rst detecting segments with transcribable speech. We refer to this as segmentation. Commonly used segmentation techniques are inadequate for domains such as YouTube, where videos may have a large variety of background and recording conditions. In this work, we investigate alternative audio features and a discriminative classier, which together yield a lower frame error rate (25.3%) on YouTube videos compared to the commonly used Gaussian mixture models trained on cepstral features (30.6%). The alternative audio features perform particularly well in noisy conditions.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
VISQOL: THE VIRTUAL SPEECH QUALITY OBJECTIVE LISTENER
International Workshop on Acoustic Signal Enhancement 2012 (IWAENC2012)
[u'Andrew Hines', u'Jan Skoglund', u'Anil Kokaram', u'Naomi Harte']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Voice Query Refinement
Interspeech (2012)
[u'Cyril Allauzen', u'Edward Benson', u'Ciprian Chelba', u'Michael Riley', u'Johan Schalkwyk']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub38078.html
notfound
=========================
A Web-Based Tool for Developing Multilingual Pronunciation Lexicons
12th Annual Conference of the International Speech Communication Association (Interspeech 2011), pp. 3331-3332
[u'Samantha Ainsley', u'Linne Ha', u'Martin Jansche', u'Ara Kim', u'Masayuki Nanzawa']
SpeechProcessing
Abstract: We present a web-based tool for generating and editing pronunciation lexicons in multiple languages. The tool is implemented as a web application on Google App Engine and can be accessed remotely from a web browser. The client application displays to users a textual prompt and interface that reconfigures based on language and task. It lets users generate pronunciations via constrained phoneme selection, which allows users with no special training to provide phonemic transcriptions efficiently and accurately.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37567.html
notfound
=========================
Bayesian Language Model Interpolation for Mobile Speech Input
Interspeech 2011, pp. 1429-1432
[u'Cyril Allauzen', u'Michael Riley']
SpeechProcessing
Abstract: This paper explores various static interpolation methods for approximating a single dynamically-interpolated language model used for a variety of recognition tasks on the Google Android platform. The goal is to nd the statically-interpolated rstpass LM that best reduces search errors in a two-pass system or that even allows eliminating the more complex dynamic second pass entirely. Static interpolation weights that are uniform, prior-weighted, and the maximum likelihood, maximum a posteriori, and Bayesian solutions are considered. Analysis argues and recognition experiments on Android test data show that a Bayesian interpolation approach performs best.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37116.html
notfound
=========================
Deploying Google Search by Voice in Cantonese
12th Annual Conference of the International Speech Communication Association (Interspeech 2011), pp. 2865-2868
[u'Yun-hsuan Sung', u'Martin Jansche', u'Pedro Moreno']
SpeechProcessing
Abstract: We describe our efforts in deploying Google search by voice for Cantonese, a southern Chinese dialect widely spoken in and around Hong Kong and Guangzhou. We collected audio data from local Cantonese speakers in Hong Kong and Guangzhou by using our DataHound smartphone application. This data was used to create appropriate acoustic models. Language models were trained on anonymized query logs from Google Web Search for Hong Kong. Because users in Hong Kong frequently mix English and Cantonese in their queries, we designed our system from the ground up to handle both languages. We report on experiments with different techniques for mapping the phoneme inventories for both languages into a common space. Based on extensive experiments we report word error rates and web scores for both Hong Kong and Guangzhou data. Cantonese Google search by voice was launched in December 2010.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Discriminative Features for Language Identification
INTERSPEECH (2011)
[u'C. Alberti', u'M. Bacchiani']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37631.html
notfound
=========================
Improving the speed of neural networks on CPUs
Deep Learning and Unsupervised Feature Learning Workshop, NIPS 2011
[u'Vincent Vanhoucke', u'Andrew Senior', u'Mark Z. Mao']
SpeechProcessing
Abstract: Recent advances in deep learning have made the use of large, deep neural networks with tens of millions of parameters suitable for a number of applications that require real-time processing. The sheer size of these networks can represent a challenging computational burden, even for modern CPUs. For this reason, GPUs are routinely used instead to train and run such networks. This paper is a tutorial for students and researchers on some of the techniques that can be used to reduce this computational cost considerably on modern x86 CPUs. We emphasize data layout, batching of the computation, the use of SSE2 instructions, and particularly leverage SSSE3 and SSE4 xed-point instructions which provide a 3X improvement over an optimized oating-point baseline. We use speech recognition as an example task, and show that a real-time hybrid hidden Markov model / neural network (HMM/NN) large vocabulary system can be built with a 10X speedup over an unoptimized baseline and a 4X speedup over an aggressively optimized oating-point baseline at no cost in accuracy. The techniques described extend readily to neural network training and provide an effective alternative to the use of specialized hardware.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub37075.html
notfound
=========================
Language Modeling for Automatic Speech Recognition Meets the Web: Google Search by Voice
OGI/OHSU Seminar Series, Portland, Oregon, USA (2011)
[u'Ciprian Chelba', u'Johan Schalkwyk', u'Boulos Harb', u'Carolina Parada', u'Cyril Allauzen', u'Michael Riley', u'Peng Xu', u'Thorsten Brants', u'Vida Ha', u'Will Neveitt']
SpeechProcessing
Abstract: The talk presents key aspects faced when building language models (LM) for the google.com query stream, and their use for automatic speech recognition (ASR). Distributed LM tools enable us to handle a huge amount of data, and experiment with LMs that are two orders of magnitude larger than usual. An empirical exploration of the problem led us to re-discovering a less known interaction between Kneser-Ney smoothing and entropy pruning, possible non-stationarity of the query stream, as well as strong dependence on various English locales---USA, Britain and Australia. LM compression techniques allowed us to use one billion n-gram LMs in the first pass of an ASR system built on FST technology, and evaluate empirically whether a two-pass system architecture has any losses over one pass.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Recognizing English Queries in Mandarin Voice Search
ICASSP (2011)
[u'Hung-An Chang', u'Yun-hsuan Sung', u'Brian Strope', u'Francoise Beaufays']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Speech Retrieval
Spoken Language Understanding, John Wiley and Sons, Ltd (2011), pp. 417-446
[u'Ciprian Chelba', u'Timothy J. Hazen', u'Bhuvana Ramabhadran', u'Murat Saralar']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub41650.html
found
=========================
Summary of Opus listening test results
IETF, IETF (2011)
[u'Christian Hoene', u'Jean-Marc Valin', u'Koen Vos', u'Jan Skoglund']
SpeechProcessing
Abstract: This document describes and examines listening test results obtained for the Opus codec and how they relate to the requirements.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
TechWare: Mobile Media Search Resources [Best of the Web]
IEEE Signal Processing Magazine, vol. 28 (2011), pp. 142-145
[u'Z. Liu', u'M. Bacchiani']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Unsupervised Testing Strategies for ASR
Interspeech 2011, pp. 1685-1688
[u'Brian Strope', u'Doug Beeferman', u'Alexander Gruenstein', u'Xin Lei']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36913.html
notfound
=========================
Challenges in Automatic Speech Recognition
Interspeech 2010
[u'Ciprian Chelba', u'Johan Schalkwyk', u'Michiel Bacchiani']
SpeechProcessing
Abstract: ISCA Student panel presentation slides
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36828.html
notfound
=========================
Decision Tree State Clustering with Word and Syllable Features
Interspeech, ISCA (2010), 2958 2961
[u'Hank Liao', u'Chris Alberti', u'Michiel Bacchiani', u'Olivier Siohan']
SpeechProcessing
Abstract: In large vocabulary continuous speech recognition, decision trees are widely used to cluster triphone states. In addition to commonly used phonetically based questions, others have proposed additional questions such as phone position within word or syllable. This paper examines using the word or syllable context itself as a feature in the decision tree, providing an elegant way of introducing word- or syllable-specific models into the system. Positive results are reported on two state-of-the-art systems: voicemail transcription and a search by voice tasks across a variety of acoustic model and training set sizes.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Discriminative Topic Segmentation of Text and Speech
International Conference on Artificial Intelligence and Statistics (AISTATS) (2010)
[u'Mehryar Mohri', u'Pedro Moreno', u'Eugene Weinstein']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Google Search by Voice: A Case Study
Advances in Speech Recognition: Mobile Environments, Call Centers and Clinics, Springer (2010), pp. 61-90
[u'Johan Schalkwyk', u'Doug Beeferman', u'Francoise Beaufays', u'Bill Byrne', u'Ciprian Chelba', u'Mike Cohen', u'Maryam Garrett', u'Brian Strope']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36756.html
notfound
=========================
On-Demand Language Model Interpolation for Mobile Speech Input
Interspeech (2010), pp. 1812-1815
[u'Brandon Ballinger', u'Cyril Allauzen', u'Alexander Gruenstein', u'Johan Schalkwyk']
SpeechProcessing
Abstract: Google offers several speech features on the Android mobile operating system: search by voice, voice input to any text field, and an API for application developers. As a result, our speech recognition service must support a wide range of usage scenarios and speaking styles: relatively short search queries, addresses, business names, dictated SMS and e-mail messages, and a long tail of spoken input to any of the applications users may install. We present a method of on-demand language model interpolation in which contextual information about each utterance determines interpolation weights among a number of n-gram language models. On-demand interpolation results in an 11.2% relative reduction in WER compared to using a single language model to handle all traffic.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36463.html
notfound
=========================
Search by Voice in Mandarin Chinese
Interspeech 2010, pp. 354-357
[u'Jiulong Shan', u'Genqing Wu', u'Zhihong Hu', u'Xiliu Tang', u'Martin Jansche', u'Pedro J. Moreno']
SpeechProcessing
Abstract: In this paper we describe our efforts to build a Mandarin Chinese voice search system. We describe our strategies for data collection, language, lexicon and acoustic modeling, as well as issues related to text normalization that are an integral part of building voice search systems. We show excellent performance on typical spoken search queries under a variety of accents and acoustic conditions. The system has been in operation since October 2009 and has received very positive user reviews.
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub36487.html
notfound
=========================
Unsupervised Discovery and Training of Maximally Dissimilar Cluster Models
Proc Interspeech (2010)
[u'Francoise Beaufays', u'Vincent Vanhoucke', u'Brian Strope']
SpeechProcessing
Abstract: One of the difficult problems of acoustic modeling for Automatic Speech Recognition (ASR) is how to adequately model the wide variety of acoustic conditions which may be present in the data. The problem is especially acute for tasks such as Google Search by Voice, where the amount of speech available per transaction is small, and adaptation techniques start showing their limitations. As training data from a very large user population is available however, it is possible to identify and jointly model subsets of the data with similar acoustic qualities. We describe a technique which allows us to perform this modeling at scale on large amounts of data by learning a treestructured partition of the acoustic space, and we demonstrate that we can significantly improve recognition accuracy in various conditions through unsupervised Maximum Mutual Information (MMI) training. Being fully unsupervised, this technique scales easily to increasing numbers of conditions.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
A new quality measure for topic segmentation of text and speech
Conference of the International Speech Communication Association (Interspeech) (2009)
[u'Mehryar Mohri', u'Pedro J. Moreno', u'Eugene Weinstein']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34562.html
notfound
=========================
Restoring Punctuation and Capitalization in Transcribed Speech
IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP) (2009), pp. 4741-4744
[u'Agustn Gravano', u'Martin Jansche', u'Michiel Bacchiani']
SpeechProcessing
Abstract: Adding punctuation and capitalization greatly improves the readability of automatic speech transcripts. We discuss an approach for performing both tasks in a single pass using a purely text-based n-gram language model. We study the effect on performance of varying the n-gram order (from n = 3 to n = 6) and the amount of training data (from 58 million to 55 billion tokens). Our results show that using larger training data sets consistently improves performance, while increasing the n-gram order does not help nearly as much.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Revisiting Graphemes with Increasing Amounts of Data
ICASSP, IEEE (2009)
[u'Yun-Hsuan Sung', u'Thad Hughes', u'Francoise Beaufays', u'Brian Strope']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
http://research.google.com/pubs/pub34837.html
notfound
=========================
Web-derived Pronunciations
IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP) (2009), pp. 4289-4292
[u'Arnab Ghoshal', u'Martin Jansche', u'Sanjeev Khudanpur', u'Michael Riley', u'Morgan Ulinski']
SpeechProcessing
Abstract: Pronunciation information is available in large quantities on the Web, in the form of IPA and ad-hoc transcriptions. We describe techniques for extracting candidate pronunciations from Web pages and associating them with orthographic words, filtering out poorly extracted pronunciations, normalizing IPA pronunciations to better conform to a common transcription standard, and generating phonemic from ad-hoc transcriptions. We show improvements on a letter-to-phoneme task when using web-derived vs. Pronlex pronunciations.
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Confidence Scores for Acoustic Model Adaptation
Proceedings of the International Conference on Acoustics,Speech and Signal Processing (2008)
[u'C. Gollan', u'M. Bacchiani']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Deploying GOOG-411: Early Lessons in Data, Measurement, and Testing
Proc. ICASSP (2008)
[u'Michiel Bacchiani', u'Francoise Beaufays', u'Johan Schalkwyk', u'Mike Schuster', u'Brian Strope']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Retrieval and Browsing of Spoken Content
Signal Processing Magazine, IEEE, vol. 25 (2008), pp. 39-49
[u'Ciprian Chelba', u'Timothy J. Hazen', u'Murat Saralar']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Speech Recognition with Weighted Finite-State Transducers
Handbook on Speech Processing and Speech Communication, Part E: Speech recognition, Springer-Verlag, Heidelberg, Germany (2008)
[u'Mehryar Mohri', u'Fernando C. N. Pereira', u'Michael Riley']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
=========================
Speech Recognition with Weighted Finite-State Transducers
Handbook on Speech Processing and Speech Communication, Part E: Speech recognition, Springer-Verlag, Heidelberg, Germany (2007)
[u'Mehryar Mohri', u'Fernando C. N. Pereira', u'Michael Riley']
SpeechProcessing
Not found
^^^^^^^^^^^^^^^^^^^^^^^^
