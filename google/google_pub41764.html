<!DOCTYPE html>
<html class="google" lang="en">
  <head>

    <script>
    (function(H){H.className=H.className.replace(/\bgoogle\b/,'google-js')})(document.documentElement)
    </script>
    <meta charset="utf-8">
    <meta content="initial-scale=1, minimum-scale=1, width=device-width" name="viewport">
    <title>
      The Intervalgram: An Audio Feature for Large-Scale Cover-Song Recognition
    </title>
    <script src="//www.google.com/js/google.js">
    </script>
    <script>
    new gweb.analytics.AutoTrack({profile:"UA-5974346-1"});
    </script>
    <link href="//fonts.googleapis.com/css?family=Open+Sans:300,400,600,700&amp;lang=en" rel=
    "stylesheet">
    <link href="/css/research.css" rel="stylesheet">
  </head>
  <body>
    <div class="maia-header" id="maia-header" role="banner">
      <div class="maia-aux">
        <h1>
          <a href="/" id="logo"><img alt="Research at Google" src=
          "/images/research_at_google.png"></a>
        </h1><a class="maia-teleport" href="#content">Skip to content</a>
        <div class="maia-util">
          <form class="maia-search" id="search" name="search">
            <input id="q" name="q" placeholder="Search this site" value=""> <input class=
            "maia-button" type="submit" value="Search">
          </form>
        </div>
      </div>
    </div>
    <div class="maia-nav maia-complex" id="maia-nav-x" role="navigation">
      <div class="maia-aux">
        <ul>
          <li>
            <a href="/index.html">Home</a>
          </li>
          <li class="active" id="ra">
            <a href="/pubs/papers.html">Research Areas &amp; Publications</a> <span class=
            "glyph">&nbsp;</span>
            <div class="hidden">
              <ul id="ramenu">
                <li class="fill">
                  <a href="/pubs/papers.html">Overview</a>
                </li>
                <li class="expand fill">
                  <a href="/pubs/AlgorithmsandTheory.html">Algorithms and Theory</a>
                </li>
                <li class="expand fill">
                  <a href="/pubs/DataManagement.html">Data Management</a>
                </li>
                <li class="expand fill">
                  <a href="/pubs/DataMiningandModeling.html">Data Mining and Modeling</a>
                </li>
                <li class="expand fill">
                  <a href="/pubs/DistributedSystemsandParallelComputing.html">Distributed Systems
                  and Parallel Computing</a>
                </li>
                <li class="expand fill">
                  <a href="/pubs/EconomicsandElectronicCommerce.html">Economics and Electronic
                  Commerce</a>
                </li>
                <li class="expand fill">
                  <a href="/pubs/EducationInnovation.html">Education Innovation</a>
                </li>
                <li class="expand fill">
                  <a href="/pubs/GeneralScience.html">General Science</a>
                </li>
                <li class="expand fill">
                  <a href="/pubs/HardwareandArchitecture.html">Hardware and Architecture</a>
                </li>
                <li class="expand fill">
                  <a href="/pubs/Human-ComputerInteractionandVisualization.html">Human-Computer
                  Interaction and Visualization</a>
                </li>
                <li class="expand fill">
                  <a href="/pubs/InformationRetrievalandtheWeb.html">Information Retrieval and the
                  Web</a>
                </li>
                <li class="expand fill">
                  <a href="/pubs/MachineIntelligence.html">Machine Intelligence</a>
                </li>
                <li class="expand fill">
                  <a href="/pubs/MachinePerception.html">Machine Perception</a>
                </li>
                <li class="expand fill">
                  <a href="/pubs/MachineTranslation.html">Machine Translation</a>
                </li>
                <li class="expand fill">
                  <a href="/pubs/MobileSystems.html">Mobile Systems</a>
                </li>
                <li class="expand fill">
                  <a href="/pubs/NaturalLanguageProcessing.html">Natural Language Processing</a>
                </li>
                <li class="expand fill">
                  <a href="/pubs/Networking.html">Networking</a>
                </li>
                <li class="expand fill">
                  <a href="/pubs/SecurityPrivacyandAbusePrevention.html">Security, Privacy and
                  Abuse Prevention</a>
                </li>
                <li class="expand fill">
                  <a href="/pubs/SoftwareEngineering.html">Software Engineering</a>
                </li>
                <li class="expand fill">
                  <a href="/pubs/SoftwareSystems.html">Software Systems</a>
                </li>
                <li class="expand fill">
                  <a href="/pubs/SpeechProcessing.html">Speech Processing</a>
                </li>
              </ul>
            </div>
          </li>
          <li>
            <a href="/researchers.html">People</a>
          </li>
          <li>
            <a href="/university/">Research Programs</a>
          </li>
          <li>
            <a href="/workatgoogle.html">Work at Google</a>
          </li>
        </ul>
      </div>
    </div>
    <div id="maia-main" role="main">
      <div class="maia-teleport" id="content"></div>
      <div id="cse">
        &nbsp;
      </div>
      <h1>
        Publication Data
      </h1>
      <div class="maia-cols">
        <div class="maia-col-4">
          <div>
            <div class="sidebar">
              <h3>
                Venue
              </h3>
              <p>
                <span class="booktitle">From Sounds to Music and Emotions: 9th International
                Symposium, CMMR 2012, London, UK, June 19-22, 2012, Revised Selected Papers</span>,
                Springer Berlin Heidelberg <span class="year">(2013)</span>, pp. 197-213
              </p>
              <h3>
                Publication Year
              </h3>
              <p>
                2013
              </p>
              <h3>
                Authors
              </h3>
              <p>
                <a href="/pubs/author38237.html" rel="author">Thomas C. Walters</a>, <a href=
                "/pubs/author23969.html" rel="author">David A. Ross</a>, <a href=
                "/pubs/author35932.html" rel="author">Richard F. Lyon</a>
              </p>
              <h3>
                BibTeX
              </h3>
              <textarea cols="38" rows="15">
@incollection{41764,
title = {The Intervalgram: An Audio Feature for Large-Scale Cover-Song Recognition},
author  = {Thomas C. Walters and David A. Ross and Richard F. Lyon},
year  = 2013,
URL = {http://link.springer.com/chapter/10.1007/978-3-642-41248-6_11},
booktitle = {From Sounds to Music and Emotions: 9th International Symposium, CMMR 2012, London, UK, June 19-22, 2012, Revised Selected Papers},
pages = {197-213}
}

</textarea>
            </div>
          </div>
        </div>
        <div class="maia-col-8">
          <h2 class="abstract-heading">
            <a class="search-icon tooltip" href=
            "http://www.google.com/search?lr&amp;ie=UTF-8&amp;oe=UTF-8&amp;q=The+Intervalgram:+An+Audio+Feature+for+Large-Scale+Cover-Song+Recognition+Walters+Ross+Lyon">
            &nbsp;</a><a class="pdf-icon tooltip" href="/pubs/archive/41764.pdf">&nbsp;</a> The
            Intervalgram: An Audio Feature for Large-Scale Cover-Song Recognition
          </h2>
          <div>
            <strong>Abstract:</strong> We present a system for representing the musical content of
            short pieces of audio using a novel chroma-based representation known as the
            ‘intervalgram’, which is a summary of the local pattern of musical intervals in a
            segment of music. The intervalgram is based on a chroma representation derived from the
            temporal profile of the stabilized auditory image [10] and is made locally pitch
            invariant by means of a ‘soft’ pitch transposition to a local reference. Intervalgrams
            are generated for a piece of music using multiple overlapping windows. These sets of
            intervalgrams are used as the basis of a system for detection of identical melodic and
            harmonic progressions in a database of music. Using a dynamic-programming approach for
            comparisons between a reference and the song database, performance is evaluated on the
            ‘covers80’ dataset [4]. A first test of an intervalgram-based system on this dataset
            yields a precision at top-1 of 53.8%, with an ROC curve that shows very high precision
            up to moderate recall, suggesting that the intervalgram is adept at identifying the
            easier-to-match cover songs in the dataset with high robustness. The intervalgram is
            designed to support locality-sensitive hashing, such that an index lookup from each
            single intervalgram feature has a moderate probability of retrieving a match, with few
            false matches. With this indexing approach, a large reference database can be quickly
            pruned before more detailed matching, as in previous content-identification systems.
          </div>
        </div>
      </div>
    </div>
    <div id="maia-signature"></div>
    <div class="maia-footer" id="maia-footer">
      <div id="maia-footer-local">
        <div class="maia-aux">
          <ul class="expand no-marker" id="footer-local">
            <li>
              <a class="googleplus middle" href=
              "//plus.google.com/117790530324740296539/posts">Google Plus</a>
              <p>
                Thoughts from Google's academic community
              </p>
            </li>
            <li>
              <a class="twitter middle" href="//twitter.com/googleresearch">Twitter</a>
              <p>
                Research at Google announcements
              </p>
            </li>
            <li>
              <a class="blogger middle" href="//googleresearch.blogspot.com/">Research Blog</a>
              <p>
                The latest news from Research at Google
              </p>
            </li>
            <li>
              <a class="scholar middle" href="//scholar.google.com/">Google Scholar</a>
              <p>
                Search for scholarly literature
              </p>
            </li>
            <li>
              <a class="youtube middle" href=
              "//www.youtube.com/user/GoogleTechTalks/featured">YouTube Tech Talks</a>
              <p>
                Tech talks by leaders in the field
              </p>
            </li>
          </ul>
        </div>
      </div>
      <div id="maia-footer-global">
        <div class="maia-aux">
          <ul>
            <li>
              <a href="//www.google.com/">Google</a>
            </li>
            <li>
              <a href="//www.google.com/intl/en/about/">About Google</a>
            </li>
            <li>
              <a href="//www.google.com/intl/en/policies/privacy/">Privacy</a>
            </li>
            <li>
              <a href="//www.google.com/intl/en/policies/terms/">Terms</a>
            </li>
          </ul>
        </div>
      </div>
    </div>
    <script src="//www.google.com/jsapi">
    </script> 
    <script src="/js/research.view.js">
    </script> 
    <script src="//www.google.com/js/maia.js">
    </script>
  </body>
</html>